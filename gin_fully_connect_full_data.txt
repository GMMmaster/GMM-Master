{'batch_size': 256, 'epochs': 200, 'lr': 0.001, 'parent_path': '../data_for_GMM-Master/', 'loc_dim': 32, 'layer': 4, 'beam_size': 5, 'wd': 0.0, 'dev_id': 1, 'use_gcn': 1, 'atten_flag': 1, 'tf_ratio': 0.0}
Loading Dataset Done!!!
get graph extra data finished!
Loading model Done!!!
================Epoch: 1================
Iteration 1: train_loss 9.06014347076416
Iteration 2: train_loss 9.036151885986328
Iteration 3: train_loss 9.005023956298828
Iteration 4: train_loss 8.940738677978516
Iteration 5: train_loss 8.88743782043457
Iteration 6: train_loss 8.818866729736328
Iteration 7: train_loss 8.705476760864258
Iteration 8: train_loss 8.633914947509766
Iteration 9: train_loss 8.523157119750977
Iteration 10: train_loss 8.493980407714844
Iteration 11: train_loss 8.339919090270996
Iteration 12: train_loss 8.2681303024292
Iteration 13: train_loss 8.17213249206543
Iteration 14: train_loss 8.133655548095703
Iteration 15: train_loss 8.109532356262207
Iteration 16: train_loss 7.979407787322998
Iteration 17: train_loss 7.990540504455566
Iteration 18: train_loss 7.8664093017578125
Iteration 19: train_loss 7.861814498901367
Iteration 20: train_loss 7.7286505699157715
Iteration 21: train_loss 7.707449436187744
Iteration 22: train_loss 7.656335353851318
Iteration 23: train_loss 7.524503231048584
Iteration 24: train_loss 7.528163433074951
Iteration 25: train_loss 7.481720924377441
Iteration 26: train_loss 7.483405590057373
Iteration 27: train_loss 7.41512393951416
Iteration 28: train_loss 7.314835548400879
Iteration 29: train_loss 7.297988414764404
Iteration 30: train_loss 7.297506332397461
Iteration 31: train_loss 7.342702388763428
Iteration 32: train_loss 7.215504169464111
Iteration 33: train_loss 7.256336688995361
Iteration 34: train_loss 7.17711067199707
Iteration 35: train_loss 7.164851665496826
Iteration 36: train_loss 7.091731548309326
Iteration 37: train_loss 7.082712173461914
Iteration 38: train_loss 7.048323631286621
Iteration 39: train_loss 7.0119781494140625
Iteration 40: train_loss 6.930918216705322
Iteration 41: train_loss 6.9121270179748535
Iteration 42: train_loss 7.028238773345947
Iteration 43: train_loss 6.788373947143555
Iteration 44: train_loss 6.846102237701416
Iteration 45: train_loss 6.823971271514893
Iteration 46: train_loss 6.789505958557129
Iteration 47: train_loss 6.714135646820068
Iteration 48: train_loss 6.848058223724365
Iteration 49: train_loss 6.818229675292969
Iteration 50: train_loss 6.655194282531738
Iteration 51: train_loss 6.637363433837891
Iteration 52: train_loss 6.6418046951293945
Iteration 53: train_loss 6.484796047210693
Iteration 54: train_loss 6.524037837982178
Iteration 55: train_loss 6.4167561531066895
Iteration 56: train_loss 6.3690104484558105
Iteration 57: train_loss 6.492578983306885
Iteration 58: train_loss 6.50521183013916
Iteration 59: train_loss 6.461766719818115
Iteration 60: train_loss 6.411669731140137
Iteration 61: train_loss 6.531896591186523
Iteration 62: train_loss 6.479382038116455
Iteration 63: train_loss 6.367215633392334
Iteration 64: train_loss 6.315394401550293
Iteration 65: train_loss 6.292158126831055
Iteration 66: train_loss 6.172724723815918
Iteration 67: train_loss 6.161345481872559
Iteration 68: train_loss 6.154659748077393
Iteration 69: train_loss 6.193501949310303
Iteration 70: train_loss 6.1870880126953125
Iteration 71: train_loss 6.155951023101807
Iteration 72: train_loss 6.295112133026123
Iteration 73: train_loss 6.257073879241943
Iteration 74: train_loss 5.986467361450195
Iteration 75: train_loss 6.183435440063477
Iteration 76: train_loss 6.0807414054870605
Iteration 77: train_loss 5.985088348388672
Iteration 78: train_loss 6.056523323059082
Iteration 79: train_loss 6.062867164611816
Iteration 80: train_loss 5.936318874359131
Iteration 81: train_loss 5.994480133056641
Iteration 82: train_loss 5.9330620765686035
Iteration 83: train_loss 5.797982215881348
Iteration 84: train_loss 5.917750835418701
Iteration 85: train_loss 5.7473649978637695
Iteration 86: train_loss 5.899275302886963
Iteration 87: train_loss 5.912957191467285
Iteration 88: train_loss 5.9193501472473145
Iteration 89: train_loss 5.900248050689697
Iteration 90: train_loss 5.785595893859863
Iteration 91: train_loss 5.820246696472168
Iteration 92: train_loss 5.760940074920654
Iteration 93: train_loss 5.682761192321777
Iteration 94: train_loss 5.703169345855713
Iteration 95: train_loss 5.722712516784668
Iteration 96: train_loss 5.731344699859619
Iteration 97: train_loss 5.720061302185059
Iteration 98: train_loss 5.741317272186279
Iteration 99: train_loss 5.750786781311035
Iteration 100: train_loss 5.579301834106445
Iteration 101: train_loss 5.641747951507568
Iteration 102: train_loss 5.547722339630127
Iteration 103: train_loss 5.629980564117432
Iteration 104: train_loss 5.6922736167907715
Iteration 105: train_loss 5.572380542755127
Iteration 106: train_loss 5.558400630950928
Iteration 107: train_loss 5.5597243309021
Iteration 108: train_loss 5.522371768951416
Iteration 109: train_loss 5.46985387802124
Iteration 110: train_loss 5.514034748077393
Iteration 111: train_loss 5.585490703582764
Iteration 112: train_loss 5.427671432495117
Iteration 113: train_loss 5.5311055183410645
Iteration 114: train_loss 5.4886274337768555
Iteration 115: train_loss 5.480484485626221
Iteration 116: train_loss 5.3955159187316895
Iteration 117: train_loss 5.431096076965332
Iteration 118: train_loss 5.388460636138916
Iteration 119: train_loss 5.491058349609375
Iteration 120: train_loss 5.211033344268799
Iteration 121: train_loss 5.277127742767334
Iteration 122: train_loss 5.4641804695129395
Iteration 123: train_loss 5.324001789093018
Iteration 124: train_loss 5.347541332244873
Iteration 125: train_loss 5.304654598236084
Iteration 126: train_loss 5.354564666748047
Iteration 127: train_loss 5.276004314422607
Iteration 128: train_loss 5.293612003326416
Iteration 129: train_loss 5.354921817779541
Iteration 130: train_loss 5.258667469024658
Iteration 131: train_loss 5.322369575500488
Iteration 132: train_loss 5.208903789520264
Iteration 133: train_loss 5.159768104553223
Iteration 134: train_loss 5.162287712097168
Iteration 135: train_loss 5.332869529724121
Iteration 136: train_loss 5.290225505828857
Iteration 137: train_loss 5.093385696411133
Iteration 138: train_loss 5.116913318634033
Iteration 139: train_loss 5.041414260864258
Iteration 140: train_loss 5.1526689529418945
Iteration 141: train_loss 5.131602764129639
Iteration 142: train_loss 5.194728374481201
Iteration 143: train_loss 5.025455951690674
Iteration 144: train_loss 5.1369147300720215
Iteration 145: train_loss 5.051340579986572
Iteration 146: train_loss 5.115110397338867
Iteration 147: train_loss 5.117038249969482
Iteration 148: train_loss 5.040756702423096
Iteration 149: train_loss 5.083354473114014
Iteration 150: train_loss 5.034601211547852
Iteration 151: train_loss 4.911447048187256
Iteration 152: train_loss 5.08985710144043
Iteration 153: train_loss 4.898561954498291
Iteration 154: train_loss 4.941341400146484
Iteration 155: train_loss 4.899366855621338
Iteration 156: train_loss 5.065749168395996
Iteration 157: train_loss 4.949878215789795
Iteration 158: train_loss 4.899447917938232
Iteration 159: train_loss 4.908699989318848
Iteration 160: train_loss 4.846312999725342
Iteration 161: train_loss 4.984523296356201
Iteration 162: train_loss 4.9809250831604
Iteration 163: train_loss 5.023159980773926
Iteration 164: train_loss 4.924239635467529
Iteration 165: train_loss 4.812003135681152
Iteration 166: train_loss 4.8128862380981445
Iteration 167: train_loss 4.769917011260986
Iteration 168: train_loss 4.969532012939453
Iteration 169: train_loss 4.865785121917725
Iteration 170: train_loss 4.8938822746276855
Iteration 171: train_loss 4.882891654968262
Iteration 172: train_loss 4.807952880859375
Iteration 173: train_loss 4.835733890533447
Iteration 174: train_loss 4.83627462387085
Iteration 175: train_loss 4.931880474090576
Iteration 176: train_loss 4.710778713226318
Iteration 177: train_loss 4.728415012359619
Epoch 1: train_avg_loss 6.135685519310041 eval_avg_acc: 0.09941189274626912 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:47:48] [32mIntermediate result: 0.09941189274626912  (Index 0)[0m
================Epoch: 2================
Iteration 1: train_loss 4.826475143432617
Iteration 2: train_loss 4.827854633331299
Iteration 3: train_loss 4.9554338455200195
Iteration 4: train_loss 4.68454647064209
Iteration 5: train_loss 4.639694690704346
Iteration 6: train_loss 4.70308780670166
Iteration 7: train_loss 4.747342586517334
Iteration 8: train_loss 4.720874309539795
Iteration 9: train_loss 4.698478698730469
Iteration 10: train_loss 4.527382850646973
Iteration 11: train_loss 4.728939056396484
Iteration 12: train_loss 4.671012878417969
Iteration 13: train_loss 4.676219463348389
Iteration 14: train_loss 4.598711013793945
Iteration 15: train_loss 4.661710739135742
Iteration 16: train_loss 4.560257911682129
Iteration 17: train_loss 4.632650375366211
Iteration 18: train_loss 4.541067600250244
Iteration 19: train_loss 4.758727073669434
Iteration 20: train_loss 4.5112810134887695
Iteration 21: train_loss 4.549699306488037
Iteration 22: train_loss 4.6611409187316895
Iteration 23: train_loss 4.525246620178223
Iteration 24: train_loss 4.600203037261963
Iteration 25: train_loss 4.7617597579956055
Iteration 26: train_loss 4.588531494140625
Iteration 27: train_loss 4.4241414070129395
Iteration 28: train_loss 4.642064571380615
Iteration 29: train_loss 4.464991569519043
Iteration 30: train_loss 4.514033317565918
Iteration 31: train_loss 4.451903343200684
Iteration 32: train_loss 4.588470935821533
Iteration 33: train_loss 4.466487407684326
Iteration 34: train_loss 4.628446102142334
Iteration 35: train_loss 4.51938533782959
Iteration 36: train_loss 4.512810230255127
Iteration 37: train_loss 4.65919828414917
Iteration 38: train_loss 4.47791051864624
Iteration 39: train_loss 4.402027130126953
Iteration 40: train_loss 4.514283657073975
Iteration 41: train_loss 4.5404791831970215
Iteration 42: train_loss 4.630404472351074
Iteration 43: train_loss 4.481629848480225
Iteration 44: train_loss 4.525675296783447
Iteration 45: train_loss 4.501270294189453
Iteration 46: train_loss 4.348259925842285
Iteration 47: train_loss 4.354669094085693
Iteration 48: train_loss 4.47544002532959
Iteration 49: train_loss 4.373044490814209
Iteration 50: train_loss 4.413208961486816
Iteration 51: train_loss 4.473572254180908
Iteration 52: train_loss 4.429510116577148
Iteration 53: train_loss 4.256521224975586
Iteration 54: train_loss 4.464644908905029
Iteration 55: train_loss 4.43441104888916
Iteration 56: train_loss 4.3096842765808105
Iteration 57: train_loss 4.386689186096191
Iteration 58: train_loss 4.359786510467529
Iteration 59: train_loss 4.329409599304199
Iteration 60: train_loss 4.354082107543945
Iteration 61: train_loss 4.290086269378662
Iteration 62: train_loss 4.362325668334961
Iteration 63: train_loss 4.397404670715332
Iteration 64: train_loss 4.498179912567139
Iteration 65: train_loss 4.328042030334473
Iteration 66: train_loss 4.228365898132324
Iteration 67: train_loss 4.2648725509643555
Iteration 68: train_loss 4.349788665771484
Iteration 69: train_loss 4.34239387512207
Iteration 70: train_loss 4.313597202301025
Iteration 71: train_loss 4.41412878036499
Iteration 72: train_loss 4.259450435638428
Iteration 73: train_loss 4.366583347320557
Iteration 74: train_loss 4.15057897567749
Iteration 75: train_loss 4.209808349609375
Iteration 76: train_loss 4.38955020904541
Iteration 77: train_loss 4.225404262542725
Iteration 78: train_loss 4.275918960571289
Iteration 79: train_loss 4.374992847442627
Iteration 80: train_loss 4.154911994934082
Iteration 81: train_loss 4.114627361297607
Iteration 82: train_loss 4.258887767791748
Iteration 83: train_loss 4.284339427947998
Iteration 84: train_loss 4.353009223937988
Iteration 85: train_loss 4.442397594451904
Iteration 86: train_loss 4.109043598175049
Iteration 87: train_loss 4.201385021209717
Iteration 88: train_loss 4.239742279052734
Iteration 89: train_loss 4.125229358673096
Iteration 90: train_loss 4.119652271270752
Iteration 91: train_loss 4.281891345977783
Iteration 92: train_loss 4.222850799560547
Iteration 93: train_loss 4.156118869781494
Iteration 94: train_loss 4.195067405700684
Iteration 95: train_loss 4.233590126037598
Iteration 96: train_loss 4.2655792236328125
Iteration 97: train_loss 4.06284236907959
Iteration 98: train_loss 4.162961959838867
Iteration 99: train_loss 4.0597453117370605
Iteration 100: train_loss 4.248722553253174
Iteration 101: train_loss 4.1840009689331055
Iteration 102: train_loss 4.086907386779785
Iteration 103: train_loss 4.189846515655518
Iteration 104: train_loss 4.123266696929932
Iteration 105: train_loss 4.1575798988342285
Iteration 106: train_loss 4.14432430267334
Iteration 107: train_loss 4.112708568572998
Iteration 108: train_loss 4.15340518951416
Iteration 109: train_loss 4.06596565246582
Iteration 110: train_loss 3.981811285018921
Iteration 111: train_loss 3.987489700317383
Iteration 112: train_loss 4.033597946166992
Iteration 113: train_loss 4.112683296203613
Iteration 114: train_loss 4.184587001800537
Iteration 115: train_loss 4.210129261016846
Iteration 116: train_loss 4.012229919433594
Iteration 117: train_loss 4.0018391609191895
Iteration 118: train_loss 4.057959079742432
Iteration 119: train_loss 3.9328901767730713
Iteration 120: train_loss 4.117830276489258
Iteration 121: train_loss 4.059637546539307
Iteration 122: train_loss 4.0229315757751465
Iteration 123: train_loss 4.033252239227295
Iteration 124: train_loss 4.080260276794434
Iteration 125: train_loss 4.0500407218933105
Iteration 126: train_loss 3.9916698932647705
Iteration 127: train_loss 4.050294399261475
Iteration 128: train_loss 4.04740047454834
Iteration 129: train_loss 4.000020503997803
Iteration 130: train_loss 4.000301361083984
Iteration 131: train_loss 4.042138576507568
Iteration 132: train_loss 4.090808391571045
Iteration 133: train_loss 4.04168176651001
Iteration 134: train_loss 3.980499744415283
Iteration 135: train_loss 4.050771713256836
Iteration 136: train_loss 4.251978397369385
Iteration 137: train_loss 4.104726314544678
Iteration 138: train_loss 4.035595417022705
Iteration 139: train_loss 4.073278427124023
Iteration 140: train_loss 4.001766204833984
Iteration 141: train_loss 3.927246570587158
Iteration 142: train_loss 4.129147529602051
Iteration 143: train_loss 3.9916505813598633
Iteration 144: train_loss 3.899897575378418
Iteration 145: train_loss 3.883091926574707
Iteration 146: train_loss 4.101006031036377
Iteration 147: train_loss 4.0454511642456055
Iteration 148: train_loss 4.119891166687012
Iteration 149: train_loss 4.041274070739746
Iteration 150: train_loss 3.9247913360595703
Iteration 151: train_loss 3.9937474727630615
Iteration 152: train_loss 4.002646446228027
Iteration 153: train_loss 3.951533079147339
Iteration 154: train_loss 3.932468891143799
Iteration 155: train_loss 3.963325023651123
Iteration 156: train_loss 3.9150099754333496
Iteration 157: train_loss 3.954714298248291
Iteration 158: train_loss 3.820650100708008
Iteration 159: train_loss 3.9560210704803467
Iteration 160: train_loss 3.939025402069092
Iteration 161: train_loss 3.9288089275360107
Iteration 162: train_loss 3.8822505474090576
Iteration 163: train_loss 3.9566190242767334
Iteration 164: train_loss 3.9466307163238525
Iteration 165: train_loss 4.084064483642578
Iteration 166: train_loss 3.780381202697754
Iteration 167: train_loss 3.853559732437134
Iteration 168: train_loss 3.9223880767822266
Iteration 169: train_loss 3.845109701156616
Iteration 170: train_loss 3.9142062664031982
Iteration 171: train_loss 3.8189797401428223
Iteration 172: train_loss 3.9250640869140625
Iteration 173: train_loss 3.8995912075042725
Iteration 174: train_loss 3.906207799911499
Iteration 175: train_loss 3.8691985607147217
Iteration 176: train_loss 3.935088872909546
Iteration 177: train_loss 3.6911604404449463
Epoch 2: train_avg_loss 4.248095762931694 eval_avg_acc: 0.1578756479473718 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:48:29] [32mIntermediate result: 0.1578756479473718  (Index 1)[0m
================Epoch: 3================
Iteration 1: train_loss 3.672887086868286
Iteration 2: train_loss 3.814208984375
Iteration 3: train_loss 3.7956976890563965
Iteration 4: train_loss 3.8791720867156982
Iteration 5: train_loss 3.8598647117614746
Iteration 6: train_loss 3.71596360206604
Iteration 7: train_loss 3.7401885986328125
Iteration 8: train_loss 3.7710654735565186
Iteration 9: train_loss 3.702552318572998
Iteration 10: train_loss 3.666550874710083
Iteration 11: train_loss 3.8653132915496826
Iteration 12: train_loss 3.779935121536255
Iteration 13: train_loss 3.7170045375823975
Iteration 14: train_loss 3.714456558227539
Iteration 15: train_loss 3.9175732135772705
Iteration 16: train_loss 3.8348405361175537
Iteration 17: train_loss 3.7739202976226807
Iteration 18: train_loss 3.8039796352386475
Iteration 19: train_loss 3.911262273788452
Iteration 20: train_loss 3.8113160133361816
Iteration 21: train_loss 3.7861499786376953
Iteration 22: train_loss 3.6948602199554443
Iteration 23: train_loss 3.8058741092681885
Iteration 24: train_loss 3.896658182144165
Iteration 25: train_loss 3.762389898300171
Iteration 26: train_loss 3.741417646408081
Iteration 27: train_loss 3.7611491680145264
Iteration 28: train_loss 3.755056381225586
Iteration 29: train_loss 3.673546552658081
Iteration 30: train_loss 3.8571555614471436
Iteration 31: train_loss 3.743852138519287
Iteration 32: train_loss 3.9441051483154297
Iteration 33: train_loss 3.6710879802703857
Iteration 34: train_loss 3.72287654876709
Iteration 35: train_loss 3.7650985717773438
Iteration 36: train_loss 3.778474807739258
Iteration 37: train_loss 3.718843698501587
Iteration 38: train_loss 3.6336851119995117
Iteration 39: train_loss 3.818690776824951
Iteration 40: train_loss 3.7586982250213623
Iteration 41: train_loss 3.6458184719085693
Iteration 42: train_loss 3.6263883113861084
Iteration 43: train_loss 3.655642032623291
Iteration 44: train_loss 3.7845847606658936
Iteration 45: train_loss 3.6398563385009766
Iteration 46: train_loss 3.6929311752319336
Iteration 47: train_loss 3.794846296310425
Iteration 48: train_loss 3.8079562187194824
Iteration 49: train_loss 3.7105648517608643
Iteration 50: train_loss 3.7399916648864746
Iteration 51: train_loss 3.6720023155212402
Iteration 52: train_loss 3.645369291305542
Iteration 53: train_loss 3.618232011795044
Iteration 54: train_loss 3.651721239089966
Iteration 55: train_loss 3.73899245262146
Iteration 56: train_loss 3.5997366905212402
Iteration 57: train_loss 3.5129592418670654
Iteration 58: train_loss 3.668313980102539
Iteration 59: train_loss 3.6419034004211426
Iteration 60: train_loss 3.663316249847412
Iteration 61: train_loss 3.6074881553649902
Iteration 62: train_loss 3.6560254096984863
Iteration 63: train_loss 3.7029528617858887
Iteration 64: train_loss 3.6553430557250977
Iteration 65: train_loss 3.557734727859497
Iteration 66: train_loss 3.665323257446289
Iteration 67: train_loss 3.6170876026153564
Iteration 68: train_loss 3.640946626663208
Iteration 69: train_loss 3.570284366607666
Iteration 70: train_loss 3.5789902210235596
Iteration 71: train_loss 3.7025907039642334
Iteration 72: train_loss 3.796501636505127
Iteration 73: train_loss 3.629918098449707
Iteration 74: train_loss 3.702162027359009
Iteration 75: train_loss 3.745173215866089
Iteration 76: train_loss 3.753774881362915
Iteration 77: train_loss 3.546480894088745
Iteration 78: train_loss 3.7467434406280518
Iteration 79: train_loss 3.6229546070098877
Iteration 80: train_loss 3.6250662803649902
Iteration 81: train_loss 3.6097748279571533
Iteration 82: train_loss 3.612118721008301
Iteration 83: train_loss 3.7516324520111084
Iteration 84: train_loss 3.7614903450012207
Iteration 85: train_loss 3.6042118072509766
Iteration 86: train_loss 3.694295883178711
Iteration 87: train_loss 3.6641342639923096
Iteration 88: train_loss 3.478991746902466
Iteration 89: train_loss 3.5031845569610596
Iteration 90: train_loss 3.562638759613037
Iteration 91: train_loss 3.489858388900757
Iteration 92: train_loss 3.63559889793396
Iteration 93: train_loss 3.641132354736328
Iteration 94: train_loss 3.648949384689331
Iteration 95: train_loss 3.6419999599456787
Iteration 96: train_loss 3.5715317726135254
Iteration 97: train_loss 3.5757522583007812
Iteration 98: train_loss 3.536287307739258
Iteration 99: train_loss 3.639587879180908
Iteration 100: train_loss 3.6805224418640137
Iteration 101: train_loss 3.587883234024048
Iteration 102: train_loss 3.4791243076324463
Iteration 103: train_loss 3.5256869792938232
Iteration 104: train_loss 3.619649887084961
Iteration 105: train_loss 3.553222179412842
Iteration 106: train_loss 3.596513271331787
Iteration 107: train_loss 3.5398664474487305
Iteration 108: train_loss 3.4970028400421143
Iteration 109: train_loss 3.483718156814575
Iteration 110: train_loss 3.483975648880005
Iteration 111: train_loss 3.5781140327453613
Iteration 112: train_loss 3.442720413208008
Iteration 113: train_loss 3.5200483798980713
Iteration 114: train_loss 3.756882667541504
Iteration 115: train_loss 3.5116117000579834
Iteration 116: train_loss 3.5731921195983887
Iteration 117: train_loss 3.4861037731170654
Iteration 118: train_loss 3.5069806575775146
Iteration 119: train_loss 3.512117385864258
Iteration 120: train_loss 3.5010673999786377
Iteration 121: train_loss 3.5686278343200684
Iteration 122: train_loss 3.6686525344848633
Iteration 123: train_loss 3.514914035797119
Iteration 124: train_loss 3.5397236347198486
Iteration 125: train_loss 3.4437263011932373
Iteration 126: train_loss 3.613102436065674
Iteration 127: train_loss 3.5235626697540283
Iteration 128: train_loss 3.3841569423675537
Iteration 129: train_loss 3.4896957874298096
Iteration 130: train_loss 3.3826804161071777
Iteration 131: train_loss 3.4393558502197266
Iteration 132: train_loss 3.6117022037506104
Iteration 133: train_loss 3.494065523147583
Iteration 134: train_loss 3.549353837966919
Iteration 135: train_loss 3.4244303703308105
Iteration 136: train_loss 3.624859571456909
Iteration 137: train_loss 3.5054173469543457
Iteration 138: train_loss 3.5191006660461426
Iteration 139: train_loss 3.501642942428589
Iteration 140: train_loss 3.4810941219329834
Iteration 141: train_loss 3.5313851833343506
Iteration 142: train_loss 3.436828374862671
Iteration 143: train_loss 3.547496795654297
Iteration 144: train_loss 3.4545023441314697
Iteration 145: train_loss 3.542051315307617
Iteration 146: train_loss 3.3642256259918213
Iteration 147: train_loss 3.5245983600616455
Iteration 148: train_loss 3.5861968994140625
Iteration 149: train_loss 3.468899965286255
Iteration 150: train_loss 3.6165573596954346
Iteration 151: train_loss 3.4764404296875
Iteration 152: train_loss 3.491018295288086
Iteration 153: train_loss 3.4298417568206787
Iteration 154: train_loss 3.504760503768921
Iteration 155: train_loss 3.40179705619812
Iteration 156: train_loss 3.326653003692627
Iteration 157: train_loss 3.521498918533325
Iteration 158: train_loss 3.416930913925171
Iteration 159: train_loss 3.3821022510528564
Iteration 160: train_loss 3.3852152824401855
Iteration 161: train_loss 3.500068187713623
Iteration 162: train_loss 3.5437116622924805
Iteration 163: train_loss 3.5849721431732178
Iteration 164: train_loss 3.421969413757324
Iteration 165: train_loss 3.4554245471954346
Iteration 166: train_loss 3.4906158447265625
Iteration 167: train_loss 3.5201244354248047
Iteration 168: train_loss 3.4809651374816895
Iteration 169: train_loss 3.367608070373535
Iteration 170: train_loss 3.412029266357422
Iteration 171: train_loss 3.4957940578460693
Iteration 172: train_loss 3.3726320266723633
Iteration 173: train_loss 3.5460920333862305
Iteration 174: train_loss 3.4032247066497803
Iteration 175: train_loss 3.533820152282715
Iteration 176: train_loss 3.4607350826263428
Iteration 177: train_loss 3.4249863624572754
Epoch 3: train_avg_loss 3.612626592991716 eval_avg_acc: 0.19611353984958463 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:49:11] [32mIntermediate result: 0.19611353984958463  (Index 2)[0m
================Epoch: 4================
Iteration 1: train_loss 3.2892746925354004
Iteration 2: train_loss 3.4724154472351074
Iteration 3: train_loss 3.330716133117676
Iteration 4: train_loss 3.3457725048065186
Iteration 5: train_loss 3.394061326980591
Iteration 6: train_loss 3.4416720867156982
Iteration 7: train_loss 3.3924190998077393
Iteration 8: train_loss 3.373505115509033
Iteration 9: train_loss 3.3826069831848145
Iteration 10: train_loss 3.2708168029785156
Iteration 11: train_loss 3.2976455688476562
Iteration 12: train_loss 3.28560733795166
Iteration 13: train_loss 3.326829195022583
Iteration 14: train_loss 3.380314588546753
Iteration 15: train_loss 3.3592042922973633
Iteration 16: train_loss 3.351134777069092
Iteration 17: train_loss 3.2944176197052
Iteration 18: train_loss 3.481442928314209
Iteration 19: train_loss 3.315401554107666
Iteration 20: train_loss 3.251640558242798
Iteration 21: train_loss 3.2961981296539307
Iteration 22: train_loss 3.320566177368164
Iteration 23: train_loss 3.3715879917144775
Iteration 24: train_loss 3.35781192779541
Iteration 25: train_loss 3.274998426437378
Iteration 26: train_loss 3.325993537902832
Iteration 27: train_loss 3.307368516921997
Iteration 28: train_loss 3.378607988357544
Iteration 29: train_loss 3.46593976020813
Iteration 30: train_loss 3.292151927947998
Iteration 31: train_loss 3.337484359741211
Iteration 32: train_loss 3.2434327602386475
Iteration 33: train_loss 3.353832721710205
Iteration 34: train_loss 3.263838768005371
Iteration 35: train_loss 3.407876491546631
Iteration 36: train_loss 3.367016077041626
Iteration 37: train_loss 3.240830898284912
Iteration 38: train_loss 3.337306499481201
Iteration 39: train_loss 3.2775700092315674
Iteration 40: train_loss 3.358053684234619
Iteration 41: train_loss 3.250037431716919
Iteration 42: train_loss 3.2956748008728027
Iteration 43: train_loss 3.263712167739868
Iteration 44: train_loss 3.3157496452331543
Iteration 45: train_loss 3.252720355987549
Iteration 46: train_loss 3.206118106842041
Iteration 47: train_loss 3.374386787414551
Iteration 48: train_loss 3.22769832611084
Iteration 49: train_loss 3.189141035079956
Iteration 50: train_loss 3.269033908843994
Iteration 51: train_loss 3.4116320610046387
Iteration 52: train_loss 3.2634079456329346
Iteration 53: train_loss 3.299349784851074
Iteration 54: train_loss 3.26794171333313
Iteration 55: train_loss 3.2128162384033203
Iteration 56: train_loss 3.2423503398895264
Iteration 57: train_loss 3.3434698581695557
Iteration 58: train_loss 3.414083242416382
Iteration 59: train_loss 3.3434417247772217
Iteration 60: train_loss 3.1917266845703125
Iteration 61: train_loss 3.2621982097625732
Iteration 62: train_loss 3.3323957920074463
Iteration 63: train_loss 3.2922136783599854
Iteration 64: train_loss 3.3672704696655273
Iteration 65: train_loss 3.3317530155181885
Iteration 66: train_loss 3.2123732566833496
Iteration 67: train_loss 3.1419754028320312
Iteration 68: train_loss 3.2943549156188965
Iteration 69: train_loss 3.283879518508911
Iteration 70: train_loss 3.2285728454589844
Iteration 71: train_loss 3.335447072982788
Iteration 72: train_loss 3.26461124420166
Iteration 73: train_loss 3.3989551067352295
Iteration 74: train_loss 3.2747957706451416
Iteration 75: train_loss 3.19081711769104
Iteration 76: train_loss 3.2710282802581787
Iteration 77: train_loss 3.2692697048187256
Iteration 78: train_loss 3.4515697956085205
Iteration 79: train_loss 3.3159403800964355
Iteration 80: train_loss 3.213021993637085
Iteration 81: train_loss 3.2250025272369385
Iteration 82: train_loss 3.271899461746216
Iteration 83: train_loss 3.1967661380767822
Iteration 84: train_loss 3.268695831298828
Iteration 85: train_loss 3.1726341247558594
Iteration 86: train_loss 3.2686257362365723
Iteration 87: train_loss 3.266709804534912
Iteration 88: train_loss 3.1982614994049072
Iteration 89: train_loss 3.293975353240967
Iteration 90: train_loss 3.292900800704956
Iteration 91: train_loss 3.2921085357666016
Iteration 92: train_loss 3.263651132583618
Iteration 93: train_loss 3.352809429168701
Iteration 94: train_loss 3.2268407344818115
Iteration 95: train_loss 3.2078895568847656
Iteration 96: train_loss 3.3314387798309326
Iteration 97: train_loss 3.289654493331909
Iteration 98: train_loss 3.2925784587860107
Iteration 99: train_loss 3.2000010013580322
Iteration 100: train_loss 3.304805278778076
Iteration 101: train_loss 3.1845147609710693
Iteration 102: train_loss 3.222560167312622
Iteration 103: train_loss 3.189535140991211
Iteration 104: train_loss 3.3492610454559326
Iteration 105: train_loss 3.3860936164855957
Iteration 106: train_loss 3.280799627304077
Iteration 107: train_loss 3.218604326248169
Iteration 108: train_loss 3.2460834980010986
Iteration 109: train_loss 3.262641668319702
Iteration 110: train_loss 3.303189992904663
Iteration 111: train_loss 3.406797170639038
Iteration 112: train_loss 3.256196975708008
Iteration 113: train_loss 3.2014758586883545
Iteration 114: train_loss 3.2879891395568848
Iteration 115: train_loss 3.282057762145996
Iteration 116: train_loss 3.1752092838287354
Iteration 117: train_loss 3.23292875289917
Iteration 118: train_loss 3.266101837158203
Iteration 119: train_loss 3.4448347091674805
Iteration 120: train_loss 3.274007797241211
Iteration 121: train_loss 3.264819622039795
Iteration 122: train_loss 3.274437189102173
Iteration 123: train_loss 3.3817734718322754
Iteration 124: train_loss 3.1618094444274902
Iteration 125: train_loss 3.2692062854766846
Iteration 126: train_loss 3.2993216514587402
Iteration 127: train_loss 3.108213186264038
Iteration 128: train_loss 3.2822139263153076
Iteration 129: train_loss 3.274751901626587
Iteration 130: train_loss 3.3088223934173584
Iteration 131: train_loss 3.3555610179901123
Iteration 132: train_loss 3.297973871231079
Iteration 133: train_loss 3.1525769233703613
Iteration 134: train_loss 3.098215341567993
Iteration 135: train_loss 3.2402873039245605
Iteration 136: train_loss 3.099061965942383
Iteration 137: train_loss 3.305779218673706
Iteration 138: train_loss 3.255715847015381
Iteration 139: train_loss 3.1488349437713623
Iteration 140: train_loss 3.356170654296875
Iteration 141: train_loss 3.23586106300354
Iteration 142: train_loss 3.169525384902954
Iteration 143: train_loss 3.2140331268310547
Iteration 144: train_loss 3.17842173576355
Iteration 145: train_loss 3.2124381065368652
Iteration 146: train_loss 3.3103837966918945
Iteration 147: train_loss 3.2627792358398438
Iteration 148: train_loss 3.2110466957092285
Iteration 149: train_loss 3.334775447845459
Iteration 150: train_loss 3.2385964393615723
Iteration 151: train_loss 3.1627798080444336
Iteration 152: train_loss 3.276393175125122
Iteration 153: train_loss 3.10776686668396
Iteration 154: train_loss 3.283905029296875
Iteration 155: train_loss 3.1023309230804443
Iteration 156: train_loss 3.2356722354888916
Iteration 157: train_loss 3.1788084506988525
Iteration 158: train_loss 3.2435550689697266
Iteration 159: train_loss 3.20560359954834
Iteration 160: train_loss 3.168637752532959
Iteration 161: train_loss 3.3029985427856445
Iteration 162: train_loss 3.1951231956481934
Iteration 163: train_loss 3.3578312397003174
Iteration 164: train_loss 3.23569393157959
Iteration 165: train_loss 3.256542682647705
Iteration 166: train_loss 3.3698110580444336
Iteration 167: train_loss 3.1617777347564697
Iteration 168: train_loss 3.2012505531311035
Iteration 169: train_loss 3.1635539531707764
Iteration 170: train_loss 3.098997116088867
Iteration 171: train_loss 3.259143590927124
Iteration 172: train_loss 3.2222323417663574
Iteration 173: train_loss 3.1231162548065186
Iteration 174: train_loss 3.212169885635376
Iteration 175: train_loss 3.1945407390594482
Iteration 176: train_loss 3.1021904945373535
Iteration 177: train_loss 3.2892513275146484
Epoch 4: train_avg_loss 3.275059421183699 eval_avg_acc: 0.1850234744605456 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:49:53] [32mIntermediate result: 0.1850234744605456  (Index 3)[0m
================Epoch: 5================
Iteration 1: train_loss 3.115466833114624
Iteration 2: train_loss 3.019970417022705
Iteration 3: train_loss 3.012359619140625
Iteration 4: train_loss 3.100625991821289
Iteration 5: train_loss 3.1483187675476074
Iteration 6: train_loss 3.0990209579467773
Iteration 7: train_loss 3.1577796936035156
Iteration 8: train_loss 3.1277008056640625
Iteration 9: train_loss 3.015453577041626
Iteration 10: train_loss 3.068037748336792
Iteration 11: train_loss 3.0378684997558594
Iteration 12: train_loss 3.032747507095337
Iteration 13: train_loss 3.005990982055664
Iteration 14: train_loss 3.081536054611206
Iteration 15: train_loss 3.253995418548584
Iteration 16: train_loss 3.108717679977417
Iteration 17: train_loss 2.9918127059936523
Iteration 18: train_loss 3.1127054691314697
Iteration 19: train_loss 3.1484901905059814
Iteration 20: train_loss 3.0457077026367188
Iteration 21: train_loss 3.0777032375335693
Iteration 22: train_loss 3.0247037410736084
Iteration 23: train_loss 3.1059372425079346
Iteration 24: train_loss 3.164893388748169
Iteration 25: train_loss 2.9899487495422363
Iteration 26: train_loss 3.1438403129577637
Iteration 27: train_loss 3.1064069271087646
Iteration 28: train_loss 3.0470383167266846
Iteration 29: train_loss 3.0298588275909424
Iteration 30: train_loss 3.1315596103668213
Iteration 31: train_loss 3.150491237640381
Iteration 32: train_loss 3.0921435356140137
Iteration 33: train_loss 3.2234113216400146
Iteration 34: train_loss 2.9978280067443848
Iteration 35: train_loss 3.0907533168792725
Iteration 36: train_loss 3.1213650703430176
Iteration 37: train_loss 3.2481420040130615
Iteration 38: train_loss 3.109673500061035
Iteration 39: train_loss 2.9826321601867676
Iteration 40: train_loss 3.1407740116119385
Iteration 41: train_loss 2.9924094676971436
Iteration 42: train_loss 2.959559202194214
Iteration 43: train_loss 3.0780649185180664
Iteration 44: train_loss 3.128962755203247
Iteration 45: train_loss 3.1600911617279053
Iteration 46: train_loss 3.0838000774383545
Iteration 47: train_loss 3.1858346462249756
Iteration 48: train_loss 3.112751007080078
Iteration 49: train_loss 3.115588426589966
Iteration 50: train_loss 3.129969596862793
Iteration 51: train_loss 3.0903897285461426
Iteration 52: train_loss 3.125103712081909
Iteration 53: train_loss 3.0292856693267822
Iteration 54: train_loss 3.1219170093536377
Iteration 55: train_loss 3.1074328422546387
Iteration 56: train_loss 3.1648292541503906
Iteration 57: train_loss 3.110093593597412
Iteration 58: train_loss 2.972914218902588
Iteration 59: train_loss 3.062528371810913
Iteration 60: train_loss 3.142874240875244
Iteration 61: train_loss 3.1112003326416016
Iteration 62: train_loss 3.0045976638793945
Iteration 63: train_loss 3.0675292015075684
Iteration 64: train_loss 3.1459546089172363
Iteration 65: train_loss 3.093348979949951
Iteration 66: train_loss 3.1042449474334717
Iteration 67: train_loss 3.110494375228882
Iteration 68: train_loss 3.057725667953491
Iteration 69: train_loss 3.048161268234253
Iteration 70: train_loss 3.0330381393432617
Iteration 71: train_loss 3.0798592567443848
Iteration 72: train_loss 2.996879816055298
Iteration 73: train_loss 3.150054931640625
Iteration 74: train_loss 3.0409536361694336
Iteration 75: train_loss 2.9674887657165527
Iteration 76: train_loss 3.1178317070007324
Iteration 77: train_loss 3.1430137157440186
Iteration 78: train_loss 3.002223491668701
Iteration 79: train_loss 3.0650832653045654
Iteration 80: train_loss 3.0416219234466553
Iteration 81: train_loss 3.121013641357422
Iteration 82: train_loss 3.1185591220855713
Iteration 83: train_loss 3.061166524887085
Iteration 84: train_loss 2.9497575759887695
Iteration 85: train_loss 3.073942184448242
Iteration 86: train_loss 3.0950071811676025
Iteration 87: train_loss 3.0334370136260986
Iteration 88: train_loss 3.0834357738494873
Iteration 89: train_loss 3.012321949005127
Iteration 90: train_loss 2.9855470657348633
Iteration 91: train_loss 3.1556179523468018
Iteration 92: train_loss 3.0745763778686523
Iteration 93: train_loss 3.088371515274048
Iteration 94: train_loss 3.0569779872894287
Iteration 95: train_loss 3.1082799434661865
Iteration 96: train_loss 3.098681688308716
Iteration 97: train_loss 2.9338736534118652
Iteration 98: train_loss 3.0971717834472656
Iteration 99: train_loss 3.0748283863067627
Iteration 100: train_loss 3.116419553756714
Iteration 101: train_loss 3.060807228088379
Iteration 102: train_loss 3.117949962615967
Iteration 103: train_loss 2.9625391960144043
Iteration 104: train_loss 3.066944122314453
Iteration 105: train_loss 2.8544387817382812
Iteration 106: train_loss 3.0536139011383057
Iteration 107: train_loss 3.022848606109619
Iteration 108: train_loss 3.079023838043213
Iteration 109: train_loss 2.9787650108337402
Iteration 110: train_loss 3.045738458633423
Iteration 111: train_loss 2.9722063541412354
Iteration 112: train_loss 3.0908355712890625
Iteration 113: train_loss 3.082303524017334
Iteration 114: train_loss 3.037801504135132
Iteration 115: train_loss 3.1252965927124023
Iteration 116: train_loss 2.95605206489563
Iteration 117: train_loss 2.9895997047424316
Iteration 118: train_loss 2.9684388637542725
Iteration 119: train_loss 3.045401096343994
Iteration 120: train_loss 3.011868953704834
Iteration 121: train_loss 3.119520425796509
Iteration 122: train_loss 2.98980712890625
Iteration 123: train_loss 2.977416753768921
Iteration 124: train_loss 2.9663984775543213
Iteration 125: train_loss 2.9063148498535156
Iteration 126: train_loss 3.086446762084961
Iteration 127: train_loss 2.889526844024658
Iteration 128: train_loss 2.9869980812072754
Iteration 129: train_loss 3.070664882659912
Iteration 130: train_loss 2.9608240127563477
Iteration 131: train_loss 2.9953925609588623
Iteration 132: train_loss 2.9469246864318848
Iteration 133: train_loss 2.970881700515747
Iteration 134: train_loss 3.037177562713623
Iteration 135: train_loss 2.9969632625579834
Iteration 136: train_loss 3.0390002727508545
Iteration 137: train_loss 2.959306001663208
Iteration 138: train_loss 3.0323567390441895
Iteration 139: train_loss 3.067380905151367
Iteration 140: train_loss 2.9487950801849365
Iteration 141: train_loss 3.073655128479004
Iteration 142: train_loss 3.0369479656219482
Iteration 143: train_loss 2.9191176891326904
Iteration 144: train_loss 3.10058856010437
Iteration 145: train_loss 2.999392509460449
Iteration 146: train_loss 3.0703682899475098
Iteration 147: train_loss 3.0629005432128906
Iteration 148: train_loss 3.024646043777466
Iteration 149: train_loss 2.990499496459961
Iteration 150: train_loss 3.0054571628570557
Iteration 151: train_loss 3.065920352935791
Iteration 152: train_loss 2.9804742336273193
Iteration 153: train_loss 2.9233522415161133
Iteration 154: train_loss 3.008847951889038
Iteration 155: train_loss 2.929513931274414
Iteration 156: train_loss 3.0327630043029785
Iteration 157: train_loss 2.9466099739074707
Iteration 158: train_loss 3.0539610385894775
Iteration 159: train_loss 2.9582128524780273
Iteration 160: train_loss 2.965885639190674
Iteration 161: train_loss 3.045762062072754
Iteration 162: train_loss 3.015385866165161
Iteration 163: train_loss 2.9448440074920654
Iteration 164: train_loss 2.995978593826294
Iteration 165: train_loss 2.886338233947754
Iteration 166: train_loss 2.9352245330810547
Iteration 167: train_loss 2.9708220958709717
Iteration 168: train_loss 3.104565382003784
Iteration 169: train_loss 3.001664638519287
Iteration 170: train_loss 3.0298843383789062
Iteration 171: train_loss 2.9846503734588623
Iteration 172: train_loss 3.0608463287353516
Iteration 173: train_loss 3.042013168334961
Iteration 174: train_loss 2.9577717781066895
Iteration 175: train_loss 3.0460658073425293
Iteration 176: train_loss 3.01130747795105
Iteration 177: train_loss 2.9419867992401123
Epoch 5: train_avg_loss 3.0500163843402754 eval_avg_acc: 0.18765478779988323 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:50:34] [32mIntermediate result: 0.18765478779988323  (Index 4)[0m
================Epoch: 6================
Iteration 1: train_loss 2.990659236907959
Iteration 2: train_loss 2.986769914627075
Iteration 3: train_loss 2.893709897994995
Iteration 4: train_loss 2.9177863597869873
Iteration 5: train_loss 2.9358317852020264
Iteration 6: train_loss 2.985252618789673
Iteration 7: train_loss 2.862011671066284
Iteration 8: train_loss 2.9109482765197754
Iteration 9: train_loss 2.8893990516662598
Iteration 10: train_loss 3.0160903930664062
Iteration 11: train_loss 2.9039502143859863
Iteration 12: train_loss 2.923530101776123
Iteration 13: train_loss 3.03791880607605
Iteration 14: train_loss 2.853358268737793
Iteration 15: train_loss 2.9601821899414062
Iteration 16: train_loss 2.9419991970062256
Iteration 17: train_loss 2.9245429039001465
Iteration 18: train_loss 2.929013252258301
Iteration 19: train_loss 2.8827357292175293
Iteration 20: train_loss 2.990447759628296
Iteration 21: train_loss 2.8972811698913574
Iteration 22: train_loss 2.9440128803253174
Iteration 23: train_loss 2.9649956226348877
Iteration 24: train_loss 2.931610107421875
Iteration 25: train_loss 2.989131450653076
Iteration 26: train_loss 3.0065982341766357
Iteration 27: train_loss 2.9233694076538086
Iteration 28: train_loss 2.9791629314422607
Iteration 29: train_loss 2.9242632389068604
Iteration 30: train_loss 2.931105613708496
Iteration 31: train_loss 2.928837537765503
Iteration 32: train_loss 2.9100143909454346
Iteration 33: train_loss 2.9361493587493896
Iteration 34: train_loss 2.835966110229492
Iteration 35: train_loss 2.9898617267608643
Iteration 36: train_loss 2.939176321029663
Iteration 37: train_loss 2.7536182403564453
Iteration 38: train_loss 2.8691513538360596
Iteration 39: train_loss 2.7131614685058594
Iteration 40: train_loss 2.9171595573425293
Iteration 41: train_loss 2.9329724311828613
Iteration 42: train_loss 2.915804624557495
Iteration 43: train_loss 2.846332311630249
Iteration 44: train_loss 2.9560844898223877
Iteration 45: train_loss 2.975188732147217
Iteration 46: train_loss 2.8756296634674072
Iteration 47: train_loss 2.8744781017303467
Iteration 48: train_loss 3.0311496257781982
Iteration 49: train_loss 2.8733439445495605
Iteration 50: train_loss 2.957660675048828
Iteration 51: train_loss 2.9394803047180176
Iteration 52: train_loss 2.9973464012145996
Iteration 53: train_loss 2.867943525314331
Iteration 54: train_loss 2.9119908809661865
Iteration 55: train_loss 2.960801362991333
Iteration 56: train_loss 2.8923614025115967
Iteration 57: train_loss 2.8952157497406006
Iteration 58: train_loss 2.969292163848877
Iteration 59: train_loss 2.961512565612793
Iteration 60: train_loss 2.825336456298828
Iteration 61: train_loss 2.8249239921569824
Iteration 62: train_loss 2.8248002529144287
Iteration 63: train_loss 2.8442747592926025
Iteration 64: train_loss 2.793926477432251
Iteration 65: train_loss 2.8990590572357178
Iteration 66: train_loss 2.957369327545166
Iteration 67: train_loss 2.917487621307373
Iteration 68: train_loss 2.853398323059082
Iteration 69: train_loss 2.8902246952056885
Iteration 70: train_loss 2.8249902725219727
Iteration 71: train_loss 2.9754767417907715
Iteration 72: train_loss 2.8216559886932373
Iteration 73: train_loss 2.852883815765381
Iteration 74: train_loss 2.840953826904297
Iteration 75: train_loss 2.9521563053131104
Iteration 76: train_loss 2.9391791820526123
Iteration 77: train_loss 2.949965238571167
Iteration 78: train_loss 2.8655645847320557
Iteration 79: train_loss 2.89607310295105
Iteration 80: train_loss 2.923860549926758
Iteration 81: train_loss 2.8493599891662598
Iteration 82: train_loss 2.863729953765869
Iteration 83: train_loss 2.9289822578430176
Iteration 84: train_loss 2.8765690326690674
Iteration 85: train_loss 2.906599521636963
Iteration 86: train_loss 2.859290361404419
Iteration 87: train_loss 2.863445281982422
Iteration 88: train_loss 2.8619637489318848
Iteration 89: train_loss 2.9227869510650635
Iteration 90: train_loss 2.9470677375793457
Iteration 91: train_loss 2.869041919708252
Iteration 92: train_loss 2.900263547897339
Iteration 93: train_loss 2.8147754669189453
Iteration 94: train_loss 2.788147449493408
Iteration 95: train_loss 2.8974125385284424
Iteration 96: train_loss 2.8379578590393066
Iteration 97: train_loss 2.9095771312713623
Iteration 98: train_loss 2.8678674697875977
Iteration 99: train_loss 2.901334762573242
Iteration 100: train_loss 2.902383804321289
Iteration 101: train_loss 2.948033571243286
Iteration 102: train_loss 3.023869276046753
Iteration 103: train_loss 2.9242382049560547
Iteration 104: train_loss 2.9251062870025635
Iteration 105: train_loss 2.87003231048584
Iteration 106: train_loss 2.9372286796569824
Iteration 107: train_loss 2.831416130065918
Iteration 108: train_loss 2.978407621383667
Iteration 109: train_loss 2.9483425617218018
Iteration 110: train_loss 2.944389581680298
Iteration 111: train_loss 3.0035746097564697
Iteration 112: train_loss 2.832322597503662
Iteration 113: train_loss 2.905982494354248
Iteration 114: train_loss 2.90766978263855
Iteration 115: train_loss 2.838637590408325
Iteration 116: train_loss 2.911707878112793
Iteration 117: train_loss 2.8664700984954834
Iteration 118: train_loss 2.842252254486084
Iteration 119: train_loss 2.8132259845733643
Iteration 120: train_loss 2.8362457752227783
Iteration 121: train_loss 2.8199570178985596
Iteration 122: train_loss 2.8426074981689453
Iteration 123: train_loss 2.82167649269104
Iteration 124: train_loss 2.9868128299713135
Iteration 125: train_loss 2.9470040798187256
Iteration 126: train_loss 2.9054574966430664
Iteration 127: train_loss 2.8415586948394775
Iteration 128: train_loss 2.910957098007202
Iteration 129: train_loss 2.9046988487243652
Iteration 130: train_loss 2.967116355895996
Iteration 131: train_loss 2.8973612785339355
Iteration 132: train_loss 2.9728574752807617
Iteration 133: train_loss 2.797576904296875
Iteration 134: train_loss 2.8991334438323975
Iteration 135: train_loss 2.8327815532684326
Iteration 136: train_loss 2.851628303527832
Iteration 137: train_loss 2.8976032733917236
Iteration 138: train_loss 2.885965347290039
Iteration 139: train_loss 2.9014463424682617
Iteration 140: train_loss 2.8822340965270996
Iteration 141: train_loss 2.9006288051605225
Iteration 142: train_loss 2.9280893802642822
Iteration 143: train_loss 2.902684211730957
Iteration 144: train_loss 2.8750228881835938
Iteration 145: train_loss 2.9464004039764404
Iteration 146: train_loss 2.8860116004943848
Iteration 147: train_loss 2.875706434249878
Iteration 148: train_loss 2.7917063236236572
Iteration 149: train_loss 2.885067939758301
Iteration 150: train_loss 2.947842597961426
Iteration 151: train_loss 2.8768579959869385
Iteration 152: train_loss 2.767275333404541
Iteration 153: train_loss 2.805983304977417
Iteration 154: train_loss 2.787537097930908
Iteration 155: train_loss 2.881833553314209
Iteration 156: train_loss 2.8433539867401123
Iteration 157: train_loss 2.9308767318725586
Iteration 158: train_loss 2.849246025085449
Iteration 159: train_loss 2.934269905090332
Iteration 160: train_loss 2.8473310470581055
Iteration 161: train_loss 2.900097370147705
Iteration 162: train_loss 2.816073417663574
Iteration 163: train_loss 2.9299700260162354
Iteration 164: train_loss 2.8539633750915527
Iteration 165: train_loss 2.8856070041656494
Iteration 166: train_loss 2.8875739574432373
Iteration 167: train_loss 2.9470746517181396
Iteration 168: train_loss 2.785287380218506
Iteration 169: train_loss 2.8328521251678467
Iteration 170: train_loss 2.899186849594116
Iteration 171: train_loss 2.9065065383911133
Iteration 172: train_loss 2.949629068374634
Iteration 173: train_loss 2.796098232269287
Iteration 174: train_loss 2.8649520874023438
Iteration 175: train_loss 2.8462703227996826
Iteration 176: train_loss 2.7007973194122314
Iteration 177: train_loss 2.8420772552490234
Epoch 6: train_avg_loss 2.896388705840892 eval_avg_acc: 0.22769260654382864 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:51:16] [32mIntermediate result: 0.22769260654382864  (Index 5)[0m
================Epoch: 7================
Iteration 1: train_loss 2.882843017578125
Iteration 2: train_loss 2.6915669441223145
Iteration 3: train_loss 2.733642339706421
Iteration 4: train_loss 2.804194211959839
Iteration 5: train_loss 2.907412052154541
Iteration 6: train_loss 2.7749288082122803
Iteration 7: train_loss 2.7708303928375244
Iteration 8: train_loss 2.7610855102539062
Iteration 9: train_loss 2.813838005065918
Iteration 10: train_loss 2.824012517929077
Iteration 11: train_loss 2.76054048538208
Iteration 12: train_loss 2.848818063735962
Iteration 13: train_loss 2.718639850616455
Iteration 14: train_loss 2.7970120906829834
Iteration 15: train_loss 2.750150203704834
Iteration 16: train_loss 2.835728883743286
Iteration 17: train_loss 2.773165464401245
Iteration 18: train_loss 2.8458595275878906
Iteration 19: train_loss 2.887110948562622
Iteration 20: train_loss 2.7368998527526855
Iteration 21: train_loss 2.7215583324432373
Iteration 22: train_loss 2.7930285930633545
Iteration 23: train_loss 2.8431646823883057
Iteration 24: train_loss 2.761317729949951
Iteration 25: train_loss 2.747997522354126
Iteration 26: train_loss 2.764540195465088
Iteration 27: train_loss 2.8168511390686035
Iteration 28: train_loss 2.921243190765381
Iteration 29: train_loss 2.8244922161102295
Iteration 30: train_loss 2.862748146057129
Iteration 31: train_loss 2.747447967529297
Iteration 32: train_loss 2.8250668048858643
Iteration 33: train_loss 2.965531587600708
Iteration 34: train_loss 2.6610639095306396
Iteration 35: train_loss 2.869248151779175
Iteration 36: train_loss 2.714287757873535
Iteration 37: train_loss 2.737490177154541
Iteration 38: train_loss 2.753571033477783
Iteration 39: train_loss 2.753901720046997
Iteration 40: train_loss 2.7012758255004883
Iteration 41: train_loss 2.738668441772461
Iteration 42: train_loss 2.779813528060913
Iteration 43: train_loss 2.803743362426758
Iteration 44: train_loss 2.7805447578430176
Iteration 45: train_loss 2.8453681468963623
Iteration 46: train_loss 2.7289297580718994
Iteration 47: train_loss 2.7128853797912598
Iteration 48: train_loss 2.829922676086426
Iteration 49: train_loss 2.7875585556030273
Iteration 50: train_loss 2.803057909011841
Iteration 51: train_loss 2.74841570854187
Iteration 52: train_loss 2.731707811355591
Iteration 53: train_loss 2.838730812072754
Iteration 54: train_loss 2.867572784423828
Iteration 55: train_loss 2.739802837371826
Iteration 56: train_loss 2.832064390182495
Iteration 57: train_loss 2.8002564907073975
Iteration 58: train_loss 2.7366082668304443
Iteration 59: train_loss 2.830120801925659
Iteration 60: train_loss 2.7759640216827393
Iteration 61: train_loss 2.809436559677124
Iteration 62: train_loss 2.7795963287353516
Iteration 63: train_loss 2.7210614681243896
Iteration 64: train_loss 2.786428213119507
Iteration 65: train_loss 2.8671987056732178
Iteration 66: train_loss 2.878737449645996
Iteration 67: train_loss 2.7040822505950928
Iteration 68: train_loss 2.836038827896118
Iteration 69: train_loss 2.849771499633789
Iteration 70: train_loss 2.82477068901062
Iteration 71: train_loss 2.866060495376587
Iteration 72: train_loss 2.767970323562622
Iteration 73: train_loss 2.7923951148986816
Iteration 74: train_loss 2.7275285720825195
Iteration 75: train_loss 2.7147247791290283
Iteration 76: train_loss 2.90246844291687
Iteration 77: train_loss 2.805708646774292
Iteration 78: train_loss 2.677988290786743
Iteration 79: train_loss 2.7872815132141113
Iteration 80: train_loss 2.9081249237060547
Iteration 81: train_loss 2.772864580154419
Iteration 82: train_loss 2.801074743270874
Iteration 83: train_loss 2.788954973220825
Iteration 84: train_loss 2.8874456882476807
Iteration 85: train_loss 2.802438259124756
Iteration 86: train_loss 2.8488998413085938
Iteration 87: train_loss 2.7874348163604736
Iteration 88: train_loss 2.745797872543335
Iteration 89: train_loss 2.731498956680298
Iteration 90: train_loss 2.815028190612793
Iteration 91: train_loss 2.6948180198669434
Iteration 92: train_loss 2.7333505153656006
Iteration 93: train_loss 2.7437074184417725
Iteration 94: train_loss 2.753603458404541
Iteration 95: train_loss 2.695096969604492
Iteration 96: train_loss 2.6581380367279053
Iteration 97: train_loss 2.7876150608062744
Iteration 98: train_loss 2.681873083114624
Iteration 99: train_loss 2.7092134952545166
Iteration 100: train_loss 2.6747262477874756
Iteration 101: train_loss 2.8660833835601807
Iteration 102: train_loss 2.742583751678467
Iteration 103: train_loss 2.7392520904541016
Iteration 104: train_loss 2.7457053661346436
Iteration 105: train_loss 2.7302160263061523
Iteration 106: train_loss 2.7277684211730957
Iteration 107: train_loss 2.736835479736328
Iteration 108: train_loss 2.78066349029541
Iteration 109: train_loss 2.8015084266662598
Iteration 110: train_loss 2.8874597549438477
Iteration 111: train_loss 2.7832510471343994
Iteration 112: train_loss 2.8483738899230957
Iteration 113: train_loss 2.7844274044036865
Iteration 114: train_loss 2.7632534503936768
Iteration 115: train_loss 2.7312607765197754
Iteration 116: train_loss 2.7322261333465576
Iteration 117: train_loss 2.7395169734954834
Iteration 118: train_loss 2.785912036895752
Iteration 119: train_loss 2.802269458770752
Iteration 120: train_loss 2.6085281372070312
Iteration 121: train_loss 2.7127323150634766
Iteration 122: train_loss 2.75635027885437
Iteration 123: train_loss 2.762465715408325
Iteration 124: train_loss 2.7645716667175293
Iteration 125: train_loss 2.846656084060669
Iteration 126: train_loss 2.7301716804504395
Iteration 127: train_loss 2.872828483581543
Iteration 128: train_loss 2.8340401649475098
Iteration 129: train_loss 2.7235922813415527
Iteration 130: train_loss 2.6694560050964355
Iteration 131: train_loss 2.9272847175598145
Iteration 132: train_loss 2.753471612930298
Iteration 133: train_loss 2.6483960151672363
Iteration 134: train_loss 2.7035093307495117
Iteration 135: train_loss 2.7095787525177
Iteration 136: train_loss 2.789652109146118
Iteration 137: train_loss 2.71445369720459
Iteration 138: train_loss 2.7175214290618896
Iteration 139: train_loss 2.7356905937194824
Iteration 140: train_loss 2.7262258529663086
Iteration 141: train_loss 2.739722728729248
Iteration 142: train_loss 2.7501983642578125
Iteration 143: train_loss 2.71746826171875
Iteration 144: train_loss 2.8105456829071045
Iteration 145: train_loss 2.7647488117218018
Iteration 146: train_loss 2.939223527908325
Iteration 147: train_loss 2.8309218883514404
Iteration 148: train_loss 2.8134608268737793
Iteration 149: train_loss 2.7030231952667236
Iteration 150: train_loss 2.7609610557556152
Iteration 151: train_loss 2.8310799598693848
Iteration 152: train_loss 2.7851274013519287
Iteration 153: train_loss 2.7384986877441406
Iteration 154: train_loss 2.7624871730804443
Iteration 155: train_loss 2.7641103267669678
Iteration 156: train_loss 2.66349720954895
Iteration 157: train_loss 2.7963688373565674
Iteration 158: train_loss 2.7650840282440186
Iteration 159: train_loss 2.664257049560547
Iteration 160: train_loss 2.6819510459899902
Iteration 161: train_loss 2.816716432571411
Iteration 162: train_loss 2.7763044834136963
Iteration 163: train_loss 2.7325358390808105
Iteration 164: train_loss 2.7099599838256836
Iteration 165: train_loss 2.701958656311035
Iteration 166: train_loss 2.743511915206909
Iteration 167: train_loss 2.7178902626037598
Iteration 168: train_loss 2.8062920570373535
Iteration 169: train_loss 2.7095696926116943
Iteration 170: train_loss 2.7325332164764404
Iteration 171: train_loss 2.715315580368042
Iteration 172: train_loss 2.7091522216796875
Iteration 173: train_loss 2.678785562515259
Iteration 174: train_loss 2.6945009231567383
Iteration 175: train_loss 2.670036554336548
Iteration 176: train_loss 2.8703489303588867
Iteration 177: train_loss 2.641690492630005
Epoch 7: train_avg_loss 2.772216829202943 eval_avg_acc: 0.24191564309069263 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:51:59] [32mIntermediate result: 0.24191564309069263  (Index 6)[0m
================Epoch: 8================
Iteration 1: train_loss 2.7876830101013184
Iteration 2: train_loss 2.7369823455810547
Iteration 3: train_loss 2.6201064586639404
Iteration 4: train_loss 2.6727285385131836
Iteration 5: train_loss 2.681504011154175
Iteration 6: train_loss 2.662714958190918
Iteration 7: train_loss 2.6367504596710205
Iteration 8: train_loss 2.5518033504486084
Iteration 9: train_loss 2.633195400238037
Iteration 10: train_loss 2.6691513061523438
Iteration 11: train_loss 2.6836912631988525
Iteration 12: train_loss 2.6081533432006836
Iteration 13: train_loss 2.6302032470703125
Iteration 14: train_loss 2.6722097396850586
Iteration 15: train_loss 2.612516403198242
Iteration 16: train_loss 2.699514150619507
Iteration 17: train_loss 2.6936824321746826
Iteration 18: train_loss 2.7491424083709717
Iteration 19: train_loss 2.739377498626709
Iteration 20: train_loss 2.6310219764709473
Iteration 21: train_loss 2.6755688190460205
Iteration 22: train_loss 2.634514093399048
Iteration 23: train_loss 2.5285632610321045
Iteration 24: train_loss 2.6727001667022705
Iteration 25: train_loss 2.684556245803833
Iteration 26: train_loss 2.7870733737945557
Iteration 27: train_loss 2.6189355850219727
Iteration 28: train_loss 2.701756238937378
Iteration 29: train_loss 2.7612664699554443
Iteration 30: train_loss 2.65195369720459
Iteration 31: train_loss 2.562572479248047
Iteration 32: train_loss 2.5954973697662354
Iteration 33: train_loss 2.6355390548706055
Iteration 34: train_loss 2.670560121536255
Iteration 35: train_loss 2.6415443420410156
Iteration 36: train_loss 2.646845579147339
Iteration 37: train_loss 2.6177492141723633
Iteration 38: train_loss 2.6792211532592773
Iteration 39: train_loss 2.7716360092163086
Iteration 40: train_loss 2.6890010833740234
Iteration 41: train_loss 2.6318039894104004
Iteration 42: train_loss 2.6660614013671875
Iteration 43: train_loss 2.683825731277466
Iteration 44: train_loss 2.7072575092315674
Iteration 45: train_loss 2.668280839920044
Iteration 46: train_loss 2.6706976890563965
Iteration 47: train_loss 2.6727776527404785
Iteration 48: train_loss 2.5735504627227783
Iteration 49: train_loss 2.666306495666504
Iteration 50: train_loss 2.689694881439209
Iteration 51: train_loss 2.675976037979126
Iteration 52: train_loss 2.681133508682251
Iteration 53: train_loss 2.6914255619049072
Iteration 54: train_loss 2.7738900184631348
Iteration 55: train_loss 2.61629581451416
Iteration 56: train_loss 2.7658426761627197
Iteration 57: train_loss 2.6483495235443115
Iteration 58: train_loss 2.6291208267211914
Iteration 59: train_loss 2.6799445152282715
Iteration 60: train_loss 2.6715574264526367
Iteration 61: train_loss 2.663361072540283
Iteration 62: train_loss 2.705883741378784
Iteration 63: train_loss 2.796729564666748
Iteration 64: train_loss 2.6351139545440674
Iteration 65: train_loss 2.6634647846221924
Iteration 66: train_loss 2.7010436058044434
Iteration 67: train_loss 2.599571466445923
Iteration 68: train_loss 2.619293451309204
Iteration 69: train_loss 2.5873398780822754
Iteration 70: train_loss 2.7088463306427
Iteration 71: train_loss 2.7595040798187256
Iteration 72: train_loss 2.6877384185791016
Iteration 73: train_loss 2.7272326946258545
Iteration 74: train_loss 2.6596944332122803
Iteration 75: train_loss 2.687304735183716
Iteration 76: train_loss 2.6320886611938477
Iteration 77: train_loss 2.708630323410034
Iteration 78: train_loss 2.6451938152313232
Iteration 79: train_loss 2.6581451892852783
Iteration 80: train_loss 2.6786410808563232
Iteration 81: train_loss 2.6968398094177246
Iteration 82: train_loss 2.6486101150512695
Iteration 83: train_loss 2.616335153579712
Iteration 84: train_loss 2.712143898010254
Iteration 85: train_loss 2.7663702964782715
Iteration 86: train_loss 2.7266080379486084
Iteration 87: train_loss 2.7116079330444336
Iteration 88: train_loss 2.674299716949463
Iteration 89: train_loss 2.783381700515747
Iteration 90: train_loss 2.6950550079345703
Iteration 91: train_loss 2.6967079639434814
Iteration 92: train_loss 2.6092467308044434
Iteration 93: train_loss 2.6667211055755615
Iteration 94: train_loss 2.683900833129883
Iteration 95: train_loss 2.7035610675811768
Iteration 96: train_loss 2.57604718208313
Iteration 97: train_loss 2.6884148120880127
Iteration 98: train_loss 2.6418113708496094
Iteration 99: train_loss 2.613105297088623
Iteration 100: train_loss 2.6983299255371094
Iteration 101: train_loss 2.7452032566070557
Iteration 102: train_loss 2.6547091007232666
Iteration 103: train_loss 2.616584062576294
Iteration 104: train_loss 2.702448844909668
Iteration 105: train_loss 2.7195310592651367
Iteration 106: train_loss 2.601130247116089
Iteration 107: train_loss 2.5711121559143066
Iteration 108: train_loss 2.6676201820373535
Iteration 109: train_loss 2.7462310791015625
Iteration 110: train_loss 2.5865092277526855
Iteration 111: train_loss 2.7651240825653076
Iteration 112: train_loss 2.559556007385254
Iteration 113: train_loss 2.650660753250122
Iteration 114: train_loss 2.7817115783691406
Iteration 115: train_loss 2.6833598613739014
Iteration 116: train_loss 2.683530330657959
Iteration 117: train_loss 2.5759501457214355
Iteration 118: train_loss 2.6335363388061523
Iteration 119: train_loss 2.7057838439941406
Iteration 120: train_loss 2.4818038940429688
Iteration 121: train_loss 2.60955810546875
Iteration 122: train_loss 2.6742353439331055
Iteration 123: train_loss 2.6685662269592285
Iteration 124: train_loss 2.642038583755493
Iteration 125: train_loss 2.6156136989593506
Iteration 126: train_loss 2.6681368350982666
Iteration 127: train_loss 2.6536755561828613
Iteration 128: train_loss 2.665728807449341
Iteration 129: train_loss 2.61037015914917
Iteration 130: train_loss 2.8170201778411865
Iteration 131: train_loss 2.6621954441070557
Iteration 132: train_loss 2.690385580062866
Iteration 133: train_loss 2.7165029048919678
Iteration 134: train_loss 2.702197790145874
Iteration 135: train_loss 2.722532033920288
Iteration 136: train_loss 2.5485763549804688
Iteration 137: train_loss 2.780283212661743
Iteration 138: train_loss 2.773422956466675
Iteration 139: train_loss 2.688570737838745
Iteration 140: train_loss 2.6717031002044678
Iteration 141: train_loss 2.658797264099121
Iteration 142: train_loss 2.6646106243133545
Iteration 143: train_loss 2.6497480869293213
Iteration 144: train_loss 2.648811101913452
Iteration 145: train_loss 2.6884517669677734
Iteration 146: train_loss 2.6513073444366455
Iteration 147: train_loss 2.7185821533203125
Iteration 148: train_loss 2.53857684135437
Iteration 149: train_loss 2.7139339447021484
Iteration 150: train_loss 2.671365261077881
Iteration 151: train_loss 2.652606964111328
Iteration 152: train_loss 2.712186574935913
Iteration 153: train_loss 2.7290611267089844
Iteration 154: train_loss 2.6078414916992188
Iteration 155: train_loss 2.636228322982788
Iteration 156: train_loss 2.6966028213500977
Iteration 157: train_loss 2.7198827266693115
Iteration 158: train_loss 2.6842000484466553
Iteration 159: train_loss 2.5524768829345703
Iteration 160: train_loss 2.6376867294311523
Iteration 161: train_loss 2.64725399017334
Iteration 162: train_loss 2.6511523723602295
Iteration 163: train_loss 2.6536366939544678
Iteration 164: train_loss 2.7763187885284424
Iteration 165: train_loss 2.645660877227783
Iteration 166: train_loss 2.7507660388946533
Iteration 167: train_loss 2.593810796737671
Iteration 168: train_loss 2.628859758377075
Iteration 169: train_loss 2.565864324569702
Iteration 170: train_loss 2.4786648750305176
Iteration 171: train_loss 2.57114315032959
Iteration 172: train_loss 2.667975902557373
Iteration 173: train_loss 2.6258771419525146
Iteration 174: train_loss 2.6465117931365967
Iteration 175: train_loss 2.626424551010132
Iteration 176: train_loss 2.635812282562256
Iteration 177: train_loss 2.783176898956299
Epoch 8: train_avg_loss 2.6671874374993103 eval_avg_acc: 0.23811518933458956 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:52:42] [32mIntermediate result: 0.23811518933458956  (Index 7)[0m
================Epoch: 9================
Iteration 1: train_loss 2.660365343093872
Iteration 2: train_loss 2.640237808227539
Iteration 3: train_loss 2.5331172943115234
Iteration 4: train_loss 2.5494229793548584
Iteration 5: train_loss 2.5850324630737305
Iteration 6: train_loss 2.612234592437744
Iteration 7: train_loss 2.6966497898101807
Iteration 8: train_loss 2.6443183422088623
Iteration 9: train_loss 2.593981981277466
Iteration 10: train_loss 2.5508508682250977
Iteration 11: train_loss 2.561756134033203
Iteration 12: train_loss 2.6248786449432373
Iteration 13: train_loss 2.5710413455963135
Iteration 14: train_loss 2.5401647090911865
Iteration 15: train_loss 2.6423869132995605
Iteration 16: train_loss 2.6371257305145264
Iteration 17: train_loss 2.5941779613494873
Iteration 18: train_loss 2.6914918422698975
Iteration 19: train_loss 2.6433463096618652
Iteration 20: train_loss 2.593287467956543
Iteration 21: train_loss 2.5995864868164062
Iteration 22: train_loss 2.521430015563965
Iteration 23: train_loss 2.677061080932617
Iteration 24: train_loss 2.5264649391174316
Iteration 25: train_loss 2.593824863433838
Iteration 26: train_loss 2.6145896911621094
Iteration 27: train_loss 2.5940864086151123
Iteration 28: train_loss 2.546480417251587
Iteration 29: train_loss 2.5801916122436523
Iteration 30: train_loss 2.522514820098877
Iteration 31: train_loss 2.5610973834991455
Iteration 32: train_loss 2.5867247581481934
Iteration 33: train_loss 2.5627548694610596
Iteration 34: train_loss 2.579421281814575
Iteration 35: train_loss 2.553485870361328
Iteration 36: train_loss 2.5371508598327637
Iteration 37: train_loss 2.6501028537750244
Iteration 38: train_loss 2.6210875511169434
Iteration 39: train_loss 2.6129350662231445
Iteration 40: train_loss 2.5232105255126953
Iteration 41: train_loss 2.6266870498657227
Iteration 42: train_loss 2.6458516120910645
Iteration 43: train_loss 2.5476393699645996
Iteration 44: train_loss 2.482543706893921
Iteration 45: train_loss 2.467393636703491
Iteration 46: train_loss 2.657315731048584
Iteration 47: train_loss 2.5688111782073975
Iteration 48: train_loss 2.6743392944335938
Iteration 49: train_loss 2.6063506603240967
Iteration 50: train_loss 2.470486879348755
Iteration 51: train_loss 2.6157898902893066
Iteration 52: train_loss 2.601935863494873
Iteration 53: train_loss 2.6251397132873535
Iteration 54: train_loss 2.6238677501678467
Iteration 55: train_loss 2.612684488296509
Iteration 56: train_loss 2.5899386405944824
Iteration 57: train_loss 2.649275779724121
Iteration 58: train_loss 2.65055513381958
Iteration 59: train_loss 2.571259021759033
Iteration 60: train_loss 2.6050758361816406
Iteration 61: train_loss 2.5203793048858643
Iteration 62: train_loss 2.5378410816192627
Iteration 63: train_loss 2.6368675231933594
Iteration 64: train_loss 2.6393935680389404
Iteration 65: train_loss 2.5919182300567627
Iteration 66: train_loss 2.5290520191192627
Iteration 67: train_loss 2.568603277206421
Iteration 68: train_loss 2.621087074279785
Iteration 69: train_loss 2.5961265563964844
Iteration 70: train_loss 2.604365587234497
Iteration 71: train_loss 2.654906749725342
Iteration 72: train_loss 2.592862367630005
Iteration 73: train_loss 2.5705373287200928
Iteration 74: train_loss 2.619281053543091
Iteration 75: train_loss 2.5658316612243652
Iteration 76: train_loss 2.5934548377990723
Iteration 77: train_loss 2.5176985263824463
Iteration 78: train_loss 2.5580332279205322
Iteration 79: train_loss 2.6822073459625244
Iteration 80: train_loss 2.622020721435547
Iteration 81: train_loss 2.6708531379699707
Iteration 82: train_loss 2.591015338897705
Iteration 83: train_loss 2.564863681793213
Iteration 84: train_loss 2.52166748046875
Iteration 85: train_loss 2.5617117881774902
Iteration 86: train_loss 2.6340787410736084
Iteration 87: train_loss 2.483320951461792
Iteration 88: train_loss 2.5179154872894287
Iteration 89: train_loss 2.544093370437622
Iteration 90: train_loss 2.63397216796875
Iteration 91: train_loss 2.649962902069092
Iteration 92: train_loss 2.6263844966888428
Iteration 93: train_loss 2.621115207672119
Iteration 94: train_loss 2.5285987854003906
Iteration 95: train_loss 2.5732498168945312
Iteration 96: train_loss 2.5897209644317627
Iteration 97: train_loss 2.6395323276519775
Iteration 98: train_loss 2.4936389923095703
Iteration 99: train_loss 2.5549044609069824
Iteration 100: train_loss 2.606684923171997
Iteration 101: train_loss 2.535327672958374
Iteration 102: train_loss 2.5513675212860107
Iteration 103: train_loss 2.488976240158081
Iteration 104: train_loss 2.4527931213378906
Iteration 105: train_loss 2.57940673828125
Iteration 106: train_loss 2.5277109146118164
Iteration 107: train_loss 2.6444361209869385
Iteration 108: train_loss 2.5766444206237793
Iteration 109: train_loss 2.573530435562134
Iteration 110: train_loss 2.5261850357055664
Iteration 111: train_loss 2.5789146423339844
Iteration 112: train_loss 2.67478346824646
Iteration 113: train_loss 2.601896047592163
Iteration 114: train_loss 2.4951729774475098
Iteration 115: train_loss 2.5039331912994385
Iteration 116: train_loss 2.4712462425231934
Iteration 117: train_loss 2.5422472953796387
Iteration 118: train_loss 2.594590187072754
Iteration 119: train_loss 2.5893361568450928
Iteration 120: train_loss 2.526885986328125
Iteration 121: train_loss 2.613213062286377
Iteration 122: train_loss 2.646761178970337
Iteration 123: train_loss 2.571913242340088
Iteration 124: train_loss 2.5936639308929443
Iteration 125: train_loss 2.5012481212615967
Iteration 126: train_loss 2.6189377307891846
Iteration 127: train_loss 2.5347800254821777
Iteration 128: train_loss 2.5175793170928955
Iteration 129: train_loss 2.537539482116699
Iteration 130: train_loss 2.5010194778442383
Iteration 131: train_loss 2.5573904514312744
Iteration 132: train_loss 2.4818880558013916
Iteration 133: train_loss 2.6278555393218994
Iteration 134: train_loss 2.579815626144409
Iteration 135: train_loss 2.5016028881073
Iteration 136: train_loss 2.5917906761169434
Iteration 137: train_loss 2.4907431602478027
Iteration 138: train_loss 2.609017848968506
Iteration 139: train_loss 2.5733067989349365
Iteration 140: train_loss 2.526064872741699
Iteration 141: train_loss 2.4802048206329346
Iteration 142: train_loss 2.5880179405212402
Iteration 143: train_loss 2.5385706424713135
Iteration 144: train_loss 2.65582275390625
Iteration 145: train_loss 2.5595169067382812
Iteration 146: train_loss 2.553318500518799
Iteration 147: train_loss 2.5836422443389893
Iteration 148: train_loss 2.6520955562591553
Iteration 149: train_loss 2.4920547008514404
Iteration 150: train_loss 2.651508092880249
Iteration 151: train_loss 2.6292030811309814
Iteration 152: train_loss 2.5394511222839355
Iteration 153: train_loss 2.413687229156494
Iteration 154: train_loss 2.591032028198242
Iteration 155: train_loss 2.576244831085205
Iteration 156: train_loss 2.5678911209106445
Iteration 157: train_loss 2.640425443649292
Iteration 158: train_loss 2.560746908187866
Iteration 159: train_loss 2.604362964630127
Iteration 160: train_loss 2.620649576187134
Iteration 161: train_loss 2.5209014415740967
Iteration 162: train_loss 2.6071481704711914
Iteration 163: train_loss 2.5717549324035645
Iteration 164: train_loss 2.5783252716064453
Iteration 165: train_loss 2.5240607261657715
Iteration 166: train_loss 2.658007860183716
Iteration 167: train_loss 2.4805495738983154
Iteration 168: train_loss 2.5812594890594482
Iteration 169: train_loss 2.664839267730713
Iteration 170: train_loss 2.609005928039551
Iteration 171: train_loss 2.6913745403289795
Iteration 172: train_loss 2.6207051277160645
Iteration 173: train_loss 2.5582315921783447
Iteration 174: train_loss 2.574770212173462
Iteration 175: train_loss 2.5283002853393555
Iteration 176: train_loss 2.5807888507843018
Iteration 177: train_loss 2.4594547748565674
Epoch 9: train_avg_loss 2.5795039807335804 eval_avg_acc: 0.250095363241593 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:53:26] [32mIntermediate result: 0.250095363241593  (Index 8)[0m
================Epoch: 10================
Iteration 1: train_loss 2.5000245571136475
Iteration 2: train_loss 2.5466129779815674
Iteration 3: train_loss 2.6015288829803467
Iteration 4: train_loss 2.484440803527832
Iteration 5: train_loss 2.471987009048462
Iteration 6: train_loss 2.526564359664917
Iteration 7: train_loss 2.496739387512207
Iteration 8: train_loss 2.489891767501831
Iteration 9: train_loss 2.421705722808838
Iteration 10: train_loss 2.474752187728882
Iteration 11: train_loss 2.518568992614746
Iteration 12: train_loss 2.514364242553711
Iteration 13: train_loss 2.4503228664398193
Iteration 14: train_loss 2.5456814765930176
Iteration 15: train_loss 2.573432683944702
Iteration 16: train_loss 2.528625249862671
Iteration 17: train_loss 2.449753522872925
Iteration 18: train_loss 2.54506516456604
Iteration 19: train_loss 2.483736038208008
Iteration 20: train_loss 2.5198280811309814
Iteration 21: train_loss 2.5313353538513184
Iteration 22: train_loss 2.5491437911987305
Iteration 23: train_loss 2.502089500427246
Iteration 24: train_loss 2.474224328994751
Iteration 25: train_loss 2.519395351409912
Iteration 26: train_loss 2.506721258163452
Iteration 27: train_loss 2.414247512817383
Iteration 28: train_loss 2.5605766773223877
Iteration 29: train_loss 2.499619245529175
Iteration 30: train_loss 2.507589101791382
Iteration 31: train_loss 2.4877185821533203
Iteration 32: train_loss 2.539984941482544
Iteration 33: train_loss 2.54107403755188
Iteration 34: train_loss 2.5934627056121826
Iteration 35: train_loss 2.5274806022644043
Iteration 36: train_loss 2.5538504123687744
Iteration 37: train_loss 2.571375608444214
Iteration 38: train_loss 2.5290591716766357
Iteration 39: train_loss 2.577756643295288
Iteration 40: train_loss 2.4996352195739746
Iteration 41: train_loss 2.626438856124878
Iteration 42: train_loss 2.468214511871338
Iteration 43: train_loss 2.4733152389526367
Iteration 44: train_loss 2.54970645904541
Iteration 45: train_loss 2.4689548015594482
Iteration 46: train_loss 2.446864604949951
Iteration 47: train_loss 2.4456095695495605
Iteration 48: train_loss 2.495373487472534
Iteration 49: train_loss 2.4357311725616455
Iteration 50: train_loss 2.4486899375915527
Iteration 51: train_loss 2.45692777633667
Iteration 52: train_loss 2.549804449081421
Iteration 53: train_loss 2.479252815246582
Iteration 54: train_loss 2.5003409385681152
Iteration 55: train_loss 2.4233436584472656
Iteration 56: train_loss 2.418315887451172
Iteration 57: train_loss 2.470259666442871
Iteration 58: train_loss 2.454019784927368
Iteration 59: train_loss 2.5612246990203857
Iteration 60: train_loss 2.4512267112731934
Iteration 61: train_loss 2.448383092880249
Iteration 62: train_loss 2.525578260421753
Iteration 63: train_loss 2.4428229331970215
Iteration 64: train_loss 2.522697925567627
Iteration 65: train_loss 2.5403754711151123
Iteration 66: train_loss 2.442772388458252
Iteration 67: train_loss 2.4445395469665527
Iteration 68: train_loss 2.5125315189361572
Iteration 69: train_loss 2.500485897064209
Iteration 70: train_loss 2.4454917907714844
Iteration 71: train_loss 2.50280499458313
Iteration 72: train_loss 2.5027427673339844
Iteration 73: train_loss 2.540958881378174
Iteration 74: train_loss 2.4744298458099365
Iteration 75: train_loss 2.5199992656707764
Iteration 76: train_loss 2.535546064376831
Iteration 77: train_loss 2.4513533115386963
Iteration 78: train_loss 2.518629550933838
Iteration 79: train_loss 2.5080723762512207
Iteration 80: train_loss 2.5464859008789062
Iteration 81: train_loss 2.4651541709899902
Iteration 82: train_loss 2.467222213745117
Iteration 83: train_loss 2.5113887786865234
Iteration 84: train_loss 2.5391414165496826
Iteration 85: train_loss 2.548124074935913
Iteration 86: train_loss 2.605232000350952
Iteration 87: train_loss 2.4758949279785156
Iteration 88: train_loss 2.47796368598938
Iteration 89: train_loss 2.472075939178467
Iteration 90: train_loss 2.431929111480713
Iteration 91: train_loss 2.508098840713501
Iteration 92: train_loss 2.4813108444213867
Iteration 93: train_loss 2.4876673221588135
Iteration 94: train_loss 2.4460625648498535
Iteration 95: train_loss 2.499697685241699
Iteration 96: train_loss 2.4665234088897705
Iteration 97: train_loss 2.56597900390625
Iteration 98: train_loss 2.539801836013794
Iteration 99: train_loss 2.5266075134277344
Iteration 100: train_loss 2.51364803314209
Iteration 101: train_loss 2.4703564643859863
Iteration 102: train_loss 2.5515573024749756
Iteration 103: train_loss 2.5455946922302246
Iteration 104: train_loss 2.5348920822143555
Iteration 105: train_loss 2.5855391025543213
Iteration 106: train_loss 2.5299670696258545
Iteration 107: train_loss 2.450176477432251
Iteration 108: train_loss 2.522446632385254
Iteration 109: train_loss 2.489241123199463
Iteration 110: train_loss 2.5560898780822754
Iteration 111: train_loss 2.5787065029144287
Iteration 112: train_loss 2.486891031265259
Iteration 113: train_loss 2.5577526092529297
Iteration 114: train_loss 2.525867223739624
Iteration 115: train_loss 2.476994037628174
Iteration 116: train_loss 2.4886982440948486
Iteration 117: train_loss 2.526254892349243
Iteration 118: train_loss 2.4615910053253174
Iteration 119: train_loss 2.505514621734619
Iteration 120: train_loss 2.604475736618042
Iteration 121: train_loss 2.4986894130706787
Iteration 122: train_loss 2.3782896995544434
Iteration 123: train_loss 2.5263521671295166
Iteration 124: train_loss 2.5241501331329346
Iteration 125: train_loss 2.5516867637634277
Iteration 126: train_loss 2.4234812259674072
Iteration 127: train_loss 2.4600558280944824
Iteration 128: train_loss 2.6887011528015137
Iteration 129: train_loss 2.5865135192871094
Iteration 130: train_loss 2.5769028663635254
Iteration 131: train_loss 2.4929678440093994
Iteration 132: train_loss 2.5428144931793213
Iteration 133: train_loss 2.596676826477051
Iteration 134: train_loss 2.447572946548462
Iteration 135: train_loss 2.533400774002075
Iteration 136: train_loss 2.4848105907440186
Iteration 137: train_loss 2.5307366847991943
Iteration 138: train_loss 2.530412435531616
Iteration 139: train_loss 2.38069748878479
Iteration 140: train_loss 2.5240018367767334
Iteration 141: train_loss 2.560002088546753
Iteration 142: train_loss 2.5253591537475586
Iteration 143: train_loss 2.60683536529541
Iteration 144: train_loss 2.5790767669677734
Iteration 145: train_loss 2.4864883422851562
Iteration 146: train_loss 2.473518133163452
Iteration 147: train_loss 2.550459146499634
Iteration 148: train_loss 2.58828067779541
Iteration 149: train_loss 2.513221263885498
Iteration 150: train_loss 2.5723631381988525
Iteration 151: train_loss 2.4800832271575928
Iteration 152: train_loss 2.604785680770874
Iteration 153: train_loss 2.49715256690979
Iteration 154: train_loss 2.5293264389038086
Iteration 155: train_loss 2.447157382965088
Iteration 156: train_loss 2.485502243041992
Iteration 157: train_loss 2.4502291679382324
Iteration 158: train_loss 2.545928955078125
Iteration 159: train_loss 2.4633896350860596
Iteration 160: train_loss 2.543048858642578
Iteration 161: train_loss 2.4364051818847656
Iteration 162: train_loss 2.5608577728271484
Iteration 163: train_loss 2.4942076206207275
Iteration 164: train_loss 2.535053014755249
Iteration 165: train_loss 2.466756820678711
Iteration 166: train_loss 2.543668031692505
Iteration 167: train_loss 2.4476237297058105
Iteration 168: train_loss 2.540607213973999
Iteration 169: train_loss 2.5594229698181152
Iteration 170: train_loss 2.5820207595825195
Iteration 171: train_loss 2.4434404373168945
Iteration 172: train_loss 2.632066249847412
Iteration 173: train_loss 2.6088826656341553
Iteration 174: train_loss 2.4988553524017334
Iteration 175: train_loss 2.5126309394836426
Iteration 176: train_loss 2.4493041038513184
Iteration 177: train_loss 2.4674839973449707
Epoch 10: train_avg_loss 2.509710862811676 eval_avg_acc: 0.26968308295307025 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:54:09] [32mIntermediate result: 0.26968308295307025  (Index 9)[0m
================Epoch: 11================
Iteration 1: train_loss 2.5040557384490967
Iteration 2: train_loss 2.422534227371216
Iteration 3: train_loss 2.40468430519104
Iteration 4: train_loss 2.439987897872925
Iteration 5: train_loss 2.5120701789855957
Iteration 6: train_loss 2.4456822872161865
Iteration 7: train_loss 2.407444477081299
Iteration 8: train_loss 2.4942007064819336
Iteration 9: train_loss 2.40913462638855
Iteration 10: train_loss 2.5510849952697754
Iteration 11: train_loss 2.5404136180877686
Iteration 12: train_loss 2.478170394897461
Iteration 13: train_loss 2.3867926597595215
Iteration 14: train_loss 2.460282802581787
Iteration 15: train_loss 2.4451277256011963
Iteration 16: train_loss 2.462658643722534
Iteration 17: train_loss 2.4294676780700684
Iteration 18: train_loss 2.3619587421417236
Iteration 19: train_loss 2.3826050758361816
Iteration 20: train_loss 2.451361894607544
Iteration 21: train_loss 2.4398789405822754
Iteration 22: train_loss 2.4643750190734863
Iteration 23: train_loss 2.3681159019470215
Iteration 24: train_loss 2.449186086654663
Iteration 25: train_loss 2.48690128326416
Iteration 26: train_loss 2.47393798828125
Iteration 27: train_loss 2.474179267883301
Iteration 28: train_loss 2.400083065032959
Iteration 29: train_loss 2.4171392917633057
Iteration 30: train_loss 2.380202531814575
Iteration 31: train_loss 2.4548850059509277
Iteration 32: train_loss 2.4232921600341797
Iteration 33: train_loss 2.3932793140411377
Iteration 34: train_loss 2.5548906326293945
Iteration 35: train_loss 2.382657527923584
Iteration 36: train_loss 2.506243944168091
Iteration 37: train_loss 2.4273743629455566
Iteration 38: train_loss 2.3980839252471924
Iteration 39: train_loss 2.4569177627563477
Iteration 40: train_loss 2.4587528705596924
Iteration 41: train_loss 2.4763236045837402
Iteration 42: train_loss 2.462172508239746
Iteration 43: train_loss 2.4109609127044678
Iteration 44: train_loss 2.4427192211151123
Iteration 45: train_loss 2.4033350944519043
Iteration 46: train_loss 2.494800329208374
Iteration 47: train_loss 2.450120687484741
Iteration 48: train_loss 2.4007513523101807
Iteration 49: train_loss 2.4877967834472656
Iteration 50: train_loss 2.472679615020752
Iteration 51: train_loss 2.4296181201934814
Iteration 52: train_loss 2.50065541267395
Iteration 53: train_loss 2.3325722217559814
Iteration 54: train_loss 2.472010612487793
Iteration 55: train_loss 2.4124820232391357
Iteration 56: train_loss 2.4694130420684814
Iteration 57: train_loss 2.4337100982666016
Iteration 58: train_loss 2.45023512840271
Iteration 59: train_loss 2.416317939758301
Iteration 60: train_loss 2.466810941696167
Iteration 61: train_loss 2.4081614017486572
Iteration 62: train_loss 2.387441873550415
Iteration 63: train_loss 2.5263442993164062
Iteration 64: train_loss 2.389636993408203
Iteration 65: train_loss 2.4733388423919678
Iteration 66: train_loss 2.4273178577423096
Iteration 67: train_loss 2.378100633621216
Iteration 68: train_loss 2.486572504043579
Iteration 69: train_loss 2.416696310043335
Iteration 70: train_loss 2.5164456367492676
Iteration 71: train_loss 2.417848587036133
Iteration 72: train_loss 2.3976752758026123
Iteration 73: train_loss 2.488222599029541
Iteration 74: train_loss 2.4652814865112305
Iteration 75: train_loss 2.442615270614624
Iteration 76: train_loss 2.469351053237915
Iteration 77: train_loss 2.471583604812622
Iteration 78: train_loss 2.396521806716919
Iteration 79: train_loss 2.410210609436035
Iteration 80: train_loss 2.3840138912200928
Iteration 81: train_loss 2.4332332611083984
Iteration 82: train_loss 2.4774584770202637
Iteration 83: train_loss 2.4665141105651855
Iteration 84: train_loss 2.410475015640259
Iteration 85: train_loss 2.3933374881744385
Iteration 86: train_loss 2.500168561935425
Iteration 87: train_loss 2.4767889976501465
Iteration 88: train_loss 2.4506492614746094
Iteration 89: train_loss 2.4791769981384277
Iteration 90: train_loss 2.454228401184082
Iteration 91: train_loss 2.4535491466522217
Iteration 92: train_loss 2.3432703018188477
Iteration 93: train_loss 2.445348024368286
Iteration 94: train_loss 2.5745272636413574
Iteration 95: train_loss 2.543682336807251
Iteration 96: train_loss 2.441767454147339
Iteration 97: train_loss 2.5253381729125977
Iteration 98: train_loss 2.5040905475616455
Iteration 99: train_loss 2.412855386734009
Iteration 100: train_loss 2.440551996231079
Iteration 101: train_loss 2.401412010192871
Iteration 102: train_loss 2.465989351272583
Iteration 103: train_loss 2.5022506713867188
Iteration 104: train_loss 2.494260549545288
Iteration 105: train_loss 2.4731087684631348
Iteration 106: train_loss 2.433504343032837
Iteration 107: train_loss 2.468580961227417
Iteration 108: train_loss 2.392319679260254
Iteration 109: train_loss 2.4823219776153564
Iteration 110: train_loss 2.4930171966552734
Iteration 111: train_loss 2.4968550205230713
Iteration 112: train_loss 2.4415881633758545
Iteration 113: train_loss 2.424006700515747
Iteration 114: train_loss 2.4240529537200928
Iteration 115: train_loss 2.482473611831665
Iteration 116: train_loss 2.443526029586792
Iteration 117: train_loss 2.470926284790039
Iteration 118: train_loss 2.3859806060791016
Iteration 119: train_loss 2.4573440551757812
Iteration 120: train_loss 2.3758089542388916
Iteration 121: train_loss 2.477159023284912
Iteration 122: train_loss 2.4098575115203857
Iteration 123: train_loss 2.4512250423431396
Iteration 124: train_loss 2.519087314605713
Iteration 125: train_loss 2.496304512023926
Iteration 126: train_loss 2.4270732402801514
Iteration 127: train_loss 2.4499518871307373
Iteration 128: train_loss 2.428008556365967
Iteration 129: train_loss 2.410543203353882
Iteration 130: train_loss 2.4169201850891113
Iteration 131: train_loss 2.4700286388397217
Iteration 132: train_loss 2.471221923828125
Iteration 133: train_loss 2.421426296234131
Iteration 134: train_loss 2.385730743408203
Iteration 135: train_loss 2.5076236724853516
Iteration 136: train_loss 2.4465878009796143
Iteration 137: train_loss 2.507725715637207
Iteration 138: train_loss 2.466996192932129
Iteration 139: train_loss 2.4477107524871826
Iteration 140: train_loss 2.3022258281707764
Iteration 141: train_loss 2.5217478275299072
Iteration 142: train_loss 2.4559738636016846
Iteration 143: train_loss 2.554431676864624
Iteration 144: train_loss 2.4690253734588623
Iteration 145: train_loss 2.4103190898895264
Iteration 146: train_loss 2.441476583480835
Iteration 147: train_loss 2.496857166290283
Iteration 148: train_loss 2.542492389678955
Iteration 149: train_loss 2.4811413288116455
Iteration 150: train_loss 2.446742534637451
Iteration 151: train_loss 2.511981725692749
Iteration 152: train_loss 2.541368246078491
Iteration 153: train_loss 2.4261112213134766
Iteration 154: train_loss 2.364617347717285
Iteration 155: train_loss 2.4135518074035645
Iteration 156: train_loss 2.4696192741394043
Iteration 157: train_loss 2.498749256134033
Iteration 158: train_loss 2.4578208923339844
Iteration 159: train_loss 2.383082389831543
Iteration 160: train_loss 2.477979898452759
Iteration 161: train_loss 2.445948600769043
Iteration 162: train_loss 2.4885947704315186
Iteration 163: train_loss 2.556356430053711
Iteration 164: train_loss 2.397609233856201
Iteration 165: train_loss 2.458299160003662
Iteration 166: train_loss 2.435145378112793
Iteration 167: train_loss 2.455054759979248
Iteration 168: train_loss 2.400665760040283
Iteration 169: train_loss 2.3858749866485596
Iteration 170: train_loss 2.4702415466308594
Iteration 171: train_loss 2.5674099922180176
Iteration 172: train_loss 2.4636011123657227
Iteration 173: train_loss 2.3721892833709717
Iteration 174: train_loss 2.4260144233703613
Iteration 175: train_loss 2.4861207008361816
Iteration 176: train_loss 2.5720462799072266
Iteration 177: train_loss 2.5433406829833984
Epoch 11: train_avg_loss 2.4512898975846458 eval_avg_acc: 0.2763896443138725 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:54:53] [32mIntermediate result: 0.2763896443138725  (Index 10)[0m
================Epoch: 12================
Iteration 1: train_loss 2.3791918754577637
Iteration 2: train_loss 2.325937271118164
Iteration 3: train_loss 2.377525568008423
Iteration 4: train_loss 2.427635431289673
Iteration 5: train_loss 2.368380546569824
Iteration 6: train_loss 2.4473752975463867
Iteration 7: train_loss 2.441314935684204
Iteration 8: train_loss 2.4563632011413574
Iteration 9: train_loss 2.4035258293151855
Iteration 10: train_loss 2.310136079788208
Iteration 11: train_loss 2.4282047748565674
Iteration 12: train_loss 2.3906753063201904
Iteration 13: train_loss 2.4196107387542725
Iteration 14: train_loss 2.3901760578155518
Iteration 15: train_loss 2.366091728210449
Iteration 16: train_loss 2.3367717266082764
Iteration 17: train_loss 2.403970241546631
Iteration 18: train_loss 2.3690686225891113
Iteration 19: train_loss 2.3860819339752197
Iteration 20: train_loss 2.4406096935272217
Iteration 21: train_loss 2.3801426887512207
Iteration 22: train_loss 2.3072221279144287
Iteration 23: train_loss 2.3554396629333496
Iteration 24: train_loss 2.4369115829467773
Iteration 25: train_loss 2.4404819011688232
Iteration 26: train_loss 2.354795217514038
Iteration 27: train_loss 2.4024720191955566
Iteration 28: train_loss 2.4349148273468018
Iteration 29: train_loss 2.352473020553589
Iteration 30: train_loss 2.2858879566192627
Iteration 31: train_loss 2.4280552864074707
Iteration 32: train_loss 2.3747241497039795
Iteration 33: train_loss 2.432774305343628
Iteration 34: train_loss 2.4788930416107178
Iteration 35: train_loss 2.379369020462036
Iteration 36: train_loss 2.374208688735962
Iteration 37: train_loss 2.3399436473846436
Iteration 38: train_loss 2.4195687770843506
Iteration 39: train_loss 2.3979084491729736
Iteration 40: train_loss 2.458085060119629
Iteration 41: train_loss 2.420635223388672
Iteration 42: train_loss 2.3752546310424805
Iteration 43: train_loss 2.4208998680114746
Iteration 44: train_loss 2.3052101135253906
Iteration 45: train_loss 2.438890218734741
Iteration 46: train_loss 2.4333009719848633
Iteration 47: train_loss 2.4044058322906494
Iteration 48: train_loss 2.3572397232055664
Iteration 49: train_loss 2.342089891433716
Iteration 50: train_loss 2.3534693717956543
Iteration 51: train_loss 2.3112542629241943
Iteration 52: train_loss 2.3920791149139404
Iteration 53: train_loss 2.423105001449585
Iteration 54: train_loss 2.4645133018493652
Iteration 55: train_loss 2.444300413131714
Iteration 56: train_loss 2.3613739013671875
Iteration 57: train_loss 2.397503614425659
Iteration 58: train_loss 2.3465631008148193
Iteration 59: train_loss 2.3962533473968506
Iteration 60: train_loss 2.410654067993164
Iteration 61: train_loss 2.421492099761963
Iteration 62: train_loss 2.335627555847168
Iteration 63: train_loss 2.4091334342956543
Iteration 64: train_loss 2.471057176589966
Iteration 65: train_loss 2.4489188194274902
Iteration 66: train_loss 2.3763856887817383
Iteration 67: train_loss 2.3955202102661133
Iteration 68: train_loss 2.4165446758270264
Iteration 69: train_loss 2.44978666305542
Iteration 70: train_loss 2.3740994930267334
Iteration 71: train_loss 2.394728660583496
Iteration 72: train_loss 2.392245054244995
Iteration 73: train_loss 2.4621200561523438
Iteration 74: train_loss 2.3814902305603027
Iteration 75: train_loss 2.425626277923584
Iteration 76: train_loss 2.360053539276123
Iteration 77: train_loss 2.4172136783599854
Iteration 78: train_loss 2.410752534866333
Iteration 79: train_loss 2.4408488273620605
Iteration 80: train_loss 2.4285101890563965
Iteration 81: train_loss 2.43644118309021
Iteration 82: train_loss 2.399796724319458
Iteration 83: train_loss 2.327402353286743
Iteration 84: train_loss 2.397814989089966
Iteration 85: train_loss 2.3484678268432617
Iteration 86: train_loss 2.4212722778320312
Iteration 87: train_loss 2.3673746585845947
Iteration 88: train_loss 2.472360849380493
Iteration 89: train_loss 2.4046521186828613
Iteration 90: train_loss 2.4394049644470215
Iteration 91: train_loss 2.434901475906372
Iteration 92: train_loss 2.406200885772705
Iteration 93: train_loss 2.493968963623047
Iteration 94: train_loss 2.3223485946655273
Iteration 95: train_loss 2.338797092437744
Iteration 96: train_loss 2.4568536281585693
Iteration 97: train_loss 2.400294780731201
Iteration 98: train_loss 2.374077796936035
Iteration 99: train_loss 2.421968698501587
Iteration 100: train_loss 2.3381311893463135
Iteration 101: train_loss 2.317920684814453
Iteration 102: train_loss 2.279045343399048
Iteration 103: train_loss 2.3437681198120117
Iteration 104: train_loss 2.4289817810058594
Iteration 105: train_loss 2.4211947917938232
Iteration 106: train_loss 2.4097378253936768
Iteration 107: train_loss 2.4299538135528564
Iteration 108: train_loss 2.3585448265075684
Iteration 109: train_loss 2.4093449115753174
Iteration 110: train_loss 2.429288148880005
Iteration 111: train_loss 2.3856208324432373
Iteration 112: train_loss 2.4429588317871094
Iteration 113: train_loss 2.4900951385498047
Iteration 114: train_loss 2.40783429145813
Iteration 115: train_loss 2.4390885829925537
Iteration 116: train_loss 2.409787654876709
Iteration 117: train_loss 2.381265878677368
Iteration 118: train_loss 2.4348092079162598
Iteration 119: train_loss 2.389979362487793
Iteration 120: train_loss 2.3688583374023438
Iteration 121: train_loss 2.4569740295410156
Iteration 122: train_loss 2.428255558013916
Iteration 123: train_loss 2.359752655029297
Iteration 124: train_loss 2.428708076477051
Iteration 125: train_loss 2.4144740104675293
Iteration 126: train_loss 2.5171995162963867
Iteration 127: train_loss 2.425314426422119
Iteration 128: train_loss 2.3654944896698
Iteration 129: train_loss 2.4571774005889893
Iteration 130: train_loss 2.3914246559143066
Iteration 131: train_loss 2.371346950531006
Iteration 132: train_loss 2.364112615585327
Iteration 133: train_loss 2.435835838317871
Iteration 134: train_loss 2.4229044914245605
Iteration 135: train_loss 2.383937358856201
Iteration 136: train_loss 2.4275591373443604
Iteration 137: train_loss 2.379476547241211
Iteration 138: train_loss 2.3663971424102783
Iteration 139: train_loss 2.37845516204834
Iteration 140: train_loss 2.391934633255005
Iteration 141: train_loss 2.3757922649383545
Iteration 142: train_loss 2.421955108642578
Iteration 143: train_loss 2.447808265686035
Iteration 144: train_loss 2.468670606613159
Iteration 145: train_loss 2.3235888481140137
Iteration 146: train_loss 2.3606691360473633
Iteration 147: train_loss 2.2110557556152344
Iteration 148: train_loss 2.419426441192627
Iteration 149: train_loss 2.409419536590576
Iteration 150: train_loss 2.460420608520508
Iteration 151: train_loss 2.4378867149353027
Iteration 152: train_loss 2.384737730026245
Iteration 153: train_loss 2.3759498596191406
Iteration 154: train_loss 2.3632264137268066
Iteration 155: train_loss 2.4766530990600586
Iteration 156: train_loss 2.4265949726104736
Iteration 157: train_loss 2.3299572467803955
Iteration 158: train_loss 2.3868730068206787
Iteration 159: train_loss 2.45078706741333
Iteration 160: train_loss 2.259004831314087
Iteration 161: train_loss 2.4167280197143555
Iteration 162: train_loss 2.5320231914520264
Iteration 163: train_loss 2.4022181034088135
Iteration 164: train_loss 2.447981834411621
Iteration 165: train_loss 2.433655023574829
Iteration 166: train_loss 2.403170585632324
Iteration 167: train_loss 2.3590071201324463
Iteration 168: train_loss 2.4058024883270264
Iteration 169: train_loss 2.404938220977783
Iteration 170: train_loss 2.4390573501586914
Iteration 171: train_loss 2.313800096511841
Iteration 172: train_loss 2.3525466918945312
Iteration 173: train_loss 2.3232781887054443
Iteration 174: train_loss 2.3110499382019043
Iteration 175: train_loss 2.355534076690674
Iteration 176: train_loss 2.3332338333129883
Iteration 177: train_loss 2.3981528282165527
Epoch 12: train_avg_loss 2.397085131898438 eval_avg_acc: 0.26400037501042334 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:55:36] [32mIntermediate result: 0.26400037501042334  (Index 11)[0m
================Epoch: 13================
Iteration 1: train_loss 2.2600226402282715
Iteration 2: train_loss 2.308403968811035
Iteration 3: train_loss 2.4138472080230713
Iteration 4: train_loss 2.3596816062927246
Iteration 5: train_loss 2.329667091369629
Iteration 6: train_loss 2.345717430114746
Iteration 7: train_loss 2.4006001949310303
Iteration 8: train_loss 2.40950345993042
Iteration 9: train_loss 2.3290340900421143
Iteration 10: train_loss 2.391129493713379
Iteration 11: train_loss 2.3438336849212646
Iteration 12: train_loss 2.41827392578125
Iteration 13: train_loss 2.305159091949463
Iteration 14: train_loss 2.3819122314453125
Iteration 15: train_loss 2.329087734222412
Iteration 16: train_loss 2.3169453144073486
Iteration 17: train_loss 2.281989812850952
Iteration 18: train_loss 2.2998909950256348
Iteration 19: train_loss 2.3500499725341797
Iteration 20: train_loss 2.342885971069336
Iteration 21: train_loss 2.3453783988952637
Iteration 22: train_loss 2.1972124576568604
Iteration 23: train_loss 2.3281092643737793
Iteration 24: train_loss 2.2878050804138184
Iteration 25: train_loss 2.290546417236328
Iteration 26: train_loss 2.2724292278289795
Iteration 27: train_loss 2.4001917839050293
Iteration 28: train_loss 2.3425028324127197
Iteration 29: train_loss 2.3943557739257812
Iteration 30: train_loss 2.3898298740386963
Iteration 31: train_loss 2.3490777015686035
Iteration 32: train_loss 2.3727622032165527
Iteration 33: train_loss 2.370882272720337
Iteration 34: train_loss 2.3107192516326904
Iteration 35: train_loss 2.34256911277771
Iteration 36: train_loss 2.326355218887329
Iteration 37: train_loss 2.2599854469299316
Iteration 38: train_loss 2.284353494644165
Iteration 39: train_loss 2.2818946838378906
Iteration 40: train_loss 2.3048338890075684
Iteration 41: train_loss 2.3631601333618164
Iteration 42: train_loss 2.3695855140686035
Iteration 43: train_loss 2.324640989303589
Iteration 44: train_loss 2.2592906951904297
Iteration 45: train_loss 2.3387725353240967
Iteration 46: train_loss 2.4077072143554688
Iteration 47: train_loss 2.2900407314300537
Iteration 48: train_loss 2.3547379970550537
Iteration 49: train_loss 2.374378204345703
Iteration 50: train_loss 2.3149421215057373
Iteration 51: train_loss 2.343380928039551
Iteration 52: train_loss 2.280282735824585
Iteration 53: train_loss 2.308579921722412
Iteration 54: train_loss 2.352630615234375
Iteration 55: train_loss 2.357825756072998
Iteration 56: train_loss 2.312049150466919
Iteration 57: train_loss 2.4074158668518066
Iteration 58: train_loss 2.389219284057617
Iteration 59: train_loss 2.425299882888794
Iteration 60: train_loss 2.2758655548095703
Iteration 61: train_loss 2.3951315879821777
Iteration 62: train_loss 2.2820069789886475
Iteration 63: train_loss 2.342250347137451
Iteration 64: train_loss 2.349707841873169
Iteration 65: train_loss 2.2889983654022217
Iteration 66: train_loss 2.292346715927124
Iteration 67: train_loss 2.408735752105713
Iteration 68: train_loss 2.429534673690796
Iteration 69: train_loss 2.2624306678771973
Iteration 70: train_loss 2.4016377925872803
Iteration 71: train_loss 2.28340744972229
Iteration 72: train_loss 2.3561503887176514
Iteration 73: train_loss 2.366046667098999
Iteration 74: train_loss 2.263064384460449
Iteration 75: train_loss 2.3763184547424316
Iteration 76: train_loss 2.2788479328155518
Iteration 77: train_loss 2.398559331893921
Iteration 78: train_loss 2.3350348472595215
Iteration 79: train_loss 2.4586875438690186
Iteration 80: train_loss 2.3459155559539795
Iteration 81: train_loss 2.399543285369873
Iteration 82: train_loss 2.2995588779449463
Iteration 83: train_loss 2.3346824645996094
Iteration 84: train_loss 2.395158290863037
Iteration 85: train_loss 2.2613625526428223
Iteration 86: train_loss 2.2572951316833496
Iteration 87: train_loss 2.3926727771759033
Iteration 88: train_loss 2.438600778579712
Iteration 89: train_loss 2.4053962230682373
Iteration 90: train_loss 2.388942241668701
Iteration 91: train_loss 2.3857479095458984
Iteration 92: train_loss 2.4065380096435547
Iteration 93: train_loss 2.3660082817077637
Iteration 94: train_loss 2.429511785507202
Iteration 95: train_loss 2.3277413845062256
Iteration 96: train_loss 2.268683671951294
Iteration 97: train_loss 2.350346088409424
Iteration 98: train_loss 2.280231237411499
Iteration 99: train_loss 2.4059898853302
Iteration 100: train_loss 2.3822624683380127
Iteration 101: train_loss 2.3748176097869873
Iteration 102: train_loss 2.3464643955230713
Iteration 103: train_loss 2.3441410064697266
Iteration 104: train_loss 2.412341356277466
Iteration 105: train_loss 2.311846971511841
Iteration 106: train_loss 2.287109613418579
Iteration 107: train_loss 2.3611693382263184
Iteration 108: train_loss 2.308964252471924
Iteration 109: train_loss 2.334906578063965
Iteration 110: train_loss 2.311323642730713
Iteration 111: train_loss 2.388319969177246
Iteration 112: train_loss 2.375032424926758
Iteration 113: train_loss 2.3685452938079834
Iteration 114: train_loss 2.39225435256958
Iteration 115: train_loss 2.392692804336548
Iteration 116: train_loss 2.3599905967712402
Iteration 117: train_loss 2.4429798126220703
Iteration 118: train_loss 2.354060173034668
Iteration 119: train_loss 2.431152582168579
Iteration 120: train_loss 2.3703386783599854
Iteration 121: train_loss 2.3317105770111084
Iteration 122: train_loss 2.3871514797210693
Iteration 123: train_loss 2.4374892711639404
Iteration 124: train_loss 2.3581626415252686
Iteration 125: train_loss 2.344087839126587
Iteration 126: train_loss 2.4175539016723633
Iteration 127: train_loss 2.3631703853607178
Iteration 128: train_loss 2.3515098094940186
Iteration 129: train_loss 2.377284526824951
Iteration 130: train_loss 2.307849168777466
Iteration 131: train_loss 2.2165687084198
Iteration 132: train_loss 2.4114623069763184
Iteration 133: train_loss 2.497772455215454
Iteration 134: train_loss 2.317507028579712
Iteration 135: train_loss 2.3876044750213623
Iteration 136: train_loss 2.4105794429779053
Iteration 137: train_loss 2.375770092010498
Iteration 138: train_loss 2.367708206176758
Iteration 139: train_loss 2.3519229888916016
Iteration 140: train_loss 2.297266721725464
Iteration 141: train_loss 2.329892635345459
Iteration 142: train_loss 2.3572232723236084
Iteration 143: train_loss 2.350933313369751
Iteration 144: train_loss 2.24570631980896
Iteration 145: train_loss 2.392989158630371
Iteration 146: train_loss 2.3140816688537598
Iteration 147: train_loss 2.375190019607544
Iteration 148: train_loss 2.3140082359313965
Iteration 149: train_loss 2.3588409423828125
Iteration 150: train_loss 2.2074851989746094
Iteration 151: train_loss 2.2916133403778076
Iteration 152: train_loss 2.2589926719665527
Iteration 153: train_loss 2.286468505859375
Iteration 154: train_loss 2.2623050212860107
Iteration 155: train_loss 2.4276623725891113
Iteration 156: train_loss 2.289354085922241
Iteration 157: train_loss 2.3756766319274902
Iteration 158: train_loss 2.320697546005249
Iteration 159: train_loss 2.3036751747131348
Iteration 160: train_loss 2.302741289138794
Iteration 161: train_loss 2.3341879844665527
Iteration 162: train_loss 2.2995975017547607
Iteration 163: train_loss 2.2894539833068848
Iteration 164: train_loss 2.3229939937591553
Iteration 165: train_loss 2.4226553440093994
Iteration 166: train_loss 2.3170382976531982
Iteration 167: train_loss 2.4391582012176514
Iteration 168: train_loss 2.3673651218414307
Iteration 169: train_loss 2.3284106254577637
Iteration 170: train_loss 2.4270899295806885
Iteration 171: train_loss 2.403838872909546
Iteration 172: train_loss 2.3110105991363525
Iteration 173: train_loss 2.485645055770874
Iteration 174: train_loss 2.3868017196655273
Iteration 175: train_loss 2.4148271083831787
Iteration 176: train_loss 2.383195638656616
Iteration 177: train_loss 2.331690549850464
Epoch 13: train_avg_loss 2.347567255214109 eval_avg_acc: 0.28112673935695415 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:56:21] [32mIntermediate result: 0.28112673935695415  (Index 12)[0m
================Epoch: 14================
Iteration 1: train_loss 2.3261492252349854
Iteration 2: train_loss 2.4333560466766357
Iteration 3: train_loss 2.342599391937256
Iteration 4: train_loss 2.37980318069458
Iteration 5: train_loss 2.3485307693481445
Iteration 6: train_loss 2.265239715576172
Iteration 7: train_loss 2.3529961109161377
Iteration 8: train_loss 2.307821750640869
Iteration 9: train_loss 2.3757429122924805
Iteration 10: train_loss 2.284832000732422
Iteration 11: train_loss 2.3527910709381104
Iteration 12: train_loss 2.3058996200561523
Iteration 13: train_loss 2.2432565689086914
Iteration 14: train_loss 2.328310966491699
Iteration 15: train_loss 2.2905635833740234
Iteration 16: train_loss 2.315687894821167
Iteration 17: train_loss 2.3348495960235596
Iteration 18: train_loss 2.1842195987701416
Iteration 19: train_loss 2.2326583862304688
Iteration 20: train_loss 2.232501745223999
Iteration 21: train_loss 2.2744925022125244
Iteration 22: train_loss 2.3410561084747314
Iteration 23: train_loss 2.163858413696289
Iteration 24: train_loss 2.2527520656585693
Iteration 25: train_loss 2.289785385131836
Iteration 26: train_loss 2.2707533836364746
Iteration 27: train_loss 2.3098349571228027
Iteration 28: train_loss 2.2818057537078857
Iteration 29: train_loss 2.357922077178955
Iteration 30: train_loss 2.3090875148773193
Iteration 31: train_loss 2.3914406299591064
Iteration 32: train_loss 2.312018871307373
Iteration 33: train_loss 2.355128526687622
Iteration 34: train_loss 2.302908182144165
Iteration 35: train_loss 2.303842067718506
Iteration 36: train_loss 2.354335308074951
Iteration 37: train_loss 2.34537672996521
Iteration 38: train_loss 2.209325075149536
Iteration 39: train_loss 2.2248780727386475
Iteration 40: train_loss 2.2399742603302
Iteration 41: train_loss 2.3527700901031494
Iteration 42: train_loss 2.2639100551605225
Iteration 43: train_loss 2.2974514961242676
Iteration 44: train_loss 2.312026023864746
Iteration 45: train_loss 2.26200532913208
Iteration 46: train_loss 2.239250421524048
Iteration 47: train_loss 2.2494685649871826
Iteration 48: train_loss 2.3412089347839355
Iteration 49: train_loss 2.340019464492798
Iteration 50: train_loss 2.3742332458496094
Iteration 51: train_loss 2.3266258239746094
Iteration 52: train_loss 2.2635772228240967
Iteration 53: train_loss 2.342660427093506
Iteration 54: train_loss 2.3332409858703613
Iteration 55: train_loss 2.363926887512207
Iteration 56: train_loss 2.333540439605713
Iteration 57: train_loss 2.2725448608398438
Iteration 58: train_loss 2.3081257343292236
Iteration 59: train_loss 2.2754905223846436
Iteration 60: train_loss 2.2665040493011475
Iteration 61: train_loss 2.2863409519195557
Iteration 62: train_loss 2.2786924839019775
Iteration 63: train_loss 2.241791248321533
Iteration 64: train_loss 2.363068103790283
Iteration 65: train_loss 2.2681989669799805
Iteration 66: train_loss 2.3515844345092773
Iteration 67: train_loss 2.2861335277557373
Iteration 68: train_loss 2.2145018577575684
Iteration 69: train_loss 2.3723111152648926
Iteration 70: train_loss 2.322326421737671
Iteration 71: train_loss 2.1930880546569824
Iteration 72: train_loss 2.404576539993286
Iteration 73: train_loss 2.33465313911438
Iteration 74: train_loss 2.309723138809204
Iteration 75: train_loss 2.1986351013183594
Iteration 76: train_loss 2.2767157554626465
Iteration 77: train_loss 2.351562738418579
Iteration 78: train_loss 2.354886770248413
Iteration 79: train_loss 2.2619950771331787
Iteration 80: train_loss 2.2669832706451416
Iteration 81: train_loss 2.279904842376709
Iteration 82: train_loss 2.298510789871216
Iteration 83: train_loss 2.2328133583068848
Iteration 84: train_loss 2.363304853439331
Iteration 85: train_loss 2.303342342376709
Iteration 86: train_loss 2.3037240505218506
Iteration 87: train_loss 2.358853578567505
Iteration 88: train_loss 2.3408236503601074
Iteration 89: train_loss 2.326249122619629
Iteration 90: train_loss 2.3581080436706543
Iteration 91: train_loss 2.26322340965271
Iteration 92: train_loss 2.2536234855651855
Iteration 93: train_loss 2.30180287361145
Iteration 94: train_loss 2.2958784103393555
Iteration 95: train_loss 2.3578269481658936
Iteration 96: train_loss 2.278290271759033
Iteration 97: train_loss 2.293708324432373
Iteration 98: train_loss 2.41019344329834
Iteration 99: train_loss 2.2674875259399414
Iteration 100: train_loss 2.2990918159484863
Iteration 101: train_loss 2.238339424133301
Iteration 102: train_loss 2.2950916290283203
Iteration 103: train_loss 2.343820333480835
Iteration 104: train_loss 2.3638534545898438
Iteration 105: train_loss 2.2990870475769043
Iteration 106: train_loss 2.3340775966644287
Iteration 107: train_loss 2.2453885078430176
Iteration 108: train_loss 2.332064151763916
Iteration 109: train_loss 2.3035688400268555
Iteration 110: train_loss 2.336366653442383
Iteration 111: train_loss 2.367506265640259
Iteration 112: train_loss 2.285649299621582
Iteration 113: train_loss 2.3718767166137695
Iteration 114: train_loss 2.307997226715088
Iteration 115: train_loss 2.283323287963867
Iteration 116: train_loss 2.3687965869903564
Iteration 117: train_loss 2.275655746459961
Iteration 118: train_loss 2.2738542556762695
Iteration 119: train_loss 2.2319107055664062
Iteration 120: train_loss 2.294724464416504
Iteration 121: train_loss 2.3527920246124268
Iteration 122: train_loss 2.3678300380706787
Iteration 123: train_loss 2.3423304557800293
Iteration 124: train_loss 2.2715585231781006
Iteration 125: train_loss 2.2501461505889893
Iteration 126: train_loss 2.366934299468994
Iteration 127: train_loss 2.2941765785217285
Iteration 128: train_loss 2.301762819290161
Iteration 129: train_loss 2.2892842292785645
Iteration 130: train_loss 2.3034446239471436
Iteration 131: train_loss 2.254945755004883
Iteration 132: train_loss 2.228588819503784
Iteration 133: train_loss 2.2899601459503174
Iteration 134: train_loss 2.3575925827026367
Iteration 135: train_loss 2.2919962406158447
Iteration 136: train_loss 2.232914686203003
Iteration 137: train_loss 2.221034288406372
Iteration 138: train_loss 2.308661937713623
Iteration 139: train_loss 2.2939653396606445
Iteration 140: train_loss 2.3674986362457275
Iteration 141: train_loss 2.3790998458862305
Iteration 142: train_loss 2.2426130771636963
Iteration 143: train_loss 2.3796603679656982
Iteration 144: train_loss 2.3057661056518555
Iteration 145: train_loss 2.322597026824951
Iteration 146: train_loss 2.413404703140259
Iteration 147: train_loss 2.3031532764434814
Iteration 148: train_loss 2.341017723083496
Iteration 149: train_loss 2.3038947582244873
Iteration 150: train_loss 2.3278613090515137
Iteration 151: train_loss 2.293583631515503
Iteration 152: train_loss 2.2375965118408203
Iteration 153: train_loss 2.389387607574463
Iteration 154: train_loss 2.258141040802002
Iteration 155: train_loss 2.286564350128174
Iteration 156: train_loss 2.329071283340454
Iteration 157: train_loss 2.2991509437561035
Iteration 158: train_loss 2.2387514114379883
Iteration 159: train_loss 2.3677101135253906
Iteration 160: train_loss 2.296217679977417
Iteration 161: train_loss 2.3270907402038574
Iteration 162: train_loss 2.300166130065918
Iteration 163: train_loss 2.290440797805786
Iteration 164: train_loss 2.2944393157958984
Iteration 165: train_loss 2.238569736480713
Iteration 166: train_loss 2.3513834476470947
Iteration 167: train_loss 2.290592670440674
Iteration 168: train_loss 2.3634815216064453
Iteration 169: train_loss 2.369570016860962
Iteration 170: train_loss 2.1931605339050293
Iteration 171: train_loss 2.245975971221924
Iteration 172: train_loss 2.3635735511779785
Iteration 173: train_loss 2.3719258308410645
Iteration 174: train_loss 2.2390477657318115
Iteration 175: train_loss 2.260580539703369
Iteration 176: train_loss 2.2830984592437744
Iteration 177: train_loss 2.299445867538452
Epoch 14: train_avg_loss 2.304574307748827 eval_avg_acc: 0.2992057362542851 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:57:05] [32mIntermediate result: 0.2992057362542851  (Index 13)[0m
================Epoch: 15================
Iteration 1: train_loss 2.197384834289551
Iteration 2: train_loss 2.1723954677581787
Iteration 3: train_loss 2.293977737426758
Iteration 4: train_loss 2.3469200134277344
Iteration 5: train_loss 2.278461456298828
Iteration 6: train_loss 2.2489776611328125
Iteration 7: train_loss 2.22830867767334
Iteration 8: train_loss 2.229602575302124
Iteration 9: train_loss 2.2573840618133545
Iteration 10: train_loss 2.194385528564453
Iteration 11: train_loss 2.2747790813446045
Iteration 12: train_loss 2.245262622833252
Iteration 13: train_loss 2.1647393703460693
Iteration 14: train_loss 2.200542688369751
Iteration 15: train_loss 2.2590649127960205
Iteration 16: train_loss 2.1871418952941895
Iteration 17: train_loss 2.2674591541290283
Iteration 18: train_loss 2.34212589263916
Iteration 19: train_loss 2.277385950088501
Iteration 20: train_loss 2.247365713119507
Iteration 21: train_loss 2.185431480407715
Iteration 22: train_loss 2.284877300262451
Iteration 23: train_loss 2.2282097339630127
Iteration 24: train_loss 2.265754222869873
Iteration 25: train_loss 2.2127561569213867
Iteration 26: train_loss 2.300443172454834
Iteration 27: train_loss 2.2149791717529297
Iteration 28: train_loss 2.241973876953125
Iteration 29: train_loss 2.2900397777557373
Iteration 30: train_loss 2.2713708877563477
Iteration 31: train_loss 2.3051528930664062
Iteration 32: train_loss 2.3493452072143555
Iteration 33: train_loss 2.2741215229034424
Iteration 34: train_loss 2.172379732131958
Iteration 35: train_loss 2.2170348167419434
Iteration 36: train_loss 2.28224515914917
Iteration 37: train_loss 2.2825794219970703
Iteration 38: train_loss 2.3453786373138428
Iteration 39: train_loss 2.176814317703247
Iteration 40: train_loss 2.2902371883392334
Iteration 41: train_loss 2.295691728591919
Iteration 42: train_loss 2.2812814712524414
Iteration 43: train_loss 2.2616474628448486
Iteration 44: train_loss 2.3076634407043457
Iteration 45: train_loss 2.2515385150909424
Iteration 46: train_loss 2.2278342247009277
Iteration 47: train_loss 2.2246673107147217
Iteration 48: train_loss 2.2963132858276367
Iteration 49: train_loss 2.3308908939361572
Iteration 50: train_loss 2.2411155700683594
Iteration 51: train_loss 2.3447961807250977
Iteration 52: train_loss 2.2544877529144287
Iteration 53: train_loss 2.2580432891845703
Iteration 54: train_loss 2.3109638690948486
Iteration 55: train_loss 2.252936601638794
Iteration 56: train_loss 2.2668089866638184
Iteration 57: train_loss 2.234835386276245
Iteration 58: train_loss 2.215332269668579
Iteration 59: train_loss 2.304504632949829
Iteration 60: train_loss 2.149352788925171
Iteration 61: train_loss 2.2491471767425537
Iteration 62: train_loss 2.2338156700134277
Iteration 63: train_loss 2.2451837062835693
Iteration 64: train_loss 2.2028861045837402
Iteration 65: train_loss 2.2911107540130615
Iteration 66: train_loss 2.267267942428589
Iteration 67: train_loss 2.2251791954040527
Iteration 68: train_loss 2.3156516551971436
Iteration 69: train_loss 2.199329376220703
Iteration 70: train_loss 2.3088793754577637
Iteration 71: train_loss 2.2868688106536865
Iteration 72: train_loss 2.297306537628174
Iteration 73: train_loss 2.333944320678711
Iteration 74: train_loss 2.295581579208374
Iteration 75: train_loss 2.253274917602539
Iteration 76: train_loss 2.259814500808716
Iteration 77: train_loss 2.2762696743011475
Iteration 78: train_loss 2.19572377204895
Iteration 79: train_loss 2.2347042560577393
Iteration 80: train_loss 2.269453525543213
Iteration 81: train_loss 2.2540905475616455
Iteration 82: train_loss 2.300304889678955
Iteration 83: train_loss 2.262127637863159
Iteration 84: train_loss 2.1984457969665527
Iteration 85: train_loss 2.200624942779541
Iteration 86: train_loss 2.1893467903137207
Iteration 87: train_loss 2.286879062652588
Iteration 88: train_loss 2.2184371948242188
Iteration 89: train_loss 2.2842729091644287
Iteration 90: train_loss 2.301907539367676
Iteration 91: train_loss 2.2624495029449463
Iteration 92: train_loss 2.288917303085327
Iteration 93: train_loss 2.2749178409576416
Iteration 94: train_loss 2.255605697631836
Iteration 95: train_loss 2.2366883754730225
Iteration 96: train_loss 2.2043585777282715
Iteration 97: train_loss 2.242828607559204
Iteration 98: train_loss 2.227001667022705
Iteration 99: train_loss 2.2212882041931152
Iteration 100: train_loss 2.2500858306884766
Iteration 101: train_loss 2.219745397567749
Iteration 102: train_loss 2.24849534034729
Iteration 103: train_loss 2.3043925762176514
Iteration 104: train_loss 2.2683894634246826
Iteration 105: train_loss 2.2697136402130127
Iteration 106: train_loss 2.2716453075408936
Iteration 107: train_loss 2.199313163757324
Iteration 108: train_loss 2.225689649581909
Iteration 109: train_loss 2.3195383548736572
Iteration 110: train_loss 2.2956295013427734
Iteration 111: train_loss 2.217808723449707
Iteration 112: train_loss 2.277061939239502
Iteration 113: train_loss 2.2328240871429443
Iteration 114: train_loss 2.3110876083374023
Iteration 115: train_loss 2.2780075073242188
Iteration 116: train_loss 2.308166742324829
Iteration 117: train_loss 2.297353982925415
Iteration 118: train_loss 2.27217435836792
Iteration 119: train_loss 2.294097423553467
Iteration 120: train_loss 2.3206787109375
Iteration 121: train_loss 2.3335416316986084
Iteration 122: train_loss 2.309478282928467
Iteration 123: train_loss 2.249007225036621
Iteration 124: train_loss 2.14516544342041
Iteration 125: train_loss 2.1923558712005615
Iteration 126: train_loss 2.2427797317504883
Iteration 127: train_loss 2.3441572189331055
Iteration 128: train_loss 2.346406936645508
Iteration 129: train_loss 2.2445976734161377
Iteration 130: train_loss 2.348200798034668
Iteration 131: train_loss 2.382450580596924
Iteration 132: train_loss 2.3486578464508057
Iteration 133: train_loss 2.2218122482299805
Iteration 134: train_loss 2.1926703453063965
Iteration 135: train_loss 2.348393201828003
Iteration 136: train_loss 2.285928726196289
Iteration 137: train_loss 2.2233335971832275
Iteration 138: train_loss 2.218078136444092
Iteration 139: train_loss 2.324369192123413
Iteration 140: train_loss 2.1931185722351074
Iteration 141: train_loss 2.331468105316162
Iteration 142: train_loss 2.26815128326416
Iteration 143: train_loss 2.3143556118011475
Iteration 144: train_loss 2.2276480197906494
Iteration 145: train_loss 2.229267120361328
Iteration 146: train_loss 2.4129064083099365
Iteration 147: train_loss 2.3276686668395996
Iteration 148: train_loss 2.214517831802368
Iteration 149: train_loss 2.288864850997925
Iteration 150: train_loss 2.2850260734558105
Iteration 151: train_loss 2.247368097305298
Iteration 152: train_loss 2.312228202819824
Iteration 153: train_loss 2.281007766723633
Iteration 154: train_loss 2.1951889991760254
Iteration 155: train_loss 2.2509350776672363
Iteration 156: train_loss 2.334592819213867
Iteration 157: train_loss 2.237821340560913
Iteration 158: train_loss 2.2921414375305176
Iteration 159: train_loss 2.325788974761963
Iteration 160: train_loss 2.219087839126587
Iteration 161: train_loss 2.3245227336883545
Iteration 162: train_loss 2.231699228286743
Iteration 163: train_loss 2.2783010005950928
Iteration 164: train_loss 2.3211658000946045
Iteration 165: train_loss 2.19964337348938
Iteration 166: train_loss 2.198132038116455
Iteration 167: train_loss 2.3315863609313965
Iteration 168: train_loss 2.3283026218414307
Iteration 169: train_loss 2.2713358402252197
Iteration 170: train_loss 2.2576398849487305
Iteration 171: train_loss 2.2932612895965576
Iteration 172: train_loss 2.209890127182007
Iteration 173: train_loss 2.265110492706299
Iteration 174: train_loss 2.2729249000549316
Iteration 175: train_loss 2.3307018280029297
Iteration 176: train_loss 2.2588419914245605
Iteration 177: train_loss 2.174095392227173
Epoch 15: train_avg_loss 2.2637682122699285 eval_avg_acc: 0.28514976929948926 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:57:51] [32mIntermediate result: 0.28514976929948926  (Index 14)[0m
================Epoch: 16================
Iteration 1: train_loss 2.19246768951416
Iteration 2: train_loss 2.179948568344116
Iteration 3: train_loss 2.2162926197052
Iteration 4: train_loss 2.167421817779541
Iteration 5: train_loss 2.1925103664398193
Iteration 6: train_loss 2.259594440460205
Iteration 7: train_loss 2.2220640182495117
Iteration 8: train_loss 2.249885320663452
Iteration 9: train_loss 2.193385124206543
Iteration 10: train_loss 2.163029909133911
Iteration 11: train_loss 2.2196717262268066
Iteration 12: train_loss 2.296050786972046
Iteration 13: train_loss 2.1619012355804443
Iteration 14: train_loss 2.2182140350341797
Iteration 15: train_loss 2.206940174102783
Iteration 16: train_loss 2.2100067138671875
Iteration 17: train_loss 2.2201173305511475
Iteration 18: train_loss 2.2926089763641357
Iteration 19: train_loss 2.211649179458618
Iteration 20: train_loss 2.2267706394195557
Iteration 21: train_loss 2.2538950443267822
Iteration 22: train_loss 2.158055067062378
Iteration 23: train_loss 2.2056798934936523
Iteration 24: train_loss 2.240025758743286
Iteration 25: train_loss 2.2586052417755127
Iteration 26: train_loss 2.249764919281006
Iteration 27: train_loss 2.191955327987671
Iteration 28: train_loss 2.2085158824920654
Iteration 29: train_loss 2.2491953372955322
Iteration 30: train_loss 2.2111589908599854
Iteration 31: train_loss 2.2973222732543945
Iteration 32: train_loss 2.207571268081665
Iteration 33: train_loss 2.3166184425354004
Iteration 34: train_loss 2.107440948486328
Iteration 35: train_loss 2.337974786758423
Iteration 36: train_loss 2.1675708293914795
Iteration 37: train_loss 2.2225515842437744
Iteration 38: train_loss 2.141014575958252
Iteration 39: train_loss 2.2399187088012695
Iteration 40: train_loss 2.181486129760742
Iteration 41: train_loss 2.136894464492798
Iteration 42: train_loss 2.210066556930542
Iteration 43: train_loss 2.1395888328552246
Iteration 44: train_loss 2.178194522857666
Iteration 45: train_loss 2.2350502014160156
Iteration 46: train_loss 2.1928722858428955
Iteration 47: train_loss 2.1913182735443115
Iteration 48: train_loss 2.205148458480835
Iteration 49: train_loss 2.2441515922546387
Iteration 50: train_loss 2.1987292766571045
Iteration 51: train_loss 2.199542999267578
Iteration 52: train_loss 2.2449264526367188
Iteration 53: train_loss 2.2091004848480225
Iteration 54: train_loss 2.1539041996002197
Iteration 55: train_loss 2.263012647628784
Iteration 56: train_loss 2.2037289142608643
Iteration 57: train_loss 2.264840602874756
Iteration 58: train_loss 2.233093738555908
Iteration 59: train_loss 2.195694923400879
Iteration 60: train_loss 2.2143123149871826
Iteration 61: train_loss 2.146284341812134
Iteration 62: train_loss 2.150479555130005
Iteration 63: train_loss 2.1235334873199463
Iteration 64: train_loss 2.1648080348968506
Iteration 65: train_loss 2.185616970062256
Iteration 66: train_loss 2.3686506748199463
Iteration 67: train_loss 2.2362327575683594
Iteration 68: train_loss 2.281670331954956
Iteration 69: train_loss 2.2502646446228027
Iteration 70: train_loss 2.224853992462158
Iteration 71: train_loss 2.2140164375305176
Iteration 72: train_loss 2.2011141777038574
Iteration 73: train_loss 2.304898738861084
Iteration 74: train_loss 2.169273614883423
Iteration 75: train_loss 2.220276117324829
Iteration 76: train_loss 2.265606641769409
Iteration 77: train_loss 2.2814838886260986
Iteration 78: train_loss 2.246830940246582
Iteration 79: train_loss 2.1719911098480225
Iteration 80: train_loss 2.165856122970581
Iteration 81: train_loss 2.2451364994049072
Iteration 82: train_loss 2.2388832569122314
Iteration 83: train_loss 2.2222704887390137
Iteration 84: train_loss 2.259554386138916
Iteration 85: train_loss 2.1930627822875977
Iteration 86: train_loss 2.2101380825042725
Iteration 87: train_loss 2.279139280319214
Iteration 88: train_loss 2.2982943058013916
Iteration 89: train_loss 2.2159409523010254
Iteration 90: train_loss 2.192922830581665
Iteration 91: train_loss 2.2206685543060303
Iteration 92: train_loss 2.211472749710083
Iteration 93: train_loss 2.237069845199585
Iteration 94: train_loss 2.2230606079101562
Iteration 95: train_loss 2.240077018737793
Iteration 96: train_loss 2.132397413253784
Iteration 97: train_loss 2.187242031097412
Iteration 98: train_loss 2.249624729156494
Iteration 99: train_loss 2.265498638153076
Iteration 100: train_loss 2.2808279991149902
Iteration 101: train_loss 2.1832776069641113
Iteration 102: train_loss 2.187100887298584
Iteration 103: train_loss 2.191343069076538
Iteration 104: train_loss 2.297010660171509
Iteration 105: train_loss 2.2596287727355957
Iteration 106: train_loss 2.2114601135253906
Iteration 107: train_loss 2.168933868408203
Iteration 108: train_loss 2.3194034099578857
Iteration 109: train_loss 2.2249600887298584
Iteration 110: train_loss 2.1186020374298096
Iteration 111: train_loss 2.1823670864105225
Iteration 112: train_loss 2.2355868816375732
Iteration 113: train_loss 2.2160542011260986
Iteration 114: train_loss 2.2039568424224854
Iteration 115: train_loss 2.2405803203582764
Iteration 116: train_loss 2.2746715545654297
Iteration 117: train_loss 2.230665922164917
Iteration 118: train_loss 2.1501715183258057
Iteration 119: train_loss 2.2901995182037354
Iteration 120: train_loss 2.2560203075408936
Iteration 121: train_loss 2.2173893451690674
Iteration 122: train_loss 2.224525213241577
Iteration 123: train_loss 2.2624247074127197
Iteration 124: train_loss 2.274259567260742
Iteration 125: train_loss 2.2302727699279785
Iteration 126: train_loss 2.203721761703491
Iteration 127: train_loss 2.1762380599975586
Iteration 128: train_loss 2.2657370567321777
Iteration 129: train_loss 2.160397529602051
Iteration 130: train_loss 2.2709097862243652
Iteration 131: train_loss 2.28963565826416
Iteration 132: train_loss 2.1446924209594727
Iteration 133: train_loss 2.223019599914551
Iteration 134: train_loss 2.265449285507202
Iteration 135: train_loss 2.2499520778656006
Iteration 136: train_loss 2.2150728702545166
Iteration 137: train_loss 2.218031883239746
Iteration 138: train_loss 2.2511813640594482
Iteration 139: train_loss 2.2952897548675537
Iteration 140: train_loss 2.215280771255493
Iteration 141: train_loss 2.2739157676696777
Iteration 142: train_loss 2.2404468059539795
Iteration 143: train_loss 2.1838042736053467
Iteration 144: train_loss 2.237288475036621
Iteration 145: train_loss 2.238422155380249
Iteration 146: train_loss 2.223491668701172
Iteration 147: train_loss 2.207813262939453
Iteration 148: train_loss 2.2808427810668945
Iteration 149: train_loss 2.2537152767181396
Iteration 150: train_loss 2.248351573944092
Iteration 151: train_loss 2.1946871280670166
Iteration 152: train_loss 2.289144515991211
Iteration 153: train_loss 2.2517242431640625
Iteration 154: train_loss 2.1839728355407715
Iteration 155: train_loss 2.2777044773101807
Iteration 156: train_loss 2.2365002632141113
Iteration 157: train_loss 2.3027729988098145
Iteration 158: train_loss 2.2072677612304688
Iteration 159: train_loss 2.250653028488159
Iteration 160: train_loss 2.21472430229187
Iteration 161: train_loss 2.223869562149048
Iteration 162: train_loss 2.266850709915161
Iteration 163: train_loss 2.340118646621704
Iteration 164: train_loss 2.2655370235443115
Iteration 165: train_loss 2.2291417121887207
Iteration 166: train_loss 2.2041919231414795
Iteration 167: train_loss 2.2512974739074707
Iteration 168: train_loss 2.293562889099121
Iteration 169: train_loss 2.246735095977783
Iteration 170: train_loss 2.254666805267334
Iteration 171: train_loss 2.2561051845550537
Iteration 172: train_loss 2.2075653076171875
Iteration 173: train_loss 2.243809223175049
Iteration 174: train_loss 2.2692723274230957
Iteration 175: train_loss 2.149796962738037
Iteration 176: train_loss 2.162465810775757
Iteration 177: train_loss 2.318221092224121
Epoch 16: train_avg_loss 2.225502689005965 eval_avg_acc: 0.2980157301748412 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:58:37] [32mIntermediate result: 0.2980157301748412  (Index 15)[0m
================Epoch: 17================
Iteration 1: train_loss 2.2089288234710693
Iteration 2: train_loss 2.1296427249908447
Iteration 3: train_loss 2.204698324203491
Iteration 4: train_loss 2.2391178607940674
Iteration 5: train_loss 2.194854497909546
Iteration 6: train_loss 2.1457741260528564
Iteration 7: train_loss 2.1372668743133545
Iteration 8: train_loss 2.2444941997528076
Iteration 9: train_loss 2.13320255279541
Iteration 10: train_loss 2.182791233062744
Iteration 11: train_loss 2.211625099182129
Iteration 12: train_loss 2.193938970565796
Iteration 13: train_loss 2.1637091636657715
Iteration 14: train_loss 2.218404531478882
Iteration 15: train_loss 2.1688072681427
Iteration 16: train_loss 2.182851791381836
Iteration 17: train_loss 2.1954736709594727
Iteration 18: train_loss 2.244755268096924
Iteration 19: train_loss 2.231513023376465
Iteration 20: train_loss 2.21034574508667
Iteration 21: train_loss 2.256256580352783
Iteration 22: train_loss 2.198653221130371
Iteration 23: train_loss 2.2364516258239746
Iteration 24: train_loss 2.1765315532684326
Iteration 25: train_loss 2.1990230083465576
Iteration 26: train_loss 2.1696059703826904
Iteration 27: train_loss 2.185800075531006
Iteration 28: train_loss 2.157838821411133
Iteration 29: train_loss 2.197425603866577
Iteration 30: train_loss 2.124114751815796
Iteration 31: train_loss 2.126831531524658
Iteration 32: train_loss 2.207820177078247
Iteration 33: train_loss 2.1499712467193604
Iteration 34: train_loss 2.1930344104766846
Iteration 35: train_loss 2.1422250270843506
Iteration 36: train_loss 2.175893545150757
Iteration 37: train_loss 2.1937971115112305
Iteration 38: train_loss 2.178269147872925
Iteration 39: train_loss 2.226841449737549
Iteration 40: train_loss 2.119580030441284
Iteration 41: train_loss 2.2016847133636475
Iteration 42: train_loss 2.1455936431884766
Iteration 43: train_loss 2.2062997817993164
Iteration 44: train_loss 2.202789068222046
Iteration 45: train_loss 2.2837812900543213
Iteration 46: train_loss 2.2139906883239746
Iteration 47: train_loss 2.0903007984161377
Iteration 48: train_loss 2.1720049381256104
Iteration 49: train_loss 2.1964633464813232
Iteration 50: train_loss 2.1945343017578125
Iteration 51: train_loss 2.2307040691375732
Iteration 52: train_loss 2.163158655166626
Iteration 53: train_loss 2.0911779403686523
Iteration 54: train_loss 2.197742223739624
Iteration 55: train_loss 2.083024501800537
Iteration 56: train_loss 2.1254618167877197
Iteration 57: train_loss 2.099245071411133
Iteration 58: train_loss 2.1043365001678467
Iteration 59: train_loss 2.138629198074341
Iteration 60: train_loss 2.2046327590942383
Iteration 61: train_loss 2.2167718410491943
Iteration 62: train_loss 2.2142140865325928
Iteration 63: train_loss 2.1864101886749268
Iteration 64: train_loss 2.2242133617401123
Iteration 65: train_loss 2.1605024337768555
Iteration 66: train_loss 2.1367673873901367
Iteration 67: train_loss 2.209158420562744
Iteration 68: train_loss 2.1462364196777344
Iteration 69: train_loss 2.1912481784820557
Iteration 70: train_loss 2.212906837463379
Iteration 71: train_loss 2.198105812072754
Iteration 72: train_loss 2.238938093185425
Iteration 73: train_loss 2.199441909790039
Iteration 74: train_loss 2.0971415042877197
Iteration 75: train_loss 2.1357736587524414
Iteration 76: train_loss 2.144984483718872
Iteration 77: train_loss 2.1910150051116943
Iteration 78: train_loss 2.1419575214385986
Iteration 79: train_loss 2.184798240661621
Iteration 80: train_loss 2.190769910812378
Iteration 81: train_loss 2.2240066528320312
Iteration 82: train_loss 2.156514883041382
Iteration 83: train_loss 2.1399598121643066
Iteration 84: train_loss 2.169379949569702
Iteration 85: train_loss 2.1744024753570557
Iteration 86: train_loss 2.2014875411987305
Iteration 87: train_loss 2.154123067855835
Iteration 88: train_loss 2.211770534515381
Iteration 89: train_loss 2.1490635871887207
Iteration 90: train_loss 2.222104787826538
Iteration 91: train_loss 2.177985191345215
Iteration 92: train_loss 2.1752607822418213
Iteration 93: train_loss 2.2336390018463135
Iteration 94: train_loss 2.2279958724975586
Iteration 95: train_loss 2.2933573722839355
Iteration 96: train_loss 2.2372560501098633
Iteration 97: train_loss 2.219653367996216
Iteration 98: train_loss 2.128920555114746
Iteration 99: train_loss 2.2601022720336914
Iteration 100: train_loss 2.215298652648926
Iteration 101: train_loss 2.1422293186187744
Iteration 102: train_loss 2.2382004261016846
Iteration 103: train_loss 2.256866216659546
Iteration 104: train_loss 2.1619935035705566
Iteration 105: train_loss 2.1868317127227783
Iteration 106: train_loss 2.1461663246154785
Iteration 107: train_loss 2.1545073986053467
Iteration 108: train_loss 2.2472169399261475
Iteration 109: train_loss 2.1309866905212402
Iteration 110: train_loss 2.1202447414398193
Iteration 111: train_loss 2.1544718742370605
Iteration 112: train_loss 2.1688997745513916
Iteration 113: train_loss 2.125143051147461
Iteration 114: train_loss 2.2481353282928467
Iteration 115: train_loss 2.191953420639038
Iteration 116: train_loss 2.1115381717681885
Iteration 117: train_loss 2.2078182697296143
Iteration 118: train_loss 2.245123863220215
Iteration 119: train_loss 2.1798534393310547
Iteration 120: train_loss 2.093548059463501
Iteration 121: train_loss 2.203658103942871
Iteration 122: train_loss 2.2105934619903564
Iteration 123: train_loss 2.185979127883911
Iteration 124: train_loss 2.2189385890960693
Iteration 125: train_loss 2.2001662254333496
Iteration 126: train_loss 2.1948423385620117
Iteration 127: train_loss 2.157308578491211
Iteration 128: train_loss 2.3117258548736572
Iteration 129: train_loss 2.1752378940582275
Iteration 130: train_loss 2.1727449893951416
Iteration 131: train_loss 2.1784489154815674
Iteration 132: train_loss 2.15280818939209
Iteration 133: train_loss 2.166367292404175
Iteration 134: train_loss 2.208299398422241
Iteration 135: train_loss 2.1483333110809326
Iteration 136: train_loss 2.1775691509246826
Iteration 137: train_loss 2.1802661418914795
Iteration 138: train_loss 2.2061469554901123
Iteration 139: train_loss 2.2290260791778564
Iteration 140: train_loss 2.2300992012023926
Iteration 141: train_loss 2.235191583633423
Iteration 142: train_loss 2.1678626537323
Iteration 143: train_loss 2.202604055404663
Iteration 144: train_loss 2.0982367992401123
Iteration 145: train_loss 2.192746877670288
Iteration 146: train_loss 2.2640085220336914
Iteration 147: train_loss 2.1866707801818848
Iteration 148: train_loss 2.2187442779541016
Iteration 149: train_loss 2.262756586074829
Iteration 150: train_loss 2.165576457977295
Iteration 151: train_loss 2.169039726257324
Iteration 152: train_loss 2.2624995708465576
Iteration 153: train_loss 2.2092511653900146
Iteration 154: train_loss 2.246225595474243
Iteration 155: train_loss 2.243739604949951
Iteration 156: train_loss 2.224133014678955
Iteration 157: train_loss 2.2679505348205566
Iteration 158: train_loss 2.1226084232330322
Iteration 159: train_loss 2.2465004920959473
Iteration 160: train_loss 2.2058067321777344
Iteration 161: train_loss 2.1968390941619873
Iteration 162: train_loss 2.2621524333953857
Iteration 163: train_loss 2.2079033851623535
Iteration 164: train_loss 2.170835494995117
Iteration 165: train_loss 2.2143452167510986
Iteration 166: train_loss 2.337671995162964
Iteration 167: train_loss 2.2169244289398193
Iteration 168: train_loss 2.0944266319274902
Iteration 169: train_loss 2.2920801639556885
Iteration 170: train_loss 2.3011841773986816
Iteration 171: train_loss 2.278592824935913
Iteration 172: train_loss 2.1358470916748047
Iteration 173: train_loss 2.2867867946624756
Iteration 174: train_loss 2.1502785682678223
Iteration 175: train_loss 2.211947202682495
Iteration 176: train_loss 2.211276054382324
Iteration 177: train_loss 2.172955274581909
Epoch 17: train_avg_loss 2.1906883743523204 eval_avg_acc: 0.3058796475277622 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 01:59:21] [32mIntermediate result: 0.3058796475277622  (Index 16)[0m
================Epoch: 18================
Iteration 1: train_loss 2.198467254638672
Iteration 2: train_loss 2.1646203994750977
Iteration 3: train_loss 2.187849998474121
Iteration 4: train_loss 2.0674784183502197
Iteration 5: train_loss 2.1869282722473145
Iteration 6: train_loss 2.1576671600341797
Iteration 7: train_loss 2.1148643493652344
Iteration 8: train_loss 2.1771605014801025
Iteration 9: train_loss 2.1460442543029785
Iteration 10: train_loss 2.1404709815979004
Iteration 11: train_loss 2.2470340728759766
Iteration 12: train_loss 2.1524462699890137
Iteration 13: train_loss 2.1327879428863525
Iteration 14: train_loss 2.2072184085845947
Iteration 15: train_loss 2.120959520339966
Iteration 16: train_loss 2.2313954830169678
Iteration 17: train_loss 2.1415603160858154
Iteration 18: train_loss 2.086148500442505
Iteration 19: train_loss 2.1196088790893555
Iteration 20: train_loss 2.1886870861053467
Iteration 21: train_loss 2.164271593093872
Iteration 22: train_loss 2.1744027137756348
Iteration 23: train_loss 2.158391237258911
Iteration 24: train_loss 2.14583158493042
Iteration 25: train_loss 2.1678802967071533
Iteration 26: train_loss 2.0964736938476562
Iteration 27: train_loss 2.143808603286743
Iteration 28: train_loss 2.1068177223205566
Iteration 29: train_loss 2.175121545791626
Iteration 30: train_loss 2.079303026199341
Iteration 31: train_loss 2.066908597946167
Iteration 32: train_loss 2.1456735134124756
Iteration 33: train_loss 2.135096311569214
Iteration 34: train_loss 2.1590356826782227
Iteration 35: train_loss 2.167285680770874
Iteration 36: train_loss 2.183678150177002
Iteration 37: train_loss 2.134392738342285
Iteration 38: train_loss 2.1707944869995117
Iteration 39: train_loss 2.2030396461486816
Iteration 40: train_loss 2.186270236968994
Iteration 41: train_loss 2.139396905899048
Iteration 42: train_loss 2.143524408340454
Iteration 43: train_loss 2.1017680168151855
Iteration 44: train_loss 2.228074789047241
Iteration 45: train_loss 2.1876235008239746
Iteration 46: train_loss 2.188589334487915
Iteration 47: train_loss 2.087599039077759
Iteration 48: train_loss 2.0757362842559814
Iteration 49: train_loss 2.1589465141296387
Iteration 50: train_loss 2.1871438026428223
Iteration 51: train_loss 2.165557861328125
Iteration 52: train_loss 2.2152936458587646
Iteration 53: train_loss 2.122591018676758
Iteration 54: train_loss 2.1622941493988037
Iteration 55: train_loss 2.259035348892212
Iteration 56: train_loss 2.2585413455963135
Iteration 57: train_loss 2.245657205581665
Iteration 58: train_loss 2.1379401683807373
Iteration 59: train_loss 2.1485884189605713
Iteration 60: train_loss 2.182720899581909
Iteration 61: train_loss 2.2241501808166504
Iteration 62: train_loss 2.202971935272217
Iteration 63: train_loss 2.1603891849517822
Iteration 64: train_loss 2.13576340675354
Iteration 65: train_loss 2.1052684783935547
Iteration 66: train_loss 2.1537530422210693
Iteration 67: train_loss 2.140503406524658
Iteration 68: train_loss 2.1294050216674805
Iteration 69: train_loss 2.227159023284912
Iteration 70: train_loss 2.197638750076294
Iteration 71: train_loss 2.1721091270446777
Iteration 72: train_loss 2.166137456893921
Iteration 73: train_loss 2.135936975479126
Iteration 74: train_loss 2.0890700817108154
Iteration 75: train_loss 2.1549570560455322
Iteration 76: train_loss 2.149986982345581
Iteration 77: train_loss 2.150606393814087
Iteration 78: train_loss 2.1676177978515625
Iteration 79: train_loss 2.2068569660186768
Iteration 80: train_loss 2.1897361278533936
Iteration 81: train_loss 2.1067261695861816
Iteration 82: train_loss 2.165628671646118
Iteration 83: train_loss 2.2225589752197266
Iteration 84: train_loss 2.1400580406188965
Iteration 85: train_loss 2.1479239463806152
Iteration 86: train_loss 2.2015159130096436
Iteration 87: train_loss 2.2345528602600098
Iteration 88: train_loss 2.1240663528442383
Iteration 89: train_loss 2.1635549068450928
Iteration 90: train_loss 2.206394672393799
Iteration 91: train_loss 2.2185347080230713
Iteration 92: train_loss 2.1626999378204346
Iteration 93: train_loss 2.139796495437622
Iteration 94: train_loss 2.1937692165374756
Iteration 95: train_loss 2.172200918197632
Iteration 96: train_loss 2.1719586849212646
Iteration 97: train_loss 2.151527166366577
Iteration 98: train_loss 2.178621292114258
Iteration 99: train_loss 2.2324180603027344
Iteration 100: train_loss 2.181917428970337
Iteration 101: train_loss 2.168214797973633
Iteration 102: train_loss 2.1336843967437744
Iteration 103: train_loss 2.2011404037475586
Iteration 104: train_loss 2.156618595123291
Iteration 105: train_loss 2.0923593044281006
Iteration 106: train_loss 2.2567942142486572
Iteration 107: train_loss 2.212085485458374
Iteration 108: train_loss 2.1391143798828125
Iteration 109: train_loss 2.2099835872650146
Iteration 110: train_loss 2.191606044769287
Iteration 111: train_loss 2.1169581413269043
Iteration 112: train_loss 2.153055429458618
Iteration 113: train_loss 2.168104410171509
Iteration 114: train_loss 2.141798973083496
Iteration 115: train_loss 2.1565959453582764
Iteration 116: train_loss 2.150789737701416
Iteration 117: train_loss 2.1113431453704834
Iteration 118: train_loss 2.216257095336914
Iteration 119: train_loss 2.1253013610839844
Iteration 120: train_loss 2.1115851402282715
Iteration 121: train_loss 2.179753303527832
Iteration 122: train_loss 2.1100194454193115
Iteration 123: train_loss 2.259899854660034
Iteration 124: train_loss 2.1878855228424072
Iteration 125: train_loss 2.207266330718994
Iteration 126: train_loss 2.0228042602539062
Iteration 127: train_loss 2.0647237300872803
Iteration 128: train_loss 2.071437358856201
Iteration 129: train_loss 2.157850503921509
Iteration 130: train_loss 2.14373517036438
Iteration 131: train_loss 2.232295513153076
Iteration 132: train_loss 2.1542224884033203
Iteration 133: train_loss 2.157432794570923
Iteration 134: train_loss 2.1179404258728027
Iteration 135: train_loss 2.169649839401245
Iteration 136: train_loss 2.21337628364563
Iteration 137: train_loss 2.169722080230713
Iteration 138: train_loss 2.168694257736206
Iteration 139: train_loss 2.2379980087280273
Iteration 140: train_loss 2.1993048191070557
Iteration 141: train_loss 2.1893768310546875
Iteration 142: train_loss 2.3036558628082275
Iteration 143: train_loss 2.2022411823272705
Iteration 144: train_loss 2.211588144302368
Iteration 145: train_loss 2.15600323677063
Iteration 146: train_loss 2.2630667686462402
Iteration 147: train_loss 2.239955425262451
Iteration 148: train_loss 2.120340585708618
Iteration 149: train_loss 2.196575164794922
Iteration 150: train_loss 2.264791488647461
Iteration 151: train_loss 2.1883199214935303
Iteration 152: train_loss 2.213435411453247
Iteration 153: train_loss 2.1198716163635254
Iteration 154: train_loss 2.128167152404785
Iteration 155: train_loss 2.101224184036255
Iteration 156: train_loss 2.1692566871643066
Iteration 157: train_loss 2.2030563354492188
Iteration 158: train_loss 2.1321723461151123
Iteration 159: train_loss 2.222935199737549
Iteration 160: train_loss 2.173628091812134
Iteration 161: train_loss 2.1740453243255615
Iteration 162: train_loss 2.1650989055633545
Iteration 163: train_loss 2.224710464477539
Iteration 164: train_loss 2.254385232925415
Iteration 165: train_loss 2.218170404434204
Iteration 166: train_loss 2.1978070735931396
Iteration 167: train_loss 2.1523611545562744
Iteration 168: train_loss 2.191134214401245
Iteration 169: train_loss 2.147454023361206
Iteration 170: train_loss 2.1244547367095947
Iteration 171: train_loss 2.24837064743042
Iteration 172: train_loss 2.2545416355133057
Iteration 173: train_loss 2.196547746658325
Iteration 174: train_loss 2.1977477073669434
Iteration 175: train_loss 2.3090004920959473
Iteration 176: train_loss 2.1997854709625244
Iteration 177: train_loss 2.2520055770874023
Epoch 18: train_avg_loss 2.1697944894348833 eval_avg_acc: 0.2896012545766303 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:00:06] [32mIntermediate result: 0.2896012545766303  (Index 17)[0m
================Epoch: 19================
Iteration 1: train_loss 2.1148993968963623
Iteration 2: train_loss 2.1635632514953613
Iteration 3: train_loss 2.11403489112854
Iteration 4: train_loss 2.180840492248535
Iteration 5: train_loss 2.0823616981506348
Iteration 6: train_loss 2.132532835006714
Iteration 7: train_loss 2.052327871322632
Iteration 8: train_loss 2.1590142250061035
Iteration 9: train_loss 2.069753646850586
Iteration 10: train_loss 2.0455918312072754
Iteration 11: train_loss 2.100221872329712
Iteration 12: train_loss 2.1330227851867676
Iteration 13: train_loss 2.0509817600250244
Iteration 14: train_loss 2.068966865539551
Iteration 15: train_loss 2.167970657348633
Iteration 16: train_loss 2.2003142833709717
Iteration 17: train_loss 2.0833017826080322
Iteration 18: train_loss 2.142324924468994
Iteration 19: train_loss 2.1657886505126953
Iteration 20: train_loss 2.121943473815918
Iteration 21: train_loss 2.1150786876678467
Iteration 22: train_loss 2.118875503540039
Iteration 23: train_loss 2.1301684379577637
Iteration 24: train_loss 2.1016945838928223
Iteration 25: train_loss 2.1211094856262207
Iteration 26: train_loss 2.0814125537872314
Iteration 27: train_loss 2.22613525390625
Iteration 28: train_loss 2.1899185180664062
Iteration 29: train_loss 2.1559674739837646
Iteration 30: train_loss 2.019299268722534
Iteration 31: train_loss 2.073387622833252
Iteration 32: train_loss 2.1953272819519043
Iteration 33: train_loss 2.241896152496338
Iteration 34: train_loss 2.2236125469207764
Iteration 35: train_loss 2.1665329933166504
Iteration 36: train_loss 2.1138367652893066
Iteration 37: train_loss 2.048442840576172
Iteration 38: train_loss 2.1910316944122314
Iteration 39: train_loss 2.0686864852905273
Iteration 40: train_loss 2.1268177032470703
Iteration 41: train_loss 2.1109120845794678
Iteration 42: train_loss 2.1802515983581543
Iteration 43: train_loss 2.044351577758789
Iteration 44: train_loss 2.1416618824005127
Iteration 45: train_loss 2.119792938232422
Iteration 46: train_loss 2.1068103313446045
Iteration 47: train_loss 2.1485421657562256
Iteration 48: train_loss 2.1091885566711426
Iteration 49: train_loss 2.108813524246216
Iteration 50: train_loss 2.1633248329162598
Iteration 51: train_loss 2.161886692047119
Iteration 52: train_loss 2.1374499797821045
Iteration 53: train_loss 2.1703741550445557
Iteration 54: train_loss 2.130952835083008
Iteration 55: train_loss 2.164990186691284
Iteration 56: train_loss 2.099182367324829
Iteration 57: train_loss 2.1272242069244385
Iteration 58: train_loss 2.2267398834228516
Iteration 59: train_loss 2.122819185256958
Iteration 60: train_loss 2.0663347244262695
Iteration 61: train_loss 2.139260768890381
Iteration 62: train_loss 2.104020833969116
Iteration 63: train_loss 2.143611192703247
Iteration 64: train_loss 2.1129355430603027
Iteration 65: train_loss 2.128697395324707
Iteration 66: train_loss 2.125149965286255
Iteration 67: train_loss 2.095832586288452
Iteration 68: train_loss 2.189364433288574
Iteration 69: train_loss 2.0626018047332764
Iteration 70: train_loss 2.1387999057769775
Iteration 71: train_loss 2.0595927238464355
Iteration 72: train_loss 2.0803868770599365
Iteration 73: train_loss 2.0961127281188965
Iteration 74: train_loss 2.156090259552002
Iteration 75: train_loss 2.209866523742676
Iteration 76: train_loss 2.0933997631073
Iteration 77: train_loss 2.1526198387145996
Iteration 78: train_loss 2.117614984512329
Iteration 79: train_loss 2.159224510192871
Iteration 80: train_loss 2.209132671356201
Iteration 81: train_loss 2.110295057296753
Iteration 82: train_loss 2.181974172592163
Iteration 83: train_loss 2.24983286857605
Iteration 84: train_loss 2.0548782348632812
Iteration 85: train_loss 2.1805050373077393
Iteration 86: train_loss 2.2245442867279053
Iteration 87: train_loss 2.1713061332702637
Iteration 88: train_loss 2.1335091590881348
Iteration 89: train_loss 2.2307558059692383
Iteration 90: train_loss 2.148569107055664
Iteration 91: train_loss 2.11338210105896
Iteration 92: train_loss 2.1338701248168945
Iteration 93: train_loss 2.07915997505188
Iteration 94: train_loss 2.040200710296631
Iteration 95: train_loss 2.164219379425049
Iteration 96: train_loss 2.151604652404785
Iteration 97: train_loss 2.170114278793335
Iteration 98: train_loss 2.2485976219177246
Iteration 99: train_loss 2.0863099098205566
Iteration 100: train_loss 2.1282589435577393
Iteration 101: train_loss 2.1479568481445312
Iteration 102: train_loss 2.175751209259033
Iteration 103: train_loss 2.1523044109344482
Iteration 104: train_loss 2.214646577835083
Iteration 105: train_loss 2.277602434158325
Iteration 106: train_loss 2.1915364265441895
Iteration 107: train_loss 2.1457107067108154
Iteration 108: train_loss 2.1011483669281006
Iteration 109: train_loss 2.1125097274780273
Iteration 110: train_loss 2.1209263801574707
Iteration 111: train_loss 2.1840782165527344
Iteration 112: train_loss 2.136183261871338
Iteration 113: train_loss 2.22395658493042
Iteration 114: train_loss 2.186082363128662
Iteration 115: train_loss 2.2010622024536133
Iteration 116: train_loss 2.150611639022827
Iteration 117: train_loss 2.1287283897399902
Iteration 118: train_loss 2.1673667430877686
Iteration 119: train_loss 2.099478244781494
Iteration 120: train_loss 2.1117522716522217
Iteration 121: train_loss 2.1940057277679443
Iteration 122: train_loss 2.202692747116089
Iteration 123: train_loss 2.0947914123535156
Iteration 124: train_loss 2.2376015186309814
Iteration 125: train_loss 2.1795783042907715
Iteration 126: train_loss 2.1325085163116455
Iteration 127: train_loss 2.0967636108398438
Iteration 128: train_loss 2.111820936203003
Iteration 129: train_loss 2.150099039077759
Iteration 130: train_loss 2.0592496395111084
Iteration 131: train_loss 2.16915225982666
Iteration 132: train_loss 2.1073427200317383
Iteration 133: train_loss 2.1628360748291016
Iteration 134: train_loss 2.17547607421875
Iteration 135: train_loss 2.090641498565674
Iteration 136: train_loss 2.139247417449951
Iteration 137: train_loss 2.041374683380127
Iteration 138: train_loss 2.11095929145813
Iteration 139: train_loss 2.076443672180176
Iteration 140: train_loss 2.2017881870269775
Iteration 141: train_loss 2.202741861343384
Iteration 142: train_loss 2.093611717224121
Iteration 143: train_loss 2.1934988498687744
Iteration 144: train_loss 2.176767349243164
Iteration 145: train_loss 2.1478817462921143
Iteration 146: train_loss 2.1827237606048584
Iteration 147: train_loss 2.116102695465088
Iteration 148: train_loss 2.160618543624878
Iteration 149: train_loss 2.199136257171631
Iteration 150: train_loss 2.0812313556671143
Iteration 151: train_loss 2.189960241317749
Iteration 152: train_loss 2.0310680866241455
Iteration 153: train_loss 2.1505744457244873
Iteration 154: train_loss 2.1939375400543213
Iteration 155: train_loss 2.1734869480133057
Iteration 156: train_loss 2.111696720123291
Iteration 157: train_loss 2.148627758026123
Iteration 158: train_loss 2.235910654067993
Iteration 159: train_loss 2.180879592895508
Iteration 160: train_loss 2.1502459049224854
Iteration 161: train_loss 2.1907200813293457
Iteration 162: train_loss 2.1708061695098877
Iteration 163: train_loss 2.1772305965423584
Iteration 164: train_loss 2.1501197814941406
Iteration 165: train_loss 2.1507396697998047
Iteration 166: train_loss 2.1079750061035156
Iteration 167: train_loss 2.0938098430633545
Iteration 168: train_loss 2.034342050552368
Iteration 169: train_loss 2.178072214126587
Iteration 170: train_loss 2.1951630115509033
Iteration 171: train_loss 2.057116985321045
Iteration 172: train_loss 2.190009593963623
Iteration 173: train_loss 2.1642069816589355
Iteration 174: train_loss 2.256446599960327
Iteration 175: train_loss 2.1277830600738525
Iteration 176: train_loss 2.0896716117858887
Iteration 177: train_loss 2.1956005096435547
Epoch 19: train_avg_loss 2.140627557948484 eval_avg_acc: 0.3091674623703928 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:00:50] [32mIntermediate result: 0.3091674623703928  (Index 18)[0m
================Epoch: 20================
Iteration 1: train_loss 2.11555814743042
Iteration 2: train_loss 2.150592088699341
Iteration 3: train_loss 2.094961404800415
Iteration 4: train_loss 2.1031534671783447
Iteration 5: train_loss 2.066783905029297
Iteration 6: train_loss 2.074770927429199
Iteration 7: train_loss 2.0892045497894287
Iteration 8: train_loss 2.0234358310699463
Iteration 9: train_loss 2.135981321334839
Iteration 10: train_loss 2.1797027587890625
Iteration 11: train_loss 2.099030017852783
Iteration 12: train_loss 2.1479833126068115
Iteration 13: train_loss 2.014172077178955
Iteration 14: train_loss 2.012979745864868
Iteration 15: train_loss 2.0383543968200684
Iteration 16: train_loss 2.1334588527679443
Iteration 17: train_loss 2.0320258140563965
Iteration 18: train_loss 2.121889591217041
Iteration 19: train_loss 2.058814764022827
Iteration 20: train_loss 2.048311471939087
Iteration 21: train_loss 2.1330063343048096
Iteration 22: train_loss 2.123018741607666
Iteration 23: train_loss 2.108952522277832
Iteration 24: train_loss 2.0773508548736572
Iteration 25: train_loss 2.1656782627105713
Iteration 26: train_loss 2.035418748855591
Iteration 27: train_loss 2.0705084800720215
Iteration 28: train_loss 2.014410972595215
Iteration 29: train_loss 2.174828052520752
Iteration 30: train_loss 1.9692437648773193
Iteration 31: train_loss 2.1160314083099365
Iteration 32: train_loss 2.088247537612915
Iteration 33: train_loss 2.0847907066345215
Iteration 34: train_loss 2.1497857570648193
Iteration 35: train_loss 2.1423470973968506
Iteration 36: train_loss 2.0554964542388916
Iteration 37: train_loss 2.203888416290283
Iteration 38: train_loss 2.1426289081573486
Iteration 39: train_loss 2.18390154838562
Iteration 40: train_loss 2.09489369392395
Iteration 41: train_loss 2.107511043548584
Iteration 42: train_loss 2.054896354675293
Iteration 43: train_loss 2.0432379245758057
Iteration 44: train_loss 2.1341912746429443
Iteration 45: train_loss 2.1391074657440186
Iteration 46: train_loss 2.160134792327881
Iteration 47: train_loss 2.079078435897827
Iteration 48: train_loss 2.1117424964904785
Iteration 49: train_loss 2.0906589031219482
Iteration 50: train_loss 2.1781814098358154
Iteration 51: train_loss 2.1486291885375977
Iteration 52: train_loss 2.0812060832977295
Iteration 53: train_loss 2.1769628524780273
Iteration 54: train_loss 2.13687801361084
Iteration 55: train_loss 2.1356849670410156
Iteration 56: train_loss 2.140570640563965
Iteration 57: train_loss 2.1205272674560547
Iteration 58: train_loss 2.160245656967163
Iteration 59: train_loss 2.095937728881836
Iteration 60: train_loss 2.148418426513672
Iteration 61: train_loss 2.182441234588623
Iteration 62: train_loss 2.1011152267456055
Iteration 63: train_loss 2.1665189266204834
Iteration 64: train_loss 2.1397671699523926
Iteration 65: train_loss 2.100529432296753
Iteration 66: train_loss 2.1266307830810547
Iteration 67: train_loss 2.140373706817627
Iteration 68: train_loss 2.100832462310791
Iteration 69: train_loss 2.1921262741088867
Iteration 70: train_loss 2.1547586917877197
Iteration 71: train_loss 2.026411533355713
Iteration 72: train_loss 2.0731523036956787
Iteration 73: train_loss 2.1041412353515625
Iteration 74: train_loss 2.0790345668792725
Iteration 75: train_loss 2.0456278324127197
Iteration 76: train_loss 2.0905070304870605
Iteration 77: train_loss 2.120567798614502
Iteration 78: train_loss 2.144806385040283
Iteration 79: train_loss 2.071168899536133
Iteration 80: train_loss 2.129051446914673
Iteration 81: train_loss 2.120344400405884
Iteration 82: train_loss 2.2228012084960938
Iteration 83: train_loss 2.0695106983184814
Iteration 84: train_loss 2.0640127658843994
Iteration 85: train_loss 2.073742151260376
Iteration 86: train_loss 2.1040689945220947
Iteration 87: train_loss 2.0616111755371094
Iteration 88: train_loss 2.1583333015441895
Iteration 89: train_loss 2.0805506706237793
Iteration 90: train_loss 2.1306822299957275
Iteration 91: train_loss 2.124448537826538
Iteration 92: train_loss 2.1320550441741943
Iteration 93: train_loss 2.077538251876831
Iteration 94: train_loss 2.1104235649108887
Iteration 95: train_loss 2.10646653175354
Iteration 96: train_loss 1.9711679220199585
Iteration 97: train_loss 2.0870931148529053
Iteration 98: train_loss 2.1018712520599365
Iteration 99: train_loss 2.1162936687469482
Iteration 100: train_loss 2.1033482551574707
Iteration 101: train_loss 2.1647491455078125
Iteration 102: train_loss 2.0984184741973877
Iteration 103: train_loss 2.0312118530273438
Iteration 104: train_loss 2.110775947570801
Iteration 105: train_loss 2.090492010116577
Iteration 106: train_loss 2.156022787094116
Iteration 107: train_loss 2.1316068172454834
Iteration 108: train_loss 2.1041369438171387
Iteration 109: train_loss 2.121767282485962
Iteration 110: train_loss 2.1265792846679688
Iteration 111: train_loss 2.119302988052368
Iteration 112: train_loss 2.1420531272888184
Iteration 113: train_loss 2.1180338859558105
Iteration 114: train_loss 2.1330089569091797
Iteration 115: train_loss 2.137535810470581
Iteration 116: train_loss 2.150174140930176
Iteration 117: train_loss 2.1615421772003174
Iteration 118: train_loss 2.127490520477295
Iteration 119: train_loss 2.0790934562683105
Iteration 120: train_loss 2.200279474258423
Iteration 121: train_loss 2.1434338092803955
Iteration 122: train_loss 2.1759963035583496
Iteration 123: train_loss 2.105272054672241
Iteration 124: train_loss 2.12271785736084
Iteration 125: train_loss 2.0988266468048096
Iteration 126: train_loss 2.0872275829315186
Iteration 127: train_loss 2.107534885406494
Iteration 128: train_loss 2.1932952404022217
Iteration 129: train_loss 2.152127265930176
Iteration 130: train_loss 2.1048293113708496
Iteration 131: train_loss 2.1113593578338623
Iteration 132: train_loss 2.099945068359375
Iteration 133: train_loss 2.0985076427459717
Iteration 134: train_loss 2.108506679534912
Iteration 135: train_loss 2.139448404312134
Iteration 136: train_loss 2.0210812091827393
Iteration 137: train_loss 2.069831132888794
Iteration 138: train_loss 2.146200656890869
Iteration 139: train_loss 2.125859498977661
Iteration 140: train_loss 2.2199506759643555
Iteration 141: train_loss 2.1826651096343994
Iteration 142: train_loss 2.2292191982269287
Iteration 143: train_loss 2.1893022060394287
Iteration 144: train_loss 2.0430490970611572
Iteration 145: train_loss 2.115497350692749
Iteration 146: train_loss 2.1427204608917236
Iteration 147: train_loss 2.1423897743225098
Iteration 148: train_loss 2.1764230728149414
Iteration 149: train_loss 2.1213443279266357
Iteration 150: train_loss 2.1179230213165283
Iteration 151: train_loss 2.123947858810425
Iteration 152: train_loss 2.1197736263275146
Iteration 153: train_loss 2.139909029006958
Iteration 154: train_loss 2.1207401752471924
Iteration 155: train_loss 2.138223648071289
Iteration 156: train_loss 2.0775980949401855
Iteration 157: train_loss 2.1504945755004883
Iteration 158: train_loss 2.07796311378479
Iteration 159: train_loss 2.1617348194122314
Iteration 160: train_loss 2.201319932937622
Iteration 161: train_loss 2.118760824203491
Iteration 162: train_loss 2.1594748497009277
Iteration 163: train_loss 2.1101033687591553
Iteration 164: train_loss 2.131992816925049
Iteration 165: train_loss 2.2007064819335938
Iteration 166: train_loss 2.074519395828247
Iteration 167: train_loss 2.1550745964050293
Iteration 168: train_loss 2.0387027263641357
Iteration 169: train_loss 2.1088809967041016
Iteration 170: train_loss 2.034719467163086
Iteration 171: train_loss 2.0574724674224854
Iteration 172: train_loss 2.0556790828704834
Iteration 173: train_loss 2.080092430114746
Iteration 174: train_loss 2.023837089538574
Iteration 175: train_loss 2.100128650665283
Iteration 176: train_loss 2.1190690994262695
Iteration 177: train_loss 2.2164087295532227
Epoch 20: train_avg_loss 2.1136689731630227 eval_avg_acc: 0.3089857664420606 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:01:33] [32mIntermediate result: 0.3089857664420606  (Index 19)[0m
================Epoch: 21================
Iteration 1: train_loss 2.081209897994995
Iteration 2: train_loss 2.00954008102417
Iteration 3: train_loss 2.0375924110412598
Iteration 4: train_loss 2.0774970054626465
Iteration 5: train_loss 2.083583116531372
Iteration 6: train_loss 2.079414129257202
Iteration 7: train_loss 2.0599138736724854
Iteration 8: train_loss 2.073340892791748
Iteration 9: train_loss 2.051156997680664
Iteration 10: train_loss 2.028109550476074
Iteration 11: train_loss 1.9210108518600464
Iteration 12: train_loss 1.967081069946289
Iteration 13: train_loss 2.072843313217163
Iteration 14: train_loss 2.0841073989868164
Iteration 15: train_loss 2.0798730850219727
Iteration 16: train_loss 2.0649092197418213
Iteration 17: train_loss 2.09369158744812
Iteration 18: train_loss 2.104990005493164
Iteration 19: train_loss 2.1005795001983643
Iteration 20: train_loss 2.0799145698547363
Iteration 21: train_loss 2.131117343902588
Iteration 22: train_loss 2.0555977821350098
Iteration 23: train_loss 2.0100433826446533
Iteration 24: train_loss 2.1463751792907715
Iteration 25: train_loss 2.069427013397217
Iteration 26: train_loss 2.1499722003936768
Iteration 27: train_loss 2.0516669750213623
Iteration 28: train_loss 2.0335474014282227
Iteration 29: train_loss 2.0253982543945312
Iteration 30: train_loss 1.9201923608779907
Iteration 31: train_loss 2.146362781524658
Iteration 32: train_loss 2.002446413040161
Iteration 33: train_loss 2.102236747741699
Iteration 34: train_loss 2.0447936058044434
Iteration 35: train_loss 2.0836658477783203
Iteration 36: train_loss 2.1333181858062744
Iteration 37: train_loss 2.0506887435913086
Iteration 38: train_loss 2.053823947906494
Iteration 39: train_loss 2.1139633655548096
Iteration 40: train_loss 2.112375020980835
Iteration 41: train_loss 2.0572195053100586
Iteration 42: train_loss 2.0603909492492676
Iteration 43: train_loss 2.0458145141601562
Iteration 44: train_loss 2.089277505874634
Iteration 45: train_loss 2.0852577686309814
Iteration 46: train_loss 2.0908029079437256
Iteration 47: train_loss 2.0790274143218994
Iteration 48: train_loss 2.0650436878204346
Iteration 49: train_loss 2.0514936447143555
Iteration 50: train_loss 2.10384202003479
Iteration 51: train_loss 2.16166353225708
Iteration 52: train_loss 2.0418107509613037
Iteration 53: train_loss 2.0905861854553223
Iteration 54: train_loss 2.087526798248291
Iteration 55: train_loss 2.084402322769165
Iteration 56: train_loss 2.138887882232666
Iteration 57: train_loss 2.0286529064178467
Iteration 58: train_loss 2.1085641384124756
Iteration 59: train_loss 2.0702526569366455
Iteration 60: train_loss 2.0180537700653076
Iteration 61: train_loss 2.037709951400757
Iteration 62: train_loss 2.117086172103882
Iteration 63: train_loss 2.122647523880005
Iteration 64: train_loss 2.0383472442626953
Iteration 65: train_loss 2.0618817806243896
Iteration 66: train_loss 2.1418228149414062
Iteration 67: train_loss 2.141206741333008
Iteration 68: train_loss 2.098020553588867
Iteration 69: train_loss 2.0737223625183105
Iteration 70: train_loss 2.055453300476074
Iteration 71: train_loss 2.1631534099578857
Iteration 72: train_loss 2.078314781188965
Iteration 73: train_loss 2.088216781616211
Iteration 74: train_loss 2.0041656494140625
Iteration 75: train_loss 2.069730043411255
Iteration 76: train_loss 2.0801684856414795
Iteration 77: train_loss 2.0706801414489746
Iteration 78: train_loss 2.078296422958374
Iteration 79: train_loss 2.162411689758301
Iteration 80: train_loss 2.115696907043457
Iteration 81: train_loss 2.0610203742980957
Iteration 82: train_loss 2.11922550201416
Iteration 83: train_loss 2.1243040561676025
Iteration 84: train_loss 2.1450953483581543
Iteration 85: train_loss 1.9926866292953491
Iteration 86: train_loss 2.0582451820373535
Iteration 87: train_loss 2.0672924518585205
Iteration 88: train_loss 2.2071969509124756
Iteration 89: train_loss 2.11167311668396
Iteration 90: train_loss 2.1039674282073975
Iteration 91: train_loss 2.113055467605591
Iteration 92: train_loss 2.0907232761383057
Iteration 93: train_loss 2.0373473167419434
Iteration 94: train_loss 2.097414970397949
Iteration 95: train_loss 2.1270670890808105
Iteration 96: train_loss 2.05815052986145
Iteration 97: train_loss 2.091163396835327
Iteration 98: train_loss 2.0337421894073486
Iteration 99: train_loss 2.077274799346924
Iteration 100: train_loss 2.003803253173828
Iteration 101: train_loss 2.0580575466156006
Iteration 102: train_loss 2.1309962272644043
Iteration 103: train_loss 2.130986452102661
Iteration 104: train_loss 2.1886019706726074
Iteration 105: train_loss 2.096433639526367
Iteration 106: train_loss 2.1211087703704834
Iteration 107: train_loss 2.0979061126708984
Iteration 108: train_loss 2.15544056892395
Iteration 109: train_loss 2.049462080001831
Iteration 110: train_loss 2.0309603214263916
Iteration 111: train_loss 2.0793938636779785
Iteration 112: train_loss 2.1288630962371826
Iteration 113: train_loss 2.0744903087615967
Iteration 114: train_loss 2.153347969055176
Iteration 115: train_loss 2.0962066650390625
Iteration 116: train_loss 2.1127984523773193
Iteration 117: train_loss 2.1061620712280273
Iteration 118: train_loss 2.0639004707336426
Iteration 119: train_loss 2.063521146774292
Iteration 120: train_loss 2.102444648742676
Iteration 121: train_loss 2.0829310417175293
Iteration 122: train_loss 2.0385711193084717
Iteration 123: train_loss 2.089043617248535
Iteration 124: train_loss 2.1678991317749023
Iteration 125: train_loss 2.142956018447876
Iteration 126: train_loss 2.0476629734039307
Iteration 127: train_loss 2.0785133838653564
Iteration 128: train_loss 2.1238276958465576
Iteration 129: train_loss 2.1111180782318115
Iteration 130: train_loss 2.101579427719116
Iteration 131: train_loss 2.0825774669647217
Iteration 132: train_loss 2.0433218479156494
Iteration 133: train_loss 2.1888110637664795
Iteration 134: train_loss 2.0965993404388428
Iteration 135: train_loss 2.0421273708343506
Iteration 136: train_loss 2.0774598121643066
Iteration 137: train_loss 2.072007417678833
Iteration 138: train_loss 2.098665714263916
Iteration 139: train_loss 2.014692783355713
Iteration 140: train_loss 2.1127967834472656
Iteration 141: train_loss 2.093668222427368
Iteration 142: train_loss 2.078047037124634
Iteration 143: train_loss 2.1439356803894043
Iteration 144: train_loss 2.1861019134521484
Iteration 145: train_loss 2.0358119010925293
Iteration 146: train_loss 2.0134494304656982
Iteration 147: train_loss 2.057852029800415
Iteration 148: train_loss 2.099940299987793
Iteration 149: train_loss 2.0941147804260254
Iteration 150: train_loss 2.057466506958008
Iteration 151: train_loss 2.074786901473999
Iteration 152: train_loss 2.0507705211639404
Iteration 153: train_loss 2.126471757888794
Iteration 154: train_loss 2.147681951522827
Iteration 155: train_loss 2.1255481243133545
Iteration 156: train_loss 2.1613996028900146
Iteration 157: train_loss 2.1595306396484375
Iteration 158: train_loss 2.138606309890747
Iteration 159: train_loss 2.1722328662872314
Iteration 160: train_loss 2.058651924133301
Iteration 161: train_loss 2.1244077682495117
Iteration 162: train_loss 2.0427675247192383
Iteration 163: train_loss 2.1128952503204346
Iteration 164: train_loss 2.057260751724243
Iteration 165: train_loss 2.0403199195861816
Iteration 166: train_loss 1.977725625038147
Iteration 167: train_loss 2.1135501861572266
Iteration 168: train_loss 2.1085944175720215
Iteration 169: train_loss 2.0797741413116455
Iteration 170: train_loss 2.0543222427368164
Iteration 171: train_loss 2.0822529792785645
Iteration 172: train_loss 2.1286046504974365
Iteration 173: train_loss 2.0913732051849365
Iteration 174: train_loss 2.0726478099823
Iteration 175: train_loss 2.073983907699585
Iteration 176: train_loss 2.0842039585113525
Iteration 177: train_loss 2.0079128742218018
Epoch 21: train_avg_loss 2.083887198550553 eval_avg_acc: 0.2986265074175001 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:02:17] [32mIntermediate result: 0.2986265074175001  (Index 20)[0m
================Epoch: 22================
Iteration 1: train_loss 2.073854923248291
Iteration 2: train_loss 2.0424959659576416
Iteration 3: train_loss 2.0661227703094482
Iteration 4: train_loss 2.0345492362976074
Iteration 5: train_loss 2.0466105937957764
Iteration 6: train_loss 1.874918818473816
Iteration 7: train_loss 2.0351974964141846
Iteration 8: train_loss 2.0194005966186523
Iteration 9: train_loss 1.9995784759521484
Iteration 10: train_loss 2.0313501358032227
Iteration 11: train_loss 1.9991792440414429
Iteration 12: train_loss 2.080275774002075
Iteration 13: train_loss 1.9836610555648804
Iteration 14: train_loss 2.0584793090820312
Iteration 15: train_loss 1.988577127456665
Iteration 16: train_loss 2.0713911056518555
Iteration 17: train_loss 2.017760753631592
Iteration 18: train_loss 2.0543222427368164
Iteration 19: train_loss 2.0448474884033203
Iteration 20: train_loss 2.077188014984131
Iteration 21: train_loss 2.0741755962371826
Iteration 22: train_loss 1.9326701164245605
Iteration 23: train_loss 2.059279441833496
Iteration 24: train_loss 2.055469512939453
Iteration 25: train_loss 2.062971830368042
Iteration 26: train_loss 2.0884952545166016
Iteration 27: train_loss 2.0146265029907227
Iteration 28: train_loss 2.1243040561676025
Iteration 29: train_loss 2.127830743789673
Iteration 30: train_loss 2.0522162914276123
Iteration 31: train_loss 2.051741123199463
Iteration 32: train_loss 2.0208945274353027
Iteration 33: train_loss 1.9798283576965332
Iteration 34: train_loss 2.0276784896850586
Iteration 35: train_loss 2.046494483947754
Iteration 36: train_loss 2.02995228767395
Iteration 37: train_loss 2.0613930225372314
Iteration 38: train_loss 2.120396614074707
Iteration 39: train_loss 2.1055734157562256
Iteration 40: train_loss 2.040085792541504
Iteration 41: train_loss 2.1023831367492676
Iteration 42: train_loss 2.087090015411377
Iteration 43: train_loss 2.011941432952881
Iteration 44: train_loss 2.029216766357422
Iteration 45: train_loss 2.0534799098968506
Iteration 46: train_loss 2.0667645931243896
Iteration 47: train_loss 2.062870979309082
Iteration 48: train_loss 2.0389091968536377
Iteration 49: train_loss 1.9904077053070068
Iteration 50: train_loss 2.0206871032714844
Iteration 51: train_loss 2.1273443698883057
Iteration 52: train_loss 2.0578858852386475
Iteration 53: train_loss 2.042715311050415
Iteration 54: train_loss 2.0392909049987793
Iteration 55: train_loss 2.0626049041748047
Iteration 56: train_loss 2.078972578048706
Iteration 57: train_loss 2.0275330543518066
Iteration 58: train_loss 2.1639273166656494
Iteration 59: train_loss 2.042642116546631
Iteration 60: train_loss 2.0708649158477783
Iteration 61: train_loss 2.0417540073394775
Iteration 62: train_loss 2.0481762886047363
Iteration 63: train_loss 2.019697427749634
Iteration 64: train_loss 2.0663769245147705
Iteration 65: train_loss 2.08805775642395
Iteration 66: train_loss 2.042210340499878
Iteration 67: train_loss 2.0696678161621094
Iteration 68: train_loss 2.0937743186950684
Iteration 69: train_loss 2.047337055206299
Iteration 70: train_loss 2.003443479537964
Iteration 71: train_loss 2.015465021133423
Iteration 72: train_loss 2.0707569122314453
Iteration 73: train_loss 2.1033802032470703
Iteration 74: train_loss 2.108376979827881
Iteration 75: train_loss 2.0282421112060547
Iteration 76: train_loss 2.1021008491516113
Iteration 77: train_loss 2.0496456623077393
Iteration 78: train_loss 2.115751266479492
Iteration 79: train_loss 2.0706984996795654
Iteration 80: train_loss 2.004218339920044
Iteration 81: train_loss 2.087707281112671
Iteration 82: train_loss 2.0826361179351807
Iteration 83: train_loss 2.0877318382263184
Iteration 84: train_loss 1.9732874631881714
Iteration 85: train_loss 2.111168622970581
Iteration 86: train_loss 2.0206313133239746
Iteration 87: train_loss 2.14955735206604
Iteration 88: train_loss 2.0604443550109863
Iteration 89: train_loss 2.0736422538757324
Iteration 90: train_loss 2.0484461784362793
Iteration 91: train_loss 2.0593364238739014
Iteration 92: train_loss 1.9958523511886597
Iteration 93: train_loss 2.0868725776672363
Iteration 94: train_loss 2.0364723205566406
Iteration 95: train_loss 2.088385581970215
Iteration 96: train_loss 2.132274627685547
Iteration 97: train_loss 2.0508580207824707
Iteration 98: train_loss 2.0308897495269775
Iteration 99: train_loss 2.039536952972412
Iteration 100: train_loss 2.066269636154175
Iteration 101: train_loss 2.1375088691711426
Iteration 102: train_loss 2.068920373916626
Iteration 103: train_loss 2.0800843238830566
Iteration 104: train_loss 2.084153413772583
Iteration 105: train_loss 2.097005605697632
Iteration 106: train_loss 2.111630439758301
Iteration 107: train_loss 1.9531476497650146
Iteration 108: train_loss 1.9254266023635864
Iteration 109: train_loss 2.0791563987731934
Iteration 110: train_loss 2.054748773574829
Iteration 111: train_loss 2.152064800262451
Iteration 112: train_loss 2.118992328643799
Iteration 113: train_loss 2.027876853942871
Iteration 114: train_loss 2.0010502338409424
Iteration 115: train_loss 2.056821584701538
Iteration 116: train_loss 2.0718722343444824
Iteration 117: train_loss 2.0825753211975098
Iteration 118: train_loss 2.040931463241577
Iteration 119: train_loss 2.134852409362793
Iteration 120: train_loss 2.081359624862671
Iteration 121: train_loss 2.0950636863708496
Iteration 122: train_loss 2.0971131324768066
Iteration 123: train_loss 2.121215581893921
Iteration 124: train_loss 2.0252115726470947
Iteration 125: train_loss 2.0857560634613037
Iteration 126: train_loss 2.0778470039367676
Iteration 127: train_loss 2.185889959335327
Iteration 128: train_loss 2.0265486240386963
Iteration 129: train_loss 2.075958013534546
Iteration 130: train_loss 2.0759968757629395
Iteration 131: train_loss 2.112292766571045
Iteration 132: train_loss 1.9699242115020752
Iteration 133: train_loss 2.021777868270874
Iteration 134: train_loss 2.0840342044830322
Iteration 135: train_loss 2.023991584777832
Iteration 136: train_loss 2.1202902793884277
Iteration 137: train_loss 2.013061761856079
Iteration 138: train_loss 1.9987125396728516
Iteration 139: train_loss 2.08980655670166
Iteration 140: train_loss 2.056974411010742
Iteration 141: train_loss 2.0591437816619873
Iteration 142: train_loss 2.087231397628784
Iteration 143: train_loss 2.029475450515747
Iteration 144: train_loss 2.098557472229004
Iteration 145: train_loss 2.010477304458618
Iteration 146: train_loss 2.044755458831787
Iteration 147: train_loss 2.1191306114196777
Iteration 148: train_loss 2.0989186763763428
Iteration 149: train_loss 2.076789617538452
Iteration 150: train_loss 2.1281638145446777
Iteration 151: train_loss 2.1157031059265137
Iteration 152: train_loss 2.0822982788085938
Iteration 153: train_loss 2.090820074081421
Iteration 154: train_loss 2.110196113586426
Iteration 155: train_loss 2.1015613079071045
Iteration 156: train_loss 2.104187250137329
Iteration 157: train_loss 2.0851123332977295
Iteration 158: train_loss 2.100036859512329
Iteration 159: train_loss 2.0755789279937744
Iteration 160: train_loss 2.1272902488708496
Iteration 161: train_loss 2.0530104637145996
Iteration 162: train_loss 2.025023937225342
Iteration 163: train_loss 2.0292859077453613
Iteration 164: train_loss 2.0763518810272217
Iteration 165: train_loss 2.0269887447357178
Iteration 166: train_loss 2.071560859680176
Iteration 167: train_loss 2.144512176513672
Iteration 168: train_loss 2.1020257472991943
Iteration 169: train_loss 2.042447328567505
Iteration 170: train_loss 2.036118268966675
Iteration 171: train_loss 2.092491865158081
Iteration 172: train_loss 2.0752575397491455
Iteration 173: train_loss 2.1491565704345703
Iteration 174: train_loss 2.1008894443511963
Iteration 175: train_loss 2.0313313007354736
Iteration 176: train_loss 2.075345277786255
Iteration 177: train_loss 2.1170814037323
Epoch 22: train_avg_loss 2.062352858020761 eval_avg_acc: 0.3182471580175662 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:03:02] [32mIntermediate result: 0.3182471580175662  (Index 21)[0m
================Epoch: 23================
Iteration 1: train_loss 2.0942742824554443
Iteration 2: train_loss 2.0242772102355957
Iteration 3: train_loss 2.008307695388794
Iteration 4: train_loss 1.9865913391113281
Iteration 5: train_loss 1.9902487993240356
Iteration 6: train_loss 1.9370050430297852
Iteration 7: train_loss 1.9534294605255127
Iteration 8: train_loss 2.023651123046875
Iteration 9: train_loss 2.0613536834716797
Iteration 10: train_loss 1.941584825515747
Iteration 11: train_loss 2.0051021575927734
Iteration 12: train_loss 2.0405349731445312
Iteration 13: train_loss 2.0200841426849365
Iteration 14: train_loss 2.0279123783111572
Iteration 15: train_loss 2.085414409637451
Iteration 16: train_loss 2.0733795166015625
Iteration 17: train_loss 2.050083637237549
Iteration 18: train_loss 2.0584053993225098
Iteration 19: train_loss 2.001136302947998
Iteration 20: train_loss 1.9867550134658813
Iteration 21: train_loss 2.0609731674194336
Iteration 22: train_loss 2.059159517288208
Iteration 23: train_loss 2.0204851627349854
Iteration 24: train_loss 2.047800064086914
Iteration 25: train_loss 2.0623233318328857
Iteration 26: train_loss 2.0395631790161133
Iteration 27: train_loss 1.9489631652832031
Iteration 28: train_loss 2.143231153488159
Iteration 29: train_loss 1.974165678024292
Iteration 30: train_loss 2.094625234603882
Iteration 31: train_loss 2.0740184783935547
Iteration 32: train_loss 2.002626419067383
Iteration 33: train_loss 2.0122902393341064
Iteration 34: train_loss 2.0711023807525635
Iteration 35: train_loss 2.091161012649536
Iteration 36: train_loss 2.0416228771209717
Iteration 37: train_loss 2.046482801437378
Iteration 38: train_loss 2.0424540042877197
Iteration 39: train_loss 1.9613258838653564
Iteration 40: train_loss 2.0033280849456787
Iteration 41: train_loss 2.032412052154541
Iteration 42: train_loss 1.9797970056533813
Iteration 43: train_loss 2.0794200897216797
Iteration 44: train_loss 1.9874356985092163
Iteration 45: train_loss 2.0499022006988525
Iteration 46: train_loss 1.9632998704910278
Iteration 47: train_loss 1.9918668270111084
Iteration 48: train_loss 2.1010477542877197
Iteration 49: train_loss 1.995804786682129
Iteration 50: train_loss 1.9816319942474365
Iteration 51: train_loss 1.9675073623657227
Iteration 52: train_loss 1.9432260990142822
Iteration 53: train_loss 2.035629987716675
Iteration 54: train_loss 2.048206090927124
Iteration 55: train_loss 2.0258901119232178
Iteration 56: train_loss 2.114654302597046
Iteration 57: train_loss 2.078676700592041
Iteration 58: train_loss 2.000847816467285
Iteration 59: train_loss 1.9572705030441284
Iteration 60: train_loss 2.0853447914123535
Iteration 61: train_loss 2.0690178871154785
Iteration 62: train_loss 2.1894400119781494
Iteration 63: train_loss 2.0136587619781494
Iteration 64: train_loss 2.0523252487182617
Iteration 65: train_loss 2.0241782665252686
Iteration 66: train_loss 2.091797113418579
Iteration 67: train_loss 1.9900782108306885
Iteration 68: train_loss 2.076387882232666
Iteration 69: train_loss 2.006237030029297
Iteration 70: train_loss 2.102324962615967
Iteration 71: train_loss 2.0802698135375977
Iteration 72: train_loss 1.983397126197815
Iteration 73: train_loss 2.055281400680542
Iteration 74: train_loss 1.9614956378936768
Iteration 75: train_loss 2.033026695251465
Iteration 76: train_loss 2.047710418701172
Iteration 77: train_loss 1.9943983554840088
Iteration 78: train_loss 2.0099360942840576
Iteration 79: train_loss 2.0644736289978027
Iteration 80: train_loss 2.080692768096924
Iteration 81: train_loss 2.0098705291748047
Iteration 82: train_loss 2.023416519165039
Iteration 83: train_loss 2.1073896884918213
Iteration 84: train_loss 2.019073486328125
Iteration 85: train_loss 2.0573365688323975
Iteration 86: train_loss 2.064847469329834
Iteration 87: train_loss 2.0268256664276123
Iteration 88: train_loss 2.0165703296661377
Iteration 89: train_loss 1.903610110282898
Iteration 90: train_loss 2.086127281188965
Iteration 91: train_loss 2.0891287326812744
Iteration 92: train_loss 2.035416841506958
Iteration 93: train_loss 2.035411834716797
Iteration 94: train_loss 2.0450594425201416
Iteration 95: train_loss 2.0882065296173096
Iteration 96: train_loss 2.0445704460144043
Iteration 97: train_loss 2.023672580718994
Iteration 98: train_loss 2.0632238388061523
Iteration 99: train_loss 2.0230236053466797
Iteration 100: train_loss 1.9882692098617554
Iteration 101: train_loss 2.0977604389190674
Iteration 102: train_loss 2.0398104190826416
Iteration 103: train_loss 2.090820789337158
Iteration 104: train_loss 2.02165150642395
Iteration 105: train_loss 2.0775604248046875
Iteration 106: train_loss 2.069150924682617
Iteration 107: train_loss 1.995906949043274
Iteration 108: train_loss 2.0457873344421387
Iteration 109: train_loss 2.0815067291259766
Iteration 110: train_loss 2.0721561908721924
Iteration 111: train_loss 2.083220958709717
Iteration 112: train_loss 2.0102832317352295
Iteration 113: train_loss 2.0463919639587402
Iteration 114: train_loss 1.9952023029327393
Iteration 115: train_loss 2.0462987422943115
Iteration 116: train_loss 1.9916930198669434
Iteration 117: train_loss 2.052549123764038
Iteration 118: train_loss 2.014962673187256
Iteration 119: train_loss 2.062080144882202
Iteration 120: train_loss 2.024268627166748
Iteration 121: train_loss 2.0528223514556885
Iteration 122: train_loss 2.137690782546997
Iteration 123: train_loss 2.036724090576172
Iteration 124: train_loss 1.9901715517044067
Iteration 125: train_loss 2.0722646713256836
Iteration 126: train_loss 2.0739686489105225
Iteration 127: train_loss 2.0797014236450195
Iteration 128: train_loss 1.9928253889083862
Iteration 129: train_loss 2.0127081871032715
Iteration 130: train_loss 2.0603673458099365
Iteration 131: train_loss 2.0351903438568115
Iteration 132: train_loss 2.138305187225342
Iteration 133: train_loss 1.9980311393737793
Iteration 134: train_loss 2.0007083415985107
Iteration 135: train_loss 1.9953590631484985
Iteration 136: train_loss 2.0774075984954834
Iteration 137: train_loss 2.0782461166381836
Iteration 138: train_loss 2.030975341796875
Iteration 139: train_loss 2.036525011062622
Iteration 140: train_loss 2.032743215560913
Iteration 141: train_loss 2.04940128326416
Iteration 142: train_loss 2.0579628944396973
Iteration 143: train_loss 2.059519052505493
Iteration 144: train_loss 2.042198657989502
Iteration 145: train_loss 2.082034111022949
Iteration 146: train_loss 2.0782864093780518
Iteration 147: train_loss 2.106132745742798
Iteration 148: train_loss 2.0100910663604736
Iteration 149: train_loss 2.1164309978485107
Iteration 150: train_loss 2.0993518829345703
Iteration 151: train_loss 2.142611265182495
Iteration 152: train_loss 2.072482109069824
Iteration 153: train_loss 2.1085236072540283
Iteration 154: train_loss 2.0640525817871094
Iteration 155: train_loss 2.1851401329040527
Iteration 156: train_loss 2.0391407012939453
Iteration 157: train_loss 2.045865535736084
Iteration 158: train_loss 2.062912940979004
Iteration 159: train_loss 2.058570146560669
Iteration 160: train_loss 2.030336856842041
Iteration 161: train_loss 2.0204575061798096
Iteration 162: train_loss 2.0597105026245117
Iteration 163: train_loss 2.0664567947387695
Iteration 164: train_loss 2.022934913635254
Iteration 165: train_loss 2.046259880065918
Iteration 166: train_loss 2.0070955753326416
Iteration 167: train_loss 2.003948450088501
Iteration 168: train_loss 2.0384576320648193
Iteration 169: train_loss 2.082517623901367
Iteration 170: train_loss 2.085397243499756
Iteration 171: train_loss 2.1005189418792725
Iteration 172: train_loss 2.023001194000244
Iteration 173: train_loss 2.1153719425201416
Iteration 174: train_loss 2.0511300563812256
Iteration 175: train_loss 2.041628122329712
Iteration 176: train_loss 2.2124361991882324
Iteration 177: train_loss 2.231839895248413
Epoch 23: train_avg_loss 2.044272819481327 eval_avg_acc: 0.29138045363419657 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:03:42] [32mIntermediate result: 0.29138045363419657  (Index 22)[0m
================Epoch: 24================
Iteration 1: train_loss 2.0954840183258057
Iteration 2: train_loss 1.9983271360397339
Iteration 3: train_loss 2.0277159214019775
Iteration 4: train_loss 2.135328769683838
Iteration 5: train_loss 2.069951295852661
Iteration 6: train_loss 1.9583823680877686
Iteration 7: train_loss 2.0298972129821777
Iteration 8: train_loss 2.0185658931732178
Iteration 9: train_loss 2.029108762741089
Iteration 10: train_loss 2.1217708587646484
Iteration 11: train_loss 2.0795211791992188
Iteration 12: train_loss 2.0357444286346436
Iteration 13: train_loss 2.0312585830688477
Iteration 14: train_loss 2.0427610874176025
Iteration 15: train_loss 2.104647159576416
Iteration 16: train_loss 2.0327465534210205
Iteration 17: train_loss 2.0088725090026855
Iteration 18: train_loss 1.9560308456420898
Iteration 19: train_loss 2.0773580074310303
Iteration 20: train_loss 1.9777690172195435
Iteration 21: train_loss 2.0531604290008545
Iteration 22: train_loss 1.9593329429626465
Iteration 23: train_loss 2.0065901279449463
Iteration 24: train_loss 2.0523364543914795
Iteration 25: train_loss 2.000791549682617
Iteration 26: train_loss 2.0105414390563965
Iteration 27: train_loss 1.9249778985977173
Iteration 28: train_loss 1.9869771003723145
Iteration 29: train_loss 1.9443011283874512
Iteration 30: train_loss 2.027183771133423
Iteration 31: train_loss 2.0628747940063477
Iteration 32: train_loss 1.9593755006790161
Iteration 33: train_loss 2.004678726196289
Iteration 34: train_loss 1.991011142730713
Iteration 35: train_loss 1.9802484512329102
Iteration 36: train_loss 2.0231916904449463
Iteration 37: train_loss 1.990023136138916
Iteration 38: train_loss 2.063194990158081
Iteration 39: train_loss 2.052570343017578
Iteration 40: train_loss 2.0716209411621094
Iteration 41: train_loss 1.983385443687439
Iteration 42: train_loss 2.0135109424591064
Iteration 43: train_loss 2.004415988922119
Iteration 44: train_loss 1.9505161046981812
Iteration 45: train_loss 2.034771203994751
Iteration 46: train_loss 2.044684648513794
Iteration 47: train_loss 2.055864095687866
Iteration 48: train_loss 2.0685501098632812
Iteration 49: train_loss 2.072972536087036
Iteration 50: train_loss 1.8908368349075317
Iteration 51: train_loss 1.923583745956421
Iteration 52: train_loss 1.9841679334640503
Iteration 53: train_loss 2.006833553314209
Iteration 54: train_loss 2.0080325603485107
Iteration 55: train_loss 1.9154415130615234
Iteration 56: train_loss 2.0140633583068848
Iteration 57: train_loss 2.039109230041504
Iteration 58: train_loss 2.0516369342803955
Iteration 59: train_loss 2.0738863945007324
Iteration 60: train_loss 1.9886709451675415
Iteration 61: train_loss 1.9417301416397095
Iteration 62: train_loss 1.9830851554870605
Iteration 63: train_loss 2.018615484237671
Iteration 64: train_loss 2.0108284950256348
Iteration 65: train_loss 2.0135555267333984
Iteration 66: train_loss 2.0413548946380615
Iteration 67: train_loss 2.091747999191284
Iteration 68: train_loss 2.0245070457458496
Iteration 69: train_loss 2.0267817974090576
Iteration 70: train_loss 2.0429961681365967
Iteration 71: train_loss 2.075218915939331
Iteration 72: train_loss 2.0165491104125977
Iteration 73: train_loss 1.9733065366744995
Iteration 74: train_loss 2.032794713973999
Iteration 75: train_loss 2.0354561805725098
Iteration 76: train_loss 2.034510850906372
Iteration 77: train_loss 2.0401575565338135
Iteration 78: train_loss 2.035705089569092
Iteration 79: train_loss 1.938053846359253
Iteration 80: train_loss 2.029435873031616
Iteration 81: train_loss 1.9875355958938599
Iteration 82: train_loss 1.96148681640625
Iteration 83: train_loss 1.9937320947647095
Iteration 84: train_loss 2.0273118019104004
Iteration 85: train_loss 2.0118062496185303
Iteration 86: train_loss 2.008491039276123
Iteration 87: train_loss 1.9437543153762817
Iteration 88: train_loss 2.0129764080047607
Iteration 89: train_loss 2.0133986473083496
Iteration 90: train_loss 1.9916353225708008
Iteration 91: train_loss 2.061342239379883
Iteration 92: train_loss 2.048726797103882
Iteration 93: train_loss 2.011939525604248
Iteration 94: train_loss 1.988563895225525
Iteration 95: train_loss 1.9979804754257202
Iteration 96: train_loss 2.057713508605957
Iteration 97: train_loss 1.9687998294830322
Iteration 98: train_loss 2.1160452365875244
Iteration 99: train_loss 2.1285455226898193
Iteration 100: train_loss 2.010152816772461
Iteration 101: train_loss 2.03182053565979
Iteration 102: train_loss 2.0759708881378174
Iteration 103: train_loss 2.0055108070373535
Iteration 104: train_loss 1.9882019758224487
Iteration 105: train_loss 1.9461400508880615
Iteration 106: train_loss 1.9903314113616943
Iteration 107: train_loss 1.970856785774231
Iteration 108: train_loss 1.960332989692688
Iteration 109: train_loss 1.990552306175232
Iteration 110: train_loss 1.9036349058151245
Iteration 111: train_loss 1.9798009395599365
Iteration 112: train_loss 1.9967193603515625
Iteration 113: train_loss 2.042182445526123
Iteration 114: train_loss 1.9792524576187134
Iteration 115: train_loss 1.9978435039520264
Iteration 116: train_loss 1.9532463550567627
Iteration 117: train_loss 2.0105955600738525
Iteration 118: train_loss 1.9607605934143066
Iteration 119: train_loss 2.0141749382019043
Iteration 120: train_loss 2.0857763290405273
Iteration 121: train_loss 2.0026352405548096
Iteration 122: train_loss 2.0105042457580566
Iteration 123: train_loss 1.9590296745300293
Iteration 124: train_loss 2.0255634784698486
Iteration 125: train_loss 1.9941914081573486
Iteration 126: train_loss 1.9921202659606934
Iteration 127: train_loss 2.025704860687256
Iteration 128: train_loss 1.9388177394866943
Iteration 129: train_loss 1.9725898504257202
Iteration 130: train_loss 2.0713090896606445
Iteration 131: train_loss 2.0791640281677246
Iteration 132: train_loss 2.096676826477051
Iteration 133: train_loss 1.9957008361816406
Iteration 134: train_loss 2.0342631340026855
Iteration 135: train_loss 2.0060505867004395
Iteration 136: train_loss 1.9629175662994385
Iteration 137: train_loss 2.0264201164245605
Iteration 138: train_loss 2.0785253047943115
Iteration 139: train_loss 2.0884287357330322
Iteration 140: train_loss 2.0564751625061035
Iteration 141: train_loss 2.085202217102051
Iteration 142: train_loss 2.0285303592681885
Iteration 143: train_loss 2.0067899227142334
Iteration 144: train_loss 1.9841687679290771
Iteration 145: train_loss 2.0016956329345703
Iteration 146: train_loss 2.018089771270752
Iteration 147: train_loss 2.075546979904175
Iteration 148: train_loss 2.070343494415283
Iteration 149: train_loss 2.0578722953796387
Iteration 150: train_loss 2.0474436283111572
Iteration 151: train_loss 2.060251235961914
Iteration 152: train_loss 1.9919815063476562
Iteration 153: train_loss 2.0535106658935547
Iteration 154: train_loss 2.03682279586792
Iteration 155: train_loss 2.0436275005340576
Iteration 156: train_loss 1.981144666671753
Iteration 157: train_loss 2.1112723350524902
Iteration 158: train_loss 2.0274438858032227
Iteration 159: train_loss 2.0696022510528564
Iteration 160: train_loss 2.0787456035614014
Iteration 161: train_loss 2.080096960067749
Iteration 162: train_loss 2.02143931388855
Iteration 163: train_loss 2.037020206451416
Iteration 164: train_loss 2.0096311569213867
Iteration 165: train_loss 2.0286006927490234
Iteration 166: train_loss 2.051384449005127
Iteration 167: train_loss 2.134007453918457
Iteration 168: train_loss 2.0633797645568848
Iteration 169: train_loss 2.0508623123168945
Iteration 170: train_loss 2.0210413932800293
Iteration 171: train_loss 2.0479769706726074
Iteration 172: train_loss 2.0891122817993164
Iteration 173: train_loss 2.005169630050659
Iteration 174: train_loss 2.0575151443481445
Iteration 175: train_loss 2.0136525630950928
Iteration 176: train_loss 2.097288131713867
Iteration 177: train_loss 2.071697473526001
Epoch 24: train_avg_loss 2.021922273824444 eval_avg_acc: 0.31319280229051794 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:04:24] [32mIntermediate result: 0.31319280229051794  (Index 23)[0m
================Epoch: 25================
Iteration 1: train_loss 2.029712677001953
Iteration 2: train_loss 1.9363683462142944
Iteration 3: train_loss 1.993000864982605
Iteration 4: train_loss 1.9495751857757568
Iteration 5: train_loss 1.9839659929275513
Iteration 6: train_loss 1.928008794784546
Iteration 7: train_loss 1.9591867923736572
Iteration 8: train_loss 1.9824782609939575
Iteration 9: train_loss 1.901412010192871
Iteration 10: train_loss 1.9238650798797607
Iteration 11: train_loss 1.8791571855545044
Iteration 12: train_loss 2.039201259613037
Iteration 13: train_loss 2.0614161491394043
Iteration 14: train_loss 1.9711785316467285
Iteration 15: train_loss 2.027688980102539
Iteration 16: train_loss 1.998724341392517
Iteration 17: train_loss 2.01058292388916
Iteration 18: train_loss 2.007662773132324
Iteration 19: train_loss 1.9949065446853638
Iteration 20: train_loss 1.9891842603683472
Iteration 21: train_loss 2.0325052738189697
Iteration 22: train_loss 1.9228078126907349
Iteration 23: train_loss 2.00698184967041
Iteration 24: train_loss 1.9994211196899414
Iteration 25: train_loss 1.9870532751083374
Iteration 26: train_loss 1.9577621221542358
Iteration 27: train_loss 1.991546630859375
Iteration 28: train_loss 1.9808423519134521
Iteration 29: train_loss 1.9658257961273193
Iteration 30: train_loss 1.9713389873504639
Iteration 31: train_loss 1.9424527883529663
Iteration 32: train_loss 1.927209496498108
Iteration 33: train_loss 1.9455392360687256
Iteration 34: train_loss 1.957865595817566
Iteration 35: train_loss 1.9625440835952759
Iteration 36: train_loss 1.9933180809020996
Iteration 37: train_loss 2.0054681301116943
Iteration 38: train_loss 2.029416561126709
Iteration 39: train_loss 2.0149028301239014
Iteration 40: train_loss 1.9322630167007446
Iteration 41: train_loss 2.1001691818237305
Iteration 42: train_loss 1.9945895671844482
Iteration 43: train_loss 1.912153720855713
Iteration 44: train_loss 2.014998197555542
Iteration 45: train_loss 2.0496225357055664
Iteration 46: train_loss 1.9726520776748657
Iteration 47: train_loss 1.9922418594360352
Iteration 48: train_loss 1.9826759099960327
Iteration 49: train_loss 2.019874334335327
Iteration 50: train_loss 2.0938005447387695
Iteration 51: train_loss 2.057917833328247
Iteration 52: train_loss 1.962675929069519
Iteration 53: train_loss 2.0335237979888916
Iteration 54: train_loss 2.040748357772827
Iteration 55: train_loss 2.045531749725342
Iteration 56: train_loss 2.0345776081085205
Iteration 57: train_loss 2.033712387084961
Iteration 58: train_loss 2.008239269256592
Iteration 59: train_loss 1.9710497856140137
Iteration 60: train_loss 2.1030850410461426
Iteration 61: train_loss 2.0218355655670166
Iteration 62: train_loss 1.979939579963684
Iteration 63: train_loss 2.0555684566497803
Iteration 64: train_loss 2.020676612854004
Iteration 65: train_loss 1.9978649616241455
Iteration 66: train_loss 1.9696743488311768
Iteration 67: train_loss 2.0317208766937256
Iteration 68: train_loss 2.022401809692383
Iteration 69: train_loss 1.9302443265914917
Iteration 70: train_loss 2.016268014907837
Iteration 71: train_loss 2.005685567855835
Iteration 72: train_loss 2.0157594680786133
Iteration 73: train_loss 1.9700720310211182
Iteration 74: train_loss 2.0010805130004883
Iteration 75: train_loss 1.963059902191162
Iteration 76: train_loss 1.984679937362671
Iteration 77: train_loss 1.946385383605957
Iteration 78: train_loss 1.9417132139205933
Iteration 79: train_loss 2.0787816047668457
Iteration 80: train_loss 2.0269007682800293
Iteration 81: train_loss 2.0597996711730957
Iteration 82: train_loss 2.0368764400482178
Iteration 83: train_loss 2.0962789058685303
Iteration 84: train_loss 1.8988914489746094
Iteration 85: train_loss 1.9236042499542236
Iteration 86: train_loss 1.9805241823196411
Iteration 87: train_loss 2.047880172729492
Iteration 88: train_loss 1.9627914428710938
Iteration 89: train_loss 2.0309529304504395
Iteration 90: train_loss 1.9633429050445557
Iteration 91: train_loss 1.9602285623550415
Iteration 92: train_loss 1.8905493021011353
Iteration 93: train_loss 1.9373507499694824
Iteration 94: train_loss 1.992173433303833
Iteration 95: train_loss 2.018939971923828
Iteration 96: train_loss 1.9178518056869507
Iteration 97: train_loss 1.9619144201278687
Iteration 98: train_loss 2.035346508026123
Iteration 99: train_loss 1.9921897649765015
Iteration 100: train_loss 2.0685837268829346
Iteration 101: train_loss 2.0181219577789307
Iteration 102: train_loss 2.074927568435669
Iteration 103: train_loss 1.9543644189834595
Iteration 104: train_loss 1.9152181148529053
Iteration 105: train_loss 1.97011399269104
Iteration 106: train_loss 1.9851669073104858
Iteration 107: train_loss 1.953760027885437
Iteration 108: train_loss 2.0390584468841553
Iteration 109: train_loss 2.059896945953369
Iteration 110: train_loss 1.991703748703003
Iteration 111: train_loss 2.002748489379883
Iteration 112: train_loss 1.9910258054733276
Iteration 113: train_loss 2.0036213397979736
Iteration 114: train_loss 2.032559871673584
Iteration 115: train_loss 1.999352216720581
Iteration 116: train_loss 1.9679044485092163
Iteration 117: train_loss 1.9862244129180908
Iteration 118: train_loss 1.9627184867858887
Iteration 119: train_loss 2.023167133331299
Iteration 120: train_loss 2.0251400470733643
Iteration 121: train_loss 1.9338200092315674
Iteration 122: train_loss 2.0341732501983643
Iteration 123: train_loss 2.0888264179229736
Iteration 124: train_loss 1.978890299797058
Iteration 125: train_loss 1.9828373193740845
Iteration 126: train_loss 1.9890638589859009
Iteration 127: train_loss 2.067058801651001
Iteration 128: train_loss 2.0279932022094727
Iteration 129: train_loss 2.0355825424194336
Iteration 130: train_loss 2.0417346954345703
Iteration 131: train_loss 1.9861172437667847
Iteration 132: train_loss 2.0259668827056885
Iteration 133: train_loss 1.9743610620498657
Iteration 134: train_loss 1.976635217666626
Iteration 135: train_loss 1.974913477897644
Iteration 136: train_loss 2.0638256072998047
Iteration 137: train_loss 2.111659049987793
Iteration 138: train_loss 2.078057289123535
Iteration 139: train_loss 1.9461604356765747
Iteration 140: train_loss 2.0654757022857666
Iteration 141: train_loss 2.0513241291046143
Iteration 142: train_loss 1.974694013595581
Iteration 143: train_loss 2.0698423385620117
Iteration 144: train_loss 2.0141818523406982
Iteration 145: train_loss 2.06636905670166
Iteration 146: train_loss 2.057384967803955
Iteration 147: train_loss 2.0108587741851807
Iteration 148: train_loss 2.0127193927764893
Iteration 149: train_loss 2.080726385116577
Iteration 150: train_loss 1.9951215982437134
Iteration 151: train_loss 2.072922945022583
Iteration 152: train_loss 2.0066795349121094
Iteration 153: train_loss 1.985273003578186
Iteration 154: train_loss 1.9413942098617554
Iteration 155: train_loss 2.013819456100464
Iteration 156: train_loss 2.0547707080841064
Iteration 157: train_loss 1.9987986087799072
Iteration 158: train_loss 1.9566694498062134
Iteration 159: train_loss 1.952195405960083
Iteration 160: train_loss 1.9020860195159912
Iteration 161: train_loss 1.9964501857757568
Iteration 162: train_loss 2.0006513595581055
Iteration 163: train_loss 1.9927080869674683
Iteration 164: train_loss 2.0588929653167725
Iteration 165: train_loss 1.9559874534606934
Iteration 166: train_loss 1.938858151435852
Iteration 167: train_loss 2.0661306381225586
Iteration 168: train_loss 2.0336720943450928
Iteration 169: train_loss 1.9647592306137085
Iteration 170: train_loss 1.9701406955718994
Iteration 171: train_loss 1.9994418621063232
Iteration 172: train_loss 2.04524564743042
Iteration 173: train_loss 1.9506664276123047
Iteration 174: train_loss 1.9863861799240112
Iteration 175: train_loss 1.9919278621673584
Iteration 176: train_loss 2.0196704864501953
Iteration 177: train_loss 2.0790324211120605
Epoch 25: train_avg_loss 1.999338788501287 eval_avg_acc: 0.31261774741610915 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:05:07] [32mIntermediate result: 0.31261774741610915  (Index 24)[0m
================Epoch: 26================
Iteration 1: train_loss 1.9174180030822754
Iteration 2: train_loss 1.928497076034546
Iteration 3: train_loss 1.9147453308105469
Iteration 4: train_loss 1.967625379562378
Iteration 5: train_loss 2.013462781906128
Iteration 6: train_loss 1.9070868492126465
Iteration 7: train_loss 1.9529073238372803
Iteration 8: train_loss 1.9609144926071167
Iteration 9: train_loss 1.9602601528167725
Iteration 10: train_loss 1.9534341096878052
Iteration 11: train_loss 1.9203803539276123
Iteration 12: train_loss 1.9478577375411987
Iteration 13: train_loss 1.982974886894226
Iteration 14: train_loss 1.9340084791183472
Iteration 15: train_loss 1.8850616216659546
Iteration 16: train_loss 1.9739865064620972
Iteration 17: train_loss 2.0230021476745605
Iteration 18: train_loss 1.9652044773101807
Iteration 19: train_loss 1.9425560235977173
Iteration 20: train_loss 1.917283296585083
Iteration 21: train_loss 1.9887821674346924
Iteration 22: train_loss 1.9464343786239624
Iteration 23: train_loss 1.9467315673828125
Iteration 24: train_loss 1.9399473667144775
Iteration 25: train_loss 2.076157569885254
Iteration 26: train_loss 1.9859809875488281
Iteration 27: train_loss 2.001664638519287
Iteration 28: train_loss 1.9763091802597046
Iteration 29: train_loss 1.9834775924682617
Iteration 30: train_loss 1.922811508178711
Iteration 31: train_loss 1.9620295763015747
Iteration 32: train_loss 1.958125352859497
Iteration 33: train_loss 1.9774888753890991
Iteration 34: train_loss 1.9062086343765259
Iteration 35: train_loss 1.9040248394012451
Iteration 36: train_loss 2.0629217624664307
Iteration 37: train_loss 1.9026943445205688
Iteration 38: train_loss 1.9007400274276733
Iteration 39: train_loss 2.0007550716400146
Iteration 40: train_loss 1.9981075525283813
Iteration 41: train_loss 1.9834351539611816
Iteration 42: train_loss 1.945031762123108
Iteration 43: train_loss 1.9851548671722412
Iteration 44: train_loss 1.8957918882369995
Iteration 45: train_loss 1.9598119258880615
Iteration 46: train_loss 2.0921781063079834
Iteration 47: train_loss 1.9525984525680542
Iteration 48: train_loss 1.922390103340149
Iteration 49: train_loss 1.990730881690979
Iteration 50: train_loss 1.923733115196228
Iteration 51: train_loss 1.952031135559082
Iteration 52: train_loss 1.947640061378479
Iteration 53: train_loss 1.9486958980560303
Iteration 54: train_loss 1.9463964700698853
Iteration 55: train_loss 1.9974044561386108
Iteration 56: train_loss 1.9630125761032104
Iteration 57: train_loss 1.9266738891601562
Iteration 58: train_loss 1.9496080875396729
Iteration 59: train_loss 1.9271241426467896
Iteration 60: train_loss 1.9895471334457397
Iteration 61: train_loss 2.0621767044067383
Iteration 62: train_loss 1.9898438453674316
Iteration 63: train_loss 1.9232068061828613
Iteration 64: train_loss 1.985479474067688
Iteration 65: train_loss 1.9765112400054932
Iteration 66: train_loss 1.950438141822815
Iteration 67: train_loss 1.9788007736206055
Iteration 68: train_loss 1.9917075634002686
Iteration 69: train_loss 1.9096593856811523
Iteration 70: train_loss 2.0020275115966797
Iteration 71: train_loss 2.0271828174591064
Iteration 72: train_loss 1.9811246395111084
Iteration 73: train_loss 2.02368426322937
Iteration 74: train_loss 1.9283206462860107
Iteration 75: train_loss 2.0145132541656494
Iteration 76: train_loss 2.0693633556365967
Iteration 77: train_loss 1.869903326034546
Iteration 78: train_loss 2.0212955474853516
Iteration 79: train_loss 2.0216238498687744
Iteration 80: train_loss 2.0113682746887207
Iteration 81: train_loss 1.9891209602355957
Iteration 82: train_loss 2.016247272491455
Iteration 83: train_loss 1.901896595954895
Iteration 84: train_loss 1.9048384428024292
Iteration 85: train_loss 1.993054986000061
Iteration 86: train_loss 1.9544708728790283
Iteration 87: train_loss 2.0087757110595703
Iteration 88: train_loss 1.991162896156311
Iteration 89: train_loss 1.9915202856063843
Iteration 90: train_loss 1.9636317491531372
Iteration 91: train_loss 2.060020685195923
Iteration 92: train_loss 1.9689085483551025
Iteration 93: train_loss 1.9567419290542603
Iteration 94: train_loss 1.9393213987350464
Iteration 95: train_loss 2.051771879196167
Iteration 96: train_loss 2.043484687805176
Iteration 97: train_loss 1.9605680704116821
Iteration 98: train_loss 1.921686053276062
Iteration 99: train_loss 1.9326765537261963
Iteration 100: train_loss 1.9727284908294678
Iteration 101: train_loss 2.0024590492248535
Iteration 102: train_loss 1.9520448446273804
Iteration 103: train_loss 1.9616506099700928
Iteration 104: train_loss 1.9348896741867065
Iteration 105: train_loss 1.9475030899047852
Iteration 106: train_loss 1.993703007698059
Iteration 107: train_loss 2.0141243934631348
Iteration 108: train_loss 1.9522773027420044
Iteration 109: train_loss 2.009207010269165
Iteration 110: train_loss 1.9995397329330444
Iteration 111: train_loss 2.0528223514556885
Iteration 112: train_loss 1.953974962234497
Iteration 113: train_loss 2.0389764308929443
Iteration 114: train_loss 2.0019242763519287
Iteration 115: train_loss 1.998528242111206
Iteration 116: train_loss 2.1591029167175293
Iteration 117: train_loss 2.0627546310424805
Iteration 118: train_loss 1.9668635129928589
Iteration 119: train_loss 2.035306930541992
Iteration 120: train_loss 2.0002548694610596
Iteration 121: train_loss 2.0212957859039307
Iteration 122: train_loss 1.9825259447097778
Iteration 123: train_loss 2.009801149368286
Iteration 124: train_loss 1.9719105958938599
Iteration 125: train_loss 1.9592194557189941
Iteration 126: train_loss 2.018129825592041
Iteration 127: train_loss 2.065993547439575
Iteration 128: train_loss 1.9232819080352783
Iteration 129: train_loss 1.9632495641708374
Iteration 130: train_loss 1.9659318923950195
Iteration 131: train_loss 2.0116500854492188
Iteration 132: train_loss 2.0451271533966064
Iteration 133: train_loss 1.9816621541976929
Iteration 134: train_loss 2.0743165016174316
Iteration 135: train_loss 1.9881521463394165
Iteration 136: train_loss 2.025836229324341
Iteration 137: train_loss 1.9764596223831177
Iteration 138: train_loss 1.9595147371292114
Iteration 139: train_loss 1.9216818809509277
Iteration 140: train_loss 1.9981284141540527
Iteration 141: train_loss 1.987126111984253
Iteration 142: train_loss 2.004818916320801
Iteration 143: train_loss 2.0189437866210938
Iteration 144: train_loss 2.058990478515625
Iteration 145: train_loss 1.9906010627746582
Iteration 146: train_loss 1.9445431232452393
Iteration 147: train_loss 1.9960179328918457
Iteration 148: train_loss 1.9898278713226318
Iteration 149: train_loss 1.9765268564224243
Iteration 150: train_loss 1.9335784912109375
Iteration 151: train_loss 1.997310996055603
Iteration 152: train_loss 1.9977006912231445
Iteration 153: train_loss 1.9556738138198853
Iteration 154: train_loss 1.9827780723571777
Iteration 155: train_loss 2.106271743774414
Iteration 156: train_loss 1.9740710258483887
Iteration 157: train_loss 2.063110113143921
Iteration 158: train_loss 2.060142993927002
Iteration 159: train_loss 1.9290848970413208
Iteration 160: train_loss 1.9770715236663818
Iteration 161: train_loss 1.9333595037460327
Iteration 162: train_loss 1.9666424989700317
Iteration 163: train_loss 1.95024573802948
Iteration 164: train_loss 1.903053641319275
Iteration 165: train_loss 1.935723900794983
Iteration 166: train_loss 2.0134053230285645
Iteration 167: train_loss 1.9274629354476929
Iteration 168: train_loss 1.9664067029953003
Iteration 169: train_loss 2.027841567993164
Iteration 170: train_loss 1.92753267288208
Iteration 171: train_loss 2.031207799911499
Iteration 172: train_loss 1.9593656063079834
Iteration 173: train_loss 2.0978362560272217
Iteration 174: train_loss 1.9479143619537354
Iteration 175: train_loss 1.9984129667282104
Iteration 176: train_loss 1.9761329889297485
Iteration 177: train_loss 2.0584633350372314
Epoch 26: train_avg_loss 1.9787394596358476 eval_avg_acc: 0.3082480638677174 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:05:51] [32mIntermediate result: 0.3082480638677174  (Index 25)[0m
================Epoch: 27================
Iteration 1: train_loss 1.9478036165237427
Iteration 2: train_loss 1.9616948366165161
Iteration 3: train_loss 1.9754010438919067
Iteration 4: train_loss 2.05865740776062
Iteration 5: train_loss 1.8780934810638428
Iteration 6: train_loss 1.9118989706039429
Iteration 7: train_loss 1.8919503688812256
Iteration 8: train_loss 1.9305431842803955
Iteration 9: train_loss 1.9264057874679565
Iteration 10: train_loss 1.9355263710021973
Iteration 11: train_loss 1.9078484773635864
Iteration 12: train_loss 1.8318421840667725
Iteration 13: train_loss 1.899763584136963
Iteration 14: train_loss 1.9249674081802368
Iteration 15: train_loss 2.0030033588409424
Iteration 16: train_loss 1.9059014320373535
Iteration 17: train_loss 1.9822901487350464
Iteration 18: train_loss 1.9611798524856567
Iteration 19: train_loss 1.890243411064148
Iteration 20: train_loss 1.8902088403701782
Iteration 21: train_loss 1.9335976839065552
Iteration 22: train_loss 1.9270175695419312
Iteration 23: train_loss 1.9590188264846802
Iteration 24: train_loss 1.8829894065856934
Iteration 25: train_loss 1.9196158647537231
Iteration 26: train_loss 1.9476560354232788
Iteration 27: train_loss 1.9402884244918823
Iteration 28: train_loss 1.9765503406524658
Iteration 29: train_loss 2.0062520503997803
Iteration 30: train_loss 2.0353221893310547
Iteration 31: train_loss 2.039283037185669
Iteration 32: train_loss 1.9838428497314453
Iteration 33: train_loss 2.0010130405426025
Iteration 34: train_loss 1.8892428874969482
Iteration 35: train_loss 1.959655523300171
Iteration 36: train_loss 2.025052785873413
Iteration 37: train_loss 2.016408681869507
Iteration 38: train_loss 1.9417668581008911
Iteration 39: train_loss 1.8634861707687378
Iteration 40: train_loss 1.8677953481674194
Iteration 41: train_loss 1.9823839664459229
Iteration 42: train_loss 1.9314919710159302
Iteration 43: train_loss 1.9275591373443604
Iteration 44: train_loss 1.898281216621399
Iteration 45: train_loss 1.9534839391708374
Iteration 46: train_loss 2.010693073272705
Iteration 47: train_loss 1.9340730905532837
Iteration 48: train_loss 1.950265645980835
Iteration 49: train_loss 1.9189072847366333
Iteration 50: train_loss 2.0068976879119873
Iteration 51: train_loss 2.0164055824279785
Iteration 52: train_loss 1.925536870956421
Iteration 53: train_loss 1.9787307977676392
Iteration 54: train_loss 1.9577445983886719
Iteration 55: train_loss 2.0231435298919678
Iteration 56: train_loss 1.946130394935608
Iteration 57: train_loss 1.9448285102844238
Iteration 58: train_loss 1.9987006187438965
Iteration 59: train_loss 1.9072599411010742
Iteration 60: train_loss 1.9082075357437134
Iteration 61: train_loss 1.920855164527893
Iteration 62: train_loss 2.0407466888427734
Iteration 63: train_loss 1.9125646352767944
Iteration 64: train_loss 1.9686459302902222
Iteration 65: train_loss 2.0060536861419678
Iteration 66: train_loss 1.9937666654586792
Iteration 67: train_loss 2.073059320449829
Iteration 68: train_loss 1.9675523042678833
Iteration 69: train_loss 1.9098961353302002
Iteration 70: train_loss 1.8679828643798828
Iteration 71: train_loss 2.003559112548828
Iteration 72: train_loss 1.9627114534378052
Iteration 73: train_loss 2.039454698562622
Iteration 74: train_loss 1.9732792377471924
Iteration 75: train_loss 1.9472010135650635
Iteration 76: train_loss 1.9436659812927246
Iteration 77: train_loss 1.9429799318313599
Iteration 78: train_loss 1.9992339611053467
Iteration 79: train_loss 1.9759498834609985
Iteration 80: train_loss 1.950851321220398
Iteration 81: train_loss 1.9167135953903198
Iteration 82: train_loss 1.8978973627090454
Iteration 83: train_loss 1.9030332565307617
Iteration 84: train_loss 2.0078046321868896
Iteration 85: train_loss 1.9428839683532715
Iteration 86: train_loss 1.983790636062622
Iteration 87: train_loss 1.9002387523651123
Iteration 88: train_loss 1.9356865882873535
Iteration 89: train_loss 1.9659565687179565
Iteration 90: train_loss 2.057039976119995
Iteration 91: train_loss 2.0063650608062744
Iteration 92: train_loss 1.991625189781189
Iteration 93: train_loss 1.9858601093292236
Iteration 94: train_loss 1.9720617532730103
Iteration 95: train_loss 1.9239071607589722
Iteration 96: train_loss 1.9678101539611816
Iteration 97: train_loss 2.014051675796509
Iteration 98: train_loss 2.0736732482910156
Iteration 99: train_loss 1.8974884748458862
Iteration 100: train_loss 2.003589153289795
Iteration 101: train_loss 1.9401731491088867
Iteration 102: train_loss 2.006938934326172
Iteration 103: train_loss 2.0099830627441406
Iteration 104: train_loss 2.0000159740448
Iteration 105: train_loss 2.0261855125427246
Iteration 106: train_loss 1.90170156955719
Iteration 107: train_loss 1.9575196504592896
Iteration 108: train_loss 1.9637622833251953
Iteration 109: train_loss 1.9781540632247925
Iteration 110: train_loss 1.9997745752334595
Iteration 111: train_loss 1.9334895610809326
Iteration 112: train_loss 1.8961172103881836
Iteration 113: train_loss 1.9595900774002075
Iteration 114: train_loss 1.9261226654052734
Iteration 115: train_loss 1.981147289276123
Iteration 116: train_loss 1.823193073272705
Iteration 117: train_loss 1.9882957935333252
Iteration 118: train_loss 1.9990670680999756
Iteration 119: train_loss 1.959874153137207
Iteration 120: train_loss 2.0668158531188965
Iteration 121: train_loss 1.9871070384979248
Iteration 122: train_loss 1.9265695810317993
Iteration 123: train_loss 1.9630842208862305
Iteration 124: train_loss 2.0625205039978027
Iteration 125: train_loss 1.9834249019622803
Iteration 126: train_loss 1.9017837047576904
Iteration 127: train_loss 1.9902299642562866
Iteration 128: train_loss 2.0182137489318848
Iteration 129: train_loss 1.9526934623718262
Iteration 130: train_loss 1.9088083505630493
Iteration 131: train_loss 1.947376012802124
Iteration 132: train_loss 1.9710218906402588
Iteration 133: train_loss 1.9002723693847656
Iteration 134: train_loss 1.9439622163772583
Iteration 135: train_loss 1.9621586799621582
Iteration 136: train_loss 1.9645411968231201
Iteration 137: train_loss 1.9535236358642578
Iteration 138: train_loss 1.9815901517868042
Iteration 139: train_loss 2.016803741455078
Iteration 140: train_loss 1.9531437158584595
Iteration 141: train_loss 1.9599769115447998
Iteration 142: train_loss 1.9588650465011597
Iteration 143: train_loss 1.9253798723220825
Iteration 144: train_loss 1.9488656520843506
Iteration 145: train_loss 1.985142707824707
Iteration 146: train_loss 1.8978074789047241
Iteration 147: train_loss 1.9645805358886719
Iteration 148: train_loss 1.912793755531311
Iteration 149: train_loss 2.0253753662109375
Iteration 150: train_loss 2.058609962463379
Iteration 151: train_loss 1.9483745098114014
Iteration 152: train_loss 1.990235447883606
Iteration 153: train_loss 2.061274290084839
Iteration 154: train_loss 1.8871420621871948
Iteration 155: train_loss 1.9359649419784546
Iteration 156: train_loss 1.9511348009109497
Iteration 157: train_loss 2.033754587173462
Iteration 158: train_loss 1.9716514348983765
Iteration 159: train_loss 2.062387466430664
Iteration 160: train_loss 2.027097225189209
Iteration 161: train_loss 2.028106212615967
Iteration 162: train_loss 2.064720392227173
Iteration 163: train_loss 1.9130651950836182
Iteration 164: train_loss 1.9525998830795288
Iteration 165: train_loss 1.9327998161315918
Iteration 166: train_loss 2.005221128463745
Iteration 167: train_loss 2.0240166187286377
Iteration 168: train_loss 1.9920802116394043
Iteration 169: train_loss 2.0005123615264893
Iteration 170: train_loss 1.9555563926696777
Iteration 171: train_loss 1.9761204719543457
Iteration 172: train_loss 1.8799874782562256
Iteration 173: train_loss 1.9679690599441528
Iteration 174: train_loss 2.0213279724121094
Iteration 175: train_loss 1.964636206626892
Iteration 176: train_loss 1.994370937347412
Iteration 177: train_loss 2.0752153396606445
Epoch 27: train_avg_loss 1.9630551546980433 eval_avg_acc: 0.3194019974426069 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:06:34] [32mIntermediate result: 0.3194019974426069  (Index 26)[0m
================Epoch: 28================
Iteration 1: train_loss 1.9395290613174438
Iteration 2: train_loss 1.95547354221344
Iteration 3: train_loss 1.9326101541519165
Iteration 4: train_loss 1.9201233386993408
Iteration 5: train_loss 2.0023345947265625
Iteration 6: train_loss 1.8996589183807373
Iteration 7: train_loss 1.914181113243103
Iteration 8: train_loss 1.943268060684204
Iteration 9: train_loss 1.8612957000732422
Iteration 10: train_loss 1.9121899604797363
Iteration 11: train_loss 1.9347776174545288
Iteration 12: train_loss 1.8630616664886475
Iteration 13: train_loss 1.9161794185638428
Iteration 14: train_loss 1.9329533576965332
Iteration 15: train_loss 1.8491756916046143
Iteration 16: train_loss 1.963585615158081
Iteration 17: train_loss 1.9280754327774048
Iteration 18: train_loss 1.8710883855819702
Iteration 19: train_loss 1.9133185148239136
Iteration 20: train_loss 1.8576395511627197
Iteration 21: train_loss 1.923201322555542
Iteration 22: train_loss 1.972854733467102
Iteration 23: train_loss 1.8807986974716187
Iteration 24: train_loss 1.8728772401809692
Iteration 25: train_loss 1.9311130046844482
Iteration 26: train_loss 1.9465550184249878
Iteration 27: train_loss 2.0089690685272217
Iteration 28: train_loss 1.9064234495162964
Iteration 29: train_loss 1.9186787605285645
Iteration 30: train_loss 1.9252254962921143
Iteration 31: train_loss 1.8955985307693481
Iteration 32: train_loss 1.9427989721298218
Iteration 33: train_loss 1.97878098487854
Iteration 34: train_loss 1.979351282119751
Iteration 35: train_loss 1.941809058189392
Iteration 36: train_loss 2.0120201110839844
Iteration 37: train_loss 1.858007550239563
Iteration 38: train_loss 1.9906086921691895
Iteration 39: train_loss 2.0122225284576416
Iteration 40: train_loss 1.898847222328186
Iteration 41: train_loss 1.9403165578842163
Iteration 42: train_loss 1.9944700002670288
Iteration 43: train_loss 1.9188861846923828
Iteration 44: train_loss 1.9781438112258911
Iteration 45: train_loss 1.909759521484375
Iteration 46: train_loss 1.976794958114624
Iteration 47: train_loss 1.9662108421325684
Iteration 48: train_loss 1.9769964218139648
Iteration 49: train_loss 1.9582504034042358
Iteration 50: train_loss 1.9162858724594116
Iteration 51: train_loss 1.9222936630249023
Iteration 52: train_loss 1.8971792459487915
Iteration 53: train_loss 1.9496846199035645
Iteration 54: train_loss 1.9625575542449951
Iteration 55: train_loss 1.940325379371643
Iteration 56: train_loss 1.865363597869873
Iteration 57: train_loss 1.8876060247421265
Iteration 58: train_loss 1.9616155624389648
Iteration 59: train_loss 1.9463163614273071
Iteration 60: train_loss 1.815958857536316
Iteration 61: train_loss 1.927444577217102
Iteration 62: train_loss 1.9775114059448242
Iteration 63: train_loss 1.9550704956054688
Iteration 64: train_loss 1.9692661762237549
Iteration 65: train_loss 1.9124690294265747
Iteration 66: train_loss 1.9593207836151123
Iteration 67: train_loss 1.9281013011932373
Iteration 68: train_loss 1.9940886497497559
Iteration 69: train_loss 1.9153882265090942
Iteration 70: train_loss 1.9708950519561768
Iteration 71: train_loss 2.0254452228546143
Iteration 72: train_loss 1.9118345975875854
Iteration 73: train_loss 1.955312728881836
Iteration 74: train_loss 1.9677786827087402
Iteration 75: train_loss 1.9718241691589355
Iteration 76: train_loss 1.8821412324905396
Iteration 77: train_loss 1.9311002492904663
Iteration 78: train_loss 1.9212507009506226
Iteration 79: train_loss 2.034027576446533
Iteration 80: train_loss 1.9095391035079956
Iteration 81: train_loss 1.9691864252090454
Iteration 82: train_loss 1.9793933629989624
Iteration 83: train_loss 1.900766134262085
Iteration 84: train_loss 1.9014930725097656
Iteration 85: train_loss 1.955891489982605
Iteration 86: train_loss 1.9422428607940674
Iteration 87: train_loss 2.018575668334961
Iteration 88: train_loss 1.9577281475067139
Iteration 89: train_loss 2.0121583938598633
Iteration 90: train_loss 1.991632342338562
Iteration 91: train_loss 1.894787311553955
Iteration 92: train_loss 1.9931155443191528
Iteration 93: train_loss 2.0390236377716064
Iteration 94: train_loss 1.9716664552688599
Iteration 95: train_loss 1.8849612474441528
Iteration 96: train_loss 1.9222224950790405
Iteration 97: train_loss 1.967223882675171
Iteration 98: train_loss 2.0063211917877197
Iteration 99: train_loss 1.961584448814392
Iteration 100: train_loss 1.9156534671783447
Iteration 101: train_loss 1.967394471168518
Iteration 102: train_loss 1.8900153636932373
Iteration 103: train_loss 1.8800255060195923
Iteration 104: train_loss 1.9963253736495972
Iteration 105: train_loss 1.935397744178772
Iteration 106: train_loss 1.9790164232254028
Iteration 107: train_loss 1.8915090560913086
Iteration 108: train_loss 1.8442516326904297
Iteration 109: train_loss 1.914434552192688
Iteration 110: train_loss 2.023021936416626
Iteration 111: train_loss 1.8715026378631592
Iteration 112: train_loss 1.9076396226882935
Iteration 113: train_loss 1.9489246606826782
Iteration 114: train_loss 1.8964720964431763
Iteration 115: train_loss 1.9869784116744995
Iteration 116: train_loss 1.931871771812439
Iteration 117: train_loss 1.8814356327056885
Iteration 118: train_loss 2.005415678024292
Iteration 119: train_loss 1.9612725973129272
Iteration 120: train_loss 1.9725011587142944
Iteration 121: train_loss 1.9799396991729736
Iteration 122: train_loss 1.8412213325500488
Iteration 123: train_loss 1.8909647464752197
Iteration 124: train_loss 1.922080159187317
Iteration 125: train_loss 2.034294843673706
Iteration 126: train_loss 2.00252103805542
Iteration 127: train_loss 1.912183165550232
Iteration 128: train_loss 1.9844040870666504
Iteration 129: train_loss 1.994065761566162
Iteration 130: train_loss 1.9576866626739502
Iteration 131: train_loss 2.024510622024536
Iteration 132: train_loss 1.923783302307129
Iteration 133: train_loss 1.911253809928894
Iteration 134: train_loss 1.9470679759979248
Iteration 135: train_loss 2.039098024368286
Iteration 136: train_loss 1.9157335758209229
Iteration 137: train_loss 1.8976333141326904
Iteration 138: train_loss 1.9487700462341309
Iteration 139: train_loss 1.924412727355957
Iteration 140: train_loss 1.8942039012908936
Iteration 141: train_loss 1.9730719327926636
Iteration 142: train_loss 1.9334800243377686
Iteration 143: train_loss 1.8724162578582764
Iteration 144: train_loss 1.9814852476119995
Iteration 145: train_loss 1.9750614166259766
Iteration 146: train_loss 1.9660074710845947
Iteration 147: train_loss 2.03056263923645
Iteration 148: train_loss 1.9543726444244385
Iteration 149: train_loss 1.9885085821151733
Iteration 150: train_loss 1.9627766609191895
Iteration 151: train_loss 1.9133598804473877
Iteration 152: train_loss 1.9737045764923096
Iteration 153: train_loss 1.9360735416412354
Iteration 154: train_loss 1.9524221420288086
Iteration 155: train_loss 1.971706509590149
Iteration 156: train_loss 1.988031268119812
Iteration 157: train_loss 1.9374216794967651
Iteration 158: train_loss 1.925727128982544
Iteration 159: train_loss 2.005502700805664
Iteration 160: train_loss 1.9316153526306152
Iteration 161: train_loss 1.925091028213501
Iteration 162: train_loss 1.9404100179672241
Iteration 163: train_loss 1.9387552738189697
Iteration 164: train_loss 1.8904366493225098
Iteration 165: train_loss 1.9297795295715332
Iteration 166: train_loss 1.96023428440094
Iteration 167: train_loss 1.9509248733520508
Iteration 168: train_loss 1.9655801057815552
Iteration 169: train_loss 1.945572018623352
Iteration 170: train_loss 1.9603089094161987
Iteration 171: train_loss 1.9879486560821533
Iteration 172: train_loss 1.9387229681015015
Iteration 173: train_loss 2.039778709411621
Iteration 174: train_loss 1.9372286796569824
Iteration 175: train_loss 1.9605944156646729
Iteration 176: train_loss 1.9904900789260864
Iteration 177: train_loss 2.0530593395233154
Epoch 28: train_avg_loss 1.9441648176160908 eval_avg_acc: 0.32394882264802033 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:07:18] [32mIntermediate result: 0.32394882264802033  (Index 27)[0m
================Epoch: 29================
Iteration 1: train_loss 1.8734484910964966
Iteration 2: train_loss 1.8732432126998901
Iteration 3: train_loss 1.8815319538116455
Iteration 4: train_loss 1.9587647914886475
Iteration 5: train_loss 1.9344619512557983
Iteration 6: train_loss 1.9002293348312378
Iteration 7: train_loss 1.852829098701477
Iteration 8: train_loss 1.8388627767562866
Iteration 9: train_loss 1.9394915103912354
Iteration 10: train_loss 1.9173451662063599
Iteration 11: train_loss 1.819350004196167
Iteration 12: train_loss 1.9125322103500366
Iteration 13: train_loss 1.9103227853775024
Iteration 14: train_loss 1.8634531497955322
Iteration 15: train_loss 1.8881030082702637
Iteration 16: train_loss 1.8273897171020508
Iteration 17: train_loss 1.9236325025558472
Iteration 18: train_loss 1.8864439725875854
Iteration 19: train_loss 1.8967270851135254
Iteration 20: train_loss 1.8385720252990723
Iteration 21: train_loss 1.9540446996688843
Iteration 22: train_loss 1.9143213033676147
Iteration 23: train_loss 1.9164464473724365
Iteration 24: train_loss 1.8636057376861572
Iteration 25: train_loss 1.902279019355774
Iteration 26: train_loss 1.875665307044983
Iteration 27: train_loss 2.069922924041748
Iteration 28: train_loss 1.837369680404663
Iteration 29: train_loss 1.912119746208191
Iteration 30: train_loss 1.842495083808899
Iteration 31: train_loss 1.9311214685440063
Iteration 32: train_loss 1.9233837127685547
Iteration 33: train_loss 1.978477120399475
Iteration 34: train_loss 1.8594111204147339
Iteration 35: train_loss 1.9549728631973267
Iteration 36: train_loss 1.8504470586776733
Iteration 37: train_loss 1.9072701930999756
Iteration 38: train_loss 2.0381617546081543
Iteration 39: train_loss 1.925912857055664
Iteration 40: train_loss 1.8868805170059204
Iteration 41: train_loss 1.9605765342712402
Iteration 42: train_loss 1.851511836051941
Iteration 43: train_loss 1.8534643650054932
Iteration 44: train_loss 1.9355690479278564
Iteration 45: train_loss 1.8758859634399414
Iteration 46: train_loss 1.8880547285079956
Iteration 47: train_loss 1.9887484312057495
Iteration 48: train_loss 1.9471806287765503
Iteration 49: train_loss 1.8824270963668823
Iteration 50: train_loss 1.9636472463607788
Iteration 51: train_loss 1.8746247291564941
Iteration 52: train_loss 1.8327668905258179
Iteration 53: train_loss 1.8985284566879272
Iteration 54: train_loss 1.996619462966919
Iteration 55: train_loss 1.934770107269287
Iteration 56: train_loss 1.9668086767196655
Iteration 57: train_loss 1.9370644092559814
Iteration 58: train_loss 1.9122945070266724
Iteration 59: train_loss 1.9191806316375732
Iteration 60: train_loss 1.90607750415802
Iteration 61: train_loss 1.8974127769470215
Iteration 62: train_loss 1.9000962972640991
Iteration 63: train_loss 1.8979355096817017
Iteration 64: train_loss 1.8921629190444946
Iteration 65: train_loss 1.921312928199768
Iteration 66: train_loss 1.8983956575393677
Iteration 67: train_loss 1.878922462463379
Iteration 68: train_loss 1.8929424285888672
Iteration 69: train_loss 1.8755286931991577
Iteration 70: train_loss 1.913474678993225
Iteration 71: train_loss 1.8891805410385132
Iteration 72: train_loss 1.865827202796936
Iteration 73: train_loss 1.999521255493164
Iteration 74: train_loss 1.9411965608596802
Iteration 75: train_loss 1.911251425743103
Iteration 76: train_loss 1.9916932582855225
Iteration 77: train_loss 1.9860453605651855
Iteration 78: train_loss 1.9540166854858398
Iteration 79: train_loss 1.8991851806640625
Iteration 80: train_loss 1.98212730884552
Iteration 81: train_loss 1.9140233993530273
Iteration 82: train_loss 1.9123430252075195
Iteration 83: train_loss 1.9535001516342163
Iteration 84: train_loss 1.9102063179016113
Iteration 85: train_loss 1.9815446138381958
Iteration 86: train_loss 1.9295791387557983
Iteration 87: train_loss 1.89533269405365
Iteration 88: train_loss 1.9470763206481934
Iteration 89: train_loss 1.940263271331787
Iteration 90: train_loss 1.9530073404312134
Iteration 91: train_loss 1.8975366353988647
Iteration 92: train_loss 1.8968830108642578
Iteration 93: train_loss 1.9480780363082886
Iteration 94: train_loss 1.9719715118408203
Iteration 95: train_loss 1.9373446702957153
Iteration 96: train_loss 1.9223374128341675
Iteration 97: train_loss 1.9303277730941772
Iteration 98: train_loss 1.9284820556640625
Iteration 99: train_loss 1.9284578561782837
Iteration 100: train_loss 1.9288398027420044
Iteration 101: train_loss 1.8567523956298828
Iteration 102: train_loss 1.8727749586105347
Iteration 103: train_loss 1.9435234069824219
Iteration 104: train_loss 1.9126343727111816
Iteration 105: train_loss 1.9247299432754517
Iteration 106: train_loss 1.8957817554473877
Iteration 107: train_loss 1.9024631977081299
Iteration 108: train_loss 1.8836209774017334
Iteration 109: train_loss 1.9157830476760864
Iteration 110: train_loss 1.8907697200775146
Iteration 111: train_loss 1.9300585985183716
Iteration 112: train_loss 1.9100996255874634
Iteration 113: train_loss 1.8943785429000854
Iteration 114: train_loss 1.917150855064392
Iteration 115: train_loss 1.9513078927993774
Iteration 116: train_loss 1.954744577407837
Iteration 117: train_loss 1.941245436668396
Iteration 118: train_loss 1.9630892276763916
Iteration 119: train_loss 1.9797991514205933
Iteration 120: train_loss 2.0046136379241943
Iteration 121: train_loss 1.9596022367477417
Iteration 122: train_loss 1.9521695375442505
Iteration 123: train_loss 1.9480865001678467
Iteration 124: train_loss 2.0254194736480713
Iteration 125: train_loss 1.9607709646224976
Iteration 126: train_loss 1.8826916217803955
Iteration 127: train_loss 1.99057936668396
Iteration 128: train_loss 1.9327020645141602
Iteration 129: train_loss 1.9635910987854004
Iteration 130: train_loss 1.9438540935516357
Iteration 131: train_loss 1.9433362483978271
Iteration 132: train_loss 1.8999040126800537
Iteration 133: train_loss 1.9686319828033447
Iteration 134: train_loss 1.88205885887146
Iteration 135: train_loss 1.8793225288391113
Iteration 136: train_loss 1.8631043434143066
Iteration 137: train_loss 2.0147573947906494
Iteration 138: train_loss 1.9370681047439575
Iteration 139: train_loss 1.8837586641311646
Iteration 140: train_loss 2.0096194744110107
Iteration 141: train_loss 1.9471609592437744
Iteration 142: train_loss 1.9271104335784912
Iteration 143: train_loss 1.9283461570739746
Iteration 144: train_loss 1.9729046821594238
Iteration 145: train_loss 1.9376044273376465
Iteration 146: train_loss 1.9441808462142944
Iteration 147: train_loss 1.9580323696136475
Iteration 148: train_loss 1.9143003225326538
Iteration 149: train_loss 1.9591290950775146
Iteration 150: train_loss 1.9542863368988037
Iteration 151: train_loss 1.9261163473129272
Iteration 152: train_loss 1.8917505741119385
Iteration 153: train_loss 1.9581170082092285
Iteration 154: train_loss 1.8893986940383911
Iteration 155: train_loss 1.9751801490783691
Iteration 156: train_loss 2.017495632171631
Iteration 157: train_loss 1.9751062393188477
Iteration 158: train_loss 1.9122836589813232
Iteration 159: train_loss 1.9016462564468384
Iteration 160: train_loss 1.9758538007736206
Iteration 161: train_loss 1.9403938055038452
Iteration 162: train_loss 2.048647880554199
Iteration 163: train_loss 1.8812516927719116
Iteration 164: train_loss 1.9516247510910034
Iteration 165: train_loss 2.036759853363037
Iteration 166: train_loss 1.942609429359436
Iteration 167: train_loss 1.9376161098480225
Iteration 168: train_loss 1.9120579957962036
Iteration 169: train_loss 1.9661282300949097
Iteration 170: train_loss 1.924505591392517
Iteration 171: train_loss 1.9565844535827637
Iteration 172: train_loss 1.9664355516433716
Iteration 173: train_loss 1.895397663116455
Iteration 174: train_loss 1.918390154838562
Iteration 175: train_loss 1.8569227457046509
Iteration 176: train_loss 1.9101802110671997
Iteration 177: train_loss 1.930568814277649
Epoch 29: train_avg_loss 1.9240149017107688 eval_avg_acc: 0.3259446850119696 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:08:01] [32mIntermediate result: 0.3259446850119696  (Index 28)[0m
================Epoch: 30================
Iteration 1: train_loss 1.9491634368896484
Iteration 2: train_loss 1.8932040929794312
Iteration 3: train_loss 1.87594735622406
Iteration 4: train_loss 1.8698805570602417
Iteration 5: train_loss 1.9058270454406738
Iteration 6: train_loss 1.7979315519332886
Iteration 7: train_loss 1.9180585145950317
Iteration 8: train_loss 1.8727376461029053
Iteration 9: train_loss 1.8679391145706177
Iteration 10: train_loss 1.9166909456253052
Iteration 11: train_loss 1.9406057596206665
Iteration 12: train_loss 1.9700223207473755
Iteration 13: train_loss 1.9474295377731323
Iteration 14: train_loss 1.9633814096450806
Iteration 15: train_loss 1.9656468629837036
Iteration 16: train_loss 1.9484552145004272
Iteration 17: train_loss 1.9224656820297241
Iteration 18: train_loss 1.902979850769043
Iteration 19: train_loss 1.9535893201828003
Iteration 20: train_loss 1.873651385307312
Iteration 21: train_loss 1.9235929250717163
Iteration 22: train_loss 1.8583781719207764
Iteration 23: train_loss 1.9130597114562988
Iteration 24: train_loss 1.9062631130218506
Iteration 25: train_loss 1.9579534530639648
Iteration 26: train_loss 1.8894227743148804
Iteration 27: train_loss 1.902219533920288
Iteration 28: train_loss 1.9044629335403442
Iteration 29: train_loss 1.9247946739196777
Iteration 30: train_loss 1.8924587965011597
Iteration 31: train_loss 1.8920131921768188
Iteration 32: train_loss 1.8333231210708618
Iteration 33: train_loss 1.8671702146530151
Iteration 34: train_loss 1.8366539478302002
Iteration 35: train_loss 1.9179208278656006
Iteration 36: train_loss 1.9614146947860718
Iteration 37: train_loss 1.9149545431137085
Iteration 38: train_loss 1.9364231824874878
Iteration 39: train_loss 1.8453491926193237
Iteration 40: train_loss 1.847783088684082
Iteration 41: train_loss 1.9984345436096191
Iteration 42: train_loss 1.8642380237579346
Iteration 43: train_loss 1.9728546142578125
Iteration 44: train_loss 1.843467354774475
Iteration 45: train_loss 1.9456602334976196
Iteration 46: train_loss 1.9071471691131592
Iteration 47: train_loss 1.8770545721054077
Iteration 48: train_loss 1.849487543106079
Iteration 49: train_loss 1.9106076955795288
Iteration 50: train_loss 1.8611278533935547
Iteration 51: train_loss 1.9537086486816406
Iteration 52: train_loss 1.8770227432250977
Iteration 53: train_loss 1.829280138015747
Iteration 54: train_loss 1.9178110361099243
Iteration 55: train_loss 1.953570008277893
Iteration 56: train_loss 1.904721736907959
Iteration 57: train_loss 1.9464564323425293
Iteration 58: train_loss 1.9409054517745972
Iteration 59: train_loss 1.8370616436004639
Iteration 60: train_loss 1.899377703666687
Iteration 61: train_loss 2.004424810409546
Iteration 62: train_loss 1.9352102279663086
Iteration 63: train_loss 1.9040336608886719
Iteration 64: train_loss 1.9001277685165405
Iteration 65: train_loss 1.940739631652832
Iteration 66: train_loss 1.8591513633728027
Iteration 67: train_loss 1.8938454389572144
Iteration 68: train_loss 1.9009604454040527
Iteration 69: train_loss 1.8264150619506836
Iteration 70: train_loss 1.9336137771606445
Iteration 71: train_loss 1.8460705280303955
Iteration 72: train_loss 1.9283292293548584
Iteration 73: train_loss 1.924136996269226
Iteration 74: train_loss 1.8830084800720215
Iteration 75: train_loss 1.980268955230713
Iteration 76: train_loss 1.8571884632110596
Iteration 77: train_loss 1.949739933013916
Iteration 78: train_loss 1.8619203567504883
Iteration 79: train_loss 1.9191709756851196
Iteration 80: train_loss 1.9393444061279297
Iteration 81: train_loss 1.8894356489181519
Iteration 82: train_loss 1.7984788417816162
Iteration 83: train_loss 1.961517572402954
Iteration 84: train_loss 1.9843541383743286
Iteration 85: train_loss 1.9406495094299316
Iteration 86: train_loss 1.8874492645263672
Iteration 87: train_loss 1.8792363405227661
Iteration 88: train_loss 1.9288487434387207
Iteration 89: train_loss 1.8990813493728638
Iteration 90: train_loss 1.912157654762268
Iteration 91: train_loss 1.9506151676177979
Iteration 92: train_loss 1.8942909240722656
Iteration 93: train_loss 1.8900669813156128
Iteration 94: train_loss 1.8912513256072998
Iteration 95: train_loss 1.9336864948272705
Iteration 96: train_loss 1.922097086906433
Iteration 97: train_loss 1.9366263151168823
Iteration 98: train_loss 2.015016555786133
Iteration 99: train_loss 1.8313552141189575
Iteration 100: train_loss 1.924556851387024
Iteration 101: train_loss 1.9254035949707031
Iteration 102: train_loss 1.949587106704712
Iteration 103: train_loss 1.9183430671691895
Iteration 104: train_loss 1.866607427597046
Iteration 105: train_loss 1.9350802898406982
Iteration 106: train_loss 1.9137237071990967
Iteration 107: train_loss 1.8826098442077637
Iteration 108: train_loss 1.9657187461853027
Iteration 109: train_loss 1.9747358560562134
Iteration 110: train_loss 2.0258004665374756
Iteration 111: train_loss 1.9246017932891846
Iteration 112: train_loss 1.9898536205291748
Iteration 113: train_loss 1.9869163036346436
Iteration 114: train_loss 1.9540235996246338
Iteration 115: train_loss 1.901389241218567
Iteration 116: train_loss 1.9209688901901245
Iteration 117: train_loss 1.9409303665161133
Iteration 118: train_loss 1.8185222148895264
Iteration 119: train_loss 1.9669091701507568
Iteration 120: train_loss 2.040175199508667
Iteration 121: train_loss 1.9135544300079346
Iteration 122: train_loss 1.939477562904358
Iteration 123: train_loss 1.9419963359832764
Iteration 124: train_loss 1.93953275680542
Iteration 125: train_loss 1.9375686645507812
Iteration 126: train_loss 1.8841614723205566
Iteration 127: train_loss 1.8259211778640747
Iteration 128: train_loss 1.9368735551834106
Iteration 129: train_loss 1.9109984636306763
Iteration 130: train_loss 1.860777497291565
Iteration 131: train_loss 1.898403525352478
Iteration 132: train_loss 2.0514373779296875
Iteration 133: train_loss 1.9511830806732178
Iteration 134: train_loss 1.9301013946533203
Iteration 135: train_loss 1.9444688558578491
Iteration 136: train_loss 1.8661729097366333
Iteration 137: train_loss 1.8913322687149048
Iteration 138: train_loss 1.9228073358535767
Iteration 139: train_loss 1.8803868293762207
Iteration 140: train_loss 1.9406038522720337
Iteration 141: train_loss 1.9886298179626465
Iteration 142: train_loss 1.921375036239624
Iteration 143: train_loss 1.9408044815063477
Iteration 144: train_loss 1.8628510236740112
Iteration 145: train_loss 1.9469693899154663
Iteration 146: train_loss 1.9107216596603394
Iteration 147: train_loss 1.8929498195648193
Iteration 148: train_loss 2.0011396408081055
Iteration 149: train_loss 1.9351017475128174
Iteration 150: train_loss 1.9855010509490967
Iteration 151: train_loss 1.9404515027999878
Iteration 152: train_loss 1.9224601984024048
Iteration 153: train_loss 1.9410948753356934
Iteration 154: train_loss 1.899274468421936
Iteration 155: train_loss 1.8921047449111938
Iteration 156: train_loss 1.9166597127914429
Iteration 157: train_loss 1.9106814861297607
Iteration 158: train_loss 1.9357211589813232
Iteration 159: train_loss 1.9066143035888672
Iteration 160: train_loss 2.0016136169433594
Iteration 161: train_loss 1.9474819898605347
Iteration 162: train_loss 1.9522743225097656
Iteration 163: train_loss 1.935137152671814
Iteration 164: train_loss 1.9634356498718262
Iteration 165: train_loss 1.9291250705718994
Iteration 166: train_loss 1.986661672592163
Iteration 167: train_loss 1.922178030014038
Iteration 168: train_loss 1.944984793663025
Iteration 169: train_loss 1.9155857563018799
Iteration 170: train_loss 1.867627501487732
Iteration 171: train_loss 1.9520338773727417
Iteration 172: train_loss 1.977397084236145
Iteration 173: train_loss 1.92122483253479
Iteration 174: train_loss 1.9290111064910889
Iteration 175: train_loss 1.9768080711364746
Iteration 176: train_loss 1.9005990028381348
Iteration 177: train_loss 1.9987670183181763
Epoch 30: train_avg_loss 1.9184881347720906 eval_avg_acc: 0.32933300718490927 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:08:41] [32mIntermediate result: 0.32933300718490927  (Index 29)[0m
================Epoch: 31================
Iteration 1: train_loss 1.8709700107574463
Iteration 2: train_loss 1.846989393234253
Iteration 3: train_loss 1.808477759361267
Iteration 4: train_loss 1.901134729385376
Iteration 5: train_loss 1.8442268371582031
Iteration 6: train_loss 1.920104742050171
Iteration 7: train_loss 1.873019814491272
Iteration 8: train_loss 1.8545714616775513
Iteration 9: train_loss 1.8803660869598389
Iteration 10: train_loss 1.927068829536438
Iteration 11: train_loss 1.927896499633789
Iteration 12: train_loss 1.8640305995941162
Iteration 13: train_loss 1.9074686765670776
Iteration 14: train_loss 1.8771462440490723
Iteration 15: train_loss 1.87595796585083
Iteration 16: train_loss 1.899734377861023
Iteration 17: train_loss 1.8333193063735962
Iteration 18: train_loss 1.879557728767395
Iteration 19: train_loss 1.8600324392318726
Iteration 20: train_loss 1.9095591306686401
Iteration 21: train_loss 1.8321012258529663
Iteration 22: train_loss 1.8971738815307617
Iteration 23: train_loss 1.815873384475708
Iteration 24: train_loss 1.9391539096832275
Iteration 25: train_loss 1.9102007150650024
Iteration 26: train_loss 1.8687763214111328
Iteration 27: train_loss 1.821358561515808
Iteration 28: train_loss 1.8837692737579346
Iteration 29: train_loss 1.8411458730697632
Iteration 30: train_loss 1.8197548389434814
Iteration 31: train_loss 1.8972378969192505
Iteration 32: train_loss 1.8361343145370483
Iteration 33: train_loss 1.913836121559143
Iteration 34: train_loss 1.9123355150222778
Iteration 35: train_loss 1.9512935876846313
Iteration 36: train_loss 1.9281599521636963
Iteration 37: train_loss 1.8805737495422363
Iteration 38: train_loss 1.8341493606567383
Iteration 39: train_loss 1.8709310293197632
Iteration 40: train_loss 1.8707853555679321
Iteration 41: train_loss 1.8905870914459229
Iteration 42: train_loss 1.809362769126892
Iteration 43: train_loss 1.9143054485321045
Iteration 44: train_loss 1.946831226348877
Iteration 45: train_loss 1.9605162143707275
Iteration 46: train_loss 1.8619111776351929
Iteration 47: train_loss 1.8063414096832275
Iteration 48: train_loss 1.8936909437179565
Iteration 49: train_loss 1.9027546644210815
Iteration 50: train_loss 1.9451441764831543
Iteration 51: train_loss 1.8925085067749023
Iteration 52: train_loss 1.8830091953277588
Iteration 53: train_loss 1.9391999244689941
Iteration 54: train_loss 1.869327425956726
Iteration 55: train_loss 1.8818641901016235
Iteration 56: train_loss 1.9701931476593018
Iteration 57: train_loss 1.9011952877044678
Iteration 58: train_loss 1.8832666873931885
Iteration 59: train_loss 1.9772624969482422
Iteration 60: train_loss 1.8633123636245728
Iteration 61: train_loss 1.9358795881271362
Iteration 62: train_loss 1.9974946975708008
Iteration 63: train_loss 1.9028438329696655
Iteration 64: train_loss 1.8885211944580078
Iteration 65: train_loss 1.8915349245071411
Iteration 66: train_loss 1.9212646484375
Iteration 67: train_loss 1.9081039428710938
Iteration 68: train_loss 1.8628159761428833
Iteration 69: train_loss 1.9051462411880493
Iteration 70: train_loss 2.013108015060425
Iteration 71: train_loss 1.9336425065994263
Iteration 72: train_loss 1.9642103910446167
Iteration 73: train_loss 1.9343061447143555
Iteration 74: train_loss 1.9123756885528564
Iteration 75: train_loss 1.9294540882110596
Iteration 76: train_loss 1.9203866720199585
Iteration 77: train_loss 1.970213532447815
Iteration 78: train_loss 1.9304028749465942
Iteration 79: train_loss 1.8432008028030396
Iteration 80: train_loss 1.8649998903274536
Iteration 81: train_loss 1.87313973903656
Iteration 82: train_loss 1.8815271854400635
Iteration 83: train_loss 1.9162256717681885
Iteration 84: train_loss 1.8066667318344116
Iteration 85: train_loss 1.873226284980774
Iteration 86: train_loss 1.884265661239624
Iteration 87: train_loss 1.886540412902832
Iteration 88: train_loss 1.900346040725708
Iteration 89: train_loss 1.9268348217010498
Iteration 90: train_loss 1.9627372026443481
Iteration 91: train_loss 1.9604581594467163
Iteration 92: train_loss 1.8365689516067505
Iteration 93: train_loss 1.8872491121292114
Iteration 94: train_loss 1.971401572227478
Iteration 95: train_loss 1.8650143146514893
Iteration 96: train_loss 1.9086921215057373
Iteration 97: train_loss 1.9066632986068726
Iteration 98: train_loss 1.9158973693847656
Iteration 99: train_loss 1.867495059967041
Iteration 100: train_loss 1.9492955207824707
Iteration 101: train_loss 1.8086344003677368
Iteration 102: train_loss 1.9356722831726074
Iteration 103: train_loss 1.9184809923171997
Iteration 104: train_loss 1.8589284420013428
Iteration 105: train_loss 1.9550350904464722
Iteration 106: train_loss 1.8791224956512451
Iteration 107: train_loss 1.9444721937179565
Iteration 108: train_loss 1.838514804840088
Iteration 109: train_loss 1.8884191513061523
Iteration 110: train_loss 1.9603228569030762
Iteration 111: train_loss 1.8725122213363647
Iteration 112: train_loss 1.8692706823349
Iteration 113: train_loss 1.8865517377853394
Iteration 114: train_loss 1.8326842784881592
Iteration 115: train_loss 1.9168494939804077
Iteration 116: train_loss 1.9438084363937378
Iteration 117: train_loss 1.911675214767456
Iteration 118: train_loss 1.8923161029815674
Iteration 119: train_loss 1.9314649105072021
Iteration 120: train_loss 1.9288567304611206
Iteration 121: train_loss 1.8666197061538696
Iteration 122: train_loss 1.896810531616211
Iteration 123: train_loss 1.8496633768081665
Iteration 124: train_loss 1.9158583879470825
Iteration 125: train_loss 1.8941298723220825
Iteration 126: train_loss 1.8572845458984375
Iteration 127: train_loss 1.8670053482055664
Iteration 128: train_loss 1.8774631023406982
Iteration 129: train_loss 1.9336036443710327
Iteration 130: train_loss 1.9234553575515747
Iteration 131: train_loss 1.931654453277588
Iteration 132: train_loss 1.8812251091003418
Iteration 133: train_loss 1.9726673364639282
Iteration 134: train_loss 1.9063763618469238
Iteration 135: train_loss 1.8863542079925537
Iteration 136: train_loss 1.840394377708435
Iteration 137: train_loss 1.8175517320632935
Iteration 138: train_loss 1.923963189125061
Iteration 139: train_loss 1.878351092338562
Iteration 140: train_loss 1.9257041215896606
Iteration 141: train_loss 1.8535722494125366
Iteration 142: train_loss 1.884629249572754
Iteration 143: train_loss 1.9090511798858643
Iteration 144: train_loss 1.8379793167114258
Iteration 145: train_loss 1.8937104940414429
Iteration 146: train_loss 1.9350214004516602
Iteration 147: train_loss 1.9136855602264404
Iteration 148: train_loss 1.86197829246521
Iteration 149: train_loss 1.8648408651351929
Iteration 150: train_loss 1.8677955865859985
Iteration 151: train_loss 1.9615834951400757
Iteration 152: train_loss 1.9136484861373901
Iteration 153: train_loss 1.930465579032898
Iteration 154: train_loss 1.8993251323699951
Iteration 155: train_loss 1.93137788772583
Iteration 156: train_loss 1.9026610851287842
Iteration 157: train_loss 1.833477258682251
Iteration 158: train_loss 1.9010087251663208
Iteration 159: train_loss 1.9328199625015259
Iteration 160: train_loss 1.891266107559204
Iteration 161: train_loss 1.923683762550354
Iteration 162: train_loss 1.9269537925720215
Iteration 163: train_loss 1.8907395601272583
Iteration 164: train_loss 1.9787306785583496
Iteration 165: train_loss 1.8515018224716187
Iteration 166: train_loss 1.9226781129837036
Iteration 167: train_loss 2.003455400466919
Iteration 168: train_loss 1.8623998165130615
Iteration 169: train_loss 1.905656099319458
Iteration 170: train_loss 1.9383903741836548
Iteration 171: train_loss 1.9517744779586792
Iteration 172: train_loss 1.977036476135254
Iteration 173: train_loss 1.8662869930267334
Iteration 174: train_loss 1.9308284521102905
Iteration 175: train_loss 1.9284995794296265
Iteration 176: train_loss 1.9905787706375122
Iteration 177: train_loss 2.012444496154785
Epoch 31: train_avg_loss 1.8988156931548468 eval_avg_acc: 0.32988205180177277 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:09:22] [32mIntermediate result: 0.32988205180177277  (Index 30)[0m
================Epoch: 32================
Iteration 1: train_loss 1.7951345443725586
Iteration 2: train_loss 1.859893798828125
Iteration 3: train_loss 1.8323676586151123
Iteration 4: train_loss 1.871252417564392
Iteration 5: train_loss 1.84053635597229
Iteration 6: train_loss 1.818617820739746
Iteration 7: train_loss 1.8661444187164307
Iteration 8: train_loss 1.8787407875061035
Iteration 9: train_loss 1.822516918182373
Iteration 10: train_loss 1.827974796295166
Iteration 11: train_loss 1.8186320066452026
Iteration 12: train_loss 1.8404490947723389
Iteration 13: train_loss 1.9128143787384033
Iteration 14: train_loss 1.9050334692001343
Iteration 15: train_loss 1.7721889019012451
Iteration 16: train_loss 1.854849934577942
Iteration 17: train_loss 1.8581613302230835
Iteration 18: train_loss 1.8474063873291016
Iteration 19: train_loss 1.857886552810669
Iteration 20: train_loss 1.8673357963562012
Iteration 21: train_loss 1.8520708084106445
Iteration 22: train_loss 1.893357515335083
Iteration 23: train_loss 1.8661425113677979
Iteration 24: train_loss 1.9388940334320068
Iteration 25: train_loss 1.879004716873169
Iteration 26: train_loss 1.75234854221344
Iteration 27: train_loss 1.8593132495880127
Iteration 28: train_loss 1.891697883605957
Iteration 29: train_loss 1.8388760089874268
Iteration 30: train_loss 1.840326189994812
Iteration 31: train_loss 1.9041160345077515
Iteration 32: train_loss 1.926357626914978
Iteration 33: train_loss 1.8734347820281982
Iteration 34: train_loss 1.8041503429412842
Iteration 35: train_loss 1.8721058368682861
Iteration 36: train_loss 1.8728208541870117
Iteration 37: train_loss 1.9063869714736938
Iteration 38: train_loss 1.842675805091858
Iteration 39: train_loss 1.9479433298110962
Iteration 40: train_loss 1.9339017868041992
Iteration 41: train_loss 1.8285058736801147
Iteration 42: train_loss 1.8817243576049805
Iteration 43: train_loss 1.9158250093460083
Iteration 44: train_loss 1.9819366931915283
Iteration 45: train_loss 1.8561053276062012
Iteration 46: train_loss 1.8830440044403076
Iteration 47: train_loss 1.895578384399414
Iteration 48: train_loss 1.891923189163208
Iteration 49: train_loss 1.921416163444519
Iteration 50: train_loss 1.9749747514724731
Iteration 51: train_loss 1.8473328351974487
Iteration 52: train_loss 1.8512327671051025
Iteration 53: train_loss 1.814416527748108
Iteration 54: train_loss 1.8810008764266968
Iteration 55: train_loss 1.9184741973876953
Iteration 56: train_loss 1.923837661743164
Iteration 57: train_loss 1.882002830505371
Iteration 58: train_loss 1.8496570587158203
Iteration 59: train_loss 1.8607231378555298
Iteration 60: train_loss 1.8964661359786987
Iteration 61: train_loss 1.8050810098648071
Iteration 62: train_loss 1.8342002630233765
Iteration 63: train_loss 1.8076692819595337
Iteration 64: train_loss 1.8661335706710815
Iteration 65: train_loss 1.919379472732544
Iteration 66: train_loss 1.9272691011428833
Iteration 67: train_loss 1.8817505836486816
Iteration 68: train_loss 1.8824769258499146
Iteration 69: train_loss 1.9610874652862549
Iteration 70: train_loss 1.831390619277954
Iteration 71: train_loss 1.878685712814331
Iteration 72: train_loss 1.8908191919326782
Iteration 73: train_loss 1.9025766849517822
Iteration 74: train_loss 1.8591506481170654
Iteration 75: train_loss 1.8386186361312866
Iteration 76: train_loss 1.8495954275131226
Iteration 77: train_loss 1.904697060585022
Iteration 78: train_loss 1.8887325525283813
Iteration 79: train_loss 1.8124219179153442
Iteration 80: train_loss 1.8990212678909302
Iteration 81: train_loss 1.8525992631912231
Iteration 82: train_loss 1.9082820415496826
Iteration 83: train_loss 1.9337788820266724
Iteration 84: train_loss 1.9255075454711914
Iteration 85: train_loss 1.8920886516571045
Iteration 86: train_loss 1.8552109003067017
Iteration 87: train_loss 1.9334468841552734
Iteration 88: train_loss 1.911641240119934
Iteration 89: train_loss 1.913658618927002
Iteration 90: train_loss 1.9609041213989258
Iteration 91: train_loss 1.9194579124450684
Iteration 92: train_loss 1.8871121406555176
Iteration 93: train_loss 1.956404209136963
Iteration 94: train_loss 1.8869267702102661
Iteration 95: train_loss 1.9144166707992554
Iteration 96: train_loss 1.9042874574661255
Iteration 97: train_loss 1.9072514772415161
Iteration 98: train_loss 1.8844459056854248
Iteration 99: train_loss 1.8809218406677246
Iteration 100: train_loss 1.9326704740524292
Iteration 101: train_loss 1.919478416442871
Iteration 102: train_loss 1.860176682472229
Iteration 103: train_loss 1.8806233406066895
Iteration 104: train_loss 1.8448259830474854
Iteration 105: train_loss 1.8610552549362183
Iteration 106: train_loss 1.8440979719161987
Iteration 107: train_loss 1.8803393840789795
Iteration 108: train_loss 1.7982538938522339
Iteration 109: train_loss 1.916480541229248
Iteration 110: train_loss 1.9605447053909302
Iteration 111: train_loss 1.946803331375122
Iteration 112: train_loss 1.9523166418075562
Iteration 113: train_loss 1.8884080648422241
Iteration 114: train_loss 1.9179425239562988
Iteration 115: train_loss 1.9092974662780762
Iteration 116: train_loss 1.8846849203109741
Iteration 117: train_loss 1.9410815238952637
Iteration 118: train_loss 1.7786309719085693
Iteration 119: train_loss 1.8519999980926514
Iteration 120: train_loss 1.8265833854675293
Iteration 121: train_loss 1.9557843208312988
Iteration 122: train_loss 1.8931711912155151
Iteration 123: train_loss 1.8668553829193115
Iteration 124: train_loss 1.8939992189407349
Iteration 125: train_loss 1.877528429031372
Iteration 126: train_loss 1.8763188123703003
Iteration 127: train_loss 1.8822259902954102
Iteration 128: train_loss 1.9212453365325928
Iteration 129: train_loss 1.8518980741500854
Iteration 130: train_loss 1.880444049835205
Iteration 131: train_loss 1.8784751892089844
Iteration 132: train_loss 1.903416633605957
Iteration 133: train_loss 1.8658490180969238
Iteration 134: train_loss 1.9229357242584229
Iteration 135: train_loss 1.8867639303207397
Iteration 136: train_loss 1.9548380374908447
Iteration 137: train_loss 1.8882850408554077
Iteration 138: train_loss 1.8134807348251343
Iteration 139: train_loss 1.8533512353897095
Iteration 140: train_loss 1.9067500829696655
Iteration 141: train_loss 1.9226361513137817
Iteration 142: train_loss 1.865276575088501
Iteration 143: train_loss 1.9081867933273315
Iteration 144: train_loss 1.8617714643478394
Iteration 145: train_loss 1.946295976638794
Iteration 146: train_loss 1.8738794326782227
Iteration 147: train_loss 1.7902709245681763
Iteration 148: train_loss 1.929423451423645
Iteration 149: train_loss 1.9207500219345093
Iteration 150: train_loss 1.8525798320770264
Iteration 151: train_loss 1.8811311721801758
Iteration 152: train_loss 1.833892583847046
Iteration 153: train_loss 1.867085337638855
Iteration 154: train_loss 1.9040477275848389
Iteration 155: train_loss 1.8376855850219727
Iteration 156: train_loss 1.9888319969177246
Iteration 157: train_loss 1.9072073698043823
Iteration 158: train_loss 1.817162036895752
Iteration 159: train_loss 1.8932888507843018
Iteration 160: train_loss 1.908521056175232
Iteration 161: train_loss 1.916329026222229
Iteration 162: train_loss 1.923316240310669
Iteration 163: train_loss 1.8702372312545776
Iteration 164: train_loss 1.8672715425491333
Iteration 165: train_loss 1.9331471920013428
Iteration 166: train_loss 1.876214623451233
Iteration 167: train_loss 1.959782600402832
Iteration 168: train_loss 1.8817301988601685
Iteration 169: train_loss 1.8630090951919556
Iteration 170: train_loss 1.968269944190979
Iteration 171: train_loss 1.9347165822982788
Iteration 172: train_loss 2.0081846714019775
Iteration 173: train_loss 1.9330534934997559
Iteration 174: train_loss 1.8608838319778442
Iteration 175: train_loss 1.866747260093689
Iteration 176: train_loss 1.86638343334198
Iteration 177: train_loss 1.8596656322479248
Epoch 32: train_avg_loss 1.8832650777310302 eval_avg_acc: 0.30906150141501226 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:10:03] [32mIntermediate result: 0.30906150141501226  (Index 31)[0m
================Epoch: 33================
Iteration 1: train_loss 1.812416911125183
Iteration 2: train_loss 1.863853931427002
Iteration 3: train_loss 1.8149086236953735
Iteration 4: train_loss 1.7991856336593628
Iteration 5: train_loss 1.9003074169158936
Iteration 6: train_loss 1.8786715269088745
Iteration 7: train_loss 1.9129987955093384
Iteration 8: train_loss 1.8838920593261719
Iteration 9: train_loss 1.8654241561889648
Iteration 10: train_loss 1.8347392082214355
Iteration 11: train_loss 1.7101056575775146
Iteration 12: train_loss 1.8430240154266357
Iteration 13: train_loss 1.8401262760162354
Iteration 14: train_loss 1.799312710762024
Iteration 15: train_loss 1.8312501907348633
Iteration 16: train_loss 1.8322759866714478
Iteration 17: train_loss 1.863124966621399
Iteration 18: train_loss 1.836440920829773
Iteration 19: train_loss 1.8437713384628296
Iteration 20: train_loss 1.826917290687561
Iteration 21: train_loss 1.8105320930480957
Iteration 22: train_loss 1.8465538024902344
Iteration 23: train_loss 1.8592385053634644
Iteration 24: train_loss 1.8280656337738037
Iteration 25: train_loss 1.8472846746444702
Iteration 26: train_loss 1.7845618724822998
Iteration 27: train_loss 1.9069198369979858
Iteration 28: train_loss 1.8655794858932495
Iteration 29: train_loss 1.8346467018127441
Iteration 30: train_loss 1.847975254058838
Iteration 31: train_loss 1.8576358556747437
Iteration 32: train_loss 1.8506745100021362
Iteration 33: train_loss 1.8774272203445435
Iteration 34: train_loss 1.9372214078903198
Iteration 35: train_loss 1.8519282341003418
Iteration 36: train_loss 1.9376095533370972
Iteration 37: train_loss 1.9219144582748413
Iteration 38: train_loss 1.7755815982818604
Iteration 39: train_loss 1.8155295848846436
Iteration 40: train_loss 1.8536341190338135
Iteration 41: train_loss 1.785423994064331
Iteration 42: train_loss 1.8585987091064453
Iteration 43: train_loss 1.8144537210464478
Iteration 44: train_loss 1.800215482711792
Iteration 45: train_loss 1.8050376176834106
Iteration 46: train_loss 1.8523191213607788
Iteration 47: train_loss 1.9242576360702515
Iteration 48: train_loss 1.901086688041687
Iteration 49: train_loss 1.825734257698059
Iteration 50: train_loss 1.8450524806976318
Iteration 51: train_loss 1.8771523237228394
Iteration 52: train_loss 1.9249616861343384
Iteration 53: train_loss 1.8214364051818848
Iteration 54: train_loss 1.8244627714157104
Iteration 55: train_loss 1.9125217199325562
Iteration 56: train_loss 1.8564612865447998
Iteration 57: train_loss 1.842211127281189
Iteration 58: train_loss 1.8856894969940186
Iteration 59: train_loss 1.852928638458252
Iteration 60: train_loss 1.8326280117034912
Iteration 61: train_loss 1.866890549659729
Iteration 62: train_loss 1.8397809267044067
Iteration 63: train_loss 1.8170287609100342
Iteration 64: train_loss 1.8350516557693481
Iteration 65: train_loss 1.9205164909362793
Iteration 66: train_loss 1.834176778793335
Iteration 67: train_loss 1.8551819324493408
Iteration 68: train_loss 1.883122444152832
Iteration 69: train_loss 1.8145049810409546
Iteration 70: train_loss 1.7941009998321533
Iteration 71: train_loss 1.8780781030654907
Iteration 72: train_loss 1.886122226715088
Iteration 73: train_loss 1.860548973083496
Iteration 74: train_loss 1.8225123882293701
Iteration 75: train_loss 1.8249684572219849
Iteration 76: train_loss 1.9344433546066284
Iteration 77: train_loss 1.8697831630706787
Iteration 78: train_loss 1.8952136039733887
Iteration 79: train_loss 1.8756108283996582
Iteration 80: train_loss 1.8379124402999878
Iteration 81: train_loss 1.8661378622055054
Iteration 82: train_loss 1.8870656490325928
Iteration 83: train_loss 1.8794574737548828
Iteration 84: train_loss 1.8346672058105469
Iteration 85: train_loss 2.029261350631714
Iteration 86: train_loss 1.8572406768798828
Iteration 87: train_loss 1.893871784210205
Iteration 88: train_loss 1.8582090139389038
Iteration 89: train_loss 1.8473092317581177
Iteration 90: train_loss 1.846286416053772
Iteration 91: train_loss 1.895607590675354
Iteration 92: train_loss 1.8778550624847412
Iteration 93: train_loss 1.864806056022644
Iteration 94: train_loss 1.8636151552200317
Iteration 95: train_loss 1.9216481447219849
Iteration 96: train_loss 1.8598061800003052
Iteration 97: train_loss 1.8602426052093506
Iteration 98: train_loss 1.8570563793182373
Iteration 99: train_loss 1.91612708568573
Iteration 100: train_loss 1.9000277519226074
Iteration 101: train_loss 1.9033015966415405
Iteration 102: train_loss 1.934910774230957
Iteration 103: train_loss 1.9107500314712524
Iteration 104: train_loss 1.8752928972244263
Iteration 105: train_loss 1.9021433591842651
Iteration 106: train_loss 1.8138898611068726
Iteration 107: train_loss 1.8575161695480347
Iteration 108: train_loss 1.8542107343673706
Iteration 109: train_loss 1.861414909362793
Iteration 110: train_loss 1.8825770616531372
Iteration 111: train_loss 1.837952971458435
Iteration 112: train_loss 1.8355449438095093
Iteration 113: train_loss 1.862182378768921
Iteration 114: train_loss 1.8878755569458008
Iteration 115: train_loss 1.8382138013839722
Iteration 116: train_loss 1.8393948078155518
Iteration 117: train_loss 1.7844213247299194
Iteration 118: train_loss 1.7730549573898315
Iteration 119: train_loss 1.8709107637405396
Iteration 120: train_loss 1.8601634502410889
Iteration 121: train_loss 1.8648216724395752
Iteration 122: train_loss 1.8353067636489868
Iteration 123: train_loss 1.8940725326538086
Iteration 124: train_loss 1.9060760736465454
Iteration 125: train_loss 1.902794361114502
Iteration 126: train_loss 1.796822428703308
Iteration 127: train_loss 1.8572794198989868
Iteration 128: train_loss 1.8853737115859985
Iteration 129: train_loss 1.9419901371002197
Iteration 130: train_loss 1.8437964916229248
Iteration 131: train_loss 1.858248233795166
Iteration 132: train_loss 1.9065148830413818
Iteration 133: train_loss 1.8632540702819824
Iteration 134: train_loss 1.9240092039108276
Iteration 135: train_loss 1.8513669967651367
Iteration 136: train_loss 1.9315348863601685
Iteration 137: train_loss 1.904924750328064
Iteration 138: train_loss 1.9493036270141602
Iteration 139: train_loss 1.9385185241699219
Iteration 140: train_loss 1.8670426607131958
Iteration 141: train_loss 1.8400555849075317
Iteration 142: train_loss 1.9145640134811401
Iteration 143: train_loss 1.9243603944778442
Iteration 144: train_loss 1.92655611038208
Iteration 145: train_loss 1.8597819805145264
Iteration 146: train_loss 1.9546549320220947
Iteration 147: train_loss 1.904733657836914
Iteration 148: train_loss 1.9228582382202148
Iteration 149: train_loss 1.9238970279693604
Iteration 150: train_loss 1.9218212366104126
Iteration 151: train_loss 1.8575234413146973
Iteration 152: train_loss 1.8445994853973389
Iteration 153: train_loss 1.8808543682098389
Iteration 154: train_loss 1.8879170417785645
Iteration 155: train_loss 1.9111195802688599
Iteration 156: train_loss 1.8784857988357544
Iteration 157: train_loss 1.9284393787384033
Iteration 158: train_loss 1.8902455568313599
Iteration 159: train_loss 1.863847255706787
Iteration 160: train_loss 1.8821384906768799
Iteration 161: train_loss 1.8645713329315186
Iteration 162: train_loss 1.872680425643921
Iteration 163: train_loss 1.846451759338379
Iteration 164: train_loss 1.8959726095199585
Iteration 165: train_loss 1.8488366603851318
Iteration 166: train_loss 1.8848447799682617
Iteration 167: train_loss 1.8257067203521729
Iteration 168: train_loss 1.8231091499328613
Iteration 169: train_loss 1.8468214273452759
Iteration 170: train_loss 1.8979196548461914
Iteration 171: train_loss 1.908042311668396
Iteration 172: train_loss 1.8637937307357788
Iteration 173: train_loss 1.9229923486709595
Iteration 174: train_loss 1.8969717025756836
Iteration 175: train_loss 1.8860951662063599
Iteration 176: train_loss 1.8532941341400146
Iteration 177: train_loss 1.9546661376953125
Epoch 33: train_avg_loss 1.866823391725788 eval_avg_acc: 0.33389157252951646 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:10:43] [32mIntermediate result: 0.33389157252951646  (Index 32)[0m
================Epoch: 34================
Iteration 1: train_loss 1.7251888513565063
Iteration 2: train_loss 1.8204947710037231
Iteration 3: train_loss 1.850001573562622
Iteration 4: train_loss 1.8075474500656128
Iteration 5: train_loss 1.8546714782714844
Iteration 6: train_loss 1.8072489500045776
Iteration 7: train_loss 1.9262198209762573
Iteration 8: train_loss 1.8837857246398926
Iteration 9: train_loss 1.793897032737732
Iteration 10: train_loss 1.8555595874786377
Iteration 11: train_loss 1.8468310832977295
Iteration 12: train_loss 1.8090131282806396
Iteration 13: train_loss 1.9055873155593872
Iteration 14: train_loss 1.8727566003799438
Iteration 15: train_loss 1.8114008903503418
Iteration 16: train_loss 1.8863844871520996
Iteration 17: train_loss 1.9534379243850708
Iteration 18: train_loss 1.8930083513259888
Iteration 19: train_loss 1.8555126190185547
Iteration 20: train_loss 1.9121332168579102
Iteration 21: train_loss 1.8548496961593628
Iteration 22: train_loss 1.8788310289382935
Iteration 23: train_loss 1.797230839729309
Iteration 24: train_loss 1.9045909643173218
Iteration 25: train_loss 1.8546881675720215
Iteration 26: train_loss 1.8260213136672974
Iteration 27: train_loss 1.8056998252868652
Iteration 28: train_loss 1.718501329421997
Iteration 29: train_loss 1.8629848957061768
Iteration 30: train_loss 1.8776971101760864
Iteration 31: train_loss 1.8283385038375854
Iteration 32: train_loss 1.8822494745254517
Iteration 33: train_loss 1.8629179000854492
Iteration 34: train_loss 1.8330787420272827
Iteration 35: train_loss 1.878857970237732
Iteration 36: train_loss 1.8560007810592651
Iteration 37: train_loss 1.8678100109100342
Iteration 38: train_loss 1.8586357831954956
Iteration 39: train_loss 1.942725419998169
Iteration 40: train_loss 1.9080867767333984
Iteration 41: train_loss 1.7578048706054688
Iteration 42: train_loss 1.8533942699432373
Iteration 43: train_loss 1.8185337781906128
Iteration 44: train_loss 1.8190027475357056
Iteration 45: train_loss 1.8141807317733765
Iteration 46: train_loss 1.9246817827224731
Iteration 47: train_loss 1.8143501281738281
Iteration 48: train_loss 1.7947031259536743
Iteration 49: train_loss 1.746953010559082
Iteration 50: train_loss 1.8228117227554321
Iteration 51: train_loss 1.775067687034607
Iteration 52: train_loss 1.8544538021087646
Iteration 53: train_loss 1.8013601303100586
Iteration 54: train_loss 1.8473809957504272
Iteration 55: train_loss 1.8850430250167847
Iteration 56: train_loss 1.8615540266036987
Iteration 57: train_loss 1.8682284355163574
Iteration 58: train_loss 1.8206876516342163
Iteration 59: train_loss 1.8066554069519043
Iteration 60: train_loss 1.864064335823059
Iteration 61: train_loss 1.8459961414337158
Iteration 62: train_loss 1.776070475578308
Iteration 63: train_loss 1.9213966131210327
Iteration 64: train_loss 1.8411304950714111
Iteration 65: train_loss 1.7905899286270142
Iteration 66: train_loss 1.8473557233810425
Iteration 67: train_loss 1.7832835912704468
Iteration 68: train_loss 1.7684433460235596
Iteration 69: train_loss 1.809991717338562
Iteration 70: train_loss 1.8418185710906982
Iteration 71: train_loss 1.8339145183563232
Iteration 72: train_loss 1.8181135654449463
Iteration 73: train_loss 1.8398463726043701
Iteration 74: train_loss 1.8604984283447266
Iteration 75: train_loss 1.8500195741653442
Iteration 76: train_loss 1.8207755088806152
Iteration 77: train_loss 1.87684965133667
Iteration 78: train_loss 1.792244553565979
Iteration 79: train_loss 1.8878154754638672
Iteration 80: train_loss 1.8859491348266602
Iteration 81: train_loss 1.8271294832229614
Iteration 82: train_loss 1.8653225898742676
Iteration 83: train_loss 1.808142066001892
Iteration 84: train_loss 1.8066543340682983
Iteration 85: train_loss 1.8640307188034058
Iteration 86: train_loss 1.8630337715148926
Iteration 87: train_loss 1.8642410039901733
Iteration 88: train_loss 1.8326810598373413
Iteration 89: train_loss 1.8780370950698853
Iteration 90: train_loss 1.8630433082580566
Iteration 91: train_loss 1.8750499486923218
Iteration 92: train_loss 1.7525560855865479
Iteration 93: train_loss 1.7070791721343994
Iteration 94: train_loss 1.876137614250183
Iteration 95: train_loss 1.8841402530670166
Iteration 96: train_loss 1.886409044265747
Iteration 97: train_loss 1.8941413164138794
Iteration 98: train_loss 1.9235138893127441
Iteration 99: train_loss 1.8475160598754883
Iteration 100: train_loss 1.8161243200302124
Iteration 101: train_loss 1.8372647762298584
Iteration 102: train_loss 1.8721742630004883
Iteration 103: train_loss 1.9258626699447632
Iteration 104: train_loss 1.794195532798767
Iteration 105: train_loss 1.887599229812622
Iteration 106: train_loss 1.868653416633606
Iteration 107: train_loss 1.8787240982055664
Iteration 108: train_loss 1.9191147089004517
Iteration 109: train_loss 1.886003017425537
Iteration 110: train_loss 1.9248164892196655
Iteration 111: train_loss 1.8446398973464966
Iteration 112: train_loss 1.786501169204712
Iteration 113: train_loss 1.8444870710372925
Iteration 114: train_loss 1.8707705736160278
Iteration 115: train_loss 1.8926606178283691
Iteration 116: train_loss 1.8487402200698853
Iteration 117: train_loss 1.8401464223861694
Iteration 118: train_loss 1.8929016590118408
Iteration 119: train_loss 1.8704228401184082
Iteration 120: train_loss 1.8603851795196533
Iteration 121: train_loss 1.774839997291565
Iteration 122: train_loss 1.8127491474151611
Iteration 123: train_loss 1.8267179727554321
Iteration 124: train_loss 1.9279134273529053
Iteration 125: train_loss 1.8892524242401123
Iteration 126: train_loss 1.9039065837860107
Iteration 127: train_loss 1.8343708515167236
Iteration 128: train_loss 1.8242406845092773
Iteration 129: train_loss 1.8761157989501953
Iteration 130: train_loss 1.8560725450515747
Iteration 131: train_loss 1.844314455986023
Iteration 132: train_loss 1.8339052200317383
Iteration 133: train_loss 1.8263777494430542
Iteration 134: train_loss 1.9527620077133179
Iteration 135: train_loss 1.8327953815460205
Iteration 136: train_loss 1.7975419759750366
Iteration 137: train_loss 1.9017990827560425
Iteration 138: train_loss 1.810027003288269
Iteration 139: train_loss 1.9467291831970215
Iteration 140: train_loss 1.9165645837783813
Iteration 141: train_loss 1.836963415145874
Iteration 142: train_loss 1.9215738773345947
Iteration 143: train_loss 1.8293483257293701
Iteration 144: train_loss 1.9293493032455444
Iteration 145: train_loss 1.9063931703567505
Iteration 146: train_loss 1.8508754968643188
Iteration 147: train_loss 1.8424946069717407
Iteration 148: train_loss 1.8511734008789062
Iteration 149: train_loss 1.8607569932937622
Iteration 150: train_loss 1.8341783285140991
Iteration 151: train_loss 1.9182831048965454
Iteration 152: train_loss 1.8527182340621948
Iteration 153: train_loss 1.8352699279785156
Iteration 154: train_loss 1.8879696130752563
Iteration 155: train_loss 1.8955202102661133
Iteration 156: train_loss 1.8359522819519043
Iteration 157: train_loss 1.86371910572052
Iteration 158: train_loss 1.8945591449737549
Iteration 159: train_loss 1.8763607740402222
Iteration 160: train_loss 1.825609564781189
Iteration 161: train_loss 1.7985891103744507
Iteration 162: train_loss 1.907299518585205
Iteration 163: train_loss 1.9487087726593018
Iteration 164: train_loss 1.8920916318893433
Iteration 165: train_loss 1.9068490266799927
Iteration 166: train_loss 1.8639987707138062
Iteration 167: train_loss 1.8453302383422852
Iteration 168: train_loss 1.7995883226394653
Iteration 169: train_loss 1.896998643875122
Iteration 170: train_loss 1.7544957399368286
Iteration 171: train_loss 1.8889869451522827
Iteration 172: train_loss 1.786057472229004
Iteration 173: train_loss 1.8222603797912598
Iteration 174: train_loss 1.9032717943191528
Iteration 175: train_loss 1.9097274541854858
Iteration 176: train_loss 1.8312702178955078
Iteration 177: train_loss 1.7695590257644653
Epoch 34: train_avg_loss 1.8517383471720636 eval_avg_acc: 0.3272841474681299 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:11:24] [32mIntermediate result: 0.3272841474681299  (Index 33)[0m
================Epoch: 35================
Iteration 1: train_loss 1.8411682844161987
Iteration 2: train_loss 1.8776733875274658
Iteration 3: train_loss 1.8442471027374268
Iteration 4: train_loss 1.8653565645217896
Iteration 5: train_loss 1.8686405420303345
Iteration 6: train_loss 1.7951180934906006
Iteration 7: train_loss 1.8083616495132446
Iteration 8: train_loss 1.8401763439178467
Iteration 9: train_loss 1.7496222257614136
Iteration 10: train_loss 1.8311342000961304
Iteration 11: train_loss 1.776386022567749
Iteration 12: train_loss 1.86018967628479
Iteration 13: train_loss 1.863911747932434
Iteration 14: train_loss 1.8507808446884155
Iteration 15: train_loss 1.728459358215332
Iteration 16: train_loss 1.7783715724945068
Iteration 17: train_loss 1.8322482109069824
Iteration 18: train_loss 1.7917248010635376
Iteration 19: train_loss 1.9187097549438477
Iteration 20: train_loss 1.8299368619918823
Iteration 21: train_loss 1.8131897449493408
Iteration 22: train_loss 1.8441575765609741
Iteration 23: train_loss 1.922877550125122
Iteration 24: train_loss 1.8204810619354248
Iteration 25: train_loss 1.9004576206207275
Iteration 26: train_loss 1.7468643188476562
Iteration 27: train_loss 1.8160755634307861
Iteration 28: train_loss 1.8735073804855347
Iteration 29: train_loss 1.8506582975387573
Iteration 30: train_loss 1.8365089893341064
Iteration 31: train_loss 1.8565704822540283
Iteration 32: train_loss 1.864004135131836
Iteration 33: train_loss 1.759149193763733
Iteration 34: train_loss 1.7948932647705078
Iteration 35: train_loss 1.819636344909668
Iteration 36: train_loss 1.8239326477050781
Iteration 37: train_loss 1.835947036743164
Iteration 38: train_loss 1.8478466272354126
Iteration 39: train_loss 1.8612534999847412
Iteration 40: train_loss 1.8349446058273315
Iteration 41: train_loss 1.891418218612671
Iteration 42: train_loss 1.8429036140441895
Iteration 43: train_loss 1.835819959640503
Iteration 44: train_loss 1.8147774934768677
Iteration 45: train_loss 1.873194932937622
Iteration 46: train_loss 1.7484151124954224
Iteration 47: train_loss 1.939077615737915
Iteration 48: train_loss 1.8020554780960083
Iteration 49: train_loss 1.8893929719924927
Iteration 50: train_loss 1.823764681816101
Iteration 51: train_loss 1.8619590997695923
Iteration 52: train_loss 1.8293266296386719
Iteration 53: train_loss 1.8288718461990356
Iteration 54: train_loss 1.8220409154891968
Iteration 55: train_loss 1.8447669744491577
Iteration 56: train_loss 1.894422173500061
Iteration 57: train_loss 1.8075932264328003
Iteration 58: train_loss 1.813132405281067
Iteration 59: train_loss 1.8163731098175049
Iteration 60: train_loss 1.850393295288086
Iteration 61: train_loss 1.898414134979248
Iteration 62: train_loss 1.8540068864822388
Iteration 63: train_loss 1.8613042831420898
Iteration 64: train_loss 1.8862894773483276
Iteration 65: train_loss 1.79826021194458
Iteration 66: train_loss 1.821995735168457
Iteration 67: train_loss 1.9096611738204956
Iteration 68: train_loss 1.79270339012146
Iteration 69: train_loss 1.803242802619934
Iteration 70: train_loss 1.7657883167266846
Iteration 71: train_loss 1.8354401588439941
Iteration 72: train_loss 1.86917245388031
Iteration 73: train_loss 1.8940225839614868
Iteration 74: train_loss 1.809781789779663
Iteration 75: train_loss 1.808605670928955
Iteration 76: train_loss 1.8788790702819824
Iteration 77: train_loss 1.7762048244476318
Iteration 78: train_loss 1.871466875076294
Iteration 79: train_loss 1.8740862607955933
Iteration 80: train_loss 1.9019379615783691
Iteration 81: train_loss 1.8253638744354248
Iteration 82: train_loss 1.877561092376709
Iteration 83: train_loss 1.8383792638778687
Iteration 84: train_loss 1.8133339881896973
Iteration 85: train_loss 1.8226916790008545
Iteration 86: train_loss 1.8861145973205566
Iteration 87: train_loss 1.7790262699127197
Iteration 88: train_loss 1.924590826034546
Iteration 89: train_loss 1.889748454093933
Iteration 90: train_loss 1.8855278491973877
Iteration 91: train_loss 1.8550702333450317
Iteration 92: train_loss 1.811733365058899
Iteration 93: train_loss 1.8008264303207397
Iteration 94: train_loss 1.8498570919036865
Iteration 95: train_loss 1.8357020616531372
Iteration 96: train_loss 1.8482170104980469
Iteration 97: train_loss 1.903818964958191
Iteration 98: train_loss 1.8951228857040405
Iteration 99: train_loss 1.804898977279663
Iteration 100: train_loss 1.8152636289596558
Iteration 101: train_loss 1.8415493965148926
Iteration 102: train_loss 1.8483301401138306
Iteration 103: train_loss 1.7696893215179443
Iteration 104: train_loss 1.7489317655563354
Iteration 105: train_loss 1.830190896987915
Iteration 106: train_loss 1.786679744720459
Iteration 107: train_loss 1.8536187410354614
Iteration 108: train_loss 1.8009816408157349
Iteration 109: train_loss 1.9415857791900635
Iteration 110: train_loss 1.8912452459335327
Iteration 111: train_loss 1.884455919265747
Iteration 112: train_loss 1.824268102645874
Iteration 113: train_loss 1.8895983695983887
Iteration 114: train_loss 1.7959530353546143
Iteration 115: train_loss 1.848692536354065
Iteration 116: train_loss 1.7157498598098755
Iteration 117: train_loss 1.8064334392547607
Iteration 118: train_loss 1.8244283199310303
Iteration 119: train_loss 1.8756378889083862
Iteration 120: train_loss 1.816219687461853
Iteration 121: train_loss 1.8246192932128906
Iteration 122: train_loss 1.8561346530914307
Iteration 123: train_loss 1.8411775827407837
Iteration 124: train_loss 1.9285719394683838
Iteration 125: train_loss 1.8281383514404297
Iteration 126: train_loss 1.7704631090164185
Iteration 127: train_loss 1.8082385063171387
Iteration 128: train_loss 1.8493036031723022
Iteration 129: train_loss 1.8272827863693237
Iteration 130: train_loss 1.851751685142517
Iteration 131: train_loss 1.8052712678909302
Iteration 132: train_loss 1.8241605758666992
Iteration 133: train_loss 1.8623958826065063
Iteration 134: train_loss 1.8180975914001465
Iteration 135: train_loss 1.8738410472869873
Iteration 136: train_loss 1.8910621404647827
Iteration 137: train_loss 1.8236862421035767
Iteration 138: train_loss 1.8620295524597168
Iteration 139: train_loss 1.9137821197509766
Iteration 140: train_loss 1.9480128288269043
Iteration 141: train_loss 1.9050356149673462
Iteration 142: train_loss 1.8315720558166504
Iteration 143: train_loss 1.8541786670684814
Iteration 144: train_loss 1.9337127208709717
Iteration 145: train_loss 1.943483829498291
Iteration 146: train_loss 1.9163833856582642
Iteration 147: train_loss 1.8620479106903076
Iteration 148: train_loss 1.8580834865570068
Iteration 149: train_loss 1.8885245323181152
Iteration 150: train_loss 1.9101449251174927
Iteration 151: train_loss 1.8535597324371338
Iteration 152: train_loss 1.8573352098464966
Iteration 153: train_loss 1.9211244583129883
Iteration 154: train_loss 1.898505449295044
Iteration 155: train_loss 1.8893247842788696
Iteration 156: train_loss 1.8670552968978882
Iteration 157: train_loss 1.8656623363494873
Iteration 158: train_loss 1.8968232870101929
Iteration 159: train_loss 1.7947274446487427
Iteration 160: train_loss 1.9174388647079468
Iteration 161: train_loss 1.881766676902771
Iteration 162: train_loss 1.824571967124939
Iteration 163: train_loss 1.8444312810897827
Iteration 164: train_loss 1.827219843864441
Iteration 165: train_loss 1.8478010892868042
Iteration 166: train_loss 1.8587125539779663
Iteration 167: train_loss 1.8516530990600586
Iteration 168: train_loss 1.8664082288742065
Iteration 169: train_loss 1.915776014328003
Iteration 170: train_loss 1.8931187391281128
Iteration 171: train_loss 1.8651955127716064
Iteration 172: train_loss 1.8525902032852173
Iteration 173: train_loss 1.8110783100128174
Iteration 174: train_loss 1.806416630744934
Iteration 175: train_loss 1.908826470375061
Iteration 176: train_loss 1.8126264810562134
Iteration 177: train_loss 2.0071825981140137
Epoch 35: train_avg_loss 1.847013253276631 eval_avg_acc: 0.32927195110750695 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:12:05] [32mIntermediate result: 0.32927195110750695  (Index 34)[0m
================Epoch: 36================
Iteration 1: train_loss 1.8010247945785522
Iteration 2: train_loss 1.848861813545227
Iteration 3: train_loss 1.8747870922088623
Iteration 4: train_loss 1.7931694984436035
Iteration 5: train_loss 1.7676599025726318
Iteration 6: train_loss 1.8977034091949463
Iteration 7: train_loss 1.845710039138794
Iteration 8: train_loss 1.7647329568862915
Iteration 9: train_loss 1.755007266998291
Iteration 10: train_loss 1.7752469778060913
Iteration 11: train_loss 1.8164143562316895
Iteration 12: train_loss 1.7840096950531006
Iteration 13: train_loss 1.741500973701477
Iteration 14: train_loss 1.831354022026062
Iteration 15: train_loss 1.7898870706558228
Iteration 16: train_loss 1.9057751893997192
Iteration 17: train_loss 1.81602942943573
Iteration 18: train_loss 1.9067304134368896
Iteration 19: train_loss 1.8023042678833008
Iteration 20: train_loss 1.790645956993103
Iteration 21: train_loss 1.8154648542404175
Iteration 22: train_loss 1.805238962173462
Iteration 23: train_loss 1.8147711753845215
Iteration 24: train_loss 1.8392544984817505
Iteration 25: train_loss 1.7581642866134644
Iteration 26: train_loss 1.7509584426879883
Iteration 27: train_loss 1.704992413520813
Iteration 28: train_loss 1.7951712608337402
Iteration 29: train_loss 1.7745031118392944
Iteration 30: train_loss 1.7082122564315796
Iteration 31: train_loss 1.717745065689087
Iteration 32: train_loss 1.8771905899047852
Iteration 33: train_loss 1.7756272554397583
Iteration 34: train_loss 1.7903048992156982
Iteration 35: train_loss 1.7218260765075684
Iteration 36: train_loss 1.8176785707473755
Iteration 37: train_loss 1.7722200155258179
Iteration 38: train_loss 1.842158317565918
Iteration 39: train_loss 1.7615084648132324
Iteration 40: train_loss 1.7633906602859497
Iteration 41: train_loss 1.8264472484588623
Iteration 42: train_loss 1.7782444953918457
Iteration 43: train_loss 1.809158444404602
Iteration 44: train_loss 1.7996314764022827
Iteration 45: train_loss 1.8039225339889526
Iteration 46: train_loss 1.8431085348129272
Iteration 47: train_loss 1.8026111125946045
Iteration 48: train_loss 1.850399136543274
Iteration 49: train_loss 1.8089277744293213
Iteration 50: train_loss 1.8378430604934692
Iteration 51: train_loss 1.840732216835022
Iteration 52: train_loss 1.8265047073364258
Iteration 53: train_loss 1.729750633239746
Iteration 54: train_loss 1.6944395303726196
Iteration 55: train_loss 1.7312067747116089
Iteration 56: train_loss 1.8332419395446777
Iteration 57: train_loss 1.8035444021224976
Iteration 58: train_loss 1.86383056640625
Iteration 59: train_loss 1.7533708810806274
Iteration 60: train_loss 1.7639704942703247
Iteration 61: train_loss 1.8630540370941162
Iteration 62: train_loss 1.7904123067855835
Iteration 63: train_loss 1.8169602155685425
Iteration 64: train_loss 1.8623391389846802
Iteration 65: train_loss 1.7771408557891846
Iteration 66: train_loss 1.8094186782836914
Iteration 67: train_loss 1.7573010921478271
Iteration 68: train_loss 1.8803170919418335
Iteration 69: train_loss 1.8094228506088257
Iteration 70: train_loss 1.8258874416351318
Iteration 71: train_loss 1.8092364072799683
Iteration 72: train_loss 1.8016306161880493
Iteration 73: train_loss 1.8070327043533325
Iteration 74: train_loss 1.8322292566299438
Iteration 75: train_loss 1.7777535915374756
Iteration 76: train_loss 1.7840372323989868
Iteration 77: train_loss 1.80900239944458
Iteration 78: train_loss 1.8629415035247803
Iteration 79: train_loss 1.790199875831604
Iteration 80: train_loss 1.8248296976089478
Iteration 81: train_loss 1.8213363885879517
Iteration 82: train_loss 1.7800228595733643
Iteration 83: train_loss 1.8257925510406494
Iteration 84: train_loss 1.8705507516860962
Iteration 85: train_loss 1.8406639099121094
Iteration 86: train_loss 1.8999428749084473
Iteration 87: train_loss 1.8349906206130981
Iteration 88: train_loss 1.791359543800354
Iteration 89: train_loss 1.873382806777954
Iteration 90: train_loss 1.7537096738815308
Iteration 91: train_loss 1.8727411031723022
Iteration 92: train_loss 1.8233798742294312
Iteration 93: train_loss 1.8725874423980713
Iteration 94: train_loss 1.873516321182251
Iteration 95: train_loss 1.8452974557876587
Iteration 96: train_loss 1.849725365638733
Iteration 97: train_loss 1.8281440734863281
Iteration 98: train_loss 1.7582042217254639
Iteration 99: train_loss 1.8149878978729248
Iteration 100: train_loss 1.7647658586502075
Iteration 101: train_loss 1.8008525371551514
Iteration 102: train_loss 1.8440800905227661
Iteration 103: train_loss 1.9302172660827637
Iteration 104: train_loss 1.8478747606277466
Iteration 105: train_loss 1.8814390897750854
Iteration 106: train_loss 1.8161522150039673
Iteration 107: train_loss 1.89620041847229
Iteration 108: train_loss 1.7891836166381836
Iteration 109: train_loss 1.8646906614303589
Iteration 110: train_loss 1.8194787502288818
Iteration 111: train_loss 1.805130958557129
Iteration 112: train_loss 1.7867631912231445
Iteration 113: train_loss 1.811966061592102
Iteration 114: train_loss 1.7848198413848877
Iteration 115: train_loss 1.8415682315826416
Iteration 116: train_loss 1.8463808298110962
Iteration 117: train_loss 1.7449318170547485
Iteration 118: train_loss 1.8359898328781128
Iteration 119: train_loss 1.8267050981521606
Iteration 120: train_loss 1.7946652173995972
Iteration 121: train_loss 1.826112151145935
Iteration 122: train_loss 1.8301165103912354
Iteration 123: train_loss 1.8293062448501587
Iteration 124: train_loss 1.8025436401367188
Iteration 125: train_loss 1.8578718900680542
Iteration 126: train_loss 1.7687410116195679
Iteration 127: train_loss 1.8005566596984863
Iteration 128: train_loss 1.8019787073135376
Iteration 129: train_loss 1.8953475952148438
Iteration 130: train_loss 1.8257739543914795
Iteration 131: train_loss 1.8609280586242676
Iteration 132: train_loss 1.8418983221054077
Iteration 133: train_loss 1.8618818521499634
Iteration 134: train_loss 1.8306423425674438
Iteration 135: train_loss 1.8108341693878174
Iteration 136: train_loss 1.8680248260498047
Iteration 137: train_loss 1.7718286514282227
Iteration 138: train_loss 1.8567980527877808
Iteration 139: train_loss 1.7985742092132568
Iteration 140: train_loss 1.8477041721343994
Iteration 141: train_loss 1.8554078340530396
Iteration 142: train_loss 1.8508293628692627
Iteration 143: train_loss 1.8392049074172974
Iteration 144: train_loss 1.8032578229904175
Iteration 145: train_loss 1.9189064502716064
Iteration 146: train_loss 1.849807858467102
Iteration 147: train_loss 1.7707831859588623
Iteration 148: train_loss 1.8480037450790405
Iteration 149: train_loss 1.8415888547897339
Iteration 150: train_loss 1.8621309995651245
Iteration 151: train_loss 1.8655531406402588
Iteration 152: train_loss 1.8494715690612793
Iteration 153: train_loss 1.8430591821670532
Iteration 154: train_loss 1.7924301624298096
Iteration 155: train_loss 1.8691357374191284
Iteration 156: train_loss 1.855303406715393
Iteration 157: train_loss 1.8859323263168335
Iteration 158: train_loss 1.858803153038025
Iteration 159: train_loss 1.845572590827942
Iteration 160: train_loss 1.8237383365631104
Iteration 161: train_loss 1.8448495864868164
Iteration 162: train_loss 1.8330607414245605
Iteration 163: train_loss 1.8732819557189941
Iteration 164: train_loss 1.8704569339752197
Iteration 165: train_loss 1.7869746685028076
Iteration 166: train_loss 1.8398849964141846
Iteration 167: train_loss 1.813877820968628
Iteration 168: train_loss 1.8825544118881226
Iteration 169: train_loss 1.8694796562194824
Iteration 170: train_loss 1.9057667255401611
Iteration 171: train_loss 1.84727942943573
Iteration 172: train_loss 1.8736826181411743
Iteration 173: train_loss 1.866045355796814
Iteration 174: train_loss 1.8783001899719238
Iteration 175: train_loss 1.913544774055481
Iteration 176: train_loss 1.85269033908844
Iteration 177: train_loss 1.958429217338562
Epoch 36: train_avg_loss 1.822585900624593 eval_avg_acc: 0.3271774073069885 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:12:47] [32mIntermediate result: 0.3271774073069885  (Index 35)[0m
================Epoch: 37================
Iteration 1: train_loss 1.8029804229736328
Iteration 2: train_loss 1.7990676164627075
Iteration 3: train_loss 1.8020360469818115
Iteration 4: train_loss 1.763959527015686
Iteration 5: train_loss 1.765826940536499
Iteration 6: train_loss 1.8388614654541016
Iteration 7: train_loss 1.8342292308807373
Iteration 8: train_loss 1.8177180290222168
Iteration 9: train_loss 1.8439286947250366
Iteration 10: train_loss 1.7531471252441406
Iteration 11: train_loss 1.8020998239517212
Iteration 12: train_loss 1.7841147184371948
Iteration 13: train_loss 1.8384451866149902
Iteration 14: train_loss 1.7919138669967651
Iteration 15: train_loss 1.866101861000061
Iteration 16: train_loss 1.7780429124832153
Iteration 17: train_loss 1.8276904821395874
Iteration 18: train_loss 1.7995704412460327
Iteration 19: train_loss 1.7838999032974243
Iteration 20: train_loss 1.8332359790802002
Iteration 21: train_loss 1.8280962705612183
Iteration 22: train_loss 1.7722212076187134
Iteration 23: train_loss 1.8730469942092896
Iteration 24: train_loss 1.7669281959533691
Iteration 25: train_loss 1.8172715902328491
Iteration 26: train_loss 1.8258576393127441
Iteration 27: train_loss 1.803534746170044
Iteration 28: train_loss 1.8019787073135376
Iteration 29: train_loss 1.8438433408737183
Iteration 30: train_loss 1.7749357223510742
Iteration 31: train_loss 1.849904179573059
Iteration 32: train_loss 1.8003138303756714
Iteration 33: train_loss 1.8243422508239746
Iteration 34: train_loss 1.7701820135116577
Iteration 35: train_loss 1.7121721506118774
Iteration 36: train_loss 1.790095329284668
Iteration 37: train_loss 1.777646541595459
Iteration 38: train_loss 1.812106728553772
Iteration 39: train_loss 1.7720178365707397
Iteration 40: train_loss 1.769627571105957
Iteration 41: train_loss 1.8112143278121948
Iteration 42: train_loss 1.8012160062789917
Iteration 43: train_loss 1.7782753705978394
Iteration 44: train_loss 1.8334599733352661
Iteration 45: train_loss 1.7772928476333618
Iteration 46: train_loss 1.8300325870513916
Iteration 47: train_loss 1.8487379550933838
Iteration 48: train_loss 1.7843154668807983
Iteration 49: train_loss 1.8505185842514038
Iteration 50: train_loss 1.8776719570159912
Iteration 51: train_loss 1.8555488586425781
Iteration 52: train_loss 1.8565188646316528
Iteration 53: train_loss 1.8288151025772095
Iteration 54: train_loss 1.769065499305725
Iteration 55: train_loss 1.809272289276123
Iteration 56: train_loss 1.7606751918792725
Iteration 57: train_loss 1.782204270362854
Iteration 58: train_loss 1.768939733505249
Iteration 59: train_loss 1.7645918130874634
Iteration 60: train_loss 1.8003253936767578
Iteration 61: train_loss 1.81194269657135
Iteration 62: train_loss 1.8164169788360596
Iteration 63: train_loss 1.822331428527832
Iteration 64: train_loss 1.784594178199768
Iteration 65: train_loss 1.7203830480575562
Iteration 66: train_loss 1.904150128364563
Iteration 67: train_loss 1.7969515323638916
Iteration 68: train_loss 1.7766845226287842
Iteration 69: train_loss 1.835432529449463
Iteration 70: train_loss 1.8046823740005493
Iteration 71: train_loss 1.796944499015808
Iteration 72: train_loss 1.7921169996261597
Iteration 73: train_loss 1.8872168064117432
Iteration 74: train_loss 1.7820754051208496
Iteration 75: train_loss 1.8052051067352295
Iteration 76: train_loss 1.8163187503814697
Iteration 77: train_loss 1.8234179019927979
Iteration 78: train_loss 1.763244867324829
Iteration 79: train_loss 1.7236756086349487
Iteration 80: train_loss 1.786598563194275
Iteration 81: train_loss 1.8224124908447266
Iteration 82: train_loss 1.8429136276245117
Iteration 83: train_loss 1.8126742839813232
Iteration 84: train_loss 1.7710063457489014
Iteration 85: train_loss 1.818501353263855
Iteration 86: train_loss 1.8700904846191406
Iteration 87: train_loss 1.857693076133728
Iteration 88: train_loss 1.851871371269226
Iteration 89: train_loss 1.8960225582122803
Iteration 90: train_loss 1.7850285768508911
Iteration 91: train_loss 1.836618423461914
Iteration 92: train_loss 1.8172340393066406
Iteration 93: train_loss 1.7793477773666382
Iteration 94: train_loss 1.7678771018981934
Iteration 95: train_loss 1.7597615718841553
Iteration 96: train_loss 1.797503113746643
Iteration 97: train_loss 1.801853060722351
Iteration 98: train_loss 1.8156644105911255
Iteration 99: train_loss 1.7420070171356201
Iteration 100: train_loss 1.7673883438110352
Iteration 101: train_loss 1.7988706827163696
Iteration 102: train_loss 1.867666482925415
Iteration 103: train_loss 1.8366758823394775
Iteration 104: train_loss 1.7996975183486938
Iteration 105: train_loss 1.8327865600585938
Iteration 106: train_loss 1.769752025604248
Iteration 107: train_loss 1.7967215776443481
Iteration 108: train_loss 1.838708519935608
Iteration 109: train_loss 1.8171790838241577
Iteration 110: train_loss 1.8260730504989624
Iteration 111: train_loss 1.8377432823181152
Iteration 112: train_loss 1.801124095916748
Iteration 113: train_loss 1.7812427282333374
Iteration 114: train_loss 1.912795066833496
Iteration 115: train_loss 1.8041059970855713
Iteration 116: train_loss 1.8610748052597046
Iteration 117: train_loss 1.8299989700317383
Iteration 118: train_loss 1.8446086645126343
Iteration 119: train_loss 1.8453400135040283
Iteration 120: train_loss 1.7783526182174683
Iteration 121: train_loss 1.7632462978363037
Iteration 122: train_loss 1.8429231643676758
Iteration 123: train_loss 1.8419103622436523
Iteration 124: train_loss 1.7981685400009155
Iteration 125: train_loss 1.835660457611084
Iteration 126: train_loss 1.8111052513122559
Iteration 127: train_loss 1.9041078090667725
Iteration 128: train_loss 1.7800838947296143
Iteration 129: train_loss 1.814733624458313
Iteration 130: train_loss 1.8737521171569824
Iteration 131: train_loss 1.831835389137268
Iteration 132: train_loss 1.8257206678390503
Iteration 133: train_loss 1.783897876739502
Iteration 134: train_loss 1.8082383871078491
Iteration 135: train_loss 1.8417526483535767
Iteration 136: train_loss 1.816914677619934
Iteration 137: train_loss 1.8429524898529053
Iteration 138: train_loss 1.7818195819854736
Iteration 139: train_loss 1.8323149681091309
Iteration 140: train_loss 1.8579633235931396
Iteration 141: train_loss 1.7942116260528564
Iteration 142: train_loss 1.782983660697937
Iteration 143: train_loss 1.7155373096466064
Iteration 144: train_loss 1.8641045093536377
Iteration 145: train_loss 1.7633697986602783
Iteration 146: train_loss 1.8063627481460571
Iteration 147: train_loss 1.785910725593567
Iteration 148: train_loss 1.8654266595840454
Iteration 149: train_loss 1.7785718441009521
Iteration 150: train_loss 1.7653125524520874
Iteration 151: train_loss 1.842160940170288
Iteration 152: train_loss 1.8775460720062256
Iteration 153: train_loss 1.80316162109375
Iteration 154: train_loss 1.8636322021484375
Iteration 155: train_loss 1.855350136756897
Iteration 156: train_loss 1.8266561031341553
Iteration 157: train_loss 1.875118374824524
Iteration 158: train_loss 1.8686175346374512
Iteration 159: train_loss 1.9018653631210327
Iteration 160: train_loss 1.9032368659973145
Iteration 161: train_loss 1.8737839460372925
Iteration 162: train_loss 1.848365306854248
Iteration 163: train_loss 1.8240346908569336
Iteration 164: train_loss 1.8849955797195435
Iteration 165: train_loss 1.776092290878296
Iteration 166: train_loss 1.7366777658462524
Iteration 167: train_loss 1.8682355880737305
Iteration 168: train_loss 1.8897219896316528
Iteration 169: train_loss 1.765644907951355
Iteration 170: train_loss 1.8334819078445435
Iteration 171: train_loss 1.7713890075683594
Iteration 172: train_loss 1.836418867111206
Iteration 173: train_loss 1.817358374595642
Iteration 174: train_loss 1.8147164583206177
Iteration 175: train_loss 1.8677409887313843
Iteration 176: train_loss 1.8339422941207886
Iteration 177: train_loss 2.043619394302368
Epoch 37: train_avg_loss 1.8155961205056832 eval_avg_acc: 0.33497391068017196 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:13:28] [32mIntermediate result: 0.33497391068017196  (Index 36)[0m
================Epoch: 38================
Iteration 1: train_loss 1.7201907634735107
Iteration 2: train_loss 1.8169400691986084
Iteration 3: train_loss 1.7460623979568481
Iteration 4: train_loss 1.7557847499847412
Iteration 5: train_loss 1.8090381622314453
Iteration 6: train_loss 1.8652857542037964
Iteration 7: train_loss 1.7859801054000854
Iteration 8: train_loss 1.7209128141403198
Iteration 9: train_loss 1.7325165271759033
Iteration 10: train_loss 1.7557340860366821
Iteration 11: train_loss 1.7501460313796997
Iteration 12: train_loss 1.7619174718856812
Iteration 13: train_loss 1.7375034093856812
Iteration 14: train_loss 1.8197641372680664
Iteration 15: train_loss 1.709545612335205
Iteration 16: train_loss 1.8571605682373047
Iteration 17: train_loss 1.7546875476837158
Iteration 18: train_loss 1.7457188367843628
Iteration 19: train_loss 1.8593122959136963
Iteration 20: train_loss 1.7620022296905518
Iteration 21: train_loss 1.7589000463485718
Iteration 22: train_loss 1.7883661985397339
Iteration 23: train_loss 1.7841219902038574
Iteration 24: train_loss 1.8246424198150635
Iteration 25: train_loss 1.7768492698669434
Iteration 26: train_loss 1.7990455627441406
Iteration 27: train_loss 1.7859598398208618
Iteration 28: train_loss 1.8542087078094482
Iteration 29: train_loss 1.7757954597473145
Iteration 30: train_loss 1.795885682106018
Iteration 31: train_loss 1.7312575578689575
Iteration 32: train_loss 1.8177144527435303
Iteration 33: train_loss 1.7870914936065674
Iteration 34: train_loss 1.7725989818572998
Iteration 35: train_loss 1.762493371963501
Iteration 36: train_loss 1.7996137142181396
Iteration 37: train_loss 1.7590444087982178
Iteration 38: train_loss 1.8422150611877441
Iteration 39: train_loss 1.7201063632965088
Iteration 40: train_loss 1.7332316637039185
Iteration 41: train_loss 1.8497778177261353
Iteration 42: train_loss 1.7690187692642212
Iteration 43: train_loss 1.7595369815826416
Iteration 44: train_loss 1.8157734870910645
Iteration 45: train_loss 1.7267482280731201
Iteration 46: train_loss 1.7781076431274414
Iteration 47: train_loss 1.8564425706863403
Iteration 48: train_loss 1.7447950839996338
Iteration 49: train_loss 1.7891396284103394
Iteration 50: train_loss 1.8222547769546509
Iteration 51: train_loss 1.713705062866211
Iteration 52: train_loss 1.7888559103012085
Iteration 53: train_loss 1.8039829730987549
Iteration 54: train_loss 1.7082040309906006
Iteration 55: train_loss 1.7312020063400269
Iteration 56: train_loss 1.7393436431884766
Iteration 57: train_loss 1.7320148944854736
Iteration 58: train_loss 1.746539831161499
Iteration 59: train_loss 1.803538203239441
Iteration 60: train_loss 1.7828844785690308
Iteration 61: train_loss 1.7616626024246216
Iteration 62: train_loss 1.8176406621932983
Iteration 63: train_loss 1.7338446378707886
Iteration 64: train_loss 1.8089828491210938
Iteration 65: train_loss 1.862735390663147
Iteration 66: train_loss 1.7907781600952148
Iteration 67: train_loss 1.7741738557815552
Iteration 68: train_loss 1.7969127893447876
Iteration 69: train_loss 1.8359681367874146
Iteration 70: train_loss 1.7883716821670532
Iteration 71: train_loss 1.751800775527954
Iteration 72: train_loss 1.7308791875839233
Iteration 73: train_loss 1.82094144821167
Iteration 74: train_loss 1.7722728252410889
Iteration 75: train_loss 1.7783739566802979
Iteration 76: train_loss 1.771543264389038
Iteration 77: train_loss 1.8135277032852173
Iteration 78: train_loss 1.754171371459961
Iteration 79: train_loss 1.8383175134658813
Iteration 80: train_loss 1.7838417291641235
Iteration 81: train_loss 1.7888151407241821
Iteration 82: train_loss 1.7993518114089966
Iteration 83: train_loss 1.8110980987548828
Iteration 84: train_loss 1.7188106775283813
Iteration 85: train_loss 1.7706626653671265
Iteration 86: train_loss 1.7620115280151367
Iteration 87: train_loss 1.7961677312850952
Iteration 88: train_loss 1.8006528615951538
Iteration 89: train_loss 1.7429187297821045
Iteration 90: train_loss 1.8319395780563354
Iteration 91: train_loss 1.7941734790802002
Iteration 92: train_loss 1.7825571298599243
Iteration 93: train_loss 1.81240975856781
Iteration 94: train_loss 1.8333370685577393
Iteration 95: train_loss 1.796843409538269
Iteration 96: train_loss 1.8503118753433228
Iteration 97: train_loss 1.8268345594406128
Iteration 98: train_loss 1.8714652061462402
Iteration 99: train_loss 1.7539960145950317
Iteration 100: train_loss 1.7693101167678833
Iteration 101: train_loss 1.818042278289795
Iteration 102: train_loss 1.825654149055481
Iteration 103: train_loss 1.7890172004699707
Iteration 104: train_loss 1.8408435583114624
Iteration 105: train_loss 1.864016056060791
Iteration 106: train_loss 1.7952349185943604
Iteration 107: train_loss 1.8238736391067505
Iteration 108: train_loss 1.804176688194275
Iteration 109: train_loss 1.8319103717803955
Iteration 110: train_loss 1.82599675655365
Iteration 111: train_loss 1.7471168041229248
Iteration 112: train_loss 1.8353444337844849
Iteration 113: train_loss 1.8909279108047485
Iteration 114: train_loss 1.8707762956619263
Iteration 115: train_loss 1.8158059120178223
Iteration 116: train_loss 1.844800591468811
Iteration 117: train_loss 1.8263731002807617
Iteration 118: train_loss 1.8677176237106323
Iteration 119: train_loss 1.7743510007858276
Iteration 120: train_loss 1.8356484174728394
Iteration 121: train_loss 1.7936561107635498
Iteration 122: train_loss 1.8102689981460571
Iteration 123: train_loss 1.7979971170425415
Iteration 124: train_loss 1.792022466659546
Iteration 125: train_loss 1.7853926420211792
Iteration 126: train_loss 1.734442949295044
Iteration 127: train_loss 1.9124032258987427
Iteration 128: train_loss 1.840080976486206
Iteration 129: train_loss 1.8145431280136108
Iteration 130: train_loss 1.8118975162506104
Iteration 131: train_loss 1.8006010055541992
Iteration 132: train_loss 1.9219571352005005
Iteration 133: train_loss 1.9043926000595093
Iteration 134: train_loss 1.893272042274475
Iteration 135: train_loss 1.778743028640747
Iteration 136: train_loss 1.9025849103927612
Iteration 137: train_loss 1.8279449939727783
Iteration 138: train_loss 1.86089026927948
Iteration 139: train_loss 1.816076397895813
Iteration 140: train_loss 1.8014129400253296
Iteration 141: train_loss 1.8135008811950684
Iteration 142: train_loss 1.815256953239441
Iteration 143: train_loss 1.8940342664718628
Iteration 144: train_loss 1.779118537902832
Iteration 145: train_loss 1.7877641916275024
Iteration 146: train_loss 1.8443965911865234
Iteration 147: train_loss 1.856971263885498
Iteration 148: train_loss 1.7737865447998047
Iteration 149: train_loss 1.8780715465545654
Iteration 150: train_loss 1.7527775764465332
Iteration 151: train_loss 1.7983691692352295
Iteration 152: train_loss 1.8708267211914062
Iteration 153: train_loss 1.8023110628128052
Iteration 154: train_loss 1.8226772546768188
Iteration 155: train_loss 1.7631266117095947
Iteration 156: train_loss 1.8517985343933105
Iteration 157: train_loss 1.7985821962356567
Iteration 158: train_loss 1.8320581912994385
Iteration 159: train_loss 1.8878096342086792
Iteration 160: train_loss 1.8382996320724487
Iteration 161: train_loss 1.8452211618423462
Iteration 162: train_loss 1.8537575006484985
Iteration 163: train_loss 1.8925701379776
Iteration 164: train_loss 1.8352779150009155
Iteration 165: train_loss 1.851843237876892
Iteration 166: train_loss 1.7997748851776123
Iteration 167: train_loss 1.8267322778701782
Iteration 168: train_loss 1.813541293144226
Iteration 169: train_loss 1.8068079948425293
Iteration 170: train_loss 1.7979106903076172
Iteration 171: train_loss 1.7727926969528198
Iteration 172: train_loss 1.8689863681793213
Iteration 173: train_loss 1.8032957315444946
Iteration 174: train_loss 1.8172520399093628
Iteration 175: train_loss 1.7772459983825684
Iteration 176: train_loss 1.795288324356079
Iteration 177: train_loss 1.8262563943862915
Epoch 38: train_avg_loss 1.8015362711276037 eval_avg_acc: 0.33840918271935233 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:14:09] [32mIntermediate result: 0.33840918271935233  (Index 37)[0m
================Epoch: 39================
Iteration 1: train_loss 1.848233938217163
Iteration 2: train_loss 1.7777678966522217
Iteration 3: train_loss 1.8765441179275513
Iteration 4: train_loss 1.760603904724121
Iteration 5: train_loss 1.8191202878952026
Iteration 6: train_loss 1.7558794021606445
Iteration 7: train_loss 1.761433482170105
Iteration 8: train_loss 1.7707712650299072
Iteration 9: train_loss 1.7218338251113892
Iteration 10: train_loss 1.7779794931411743
Iteration 11: train_loss 1.736647367477417
Iteration 12: train_loss 1.7865792512893677
Iteration 13: train_loss 1.748576045036316
Iteration 14: train_loss 1.7195324897766113
Iteration 15: train_loss 1.7461040019989014
Iteration 16: train_loss 1.7772825956344604
Iteration 17: train_loss 1.7208242416381836
Iteration 18: train_loss 1.7211558818817139
Iteration 19: train_loss 1.6840721368789673
Iteration 20: train_loss 1.7961796522140503
Iteration 21: train_loss 1.7679153680801392
Iteration 22: train_loss 1.7708370685577393
Iteration 23: train_loss 1.742017149925232
Iteration 24: train_loss 1.7092018127441406
Iteration 25: train_loss 1.7751649618148804
Iteration 26: train_loss 1.7899272441864014
Iteration 27: train_loss 1.7629146575927734
Iteration 28: train_loss 1.8025838136672974
Iteration 29: train_loss 1.7823783159255981
Iteration 30: train_loss 1.6743448972702026
Iteration 31: train_loss 1.7408576011657715
Iteration 32: train_loss 1.7325482368469238
Iteration 33: train_loss 1.8338643312454224
Iteration 34: train_loss 1.8172117471694946
Iteration 35: train_loss 1.8663890361785889
Iteration 36: train_loss 1.7933740615844727
Iteration 37: train_loss 1.7322466373443604
Iteration 38: train_loss 1.8184690475463867
Iteration 39: train_loss 1.8153026103973389
Iteration 40: train_loss 1.7538201808929443
Iteration 41: train_loss 1.7893798351287842
Iteration 42: train_loss 1.8078677654266357
Iteration 43: train_loss 1.8256150484085083
Iteration 44: train_loss 1.738595724105835
Iteration 45: train_loss 1.8452574014663696
Iteration 46: train_loss 1.7638381719589233
Iteration 47: train_loss 1.8175199031829834
Iteration 48: train_loss 1.8199408054351807
Iteration 49: train_loss 1.8007107973098755
Iteration 50: train_loss 1.8033589124679565
Iteration 51: train_loss 1.7252528667449951
Iteration 52: train_loss 1.88613760471344
Iteration 53: train_loss 1.7170860767364502
Iteration 54: train_loss 1.756460189819336
Iteration 55: train_loss 1.800035834312439
Iteration 56: train_loss 1.696916103363037
Iteration 57: train_loss 1.7796756029129028
Iteration 58: train_loss 1.8475911617279053
Iteration 59: train_loss 1.7828466892242432
Iteration 60: train_loss 1.7809239625930786
Iteration 61: train_loss 1.7646514177322388
Iteration 62: train_loss 1.7101303339004517
Iteration 63: train_loss 1.7172091007232666
Iteration 64: train_loss 1.7754650115966797
Iteration 65: train_loss 1.8729830980300903
Iteration 66: train_loss 1.7173519134521484
Iteration 67: train_loss 1.7565940618515015
Iteration 68: train_loss 1.794116735458374
Iteration 69: train_loss 1.7326843738555908
Iteration 70: train_loss 1.7765405178070068
Iteration 71: train_loss 1.8296387195587158
Iteration 72: train_loss 1.737453579902649
Iteration 73: train_loss 1.7779879570007324
Iteration 74: train_loss 1.7505854368209839
Iteration 75: train_loss 1.8217027187347412
Iteration 76: train_loss 1.7699745893478394
Iteration 77: train_loss 1.7275545597076416
Iteration 78: train_loss 1.7864753007888794
Iteration 79: train_loss 1.8123586177825928
Iteration 80: train_loss 1.7947427034378052
Iteration 81: train_loss 1.887193202972412
Iteration 82: train_loss 1.835667371749878
Iteration 83: train_loss 1.7402796745300293
Iteration 84: train_loss 1.8451627492904663
Iteration 85: train_loss 1.8636853694915771
Iteration 86: train_loss 1.8309272527694702
Iteration 87: train_loss 1.7764413356781006
Iteration 88: train_loss 1.811486005783081
Iteration 89: train_loss 1.84768545627594
Iteration 90: train_loss 1.8171653747558594
Iteration 91: train_loss 1.859771490097046
Iteration 92: train_loss 1.8196532726287842
Iteration 93: train_loss 1.879866600036621
Iteration 94: train_loss 1.818691611289978
Iteration 95: train_loss 1.8697317838668823
Iteration 96: train_loss 1.7674171924591064
Iteration 97: train_loss 1.8529679775238037
Iteration 98: train_loss 1.8384134769439697
Iteration 99: train_loss 1.7456406354904175
Iteration 100: train_loss 1.8586663007736206
Iteration 101: train_loss 1.8145796060562134
Iteration 102: train_loss 1.8818397521972656
Iteration 103: train_loss 1.8053269386291504
Iteration 104: train_loss 1.798172116279602
Iteration 105: train_loss 1.8890169858932495
Iteration 106: train_loss 1.8447325229644775
Iteration 107: train_loss 1.8882876634597778
Iteration 108: train_loss 1.8333038091659546
Iteration 109: train_loss 1.9029005765914917
Iteration 110: train_loss 1.807446002960205
Iteration 111: train_loss 1.904884934425354
Iteration 112: train_loss 1.7647939920425415
Iteration 113: train_loss 1.7971405982971191
Iteration 114: train_loss 1.814570426940918
Iteration 115: train_loss 1.822941541671753
Iteration 116: train_loss 1.7538750171661377
Iteration 117: train_loss 1.714434266090393
Iteration 118: train_loss 1.7777725458145142
Iteration 119: train_loss 1.7557390928268433
Iteration 120: train_loss 1.910921335220337
Iteration 121: train_loss 1.7618616819381714
Iteration 122: train_loss 1.7494832277297974
Iteration 123: train_loss 1.8191730976104736
Iteration 124: train_loss 1.8043814897537231
Iteration 125: train_loss 1.7990317344665527
Iteration 126: train_loss 1.8259743452072144
Iteration 127: train_loss 1.817676067352295
Iteration 128: train_loss 1.7675238847732544
Iteration 129: train_loss 1.7630616426467896
Iteration 130: train_loss 1.7794605493545532
Iteration 131: train_loss 1.7763580083847046
Iteration 132: train_loss 1.7488003969192505
Iteration 133: train_loss 1.80305814743042
Iteration 134: train_loss 1.8201655149459839
Iteration 135: train_loss 1.7702889442443848
Iteration 136: train_loss 1.7425756454467773
Iteration 137: train_loss 1.8291304111480713
Iteration 138: train_loss 1.7770432233810425
Iteration 139: train_loss 1.7744905948638916
Iteration 140: train_loss 1.8483257293701172
Iteration 141: train_loss 1.800385594367981
Iteration 142: train_loss 1.8085126876831055
Iteration 143: train_loss 1.800620436668396
Iteration 144: train_loss 1.8009306192398071
Iteration 145: train_loss 1.867247223854065
Iteration 146: train_loss 1.8653969764709473
Iteration 147: train_loss 1.866845726966858
Iteration 148: train_loss 1.795636534690857
Iteration 149: train_loss 1.8582018613815308
Iteration 150: train_loss 1.833308458328247
Iteration 151: train_loss 1.809141993522644
Iteration 152: train_loss 1.8976622819900513
Iteration 153: train_loss 1.8208041191101074
Iteration 154: train_loss 1.812321662902832
Iteration 155: train_loss 1.8451300859451294
Iteration 156: train_loss 1.8554463386535645
Iteration 157: train_loss 1.7953532934188843
Iteration 158: train_loss 1.845254898071289
Iteration 159: train_loss 1.8488844633102417
Iteration 160: train_loss 1.7797939777374268
Iteration 161: train_loss 1.8229998350143433
Iteration 162: train_loss 1.8280497789382935
Iteration 163: train_loss 1.8057657480239868
Iteration 164: train_loss 1.843321442604065
Iteration 165: train_loss 1.7288002967834473
Iteration 166: train_loss 1.746351718902588
Iteration 167: train_loss 1.7455759048461914
Iteration 168: train_loss 1.7628157138824463
Iteration 169: train_loss 1.7846226692199707
Iteration 170: train_loss 1.690200686454773
Iteration 171: train_loss 1.8503077030181885
Iteration 172: train_loss 1.831046462059021
Iteration 173: train_loss 1.840427041053772
Iteration 174: train_loss 1.789778470993042
Iteration 175: train_loss 1.9010120630264282
Iteration 176: train_loss 1.7868281602859497
Iteration 177: train_loss 1.7170251607894897
Epoch 39: train_avg_loss 1.7960936019649614 eval_avg_acc: 0.33288625863411386 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:14:50] [32mIntermediate result: 0.33288625863411386  (Index 38)[0m
================Epoch: 40================
Iteration 1: train_loss 1.815945029258728
Iteration 2: train_loss 1.7708009481430054
Iteration 3: train_loss 1.737570881843567
Iteration 4: train_loss 1.753269910812378
Iteration 5: train_loss 1.7655576467514038
Iteration 6: train_loss 1.7289592027664185
Iteration 7: train_loss 1.78182852268219
Iteration 8: train_loss 1.7548600435256958
Iteration 9: train_loss 1.7865984439849854
Iteration 10: train_loss 1.6861945390701294
Iteration 11: train_loss 1.7861486673355103
Iteration 12: train_loss 1.7428877353668213
Iteration 13: train_loss 1.7307868003845215
Iteration 14: train_loss 1.7497974634170532
Iteration 15: train_loss 1.7972115278244019
Iteration 16: train_loss 1.8016631603240967
Iteration 17: train_loss 1.7622935771942139
Iteration 18: train_loss 1.8056961297988892
Iteration 19: train_loss 1.7781933546066284
Iteration 20: train_loss 1.7819393873214722
Iteration 21: train_loss 1.7140190601348877
Iteration 22: train_loss 1.7379040718078613
Iteration 23: train_loss 1.8042844533920288
Iteration 24: train_loss 1.745125412940979
Iteration 25: train_loss 1.7654615640640259
Iteration 26: train_loss 1.7297520637512207
Iteration 27: train_loss 1.86198890209198
Iteration 28: train_loss 1.854485034942627
Iteration 29: train_loss 1.6737209558486938
Iteration 30: train_loss 1.765546202659607
Iteration 31: train_loss 1.8139399290084839
Iteration 32: train_loss 1.865228295326233
Iteration 33: train_loss 1.7367644309997559
Iteration 34: train_loss 1.735292673110962
Iteration 35: train_loss 1.7667113542556763
Iteration 36: train_loss 1.809893012046814
Iteration 37: train_loss 1.775977373123169
Iteration 38: train_loss 1.7558691501617432
Iteration 39: train_loss 1.7094542980194092
Iteration 40: train_loss 1.766053557395935
Iteration 41: train_loss 1.7986383438110352
Iteration 42: train_loss 1.7481170892715454
Iteration 43: train_loss 1.7792516946792603
Iteration 44: train_loss 1.8142274618148804
Iteration 45: train_loss 1.7239301204681396
Iteration 46: train_loss 1.8299201726913452
Iteration 47: train_loss 1.7526280879974365
Iteration 48: train_loss 1.7747212648391724
Iteration 49: train_loss 1.7392230033874512
Iteration 50: train_loss 1.780505657196045
Iteration 51: train_loss 1.7374752759933472
Iteration 52: train_loss 1.7360565662384033
Iteration 53: train_loss 1.7093846797943115
Iteration 54: train_loss 1.7886258363723755
Iteration 55: train_loss 1.7789955139160156
Iteration 56: train_loss 1.7894002199172974
Iteration 57: train_loss 1.7509682178497314
Iteration 58: train_loss 1.758517861366272
Iteration 59: train_loss 1.807494044303894
Iteration 60: train_loss 1.7815296649932861
Iteration 61: train_loss 1.815334677696228
Iteration 62: train_loss 1.8099794387817383
Iteration 63: train_loss 1.8604443073272705
Iteration 64: train_loss 1.8407734632492065
Iteration 65: train_loss 1.7804664373397827
Iteration 66: train_loss 1.786784291267395
Iteration 67: train_loss 1.74672269821167
Iteration 68: train_loss 1.7813409566879272
Iteration 69: train_loss 1.8099178075790405
Iteration 70: train_loss 1.734161376953125
Iteration 71: train_loss 1.742335557937622
Iteration 72: train_loss 1.7537282705307007
Iteration 73: train_loss 1.8326188325881958
Iteration 74: train_loss 1.7733114957809448
Iteration 75: train_loss 1.7597460746765137
Iteration 76: train_loss 1.7923723459243774
Iteration 77: train_loss 1.7900493144989014
Iteration 78: train_loss 1.8280537128448486
Iteration 79: train_loss 1.7483456134796143
Iteration 80: train_loss 1.7708897590637207
Iteration 81: train_loss 1.7112661600112915
Iteration 82: train_loss 1.7621763944625854
Iteration 83: train_loss 1.7873023748397827
Iteration 84: train_loss 1.8478178977966309
Iteration 85: train_loss 1.8140641450881958
Iteration 86: train_loss 1.8332884311676025
Iteration 87: train_loss 1.7635356187820435
Iteration 88: train_loss 1.882604718208313
Iteration 89: train_loss 1.7627058029174805
Iteration 90: train_loss 1.7475718259811401
Iteration 91: train_loss 1.7397817373275757
Iteration 92: train_loss 1.8351609706878662
Iteration 93: train_loss 1.7811741828918457
Iteration 94: train_loss 1.7027437686920166
Iteration 95: train_loss 1.7909986972808838
Iteration 96: train_loss 1.770444631576538
Iteration 97: train_loss 1.7475165128707886
Iteration 98: train_loss 1.8060818910598755
Iteration 99: train_loss 1.7375047206878662
Iteration 100: train_loss 1.8495384454727173
Iteration 101: train_loss 1.794791340827942
Iteration 102: train_loss 1.8172461986541748
Iteration 103: train_loss 1.697855830192566
Iteration 104: train_loss 1.7668230533599854
Iteration 105: train_loss 1.8002476692199707
Iteration 106: train_loss 1.722770094871521
Iteration 107: train_loss 1.7190476655960083
Iteration 108: train_loss 1.792070746421814
Iteration 109: train_loss 1.8075581789016724
Iteration 110: train_loss 1.7917091846466064
Iteration 111: train_loss 1.7461451292037964
Iteration 112: train_loss 1.7764698266983032
Iteration 113: train_loss 1.8362905979156494
Iteration 114: train_loss 1.7683202028274536
Iteration 115: train_loss 1.7958054542541504
Iteration 116: train_loss 1.9619789123535156
Iteration 117: train_loss 1.7734845876693726
Iteration 118: train_loss 1.8472790718078613
Iteration 119: train_loss 1.8266470432281494
Iteration 120: train_loss 1.855023741722107
Iteration 121: train_loss 1.8096588850021362
Iteration 122: train_loss 1.7720710039138794
Iteration 123: train_loss 1.7951507568359375
Iteration 124: train_loss 1.775486707687378
Iteration 125: train_loss 1.7709386348724365
Iteration 126: train_loss 1.748370885848999
Iteration 127: train_loss 1.7053419351577759
Iteration 128: train_loss 1.7821166515350342
Iteration 129: train_loss 1.7680553197860718
Iteration 130: train_loss 1.7964788675308228
Iteration 131: train_loss 1.7468600273132324
Iteration 132: train_loss 1.7907952070236206
Iteration 133: train_loss 1.7234065532684326
Iteration 134: train_loss 1.748036503791809
Iteration 135: train_loss 1.7832236289978027
Iteration 136: train_loss 1.7543259859085083
Iteration 137: train_loss 1.8463577032089233
Iteration 138: train_loss 1.7942339181900024
Iteration 139: train_loss 1.8687362670898438
Iteration 140: train_loss 1.789876937866211
Iteration 141: train_loss 1.8352088928222656
Iteration 142: train_loss 1.7788175344467163
Iteration 143: train_loss 1.7867693901062012
Iteration 144: train_loss 1.7461237907409668
Iteration 145: train_loss 1.848172903060913
Iteration 146: train_loss 1.8046280145645142
Iteration 147: train_loss 1.7710449695587158
Iteration 148: train_loss 1.6886671781539917
Iteration 149: train_loss 1.8314614295959473
Iteration 150: train_loss 1.725092887878418
Iteration 151: train_loss 1.8257826566696167
Iteration 152: train_loss 1.828542947769165
Iteration 153: train_loss 1.8011536598205566
Iteration 154: train_loss 1.795617699623108
Iteration 155: train_loss 1.8727436065673828
Iteration 156: train_loss 1.7123346328735352
Iteration 157: train_loss 1.821925163269043
Iteration 158: train_loss 1.8279190063476562
Iteration 159: train_loss 1.7806967496871948
Iteration 160: train_loss 1.7893321514129639
Iteration 161: train_loss 1.8202576637268066
Iteration 162: train_loss 1.7859081029891968
Iteration 163: train_loss 1.8010128736495972
Iteration 164: train_loss 1.8283977508544922
Iteration 165: train_loss 1.8000307083129883
Iteration 166: train_loss 1.7509987354278564
Iteration 167: train_loss 1.873483657836914
Iteration 168: train_loss 1.8520492315292358
Iteration 169: train_loss 1.7809115648269653
Iteration 170: train_loss 1.7559350728988647
Iteration 171: train_loss 1.8695882558822632
Iteration 172: train_loss 1.8214038610458374
Iteration 173: train_loss 1.7878345251083374
Iteration 174: train_loss 1.7924965620040894
Iteration 175: train_loss 1.7585426568984985
Iteration 176: train_loss 1.8349652290344238
Iteration 177: train_loss 1.8192602396011353
Epoch 40: train_avg_loss 1.7829838405221194 eval_avg_acc: 0.3372997521256367 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:15:31] [32mIntermediate result: 0.3372997521256367  (Index 39)[0m
================Epoch: 41================
Iteration 1: train_loss 1.7777900695800781
Iteration 2: train_loss 1.8132692575454712
Iteration 3: train_loss 1.7559202909469604
Iteration 4: train_loss 1.8147951364517212
Iteration 5: train_loss 1.7413214445114136
Iteration 6: train_loss 1.7635468244552612
Iteration 7: train_loss 1.7781596183776855
Iteration 8: train_loss 1.7321429252624512
Iteration 9: train_loss 1.7709647417068481
Iteration 10: train_loss 1.8128243684768677
Iteration 11: train_loss 1.7496687173843384
Iteration 12: train_loss 1.826730728149414
Iteration 13: train_loss 1.7746577262878418
Iteration 14: train_loss 1.7471915483474731
Iteration 15: train_loss 1.813475489616394
Iteration 16: train_loss 1.8119335174560547
Iteration 17: train_loss 1.7304521799087524
Iteration 18: train_loss 1.8117557764053345
Iteration 19: train_loss 1.7205151319503784
Iteration 20: train_loss 1.7172306776046753
Iteration 21: train_loss 1.6981263160705566
Iteration 22: train_loss 1.7019999027252197
Iteration 23: train_loss 1.7510991096496582
Iteration 24: train_loss 1.6468201875686646
Iteration 25: train_loss 1.7490161657333374
Iteration 26: train_loss 1.7330900430679321
Iteration 27: train_loss 1.7426666021347046
Iteration 28: train_loss 1.709851622581482
Iteration 29: train_loss 1.7789921760559082
Iteration 30: train_loss 1.6996300220489502
Iteration 31: train_loss 1.6903735399246216
Iteration 32: train_loss 1.6865087747573853
Iteration 33: train_loss 1.7223126888275146
Iteration 34: train_loss 1.7027539014816284
Iteration 35: train_loss 1.7230937480926514
Iteration 36: train_loss 1.7717517614364624
Iteration 37: train_loss 1.7676392793655396
Iteration 38: train_loss 1.7113746404647827
Iteration 39: train_loss 1.7228047847747803
Iteration 40: train_loss 1.695035457611084
Iteration 41: train_loss 1.7865853309631348
Iteration 42: train_loss 1.69917631149292
Iteration 43: train_loss 1.667832851409912
Iteration 44: train_loss 1.7055193185806274
Iteration 45: train_loss 1.7697491645812988
Iteration 46: train_loss 1.7580139636993408
Iteration 47: train_loss 1.7042020559310913
Iteration 48: train_loss 1.7517225742340088
Iteration 49: train_loss 1.8115090131759644
Iteration 50: train_loss 1.7445893287658691
Iteration 51: train_loss 1.7312058210372925
Iteration 52: train_loss 1.7120320796966553
Iteration 53: train_loss 1.7182294130325317
Iteration 54: train_loss 1.7803759574890137
Iteration 55: train_loss 1.8115421533584595
Iteration 56: train_loss 1.7193567752838135
Iteration 57: train_loss 1.7468992471694946
Iteration 58: train_loss 1.7592177391052246
Iteration 59: train_loss 1.7868804931640625
Iteration 60: train_loss 1.7255669832229614
Iteration 61: train_loss 1.8238741159439087
Iteration 62: train_loss 1.7641069889068604
Iteration 63: train_loss 1.8035541772842407
Iteration 64: train_loss 1.7654778957366943
Iteration 65: train_loss 1.7485995292663574
Iteration 66: train_loss 1.7220420837402344
Iteration 67: train_loss 1.7358479499816895
Iteration 68: train_loss 1.7614572048187256
Iteration 69: train_loss 1.7826621532440186
Iteration 70: train_loss 1.796150803565979
Iteration 71: train_loss 1.7407958507537842
Iteration 72: train_loss 1.793688178062439
Iteration 73: train_loss 1.7875803709030151
Iteration 74: train_loss 1.7658195495605469
Iteration 75: train_loss 1.69671630859375
Iteration 76: train_loss 1.7876652479171753
Iteration 77: train_loss 1.7747786045074463
Iteration 78: train_loss 1.7324497699737549
Iteration 79: train_loss 1.8078737258911133
Iteration 80: train_loss 1.8033889532089233
Iteration 81: train_loss 1.8197866678237915
Iteration 82: train_loss 1.6395612955093384
Iteration 83: train_loss 1.7375059127807617
Iteration 84: train_loss 1.73397958278656
Iteration 85: train_loss 1.767191767692566
Iteration 86: train_loss 1.8054455518722534
Iteration 87: train_loss 1.8331398963928223
Iteration 88: train_loss 1.7426613569259644
Iteration 89: train_loss 1.8090161085128784
Iteration 90: train_loss 1.8378418684005737
Iteration 91: train_loss 1.7750930786132812
Iteration 92: train_loss 1.787398099899292
Iteration 93: train_loss 1.8461815118789673
Iteration 94: train_loss 1.7815262079238892
Iteration 95: train_loss 1.7683022022247314
Iteration 96: train_loss 1.8137205839157104
Iteration 97: train_loss 1.7265549898147583
Iteration 98: train_loss 1.8098711967468262
Iteration 99: train_loss 1.8846718072891235
Iteration 100: train_loss 1.7709773778915405
Iteration 101: train_loss 1.7494975328445435
Iteration 102: train_loss 1.7518556118011475
Iteration 103: train_loss 1.7605022192001343
Iteration 104: train_loss 1.8297605514526367
Iteration 105: train_loss 1.7584227323532104
Iteration 106: train_loss 1.7638723850250244
Iteration 107: train_loss 1.794899344444275
Iteration 108: train_loss 1.811126947402954
Iteration 109: train_loss 1.7479947805404663
Iteration 110: train_loss 1.8518410921096802
Iteration 111: train_loss 1.7453622817993164
Iteration 112: train_loss 1.710988998413086
Iteration 113: train_loss 1.6350816488265991
Iteration 114: train_loss 1.7282987833023071
Iteration 115: train_loss 1.7454752922058105
Iteration 116: train_loss 1.6692795753479004
Iteration 117: train_loss 1.7204748392105103
Iteration 118: train_loss 1.7802774906158447
Iteration 119: train_loss 1.8135182857513428
Iteration 120: train_loss 1.8241037130355835
Iteration 121: train_loss 1.7583447694778442
Iteration 122: train_loss 1.8466821908950806
Iteration 123: train_loss 1.7729036808013916
Iteration 124: train_loss 1.783974528312683
Iteration 125: train_loss 1.7661964893341064
Iteration 126: train_loss 1.788893461227417
Iteration 127: train_loss 1.837917685508728
Iteration 128: train_loss 1.7789666652679443
Iteration 129: train_loss 1.7819126844406128
Iteration 130: train_loss 1.7850555181503296
Iteration 131: train_loss 1.75399911403656
Iteration 132: train_loss 1.8049553632736206
Iteration 133: train_loss 1.7369829416275024
Iteration 134: train_loss 1.7015438079833984
Iteration 135: train_loss 1.7909332513809204
Iteration 136: train_loss 1.796287178993225
Iteration 137: train_loss 1.8031331300735474
Iteration 138: train_loss 1.738779902458191
Iteration 139: train_loss 1.7640000581741333
Iteration 140: train_loss 1.6911040544509888
Iteration 141: train_loss 1.80454421043396
Iteration 142: train_loss 1.7824122905731201
Iteration 143: train_loss 1.780463457107544
Iteration 144: train_loss 1.722095012664795
Iteration 145: train_loss 1.7487846612930298
Iteration 146: train_loss 1.7022682428359985
Iteration 147: train_loss 1.7555948495864868
Iteration 148: train_loss 1.8075064420700073
Iteration 149: train_loss 1.78484308719635
Iteration 150: train_loss 1.8257834911346436
Iteration 151: train_loss 1.7362983226776123
Iteration 152: train_loss 1.8029041290283203
Iteration 153: train_loss 1.7913159132003784
Iteration 154: train_loss 1.7367346286773682
Iteration 155: train_loss 1.7561194896697998
Iteration 156: train_loss 1.8410758972167969
Iteration 157: train_loss 1.7900240421295166
Iteration 158: train_loss 1.788941740989685
Iteration 159: train_loss 1.7757881879806519
Iteration 160: train_loss 1.7404707670211792
Iteration 161: train_loss 1.759020209312439
Iteration 162: train_loss 1.8031628131866455
Iteration 163: train_loss 1.782381296157837
Iteration 164: train_loss 1.8509691953659058
Iteration 165: train_loss 1.777631402015686
Iteration 166: train_loss 1.77312171459198
Iteration 167: train_loss 1.8281829357147217
Iteration 168: train_loss 1.7741063833236694
Iteration 169: train_loss 1.7875677347183228
Iteration 170: train_loss 1.7176910638809204
Iteration 171: train_loss 1.8255407810211182
Iteration 172: train_loss 1.8168760538101196
Iteration 173: train_loss 1.7614513635635376
Iteration 174: train_loss 1.7658454179763794
Iteration 175: train_loss 1.7432445287704468
Iteration 176: train_loss 1.6968162059783936
Iteration 177: train_loss 1.844302773475647
Epoch 41: train_avg_loss 1.764415431157344 eval_avg_acc: 0.31137608468501404 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:16:13] [32mIntermediate result: 0.31137608468501404  (Index 40)[0m
================Epoch: 42================
Iteration 1: train_loss 1.673153281211853
Iteration 2: train_loss 1.7905399799346924
Iteration 3: train_loss 1.6805088520050049
Iteration 4: train_loss 1.6836094856262207
Iteration 5: train_loss 1.6720298528671265
Iteration 6: train_loss 1.788426399230957
Iteration 7: train_loss 1.6881433725357056
Iteration 8: train_loss 1.7108780145645142
Iteration 9: train_loss 1.7329280376434326
Iteration 10: train_loss 1.7097171545028687
Iteration 11: train_loss 1.7782115936279297
Iteration 12: train_loss 1.6788092851638794
Iteration 13: train_loss 1.7645338773727417
Iteration 14: train_loss 1.7490615844726562
Iteration 15: train_loss 1.714450478553772
Iteration 16: train_loss 1.7373706102371216
Iteration 17: train_loss 1.7864387035369873
Iteration 18: train_loss 1.74796462059021
Iteration 19: train_loss 1.7062081098556519
Iteration 20: train_loss 1.7064523696899414
Iteration 21: train_loss 1.7406617403030396
Iteration 22: train_loss 1.812174677848816
Iteration 23: train_loss 1.7308168411254883
Iteration 24: train_loss 1.7174702882766724
Iteration 25: train_loss 1.693232774734497
Iteration 26: train_loss 1.7521318197250366
Iteration 27: train_loss 1.668108582496643
Iteration 28: train_loss 1.678907871246338
Iteration 29: train_loss 1.7201143503189087
Iteration 30: train_loss 1.7264269590377808
Iteration 31: train_loss 1.7947622537612915
Iteration 32: train_loss 1.7087856531143188
Iteration 33: train_loss 1.6603319644927979
Iteration 34: train_loss 1.7777585983276367
Iteration 35: train_loss 1.7603826522827148
Iteration 36: train_loss 1.7883598804473877
Iteration 37: train_loss 1.7212953567504883
Iteration 38: train_loss 1.7459367513656616
Iteration 39: train_loss 1.7729707956314087
Iteration 40: train_loss 1.7033417224884033
Iteration 41: train_loss 1.7601547241210938
Iteration 42: train_loss 1.791644811630249
Iteration 43: train_loss 1.7850992679595947
Iteration 44: train_loss 1.7992526292800903
Iteration 45: train_loss 1.744206428527832
Iteration 46: train_loss 1.7414088249206543
Iteration 47: train_loss 1.730488657951355
Iteration 48: train_loss 1.7536801099777222
Iteration 49: train_loss 1.7005912065505981
Iteration 50: train_loss 1.719535231590271
Iteration 51: train_loss 1.7447044849395752
Iteration 52: train_loss 1.8073111772537231
Iteration 53: train_loss 1.7306225299835205
Iteration 54: train_loss 1.775169014930725
Iteration 55: train_loss 1.7651840448379517
Iteration 56: train_loss 1.6844377517700195
Iteration 57: train_loss 1.6795588731765747
Iteration 58: train_loss 1.734725832939148
Iteration 59: train_loss 1.6573045253753662
Iteration 60: train_loss 1.7562617063522339
Iteration 61: train_loss 1.7537986040115356
Iteration 62: train_loss 1.782531499862671
Iteration 63: train_loss 1.7702635526657104
Iteration 64: train_loss 1.76670241355896
Iteration 65: train_loss 1.7656728029251099
Iteration 66: train_loss 1.728013038635254
Iteration 67: train_loss 1.7836532592773438
Iteration 68: train_loss 1.862078070640564
Iteration 69: train_loss 1.731142282485962
Iteration 70: train_loss 1.7901629209518433
Iteration 71: train_loss 1.7529616355895996
Iteration 72: train_loss 1.7542567253112793
Iteration 73: train_loss 1.7204338312149048
Iteration 74: train_loss 1.7747623920440674
Iteration 75: train_loss 1.728635311126709
Iteration 76: train_loss 1.7542040348052979
Iteration 77: train_loss 1.7805818319320679
Iteration 78: train_loss 1.7235536575317383
Iteration 79: train_loss 1.782144546508789
Iteration 80: train_loss 1.741007924079895
Iteration 81: train_loss 1.7498667240142822
Iteration 82: train_loss 1.7022926807403564
Iteration 83: train_loss 1.7900973558425903
Iteration 84: train_loss 1.7895373106002808
Iteration 85: train_loss 1.7943793535232544
Iteration 86: train_loss 1.7722442150115967
Iteration 87: train_loss 1.7035211324691772
Iteration 88: train_loss 1.7146207094192505
Iteration 89: train_loss 1.7442978620529175
Iteration 90: train_loss 1.7107181549072266
Iteration 91: train_loss 1.7506417036056519
Iteration 92: train_loss 1.7817015647888184
Iteration 93: train_loss 1.7610629796981812
Iteration 94: train_loss 1.6373417377471924
Iteration 95: train_loss 1.8007105588912964
Iteration 96: train_loss 1.7732385396957397
Iteration 97: train_loss 1.7248283624649048
Iteration 98: train_loss 1.707187533378601
Iteration 99: train_loss 1.780257225036621
Iteration 100: train_loss 1.7750948667526245
Iteration 101: train_loss 1.6795696020126343
Iteration 102: train_loss 1.754939317703247
Iteration 103: train_loss 1.7750674486160278
Iteration 104: train_loss 1.7225708961486816
Iteration 105: train_loss 1.7183289527893066
Iteration 106: train_loss 1.7841066122055054
Iteration 107: train_loss 1.7679314613342285
Iteration 108: train_loss 1.9038892984390259
Iteration 109: train_loss 1.6923420429229736
Iteration 110: train_loss 1.8522297143936157
Iteration 111: train_loss 1.6877872943878174
Iteration 112: train_loss 1.82403564453125
Iteration 113: train_loss 1.7669436931610107
Iteration 114: train_loss 1.68922758102417
Iteration 115: train_loss 1.7394437789916992
Iteration 116: train_loss 1.741589903831482
Iteration 117: train_loss 1.7159779071807861
Iteration 118: train_loss 1.723651647567749
Iteration 119: train_loss 1.7020238637924194
Iteration 120: train_loss 1.7080206871032715
Iteration 121: train_loss 1.7933772802352905
Iteration 122: train_loss 1.6905189752578735
Iteration 123: train_loss 1.8195704221725464
Iteration 124: train_loss 1.8167203664779663
Iteration 125: train_loss 1.7270740270614624
Iteration 126: train_loss 1.7684098482131958
Iteration 127: train_loss 1.7338812351226807
Iteration 128: train_loss 1.738101601600647
Iteration 129: train_loss 1.7559489011764526
Iteration 130: train_loss 1.7165844440460205
Iteration 131: train_loss 1.779086709022522
Iteration 132: train_loss 1.7465977668762207
Iteration 133: train_loss 1.7534637451171875
Iteration 134: train_loss 1.7407982349395752
Iteration 135: train_loss 1.8199681043624878
Iteration 136: train_loss 1.8073780536651611
Iteration 137: train_loss 1.7529163360595703
Iteration 138: train_loss 1.752832293510437
Iteration 139: train_loss 1.7116889953613281
Iteration 140: train_loss 1.7316615581512451
Iteration 141: train_loss 1.6320064067840576
Iteration 142: train_loss 1.8009042739868164
Iteration 143: train_loss 1.773402214050293
Iteration 144: train_loss 1.7435790300369263
Iteration 145: train_loss 1.743648648262024
Iteration 146: train_loss 1.7496874332427979
Iteration 147: train_loss 1.8221027851104736
Iteration 148: train_loss 1.759738802909851
Iteration 149: train_loss 1.7377640008926392
Iteration 150: train_loss 1.7521238327026367
Iteration 151: train_loss 1.7202519178390503
Iteration 152: train_loss 1.7405846118927002
Iteration 153: train_loss 1.7709852457046509
Iteration 154: train_loss 1.751697063446045
Iteration 155: train_loss 1.7089731693267822
Iteration 156: train_loss 1.7646535634994507
Iteration 157: train_loss 1.740701675415039
Iteration 158: train_loss 1.7110719680786133
Iteration 159: train_loss 1.7398221492767334
Iteration 160: train_loss 1.7845803499221802
Iteration 161: train_loss 1.7580376863479614
Iteration 162: train_loss 1.6577715873718262
Iteration 163: train_loss 1.7681554555892944
Iteration 164: train_loss 1.75921630859375
Iteration 165: train_loss 1.8172330856323242
Iteration 166: train_loss 1.7418228387832642
Iteration 167: train_loss 1.793799638748169
Iteration 168: train_loss 1.7628958225250244
Iteration 169: train_loss 1.7477385997772217
Iteration 170: train_loss 1.7120740413665771
Iteration 171: train_loss 1.7487733364105225
Iteration 172: train_loss 1.7561894655227661
Iteration 173: train_loss 1.790321707725525
Iteration 174: train_loss 1.7431061267852783
Iteration 175: train_loss 1.795166015625
Iteration 176: train_loss 1.8033541440963745
Iteration 177: train_loss 1.7783867120742798
Epoch 42: train_avg_loss 1.7470820785242285 eval_avg_acc: 0.33552585449220546 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:16:55] [32mIntermediate result: 0.33552585449220546  (Index 41)[0m
================Epoch: 43================
Iteration 1: train_loss 1.732876181602478
Iteration 2: train_loss 1.71872878074646
Iteration 3: train_loss 1.6564077138900757
Iteration 4: train_loss 1.7727266550064087
Iteration 5: train_loss 1.8536559343338013
Iteration 6: train_loss 1.7729800939559937
Iteration 7: train_loss 1.7313405275344849
Iteration 8: train_loss 1.716774821281433
Iteration 9: train_loss 1.7462918758392334
Iteration 10: train_loss 1.7618252038955688
Iteration 11: train_loss 1.6866079568862915
Iteration 12: train_loss 1.6525315046310425
Iteration 13: train_loss 1.7337509393692017
Iteration 14: train_loss 1.7318894863128662
Iteration 15: train_loss 1.728129506111145
Iteration 16: train_loss 1.7751317024230957
Iteration 17: train_loss 1.757782220840454
Iteration 18: train_loss 1.7491494417190552
Iteration 19: train_loss 1.6930265426635742
Iteration 20: train_loss 1.705538272857666
Iteration 21: train_loss 1.7525293827056885
Iteration 22: train_loss 1.7411608695983887
Iteration 23: train_loss 1.6763445138931274
Iteration 24: train_loss 1.760670781135559
Iteration 25: train_loss 1.7107300758361816
Iteration 26: train_loss 1.6755247116088867
Iteration 27: train_loss 1.6709519624710083
Iteration 28: train_loss 1.678308367729187
Iteration 29: train_loss 1.722945213317871
Iteration 30: train_loss 1.718691110610962
Iteration 31: train_loss 1.7130494117736816
Iteration 32: train_loss 1.6931012868881226
Iteration 33: train_loss 1.6549354791641235
Iteration 34: train_loss 1.7791908979415894
Iteration 35: train_loss 1.7860995531082153
Iteration 36: train_loss 1.7610654830932617
Iteration 37: train_loss 1.7481120824813843
Iteration 38: train_loss 1.7074568271636963
Iteration 39: train_loss 1.7260984182357788
Iteration 40: train_loss 1.758840560913086
Iteration 41: train_loss 1.8335217237472534
Iteration 42: train_loss 1.6751949787139893
Iteration 43: train_loss 1.7368483543395996
Iteration 44: train_loss 1.6857918500900269
Iteration 45: train_loss 1.8285541534423828
Iteration 46: train_loss 1.727757453918457
Iteration 47: train_loss 1.6888011693954468
Iteration 48: train_loss 1.7380633354187012
Iteration 49: train_loss 1.7406589984893799
Iteration 50: train_loss 1.737164855003357
Iteration 51: train_loss 1.7154359817504883
Iteration 52: train_loss 1.7182515859603882
Iteration 53: train_loss 1.6985201835632324
Iteration 54: train_loss 1.761055827140808
Iteration 55: train_loss 1.7462486028671265
Iteration 56: train_loss 1.721683382987976
Iteration 57: train_loss 1.741410493850708
Iteration 58: train_loss 1.711194634437561
Iteration 59: train_loss 1.6988060474395752
Iteration 60: train_loss 1.7072527408599854
Iteration 61: train_loss 1.65192711353302
Iteration 62: train_loss 1.6514837741851807
Iteration 63: train_loss 1.7301197052001953
Iteration 64: train_loss 1.8206809759140015
Iteration 65: train_loss 1.7241095304489136
Iteration 66: train_loss 1.6779677867889404
Iteration 67: train_loss 1.7016328573226929
Iteration 68: train_loss 1.7129132747650146
Iteration 69: train_loss 1.689220666885376
Iteration 70: train_loss 1.724146842956543
Iteration 71: train_loss 1.7445650100708008
Iteration 72: train_loss 1.6961085796356201
Iteration 73: train_loss 1.7335997819900513
Iteration 74: train_loss 1.7341886758804321
Iteration 75: train_loss 1.7416975498199463
Iteration 76: train_loss 1.7476915121078491
Iteration 77: train_loss 1.6873363256454468
Iteration 78: train_loss 1.7144784927368164
Iteration 79: train_loss 1.7262344360351562
Iteration 80: train_loss 1.7461037635803223
Iteration 81: train_loss 1.7450238466262817
Iteration 82: train_loss 1.7245473861694336
Iteration 83: train_loss 1.6899222135543823
Iteration 84: train_loss 1.796800971031189
Iteration 85: train_loss 1.7814114093780518
Iteration 86: train_loss 1.7905206680297852
Iteration 87: train_loss 1.7271028757095337
Iteration 88: train_loss 1.792969822883606
Iteration 89: train_loss 1.751107096672058
Iteration 90: train_loss 1.7811161279678345
Iteration 91: train_loss 1.7023797035217285
Iteration 92: train_loss 1.7798341512680054
Iteration 93: train_loss 1.6559011936187744
Iteration 94: train_loss 1.7461808919906616
Iteration 95: train_loss 1.7554175853729248
Iteration 96: train_loss 1.7585763931274414
Iteration 97: train_loss 1.7893773317337036
Iteration 98: train_loss 1.8298317193984985
Iteration 99: train_loss 1.7567155361175537
Iteration 100: train_loss 1.6979758739471436
Iteration 101: train_loss 1.7649478912353516
Iteration 102: train_loss 1.7358167171478271
Iteration 103: train_loss 1.7566485404968262
Iteration 104: train_loss 1.771301031112671
Iteration 105: train_loss 1.7701712846755981
Iteration 106: train_loss 1.7487369775772095
Iteration 107: train_loss 1.751654028892517
Iteration 108: train_loss 1.775225043296814
Iteration 109: train_loss 1.7449212074279785
Iteration 110: train_loss 1.8031175136566162
Iteration 111: train_loss 1.7140333652496338
Iteration 112: train_loss 1.7760374546051025
Iteration 113: train_loss 1.795089602470398
Iteration 114: train_loss 1.8193103075027466
Iteration 115: train_loss 1.8279236555099487
Iteration 116: train_loss 1.7188684940338135
Iteration 117: train_loss 1.78582763671875
Iteration 118: train_loss 1.7467283010482788
Iteration 119: train_loss 1.7218904495239258
Iteration 120: train_loss 1.8047800064086914
Iteration 121: train_loss 1.7408339977264404
Iteration 122: train_loss 1.7327821254730225
Iteration 123: train_loss 1.7010716199874878
Iteration 124: train_loss 1.7928707599639893
Iteration 125: train_loss 1.7480179071426392
Iteration 126: train_loss 1.7222291231155396
Iteration 127: train_loss 1.749630093574524
Iteration 128: train_loss 1.6686441898345947
Iteration 129: train_loss 1.706929326057434
Iteration 130: train_loss 1.7344183921813965
Iteration 131: train_loss 1.7532223463058472
Iteration 132: train_loss 1.7697523832321167
Iteration 133: train_loss 1.7672637701034546
Iteration 134: train_loss 1.7731682062149048
Iteration 135: train_loss 1.7196717262268066
Iteration 136: train_loss 1.804348111152649
Iteration 137: train_loss 1.7587758302688599
Iteration 138: train_loss 1.7827340364456177
Iteration 139: train_loss 1.7825453281402588
Iteration 140: train_loss 1.7218066453933716
Iteration 141: train_loss 1.789543628692627
Iteration 142: train_loss 1.7591718435287476
Iteration 143: train_loss 1.7735974788665771
Iteration 144: train_loss 1.781158685684204
Iteration 145: train_loss 1.7682774066925049
Iteration 146: train_loss 1.6783710718154907
Iteration 147: train_loss 1.8573975563049316
Iteration 148: train_loss 1.7480696439743042
Iteration 149: train_loss 1.8565168380737305
Iteration 150: train_loss 1.7531276941299438
Iteration 151: train_loss 1.7177131175994873
Iteration 152: train_loss 1.795719861984253
Iteration 153: train_loss 1.7861346006393433
Iteration 154: train_loss 1.7222174406051636
Iteration 155: train_loss 1.7773737907409668
Iteration 156: train_loss 1.7533259391784668
Iteration 157: train_loss 1.8508036136627197
Iteration 158: train_loss 1.804186224937439
Iteration 159: train_loss 1.7645671367645264
Iteration 160: train_loss 1.7798677682876587
Iteration 161: train_loss 1.8155770301818848
Iteration 162: train_loss 1.7032827138900757
Iteration 163: train_loss 1.7720814943313599
Iteration 164: train_loss 1.7146590948104858
Iteration 165: train_loss 1.7906124591827393
Iteration 166: train_loss 1.7484334707260132
Iteration 167: train_loss 1.7769578695297241
Iteration 168: train_loss 1.7816916704177856
Iteration 169: train_loss 1.821244716644287
Iteration 170: train_loss 1.8032190799713135
Iteration 171: train_loss 1.7433669567108154
Iteration 172: train_loss 1.7562288045883179
Iteration 173: train_loss 1.7500720024108887
Iteration 174: train_loss 1.7331690788269043
Iteration 175: train_loss 1.737021803855896
Iteration 176: train_loss 1.6748255491256714
Iteration 177: train_loss 1.7251553535461426
Epoch 43: train_avg_loss 1.7444213224669634 eval_avg_acc: 0.3316562642339521 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:17:36] [32mIntermediate result: 0.3316562642339521  (Index 42)[0m
================Epoch: 44================
Iteration 1: train_loss 1.706167221069336
Iteration 2: train_loss 1.6794730424880981
Iteration 3: train_loss 1.7053807973861694
Iteration 4: train_loss 1.7148728370666504
Iteration 5: train_loss 1.7754406929016113
Iteration 6: train_loss 1.7229862213134766
Iteration 7: train_loss 1.630427360534668
Iteration 8: train_loss 1.7296488285064697
Iteration 9: train_loss 1.7205290794372559
Iteration 10: train_loss 1.6977509260177612
Iteration 11: train_loss 1.659076452255249
Iteration 12: train_loss 1.6107653379440308
Iteration 13: train_loss 1.7298530340194702
Iteration 14: train_loss 1.6971412897109985
Iteration 15: train_loss 1.7308356761932373
Iteration 16: train_loss 1.6575251817703247
Iteration 17: train_loss 1.6557583808898926
Iteration 18: train_loss 1.6715033054351807
Iteration 19: train_loss 1.6948204040527344
Iteration 20: train_loss 1.7237555980682373
Iteration 21: train_loss 1.6939557790756226
Iteration 22: train_loss 1.716866135597229
Iteration 23: train_loss 1.7497190237045288
Iteration 24: train_loss 1.674399495124817
Iteration 25: train_loss 1.6654088497161865
Iteration 26: train_loss 1.6352695226669312
Iteration 27: train_loss 1.765697717666626
Iteration 28: train_loss 1.7408206462860107
Iteration 29: train_loss 1.6650503873825073
Iteration 30: train_loss 1.601439118385315
Iteration 31: train_loss 1.6878376007080078
Iteration 32: train_loss 1.731711745262146
Iteration 33: train_loss 1.6657207012176514
Iteration 34: train_loss 1.7433898448944092
Iteration 35: train_loss 1.7036513090133667
Iteration 36: train_loss 1.7476056814193726
Iteration 37: train_loss 1.7548351287841797
Iteration 38: train_loss 1.7381561994552612
Iteration 39: train_loss 1.8212093114852905
Iteration 40: train_loss 1.8045300245285034
Iteration 41: train_loss 1.7914663553237915
Iteration 42: train_loss 1.7093091011047363
Iteration 43: train_loss 1.77902090549469
Iteration 44: train_loss 1.7481112480163574
Iteration 45: train_loss 1.6843913793563843
Iteration 46: train_loss 1.7520595788955688
Iteration 47: train_loss 1.7273459434509277
Iteration 48: train_loss 1.7425936460494995
Iteration 49: train_loss 1.7349923849105835
Iteration 50: train_loss 1.7425259351730347
Iteration 51: train_loss 1.8326749801635742
Iteration 52: train_loss 1.738685131072998
Iteration 53: train_loss 1.6801203489303589
Iteration 54: train_loss 1.8115496635437012
Iteration 55: train_loss 1.7514255046844482
Iteration 56: train_loss 1.7360070943832397
Iteration 57: train_loss 1.6562225818634033
Iteration 58: train_loss 1.7898871898651123
Iteration 59: train_loss 1.7672438621520996
Iteration 60: train_loss 1.7333974838256836
Iteration 61: train_loss 1.6842120885849
Iteration 62: train_loss 1.7511423826217651
Iteration 63: train_loss 1.795182228088379
Iteration 64: train_loss 1.7027060985565186
Iteration 65: train_loss 1.7232853174209595
Iteration 66: train_loss 1.7243695259094238
Iteration 67: train_loss 1.7485185861587524
Iteration 68: train_loss 1.738703727722168
Iteration 69: train_loss 1.7226759195327759
Iteration 70: train_loss 1.7513444423675537
Iteration 71: train_loss 1.7317732572555542
Iteration 72: train_loss 1.811829924583435
Iteration 73: train_loss 1.7332171201705933
Iteration 74: train_loss 1.7619524002075195
Iteration 75: train_loss 1.769958257675171
Iteration 76: train_loss 1.7450006008148193
Iteration 77: train_loss 1.733107328414917
Iteration 78: train_loss 1.7790148258209229
Iteration 79: train_loss 1.7247107028961182
Iteration 80: train_loss 1.7903562784194946
Iteration 81: train_loss 1.6879982948303223
Iteration 82: train_loss 1.6880571842193604
Iteration 83: train_loss 1.7194864749908447
Iteration 84: train_loss 1.7330095767974854
Iteration 85: train_loss 1.6834304332733154
Iteration 86: train_loss 1.7407526969909668
Iteration 87: train_loss 1.784660816192627
Iteration 88: train_loss 1.7368462085723877
Iteration 89: train_loss 1.7464241981506348
Iteration 90: train_loss 1.7859426736831665
Iteration 91: train_loss 1.6703662872314453
Iteration 92: train_loss 1.7413793802261353
Iteration 93: train_loss 1.7355965375900269
Iteration 94: train_loss 1.7108511924743652
Iteration 95: train_loss 1.726305365562439
Iteration 96: train_loss 1.7236295938491821
Iteration 97: train_loss 1.7097086906433105
Iteration 98: train_loss 1.7037931680679321
Iteration 99: train_loss 1.7292717695236206
Iteration 100: train_loss 1.7024555206298828
Iteration 101: train_loss 1.677829623222351
Iteration 102: train_loss 1.7418603897094727
Iteration 103: train_loss 1.692216157913208
Iteration 104: train_loss 1.723832607269287
Iteration 105: train_loss 1.7857050895690918
Iteration 106: train_loss 1.700031042098999
Iteration 107: train_loss 1.7059216499328613
Iteration 108: train_loss 1.6588828563690186
Iteration 109: train_loss 1.725614309310913
Iteration 110: train_loss 1.706992745399475
Iteration 111: train_loss 1.7337270975112915
Iteration 112: train_loss 1.753988265991211
Iteration 113: train_loss 1.7563326358795166
Iteration 114: train_loss 1.7815393209457397
Iteration 115: train_loss 1.7678273916244507
Iteration 116: train_loss 1.7292461395263672
Iteration 117: train_loss 1.7255908250808716
Iteration 118: train_loss 1.6635501384735107
Iteration 119: train_loss 1.7334119081497192
Iteration 120: train_loss 1.7540684938430786
Iteration 121: train_loss 1.7086163759231567
Iteration 122: train_loss 1.648053765296936
Iteration 123: train_loss 1.726746678352356
Iteration 124: train_loss 1.7563979625701904
Iteration 125: train_loss 1.7497282028198242
Iteration 126: train_loss 1.7298755645751953
Iteration 127: train_loss 1.7561262845993042
Iteration 128: train_loss 1.7940738201141357
Iteration 129: train_loss 1.7566859722137451
Iteration 130: train_loss 1.735388159751892
Iteration 131: train_loss 1.7612687349319458
Iteration 132: train_loss 1.7336523532867432
Iteration 133: train_loss 1.7108423709869385
Iteration 134: train_loss 1.7734078168869019
Iteration 135: train_loss 1.6872036457061768
Iteration 136: train_loss 1.7984036207199097
Iteration 137: train_loss 1.787204384803772
Iteration 138: train_loss 1.7454595565795898
Iteration 139: train_loss 1.71009361743927
Iteration 140: train_loss 1.787980556488037
Iteration 141: train_loss 1.76790189743042
Iteration 142: train_loss 1.7401385307312012
Iteration 143: train_loss 1.8219070434570312
Iteration 144: train_loss 1.7086901664733887
Iteration 145: train_loss 1.7693490982055664
Iteration 146: train_loss 1.796028733253479
Iteration 147: train_loss 1.7108988761901855
Iteration 148: train_loss 1.6993919610977173
Iteration 149: train_loss 1.7875458002090454
Iteration 150: train_loss 1.7841609716415405
Iteration 151: train_loss 1.780523419380188
Iteration 152: train_loss 1.7090638875961304
Iteration 153: train_loss 1.747788429260254
Iteration 154: train_loss 1.7165619134902954
Iteration 155: train_loss 1.8005675077438354
Iteration 156: train_loss 1.7970079183578491
Iteration 157: train_loss 1.7955315113067627
Iteration 158: train_loss 1.768046259880066
Iteration 159: train_loss 1.8068088293075562
Iteration 160: train_loss 1.7629345655441284
Iteration 161: train_loss 1.7969303131103516
Iteration 162: train_loss 1.8059535026550293
Iteration 163: train_loss 1.7204543352127075
Iteration 164: train_loss 1.7074660062789917
Iteration 165: train_loss 1.7611205577850342
Iteration 166: train_loss 1.7004324197769165
Iteration 167: train_loss 1.8021148443222046
Iteration 168: train_loss 1.7734028100967407
Iteration 169: train_loss 1.8544602394104004
Iteration 170: train_loss 1.7532892227172852
Iteration 171: train_loss 1.760919213294983
Iteration 172: train_loss 1.8224085569381714
Iteration 173: train_loss 1.7789853811264038
Iteration 174: train_loss 1.7973434925079346
Iteration 175: train_loss 1.7038544416427612
Iteration 176: train_loss 1.8384838104248047
Iteration 177: train_loss 1.684936285018921
Epoch 44: train_avg_loss 1.7357165207297116 eval_avg_acc: 0.33658537692696183 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:18:17] [32mIntermediate result: 0.33658537692696183  (Index 43)[0m
================Epoch: 45================
Iteration 1: train_loss 1.759143590927124
Iteration 2: train_loss 1.6568677425384521
Iteration 3: train_loss 1.6054733991622925
Iteration 4: train_loss 1.6474311351776123
Iteration 5: train_loss 1.6871801614761353
Iteration 6: train_loss 1.6601736545562744
Iteration 7: train_loss 1.6808096170425415
Iteration 8: train_loss 1.6815869808197021
Iteration 9: train_loss 1.7040479183197021
Iteration 10: train_loss 1.744903802871704
Iteration 11: train_loss 1.7630685567855835
Iteration 12: train_loss 1.7165910005569458
Iteration 13: train_loss 1.6904100179672241
Iteration 14: train_loss 1.705473780632019
Iteration 15: train_loss 1.7653130292892456
Iteration 16: train_loss 1.6935391426086426
Iteration 17: train_loss 1.698323130607605
Iteration 18: train_loss 1.6678578853607178
Iteration 19: train_loss 1.7222957611083984
Iteration 20: train_loss 1.7099047899246216
Iteration 21: train_loss 1.69058358669281
Iteration 22: train_loss 1.7238980531692505
Iteration 23: train_loss 1.7532384395599365
Iteration 24: train_loss 1.690454363822937
Iteration 25: train_loss 1.6884492635726929
Iteration 26: train_loss 1.7437057495117188
Iteration 27: train_loss 1.752549171447754
Iteration 28: train_loss 1.7158141136169434
Iteration 29: train_loss 1.7245240211486816
Iteration 30: train_loss 1.6561191082000732
Iteration 31: train_loss 1.7367888689041138
Iteration 32: train_loss 1.694472312927246
Iteration 33: train_loss 1.6959617137908936
Iteration 34: train_loss 1.765161156654358
Iteration 35: train_loss 1.7391303777694702
Iteration 36: train_loss 1.7099254131317139
Iteration 37: train_loss 1.6643693447113037
Iteration 38: train_loss 1.7152717113494873
Iteration 39: train_loss 1.7135316133499146
Iteration 40: train_loss 1.7033698558807373
Iteration 41: train_loss 1.689379334449768
Iteration 42: train_loss 1.64304780960083
Iteration 43: train_loss 1.6606959104537964
Iteration 44: train_loss 1.7082817554473877
Iteration 45: train_loss 1.6216031312942505
Iteration 46: train_loss 1.6718708276748657
Iteration 47: train_loss 1.6898729801177979
Iteration 48: train_loss 1.6787227392196655
Iteration 49: train_loss 1.6715562343597412
Iteration 50: train_loss 1.6684688329696655
Iteration 51: train_loss 1.7801941633224487
Iteration 52: train_loss 1.7361817359924316
Iteration 53: train_loss 1.7479627132415771
Iteration 54: train_loss 1.7487496137619019
Iteration 55: train_loss 1.7625641822814941
Iteration 56: train_loss 1.8575530052185059
Iteration 57: train_loss 1.773723840713501
Iteration 58: train_loss 1.8167219161987305
Iteration 59: train_loss 1.6934278011322021
Iteration 60: train_loss 1.700656533241272
Iteration 61: train_loss 1.7338650226593018
Iteration 62: train_loss 1.7735319137573242
Iteration 63: train_loss 1.7066116333007812
Iteration 64: train_loss 1.684363842010498
Iteration 65: train_loss 1.6630020141601562
Iteration 66: train_loss 1.690405011177063
Iteration 67: train_loss 1.7396142482757568
Iteration 68: train_loss 1.7123576402664185
Iteration 69: train_loss 1.706128716468811
Iteration 70: train_loss 1.7174972295761108
Iteration 71: train_loss 1.6608549356460571
Iteration 72: train_loss 1.7060563564300537
Iteration 73: train_loss 1.7107584476470947
Iteration 74: train_loss 1.7105227708816528
Iteration 75: train_loss 1.6386356353759766
Iteration 76: train_loss 1.8006365299224854
Iteration 77: train_loss 1.7525029182434082
Iteration 78: train_loss 1.718641996383667
Iteration 79: train_loss 1.7312647104263306
Iteration 80: train_loss 1.6826579570770264
Iteration 81: train_loss 1.7366454601287842
Iteration 82: train_loss 1.7286776304244995
Iteration 83: train_loss 1.6982144117355347
Iteration 84: train_loss 1.7940425872802734
Iteration 85: train_loss 1.7775230407714844
Iteration 86: train_loss 1.7020204067230225
Iteration 87: train_loss 1.736943006515503
Iteration 88: train_loss 1.6964657306671143
Iteration 89: train_loss 1.6831291913986206
Iteration 90: train_loss 1.84389066696167
Iteration 91: train_loss 1.7160791158676147
Iteration 92: train_loss 1.7121860980987549
Iteration 93: train_loss 1.678600788116455
Iteration 94: train_loss 1.677689790725708
Iteration 95: train_loss 1.6840572357177734
Iteration 96: train_loss 1.8142454624176025
Iteration 97: train_loss 1.7389037609100342
Iteration 98: train_loss 1.7668912410736084
Iteration 99: train_loss 1.7041434049606323
Iteration 100: train_loss 1.763417363166809
Iteration 101: train_loss 1.7768386602401733
Iteration 102: train_loss 1.7752317190170288
Iteration 103: train_loss 1.7244179248809814
Iteration 104: train_loss 1.6877766847610474
Iteration 105: train_loss 1.7257782220840454
Iteration 106: train_loss 1.7712422609329224
Iteration 107: train_loss 1.768446683883667
Iteration 108: train_loss 1.639790415763855
Iteration 109: train_loss 1.7413268089294434
Iteration 110: train_loss 1.7181957960128784
Iteration 111: train_loss 1.7257648706436157
Iteration 112: train_loss 1.7076677083969116
Iteration 113: train_loss 1.782252311706543
Iteration 114: train_loss 1.6812317371368408
Iteration 115: train_loss 1.7379783391952515
Iteration 116: train_loss 1.7543957233428955
Iteration 117: train_loss 1.7789080142974854
Iteration 118: train_loss 1.6618471145629883
Iteration 119: train_loss 1.7729185819625854
Iteration 120: train_loss 1.7432247400283813
Iteration 121: train_loss 1.7698153257369995
Iteration 122: train_loss 1.751408338546753
Iteration 123: train_loss 1.7649627923965454
Iteration 124: train_loss 1.7884119749069214
Iteration 125: train_loss 1.7694165706634521
Iteration 126: train_loss 1.7559826374053955
Iteration 127: train_loss 1.7261861562728882
Iteration 128: train_loss 1.7645751237869263
Iteration 129: train_loss 1.7272454500198364
Iteration 130: train_loss 1.7203984260559082
Iteration 131: train_loss 1.7310373783111572
Iteration 132: train_loss 1.766893982887268
Iteration 133: train_loss 1.6891460418701172
Iteration 134: train_loss 1.7580463886260986
Iteration 135: train_loss 1.7160457372665405
Iteration 136: train_loss 1.816249132156372
Iteration 137: train_loss 1.7455390691757202
Iteration 138: train_loss 1.6882386207580566
Iteration 139: train_loss 1.746720552444458
Iteration 140: train_loss 1.657809853553772
Iteration 141: train_loss 1.681074857711792
Iteration 142: train_loss 1.7071168422698975
Iteration 143: train_loss 1.7542980909347534
Iteration 144: train_loss 1.7066435813903809
Iteration 145: train_loss 1.6917452812194824
Iteration 146: train_loss 1.746969223022461
Iteration 147: train_loss 1.652294397354126
Iteration 148: train_loss 1.761236548423767
Iteration 149: train_loss 1.7383184432983398
Iteration 150: train_loss 1.789954662322998
Iteration 151: train_loss 1.75169837474823
Iteration 152: train_loss 1.7779035568237305
Iteration 153: train_loss 1.6791330575942993
Iteration 154: train_loss 1.7608917951583862
Iteration 155: train_loss 1.8519961833953857
Iteration 156: train_loss 1.738329529762268
Iteration 157: train_loss 1.7595309019088745
Iteration 158: train_loss 1.7078816890716553
Iteration 159: train_loss 1.770031213760376
Iteration 160: train_loss 1.7831257581710815
Iteration 161: train_loss 1.7926194667816162
Iteration 162: train_loss 1.7701606750488281
Iteration 163: train_loss 1.7626879215240479
Iteration 164: train_loss 1.7320082187652588
Iteration 165: train_loss 1.742371678352356
Iteration 166: train_loss 1.7623125314712524
Iteration 167: train_loss 1.6935279369354248
Iteration 168: train_loss 1.802327036857605
Iteration 169: train_loss 1.7180005311965942
Iteration 170: train_loss 1.7208809852600098
Iteration 171: train_loss 1.752166509628296
Iteration 172: train_loss 1.7889671325683594
Iteration 173: train_loss 1.7484084367752075
Iteration 174: train_loss 1.7463352680206299
Iteration 175: train_loss 1.7442470788955688
Iteration 176: train_loss 1.674709677696228
Iteration 177: train_loss 1.7963770627975464
Epoch 45: train_avg_loss 1.7262162165453205 eval_avg_acc: 0.3062554454592015 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:18:59] [32mIntermediate result: 0.3062554454592015  (Index 44)[0m
================Epoch: 46================
Iteration 1: train_loss 1.6575287580490112
Iteration 2: train_loss 1.6954971551895142
Iteration 3: train_loss 1.7251616716384888
Iteration 4: train_loss 1.7240217924118042
Iteration 5: train_loss 1.6554635763168335
Iteration 6: train_loss 1.696713924407959
Iteration 7: train_loss 1.6678297519683838
Iteration 8: train_loss 1.7136609554290771
Iteration 9: train_loss 1.6206517219543457
Iteration 10: train_loss 1.7021267414093018
Iteration 11: train_loss 1.6574333906173706
Iteration 12: train_loss 1.6608555316925049
Iteration 13: train_loss 1.6589690446853638
Iteration 14: train_loss 1.7215672731399536
Iteration 15: train_loss 1.6166568994522095
Iteration 16: train_loss 1.7530633211135864
Iteration 17: train_loss 1.7204798460006714
Iteration 18: train_loss 1.7046717405319214
Iteration 19: train_loss 1.6841351985931396
Iteration 20: train_loss 1.7208998203277588
Iteration 21: train_loss 1.7011574506759644
Iteration 22: train_loss 1.6448315382003784
Iteration 23: train_loss 1.7069106101989746
Iteration 24: train_loss 1.7323545217514038
Iteration 25: train_loss 1.754565954208374
Iteration 26: train_loss 1.7526812553405762
Iteration 27: train_loss 1.7009005546569824
Iteration 28: train_loss 1.7496134042739868
Iteration 29: train_loss 1.688649296760559
Iteration 30: train_loss 1.6728767156600952
Iteration 31: train_loss 1.7020578384399414
Iteration 32: train_loss 1.7069722414016724
Iteration 33: train_loss 1.7313405275344849
Iteration 34: train_loss 1.627296805381775
Iteration 35: train_loss 1.6233876943588257
Iteration 36: train_loss 1.6399235725402832
Iteration 37: train_loss 1.6923121213912964
Iteration 38: train_loss 1.6592260599136353
Iteration 39: train_loss 1.6571284532546997
Iteration 40: train_loss 1.6939103603363037
Iteration 41: train_loss 1.7207533121109009
Iteration 42: train_loss 1.7655858993530273
Iteration 43: train_loss 1.7690826654434204
Iteration 44: train_loss 1.7193461656570435
Iteration 45: train_loss 1.7478764057159424
Iteration 46: train_loss 1.676008701324463
Iteration 47: train_loss 1.663956642150879
Iteration 48: train_loss 1.6225448846817017
Iteration 49: train_loss 1.679913878440857
Iteration 50: train_loss 1.7408522367477417
Iteration 51: train_loss 1.7045385837554932
Iteration 52: train_loss 1.7087029218673706
Iteration 53: train_loss 1.6861600875854492
Iteration 54: train_loss 1.766061544418335
Iteration 55: train_loss 1.6905921697616577
Iteration 56: train_loss 1.6995943784713745
Iteration 57: train_loss 1.7591842412948608
Iteration 58: train_loss 1.6970384120941162
Iteration 59: train_loss 1.614231824874878
Iteration 60: train_loss 1.7340275049209595
Iteration 61: train_loss 1.7183301448822021
Iteration 62: train_loss 1.6325241327285767
Iteration 63: train_loss 1.706411361694336
Iteration 64: train_loss 1.6563283205032349
Iteration 65: train_loss 1.6808984279632568
Iteration 66: train_loss 1.7123299837112427
Iteration 67: train_loss 1.6809443235397339
Iteration 68: train_loss 1.7333663702011108
Iteration 69: train_loss 1.7356560230255127
Iteration 70: train_loss 1.673793077468872
Iteration 71: train_loss 1.7052314281463623
Iteration 72: train_loss 1.728291392326355
Iteration 73: train_loss 1.7470229864120483
Iteration 74: train_loss 1.8040834665298462
Iteration 75: train_loss 1.6994174718856812
Iteration 76: train_loss 1.7286345958709717
Iteration 77: train_loss 1.7129892110824585
Iteration 78: train_loss 1.786454677581787
Iteration 79: train_loss 1.7090513706207275
Iteration 80: train_loss 1.741627812385559
Iteration 81: train_loss 1.7422504425048828
Iteration 82: train_loss 1.7696751356124878
Iteration 83: train_loss 1.7123509645462036
Iteration 84: train_loss 1.8120460510253906
Iteration 85: train_loss 1.7644579410552979
Iteration 86: train_loss 1.682235598564148
Iteration 87: train_loss 1.6953972578048706
Iteration 88: train_loss 1.7869677543640137
Iteration 89: train_loss 1.7016491889953613
Iteration 90: train_loss 1.7801507711410522
Iteration 91: train_loss 1.7222299575805664
Iteration 92: train_loss 1.7351866960525513
Iteration 93: train_loss 1.6187083721160889
Iteration 94: train_loss 1.775802731513977
Iteration 95: train_loss 1.7544349431991577
Iteration 96: train_loss 1.6940255165100098
Iteration 97: train_loss 1.6693096160888672
Iteration 98: train_loss 1.6782646179199219
Iteration 99: train_loss 1.747051477432251
Iteration 100: train_loss 1.7580714225769043
Iteration 101: train_loss 1.6609514951705933
Iteration 102: train_loss 1.6971027851104736
Iteration 103: train_loss 1.7141879796981812
Iteration 104: train_loss 1.7436158657073975
Iteration 105: train_loss 1.699001669883728
Iteration 106: train_loss 1.6645135879516602
Iteration 107: train_loss 1.680822491645813
Iteration 108: train_loss 1.7040438652038574
Iteration 109: train_loss 1.7102490663528442
Iteration 110: train_loss 1.7541297674179077
Iteration 111: train_loss 1.6791726350784302
Iteration 112: train_loss 1.7238385677337646
Iteration 113: train_loss 1.7157495021820068
Iteration 114: train_loss 1.7224539518356323
Iteration 115: train_loss 1.7880748510360718
Iteration 116: train_loss 1.7964192628860474
Iteration 117: train_loss 1.6532034873962402
Iteration 118: train_loss 1.7744145393371582
Iteration 119: train_loss 1.7863185405731201
Iteration 120: train_loss 1.714638113975525
Iteration 121: train_loss 1.7581253051757812
Iteration 122: train_loss 1.7158762216567993
Iteration 123: train_loss 1.8775193691253662
Iteration 124: train_loss 1.7790679931640625
Iteration 125: train_loss 1.764383316040039
Iteration 126: train_loss 1.6642436981201172
Iteration 127: train_loss 1.7915667295455933
Iteration 128: train_loss 1.7179369926452637
Iteration 129: train_loss 1.696384072303772
Iteration 130: train_loss 1.6881271600723267
Iteration 131: train_loss 1.66321861743927
Iteration 132: train_loss 1.7597694396972656
Iteration 133: train_loss 1.6602280139923096
Iteration 134: train_loss 1.7061755657196045
Iteration 135: train_loss 1.7671353816986084
Iteration 136: train_loss 1.7153713703155518
Iteration 137: train_loss 1.8138434886932373
Iteration 138: train_loss 1.7418732643127441
Iteration 139: train_loss 1.648671269416809
Iteration 140: train_loss 1.71051824092865
Iteration 141: train_loss 1.7100193500518799
Iteration 142: train_loss 1.8116471767425537
Iteration 143: train_loss 1.7419754266738892
Iteration 144: train_loss 1.6890331506729126
Iteration 145: train_loss 1.7145593166351318
Iteration 146: train_loss 1.7333259582519531
Iteration 147: train_loss 1.667445182800293
Iteration 148: train_loss 1.6461256742477417
Iteration 149: train_loss 1.748679757118225
Iteration 150: train_loss 1.7279036045074463
Iteration 151: train_loss 1.722974181175232
Iteration 152: train_loss 1.7909327745437622
Iteration 153: train_loss 1.7470407485961914
Iteration 154: train_loss 1.7653473615646362
Iteration 155: train_loss 1.719461441040039
Iteration 156: train_loss 1.8115910291671753
Iteration 157: train_loss 1.7399518489837646
Iteration 158: train_loss 1.7495967149734497
Iteration 159: train_loss 1.7531814575195312
Iteration 160: train_loss 1.7163619995117188
Iteration 161: train_loss 1.7280046939849854
Iteration 162: train_loss 1.7079105377197266
Iteration 163: train_loss 1.7343976497650146
Iteration 164: train_loss 1.6405633687973022
Iteration 165: train_loss 1.7533468008041382
Iteration 166: train_loss 1.7540282011032104
Iteration 167: train_loss 1.6934682130813599
Iteration 168: train_loss 1.7116036415100098
Iteration 169: train_loss 1.746303915977478
Iteration 170: train_loss 1.670614242553711
Iteration 171: train_loss 1.7312172651290894
Iteration 172: train_loss 1.7772830724716187
Iteration 173: train_loss 1.7729238271713257
Iteration 174: train_loss 1.7049633264541626
Iteration 175: train_loss 1.7898927927017212
Iteration 176: train_loss 1.8298760652542114
Iteration 177: train_loss 1.740588903427124
Epoch 46: train_avg_loss 1.7167924790732605 eval_avg_acc: 0.3219140266689314 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:19:41] [32mIntermediate result: 0.3219140266689314  (Index 45)[0m
================Epoch: 47================
Iteration 1: train_loss 1.7109485864639282
Iteration 2: train_loss 1.6729822158813477
Iteration 3: train_loss 1.633840560913086
Iteration 4: train_loss 1.690930962562561
Iteration 5: train_loss 1.7324990034103394
Iteration 6: train_loss 1.6351391077041626
Iteration 7: train_loss 1.6629074811935425
Iteration 8: train_loss 1.748992681503296
Iteration 9: train_loss 1.732622742652893
Iteration 10: train_loss 1.6645828485488892
Iteration 11: train_loss 1.6790400743484497
Iteration 12: train_loss 1.6533958911895752
Iteration 13: train_loss 1.6829270124435425
Iteration 14: train_loss 1.7344123125076294
Iteration 15: train_loss 1.6695655584335327
Iteration 16: train_loss 1.7019206285476685
Iteration 17: train_loss 1.6479501724243164
Iteration 18: train_loss 1.7162073850631714
Iteration 19: train_loss 1.7727720737457275
Iteration 20: train_loss 1.7141718864440918
Iteration 21: train_loss 1.652841567993164
Iteration 22: train_loss 1.7171416282653809
Iteration 23: train_loss 1.733994960784912
Iteration 24: train_loss 1.7836904525756836
Iteration 25: train_loss 1.6876815557479858
Iteration 26: train_loss 1.6955145597457886
Iteration 27: train_loss 1.6627867221832275
Iteration 28: train_loss 1.5992825031280518
Iteration 29: train_loss 1.6992347240447998
Iteration 30: train_loss 1.6803361177444458
Iteration 31: train_loss 1.7877278327941895
Iteration 32: train_loss 1.7176451683044434
Iteration 33: train_loss 1.6890043020248413
Iteration 34: train_loss 1.6879240274429321
Iteration 35: train_loss 1.6620084047317505
Iteration 36: train_loss 1.6778484582901
Iteration 37: train_loss 1.7267814874649048
Iteration 38: train_loss 1.6771951913833618
Iteration 39: train_loss 1.684430480003357
Iteration 40: train_loss 1.6669230461120605
Iteration 41: train_loss 1.6861929893493652
Iteration 42: train_loss 1.7068121433258057
Iteration 43: train_loss 1.6539978981018066
Iteration 44: train_loss 1.666050672531128
Iteration 45: train_loss 1.7608603239059448
Iteration 46: train_loss 1.6833151578903198
Iteration 47: train_loss 1.666046142578125
Iteration 48: train_loss 1.6390053033828735
Iteration 49: train_loss 1.731014609336853
Iteration 50: train_loss 1.6910576820373535
Iteration 51: train_loss 1.6555029153823853
Iteration 52: train_loss 1.6688019037246704
Iteration 53: train_loss 1.6549612283706665
Iteration 54: train_loss 1.6900640726089478
Iteration 55: train_loss 1.676209568977356
Iteration 56: train_loss 1.6505285501480103
Iteration 57: train_loss 1.7089754343032837
Iteration 58: train_loss 1.6551434993743896
Iteration 59: train_loss 1.6785893440246582
Iteration 60: train_loss 1.6941615343093872
Iteration 61: train_loss 1.7089483737945557
Iteration 62: train_loss 1.7662203311920166
Iteration 63: train_loss 1.695914626121521
Iteration 64: train_loss 1.7070002555847168
Iteration 65: train_loss 1.6644399166107178
Iteration 66: train_loss 1.6835620403289795
Iteration 67: train_loss 1.7242733240127563
Iteration 68: train_loss 1.685692548751831
Iteration 69: train_loss 1.690589427947998
Iteration 70: train_loss 1.7527703046798706
Iteration 71: train_loss 1.7133535146713257
Iteration 72: train_loss 1.7244741916656494
Iteration 73: train_loss 1.6977853775024414
Iteration 74: train_loss 1.7159868478775024
Iteration 75: train_loss 1.756801724433899
Iteration 76: train_loss 1.729507327079773
Iteration 77: train_loss 1.7449568510055542
Iteration 78: train_loss 1.7652294635772705
Iteration 79: train_loss 1.683929681777954
Iteration 80: train_loss 1.740658164024353
Iteration 81: train_loss 1.7124149799346924
Iteration 82: train_loss 1.6820855140686035
Iteration 83: train_loss 1.7053477764129639
Iteration 84: train_loss 1.673869013786316
Iteration 85: train_loss 1.6942812204360962
Iteration 86: train_loss 1.6123765707015991
Iteration 87: train_loss 1.661426067352295
Iteration 88: train_loss 1.6122528314590454
Iteration 89: train_loss 1.741382122039795
Iteration 90: train_loss 1.7736276388168335
Iteration 91: train_loss 1.7324174642562866
Iteration 92: train_loss 1.6574938297271729
Iteration 93: train_loss 1.7091106176376343
Iteration 94: train_loss 1.740535855293274
Iteration 95: train_loss 1.6689921617507935
Iteration 96: train_loss 1.7529178857803345
Iteration 97: train_loss 1.6643229722976685
Iteration 98: train_loss 1.6773920059204102
Iteration 99: train_loss 1.708480954170227
Iteration 100: train_loss 1.7563929557800293
Iteration 101: train_loss 1.7046129703521729
Iteration 102: train_loss 1.790193796157837
Iteration 103: train_loss 1.7149561643600464
Iteration 104: train_loss 1.6912168264389038
Iteration 105: train_loss 1.7369548082351685
Iteration 106: train_loss 1.7466228008270264
Iteration 107: train_loss 1.6992542743682861
Iteration 108: train_loss 1.7291628122329712
Iteration 109: train_loss 1.681941032409668
Iteration 110: train_loss 1.7213966846466064
Iteration 111: train_loss 1.7225226163864136
Iteration 112: train_loss 1.7114883661270142
Iteration 113: train_loss 1.7160753011703491
Iteration 114: train_loss 1.7254747152328491
Iteration 115: train_loss 1.7663822174072266
Iteration 116: train_loss 1.7190238237380981
Iteration 117: train_loss 1.6744797229766846
Iteration 118: train_loss 1.6807507276535034
Iteration 119: train_loss 1.6650819778442383
Iteration 120: train_loss 1.698056697845459
Iteration 121: train_loss 1.7666757106781006
Iteration 122: train_loss 1.7250474691390991
Iteration 123: train_loss 1.784766674041748
Iteration 124: train_loss 1.8316305875778198
Iteration 125: train_loss 1.74543297290802
Iteration 126: train_loss 1.750235915184021
Iteration 127: train_loss 1.7027508020401
Iteration 128: train_loss 1.7327020168304443
Iteration 129: train_loss 1.7102022171020508
Iteration 130: train_loss 1.730366587638855
Iteration 131: train_loss 1.7549667358398438
Iteration 132: train_loss 1.7550270557403564
Iteration 133: train_loss 1.7232203483581543
Iteration 134: train_loss 1.6924470663070679
Iteration 135: train_loss 1.7575126886367798
Iteration 136: train_loss 1.7732841968536377
Iteration 137: train_loss 1.711960792541504
Iteration 138: train_loss 1.6725667715072632
Iteration 139: train_loss 1.6882609128952026
Iteration 140: train_loss 1.6955868005752563
Iteration 141: train_loss 1.7980948686599731
Iteration 142: train_loss 1.6748311519622803
Iteration 143: train_loss 1.763269305229187
Iteration 144: train_loss 1.6938674449920654
Iteration 145: train_loss 1.696713924407959
Iteration 146: train_loss 1.7314538955688477
Iteration 147: train_loss 1.7083089351654053
Iteration 148: train_loss 1.7392324209213257
Iteration 149: train_loss 1.7469873428344727
Iteration 150: train_loss 1.7470403909683228
Iteration 151: train_loss 1.6869078874588013
Iteration 152: train_loss 1.7910505533218384
Iteration 153: train_loss 1.754316806793213
Iteration 154: train_loss 1.7236809730529785
Iteration 155: train_loss 1.7820543050765991
Iteration 156: train_loss 1.760624885559082
Iteration 157: train_loss 1.7516485452651978
Iteration 158: train_loss 1.6694576740264893
Iteration 159: train_loss 1.6863595247268677
Iteration 160: train_loss 1.7514328956604004
Iteration 161: train_loss 1.6941217184066772
Iteration 162: train_loss 1.7492094039916992
Iteration 163: train_loss 1.7433581352233887
Iteration 164: train_loss 1.680637240409851
Iteration 165: train_loss 1.7285535335540771
Iteration 166: train_loss 1.7029454708099365
Iteration 167: train_loss 1.7155303955078125
Iteration 168: train_loss 1.7188735008239746
Iteration 169: train_loss 1.7396420240402222
Iteration 170: train_loss 1.6606810092926025
Iteration 171: train_loss 1.8006221055984497
Iteration 172: train_loss 1.714605450630188
Iteration 173: train_loss 1.708998441696167
Iteration 174: train_loss 1.7170355319976807
Iteration 175: train_loss 1.7236651182174683
Iteration 176: train_loss 1.745898723602295
Iteration 177: train_loss 1.6008144617080688
Epoch 47: train_avg_loss 1.7087973261957115 eval_avg_acc: 0.34103802756101886 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:20:16] [32mIntermediate result: 0.34103802756101886  (Index 46)[0m
================Epoch: 48================
Iteration 1: train_loss 1.6360918283462524
Iteration 2: train_loss 1.7062970399856567
Iteration 3: train_loss 1.7144685983657837
Iteration 4: train_loss 1.646112084388733
Iteration 5: train_loss 1.655559778213501
Iteration 6: train_loss 1.7032474279403687
Iteration 7: train_loss 1.7225230932235718
Iteration 8: train_loss 1.6634732484817505
Iteration 9: train_loss 1.6999967098236084
Iteration 10: train_loss 1.6598097085952759
Iteration 11: train_loss 1.7140721082687378
Iteration 12: train_loss 1.604762077331543
Iteration 13: train_loss 1.7695932388305664
Iteration 14: train_loss 1.757260799407959
Iteration 15: train_loss 1.732367992401123
Iteration 16: train_loss 1.7105321884155273
Iteration 17: train_loss 1.6268364191055298
Iteration 18: train_loss 1.686521291732788
Iteration 19: train_loss 1.7375696897506714
Iteration 20: train_loss 1.7069371938705444
Iteration 21: train_loss 1.644113540649414
Iteration 22: train_loss 1.739145040512085
Iteration 23: train_loss 1.6731853485107422
Iteration 24: train_loss 1.6729530096054077
Iteration 25: train_loss 1.680376410484314
Iteration 26: train_loss 1.6450814008712769
Iteration 27: train_loss 1.7319602966308594
Iteration 28: train_loss 1.6139215230941772
Iteration 29: train_loss 1.7226589918136597
Iteration 30: train_loss 1.617748737335205
Iteration 31: train_loss 1.6569699048995972
Iteration 32: train_loss 1.6451635360717773
Iteration 33: train_loss 1.7310264110565186
Iteration 34: train_loss 1.6485824584960938
Iteration 35: train_loss 1.700481653213501
Iteration 36: train_loss 1.6837408542633057
Iteration 37: train_loss 1.7095576524734497
Iteration 38: train_loss 1.689747929573059
Iteration 39: train_loss 1.6870709657669067
Iteration 40: train_loss 1.6412173509597778
Iteration 41: train_loss 1.7430531978607178
Iteration 42: train_loss 1.700845718383789
Iteration 43: train_loss 1.6884260177612305
Iteration 44: train_loss 1.6094552278518677
Iteration 45: train_loss 1.7077535390853882
Iteration 46: train_loss 1.6770987510681152
Iteration 47: train_loss 1.6848758459091187
Iteration 48: train_loss 1.7064181566238403
Iteration 49: train_loss 1.7531607151031494
Iteration 50: train_loss 1.6153031587600708
Iteration 51: train_loss 1.6441149711608887
Iteration 52: train_loss 1.6148402690887451
Iteration 53: train_loss 1.6149225234985352
Iteration 54: train_loss 1.6344999074935913
Iteration 55: train_loss 1.7265146970748901
Iteration 56: train_loss 1.6475354433059692
Iteration 57: train_loss 1.6949883699417114
Iteration 58: train_loss 1.649217963218689
Iteration 59: train_loss 1.6771752834320068
Iteration 60: train_loss 1.6653685569763184
Iteration 61: train_loss 1.6890053749084473
Iteration 62: train_loss 1.6879504919052124
Iteration 63: train_loss 1.738875150680542
Iteration 64: train_loss 1.6951451301574707
Iteration 65: train_loss 1.7276291847229004
Iteration 66: train_loss 1.6912317276000977
Iteration 67: train_loss 1.7137224674224854
Iteration 68: train_loss 1.7203748226165771
Iteration 69: train_loss 1.6619731187820435
Iteration 70: train_loss 1.7318426370620728
Iteration 71: train_loss 1.6629222631454468
Iteration 72: train_loss 1.7093100547790527
Iteration 73: train_loss 1.6151630878448486
Iteration 74: train_loss 1.6897369623184204
Iteration 75: train_loss 1.7073583602905273
Iteration 76: train_loss 1.6734702587127686
Iteration 77: train_loss 1.744323492050171
Iteration 78: train_loss 1.6523622274398804
Iteration 79: train_loss 1.6735597848892212
Iteration 80: train_loss 1.6876437664031982
Iteration 81: train_loss 1.7102766036987305
Iteration 82: train_loss 1.6193504333496094
Iteration 83: train_loss 1.6758817434310913
Iteration 84: train_loss 1.7831122875213623
Iteration 85: train_loss 1.6557245254516602
Iteration 86: train_loss 1.7334898710250854
Iteration 87: train_loss 1.6897639036178589
Iteration 88: train_loss 1.641022801399231
Iteration 89: train_loss 1.6802241802215576
Iteration 90: train_loss 1.6965938806533813
Iteration 91: train_loss 1.699195146560669
Iteration 92: train_loss 1.6422525644302368
Iteration 93: train_loss 1.614090919494629
Iteration 94: train_loss 1.6422860622406006
Iteration 95: train_loss 1.677861213684082
Iteration 96: train_loss 1.725387692451477
Iteration 97: train_loss 1.6800302267074585
Iteration 98: train_loss 1.7366106510162354
Iteration 99: train_loss 1.7301968336105347
Iteration 100: train_loss 1.7366549968719482
Iteration 101: train_loss 1.6579525470733643
Iteration 102: train_loss 1.7180429697036743
Iteration 103: train_loss 1.7432812452316284
Iteration 104: train_loss 1.6780670881271362
Iteration 105: train_loss 1.7543706893920898
Iteration 106: train_loss 1.7096614837646484
Iteration 107: train_loss 1.7018287181854248
Iteration 108: train_loss 1.703966498374939
Iteration 109: train_loss 1.713462471961975
Iteration 110: train_loss 1.8021951913833618
Iteration 111: train_loss 1.7218846082687378
Iteration 112: train_loss 1.760300636291504
Iteration 113: train_loss 1.6419252157211304
Iteration 114: train_loss 1.6951701641082764
Iteration 115: train_loss 1.6852774620056152
Iteration 116: train_loss 1.6971545219421387
Iteration 117: train_loss 1.7525097131729126
Iteration 118: train_loss 1.6768327951431274
Iteration 119: train_loss 1.6519066095352173
Iteration 120: train_loss 1.77213454246521
Iteration 121: train_loss 1.7122933864593506
Iteration 122: train_loss 1.6574424505233765
Iteration 123: train_loss 1.6734416484832764
Iteration 124: train_loss 1.6310323476791382
Iteration 125: train_loss 1.694640040397644
Iteration 126: train_loss 1.7230689525604248
Iteration 127: train_loss 1.679468035697937
Iteration 128: train_loss 1.687690258026123
Iteration 129: train_loss 1.6765726804733276
Iteration 130: train_loss 1.6913180351257324
Iteration 131: train_loss 1.6508442163467407
Iteration 132: train_loss 1.7200874090194702
Iteration 133: train_loss 1.7800174951553345
Iteration 134: train_loss 1.5872924327850342
Iteration 135: train_loss 1.729676604270935
Iteration 136: train_loss 1.6608387231826782
Iteration 137: train_loss 1.6775085926055908
Iteration 138: train_loss 1.6412466764450073
Iteration 139: train_loss 1.7823816537857056
Iteration 140: train_loss 1.684072494506836
Iteration 141: train_loss 1.7186431884765625
Iteration 142: train_loss 1.7413960695266724
Iteration 143: train_loss 1.6835299730300903
Iteration 144: train_loss 1.7343571186065674
Iteration 145: train_loss 1.6503382921218872
Iteration 146: train_loss 1.7106376886367798
Iteration 147: train_loss 1.6650232076644897
Iteration 148: train_loss 1.7551243305206299
Iteration 149: train_loss 1.7208436727523804
Iteration 150: train_loss 1.7538703680038452
Iteration 151: train_loss 1.683351993560791
Iteration 152: train_loss 1.7882106304168701
Iteration 153: train_loss 1.6738356351852417
Iteration 154: train_loss 1.7598426342010498
Iteration 155: train_loss 1.7363920211791992
Iteration 156: train_loss 1.6953074932098389
Iteration 157: train_loss 1.622958779335022
Iteration 158: train_loss 1.7169394493103027
Iteration 159: train_loss 1.683356523513794
Iteration 160: train_loss 1.715462327003479
Iteration 161: train_loss 1.7495241165161133
Iteration 162: train_loss 1.7130286693572998
Iteration 163: train_loss 1.6678673028945923
Iteration 164: train_loss 1.764974594116211
Iteration 165: train_loss 1.7247745990753174
Iteration 166: train_loss 1.7629541158676147
Iteration 167: train_loss 1.7627023458480835
Iteration 168: train_loss 1.776082158088684
Iteration 169: train_loss 1.7197831869125366
Iteration 170: train_loss 1.7130589485168457
Iteration 171: train_loss 1.7238397598266602
Iteration 172: train_loss 1.7122136354446411
Iteration 173: train_loss 1.7526401281356812
Iteration 174: train_loss 1.7256220579147339
Iteration 175: train_loss 1.7891427278518677
Iteration 176: train_loss 1.7684266567230225
Iteration 177: train_loss 1.7756983041763306
Epoch 48: train_avg_loss 1.6964888404318168 eval_avg_acc: 0.3236488193688592 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:20:54] [32mIntermediate result: 0.3236488193688592  (Index 47)[0m
================Epoch: 49================
Iteration 1: train_loss 1.631361961364746
Iteration 2: train_loss 1.6559828519821167
Iteration 3: train_loss 1.605910301208496
Iteration 4: train_loss 1.8019591569900513
Iteration 5: train_loss 1.701570987701416
Iteration 6: train_loss 1.6168088912963867
Iteration 7: train_loss 1.6723562479019165
Iteration 8: train_loss 1.6275972127914429
Iteration 9: train_loss 1.6695003509521484
Iteration 10: train_loss 1.6815565824508667
Iteration 11: train_loss 1.6967463493347168
Iteration 12: train_loss 1.6753491163253784
Iteration 13: train_loss 1.6743617057800293
Iteration 14: train_loss 1.6809782981872559
Iteration 15: train_loss 1.628592848777771
Iteration 16: train_loss 1.7143094539642334
Iteration 17: train_loss 1.6819943189620972
Iteration 18: train_loss 1.75126051902771
Iteration 19: train_loss 1.6973981857299805
Iteration 20: train_loss 1.7043546438217163
Iteration 21: train_loss 1.6548329591751099
Iteration 22: train_loss 1.6903417110443115
Iteration 23: train_loss 1.7214293479919434
Iteration 24: train_loss 1.6478840112686157
Iteration 25: train_loss 1.6683515310287476
Iteration 26: train_loss 1.7141786813735962
Iteration 27: train_loss 1.5917904376983643
Iteration 28: train_loss 1.6781268119812012
Iteration 29: train_loss 1.6560996770858765
Iteration 30: train_loss 1.6239697933197021
Iteration 31: train_loss 1.6861963272094727
Iteration 32: train_loss 1.6525055170059204
Iteration 33: train_loss 1.7072031497955322
Iteration 34: train_loss 1.713395118713379
Iteration 35: train_loss 1.679963231086731
Iteration 36: train_loss 1.673593521118164
Iteration 37: train_loss 1.6608227491378784
Iteration 38: train_loss 1.6551533937454224
Iteration 39: train_loss 1.7079589366912842
Iteration 40: train_loss 1.6031607389450073
Iteration 41: train_loss 1.5780868530273438
Iteration 42: train_loss 1.6558558940887451
Iteration 43: train_loss 1.6885536909103394
Iteration 44: train_loss 1.717565894126892
Iteration 45: train_loss 1.708866000175476
Iteration 46: train_loss 1.561815857887268
Iteration 47: train_loss 1.6465840339660645
Iteration 48: train_loss 1.6370353698730469
Iteration 49: train_loss 1.617535948753357
Iteration 50: train_loss 1.7512967586517334
Iteration 51: train_loss 1.6989364624023438
Iteration 52: train_loss 1.7101460695266724
Iteration 53: train_loss 1.7045544385910034
Iteration 54: train_loss 1.6662321090698242
Iteration 55: train_loss 1.7140107154846191
Iteration 56: train_loss 1.7145764827728271
Iteration 57: train_loss 1.655735731124878
Iteration 58: train_loss 1.651971697807312
Iteration 59: train_loss 1.6866377592086792
Iteration 60: train_loss 1.687512755393982
Iteration 61: train_loss 1.6681805849075317
Iteration 62: train_loss 1.6366605758666992
Iteration 63: train_loss 1.7055503129959106
Iteration 64: train_loss 1.7495429515838623
Iteration 65: train_loss 1.6501485109329224
Iteration 66: train_loss 1.656148076057434
Iteration 67: train_loss 1.671128511428833
Iteration 68: train_loss 1.71337890625
Iteration 69: train_loss 1.6903300285339355
Iteration 70: train_loss 1.637070655822754
Iteration 71: train_loss 1.7269898653030396
Iteration 72: train_loss 1.613857626914978
Iteration 73: train_loss 1.6546543836593628
Iteration 74: train_loss 1.580615758895874
Iteration 75: train_loss 1.629994511604309
Iteration 76: train_loss 1.6546926498413086
Iteration 77: train_loss 1.7187656164169312
Iteration 78: train_loss 1.7092344760894775
Iteration 79: train_loss 1.6518871784210205
Iteration 80: train_loss 1.6835534572601318
Iteration 81: train_loss 1.6905114650726318
Iteration 82: train_loss 1.631219744682312
Iteration 83: train_loss 1.7022151947021484
Iteration 84: train_loss 1.6123360395431519
Iteration 85: train_loss 1.7235935926437378
Iteration 86: train_loss 1.7002094984054565
Iteration 87: train_loss 1.7124403715133667
Iteration 88: train_loss 1.7364825010299683
Iteration 89: train_loss 1.7234253883361816
Iteration 90: train_loss 1.6631661653518677
Iteration 91: train_loss 1.7031530141830444
Iteration 92: train_loss 1.7005271911621094
Iteration 93: train_loss 1.7104510068893433
Iteration 94: train_loss 1.7091795206069946
Iteration 95: train_loss 1.6429671049118042
Iteration 96: train_loss 1.695189118385315
Iteration 97: train_loss 1.6605472564697266
Iteration 98: train_loss 1.6202342510223389
Iteration 99: train_loss 1.6967967748641968
Iteration 100: train_loss 1.7034893035888672
Iteration 101: train_loss 1.7238185405731201
Iteration 102: train_loss 1.6217014789581299
Iteration 103: train_loss 1.717715859413147
Iteration 104: train_loss 1.7171837091445923
Iteration 105: train_loss 1.6972965002059937
Iteration 106: train_loss 1.7192466259002686
Iteration 107: train_loss 1.6767158508300781
Iteration 108: train_loss 1.7063685655593872
Iteration 109: train_loss 1.6381340026855469
Iteration 110: train_loss 1.6893773078918457
Iteration 111: train_loss 1.721282958984375
Iteration 112: train_loss 1.6630661487579346
Iteration 113: train_loss 1.6653413772583008
Iteration 114: train_loss 1.6765434741973877
Iteration 115: train_loss 1.64212965965271
Iteration 116: train_loss 1.7285929918289185
Iteration 117: train_loss 1.7251498699188232
Iteration 118: train_loss 1.710541009902954
Iteration 119: train_loss 1.7094531059265137
Iteration 120: train_loss 1.6996220350265503
Iteration 121: train_loss 1.6610119342803955
Iteration 122: train_loss 1.723475456237793
Iteration 123: train_loss 1.6657402515411377
Iteration 124: train_loss 1.7032513618469238
Iteration 125: train_loss 1.7101885080337524
Iteration 126: train_loss 1.6424384117126465
Iteration 127: train_loss 1.7159650325775146
Iteration 128: train_loss 1.692078948020935
Iteration 129: train_loss 1.6936798095703125
Iteration 130: train_loss 1.7348347902297974
Iteration 131: train_loss 1.6784294843673706
Iteration 132: train_loss 1.641722321510315
Iteration 133: train_loss 1.6418637037277222
Iteration 134: train_loss 1.7202130556106567
Iteration 135: train_loss 1.767678141593933
Iteration 136: train_loss 1.6211066246032715
Iteration 137: train_loss 1.6729756593704224
Iteration 138: train_loss 1.6776314973831177
Iteration 139: train_loss 1.6967122554779053
Iteration 140: train_loss 1.7633532285690308
Iteration 141: train_loss 1.6769824028015137
Iteration 142: train_loss 1.6858043670654297
Iteration 143: train_loss 1.6727291345596313
Iteration 144: train_loss 1.6812238693237305
Iteration 145: train_loss 1.7132997512817383
Iteration 146: train_loss 1.7177728414535522
Iteration 147: train_loss 1.7022913694381714
Iteration 148: train_loss 1.653199315071106
Iteration 149: train_loss 1.7424827814102173
Iteration 150: train_loss 1.612494707107544
Iteration 151: train_loss 1.7114129066467285
Iteration 152: train_loss 1.7437872886657715
Iteration 153: train_loss 1.7234307527542114
Iteration 154: train_loss 1.7033034563064575
Iteration 155: train_loss 1.6847598552703857
Iteration 156: train_loss 1.6915695667266846
Iteration 157: train_loss 1.7104263305664062
Iteration 158: train_loss 1.7324652671813965
Iteration 159: train_loss 1.696434736251831
Iteration 160: train_loss 1.7611777782440186
Iteration 161: train_loss 1.7734248638153076
Iteration 162: train_loss 1.685922622680664
Iteration 163: train_loss 1.7173364162445068
Iteration 164: train_loss 1.7185277938842773
Iteration 165: train_loss 1.698001503944397
Iteration 166: train_loss 1.7599045038223267
Iteration 167: train_loss 1.686447262763977
Iteration 168: train_loss 1.683937907218933
Iteration 169: train_loss 1.6833850145339966
Iteration 170: train_loss 1.7039361000061035
Iteration 171: train_loss 1.6764483451843262
Iteration 172: train_loss 1.704350233078003
Iteration 173: train_loss 1.7023789882659912
Iteration 174: train_loss 1.7954022884368896
Iteration 175: train_loss 1.754538655281067
Iteration 176: train_loss 1.7748597860336304
Iteration 177: train_loss 1.7540773153305054
Epoch 49: train_avg_loss 1.6865225814830112 eval_avg_acc: 0.33204476454413295 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:21:32] [32mIntermediate result: 0.33204476454413295  (Index 48)[0m
================Epoch: 50================
Iteration 1: train_loss 1.5848668813705444
Iteration 2: train_loss 1.6318126916885376
Iteration 3: train_loss 1.6542770862579346
Iteration 4: train_loss 1.6079579591751099
Iteration 5: train_loss 1.5978341102600098
Iteration 6: train_loss 1.6449060440063477
Iteration 7: train_loss 1.6741234064102173
Iteration 8: train_loss 1.6662479639053345
Iteration 9: train_loss 1.6156985759735107
Iteration 10: train_loss 1.6580463647842407
Iteration 11: train_loss 1.6283352375030518
Iteration 12: train_loss 1.6608699560165405
Iteration 13: train_loss 1.6383734941482544
Iteration 14: train_loss 1.639848232269287
Iteration 15: train_loss 1.6605894565582275
Iteration 16: train_loss 1.5716356039047241
Iteration 17: train_loss 1.5981298685073853
Iteration 18: train_loss 1.6462355852127075
Iteration 19: train_loss 1.642216682434082
Iteration 20: train_loss 1.6342084407806396
Iteration 21: train_loss 1.6632152795791626
Iteration 22: train_loss 1.6684138774871826
Iteration 23: train_loss 1.6114989519119263
Iteration 24: train_loss 1.7032570838928223
Iteration 25: train_loss 1.6507097482681274
Iteration 26: train_loss 1.7354975938796997
Iteration 27: train_loss 1.6409059762954712
Iteration 28: train_loss 1.5995748043060303
Iteration 29: train_loss 1.6097403764724731
Iteration 30: train_loss 1.6593520641326904
Iteration 31: train_loss 1.6676535606384277
Iteration 32: train_loss 1.671411156654358
Iteration 33: train_loss 1.6588780879974365
Iteration 34: train_loss 1.6508965492248535
Iteration 35: train_loss 1.6485583782196045
Iteration 36: train_loss 1.6405004262924194
Iteration 37: train_loss 1.5855406522750854
Iteration 38: train_loss 1.6621733903884888
Iteration 39: train_loss 1.644364356994629
Iteration 40: train_loss 1.6661232709884644
Iteration 41: train_loss 1.6594356298446655
Iteration 42: train_loss 1.610122561454773
Iteration 43: train_loss 1.6779063940048218
Iteration 44: train_loss 1.6472859382629395
Iteration 45: train_loss 1.6883032321929932
Iteration 46: train_loss 1.6704380512237549
Iteration 47: train_loss 1.6011303663253784
Iteration 48: train_loss 1.6637953519821167
Iteration 49: train_loss 1.6527862548828125
Iteration 50: train_loss 1.664809226989746
Iteration 51: train_loss 1.688154697418213
Iteration 52: train_loss 1.6862921714782715
Iteration 53: train_loss 1.7408121824264526
Iteration 54: train_loss 1.678919792175293
Iteration 55: train_loss 1.6977996826171875
Iteration 56: train_loss 1.700335144996643
Iteration 57: train_loss 1.67409086227417
Iteration 58: train_loss 1.752462387084961
Iteration 59: train_loss 1.6145979166030884
Iteration 60: train_loss 1.7065011262893677
Iteration 61: train_loss 1.6080840826034546
Iteration 62: train_loss 1.6882803440093994
Iteration 63: train_loss 1.6144511699676514
Iteration 64: train_loss 1.6552928686141968
Iteration 65: train_loss 1.7102556228637695
Iteration 66: train_loss 1.6374961137771606
Iteration 67: train_loss 1.7280945777893066
Iteration 68: train_loss 1.6505728960037231
Iteration 69: train_loss 1.6901497840881348
Iteration 70: train_loss 1.668142557144165
Iteration 71: train_loss 1.6301263570785522
Iteration 72: train_loss 1.6635632514953613
Iteration 73: train_loss 1.6370232105255127
Iteration 74: train_loss 1.6557481288909912
Iteration 75: train_loss 1.6843184232711792
Iteration 76: train_loss 1.7207573652267456
Iteration 77: train_loss 1.7074015140533447
Iteration 78: train_loss 1.6735517978668213
Iteration 79: train_loss 1.563596487045288
Iteration 80: train_loss 1.7041363716125488
Iteration 81: train_loss 1.7582348585128784
Iteration 82: train_loss 1.6546229124069214
Iteration 83: train_loss 1.7597095966339111
Iteration 84: train_loss 1.7232006788253784
Iteration 85: train_loss 1.6829689741134644
Iteration 86: train_loss 1.6978402137756348
Iteration 87: train_loss 1.6919070482254028
Iteration 88: train_loss 1.648935317993164
Iteration 89: train_loss 1.6390581130981445
Iteration 90: train_loss 1.6428697109222412
Iteration 91: train_loss 1.7095576524734497
Iteration 92: train_loss 1.699897289276123
Iteration 93: train_loss 1.6900135278701782
Iteration 94: train_loss 1.626819372177124
Iteration 95: train_loss 1.631404995918274
Iteration 96: train_loss 1.641636848449707
Iteration 97: train_loss 1.6408025026321411
Iteration 98: train_loss 1.7068285942077637
Iteration 99: train_loss 1.6605801582336426
Iteration 100: train_loss 1.7231005430221558
Iteration 101: train_loss 1.687778353691101
Iteration 102: train_loss 1.7224639654159546
Iteration 103: train_loss 1.6411006450653076
Iteration 104: train_loss 1.6625272035598755
Iteration 105: train_loss 1.7157756090164185
Iteration 106: train_loss 1.7311632633209229
Iteration 107: train_loss 1.6303924322128296
Iteration 108: train_loss 1.6996934413909912
Iteration 109: train_loss 1.675157070159912
Iteration 110: train_loss 1.7372034788131714
Iteration 111: train_loss 1.6122111082077026
Iteration 112: train_loss 1.7111401557922363
Iteration 113: train_loss 1.685521125793457
Iteration 114: train_loss 1.6635487079620361
Iteration 115: train_loss 1.6383942365646362
Iteration 116: train_loss 1.6910561323165894
Iteration 117: train_loss 1.6147068738937378
Iteration 118: train_loss 1.7010692358016968
Iteration 119: train_loss 1.7058417797088623
Iteration 120: train_loss 1.691765308380127
Iteration 121: train_loss 1.6258823871612549
Iteration 122: train_loss 1.6438676118850708
Iteration 123: train_loss 1.736504316329956
Iteration 124: train_loss 1.6839966773986816
Iteration 125: train_loss 1.7010749578475952
Iteration 126: train_loss 1.6312000751495361
Iteration 127: train_loss 1.710403561592102
Iteration 128: train_loss 1.695568561553955
Iteration 129: train_loss 1.712180256843567
Iteration 130: train_loss 1.7618838548660278
Iteration 131: train_loss 1.6731829643249512
Iteration 132: train_loss 1.6496868133544922
Iteration 133: train_loss 1.623155117034912
Iteration 134: train_loss 1.6432793140411377
Iteration 135: train_loss 1.6779919862747192
Iteration 136: train_loss 1.730775237083435
Iteration 137: train_loss 1.685472011566162
Iteration 138: train_loss 1.733449935913086
Iteration 139: train_loss 1.6317521333694458
Iteration 140: train_loss 1.7020659446716309
Iteration 141: train_loss 1.7408367395401
Iteration 142: train_loss 1.7017194032669067
Iteration 143: train_loss 1.7506791353225708
Iteration 144: train_loss 1.6327317953109741
Iteration 145: train_loss 1.641119122505188
Iteration 146: train_loss 1.6698873043060303
Iteration 147: train_loss 1.6037180423736572
Iteration 148: train_loss 1.7254525423049927
Iteration 149: train_loss 1.719383955001831
Iteration 150: train_loss 1.684091567993164
Iteration 151: train_loss 1.7380586862564087
Iteration 152: train_loss 1.6994270086288452
Iteration 153: train_loss 1.7549539804458618
Iteration 154: train_loss 1.7757552862167358
Iteration 155: train_loss 1.7740581035614014
Iteration 156: train_loss 1.7750390768051147
Iteration 157: train_loss 1.7084815502166748
Iteration 158: train_loss 1.764797568321228
Iteration 159: train_loss 1.7721604108810425
Iteration 160: train_loss 1.6737598180770874
Iteration 161: train_loss 1.6905176639556885
Iteration 162: train_loss 1.732896327972412
Iteration 163: train_loss 1.8081121444702148
Iteration 164: train_loss 1.7154250144958496
Iteration 165: train_loss 1.651305079460144
Iteration 166: train_loss 1.7020896673202515
Iteration 167: train_loss 1.6837600469589233
Iteration 168: train_loss 1.7059837579727173
Iteration 169: train_loss 1.6746042966842651
Iteration 170: train_loss 1.6984765529632568
Iteration 171: train_loss 1.6931397914886475
Iteration 172: train_loss 1.7318609952926636
Iteration 173: train_loss 1.672541618347168
Iteration 174: train_loss 1.640964388847351
Iteration 175: train_loss 1.6682908535003662
Iteration 176: train_loss 1.6033803224563599
Iteration 177: train_loss 1.7000889778137207
Epoch 50: train_avg_loss 1.6748187710336373 eval_avg_acc: 0.3294120391505582 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:22:10] [32mIntermediate result: 0.3294120391505582  (Index 49)[0m
================Epoch: 51================
Iteration 1: train_loss 1.6132253408432007
Iteration 2: train_loss 1.6351016759872437
Iteration 3: train_loss 1.659492015838623
Iteration 4: train_loss 1.623262643814087
Iteration 5: train_loss 1.7358108758926392
Iteration 6: train_loss 1.6869256496429443
Iteration 7: train_loss 1.645469069480896
Iteration 8: train_loss 1.5876511335372925
Iteration 9: train_loss 1.6607972383499146
Iteration 10: train_loss 1.6560546159744263
Iteration 11: train_loss 1.7244937419891357
Iteration 12: train_loss 1.6411107778549194
Iteration 13: train_loss 1.6699085235595703
Iteration 14: train_loss 1.6753273010253906
Iteration 15: train_loss 1.629963755607605
Iteration 16: train_loss 1.660238265991211
Iteration 17: train_loss 1.624345302581787
Iteration 18: train_loss 1.6320099830627441
Iteration 19: train_loss 1.6289563179016113
Iteration 20: train_loss 1.688370704650879
Iteration 21: train_loss 1.6213396787643433
Iteration 22: train_loss 1.6739455461502075
Iteration 23: train_loss 1.688565731048584
Iteration 24: train_loss 1.6501975059509277
Iteration 25: train_loss 1.6700725555419922
Iteration 26: train_loss 1.700374960899353
Iteration 27: train_loss 1.657571792602539
Iteration 28: train_loss 1.7091147899627686
Iteration 29: train_loss 1.6321743726730347
Iteration 30: train_loss 1.63908851146698
Iteration 31: train_loss 1.6532387733459473
Iteration 32: train_loss 1.626796841621399
Iteration 33: train_loss 1.6009780168533325
Iteration 34: train_loss 1.582390308380127
Iteration 35: train_loss 1.6659932136535645
Iteration 36: train_loss 1.62944757938385
Iteration 37: train_loss 1.6368136405944824
Iteration 38: train_loss 1.6273832321166992
Iteration 39: train_loss 1.7837927341461182
Iteration 40: train_loss 1.711655855178833
Iteration 41: train_loss 1.6790411472320557
Iteration 42: train_loss 1.697446346282959
Iteration 43: train_loss 1.6956995725631714
Iteration 44: train_loss 1.635006070137024
Iteration 45: train_loss 1.682915210723877
Iteration 46: train_loss 1.632081151008606
Iteration 47: train_loss 1.6807044744491577
Iteration 48: train_loss 1.6902344226837158
Iteration 49: train_loss 1.6732169389724731
Iteration 50: train_loss 1.6471889019012451
Iteration 51: train_loss 1.655767560005188
Iteration 52: train_loss 1.6269975900650024
Iteration 53: train_loss 1.666909098625183
Iteration 54: train_loss 1.7465795278549194
Iteration 55: train_loss 1.6667234897613525
Iteration 56: train_loss 1.7039648294448853
Iteration 57: train_loss 1.6844346523284912
Iteration 58: train_loss 1.730590581893921
Iteration 59: train_loss 1.6811447143554688
Iteration 60: train_loss 1.6325442790985107
Iteration 61: train_loss 1.7132461071014404
Iteration 62: train_loss 1.6409083604812622
Iteration 63: train_loss 1.6950989961624146
Iteration 64: train_loss 1.7156527042388916
Iteration 65: train_loss 1.7011317014694214
Iteration 66: train_loss 1.6678297519683838
Iteration 67: train_loss 1.6013745069503784
Iteration 68: train_loss 1.6657354831695557
Iteration 69: train_loss 1.6597167253494263
Iteration 70: train_loss 1.6500624418258667
Iteration 71: train_loss 1.6142410039901733
Iteration 72: train_loss 1.5736949443817139
Iteration 73: train_loss 1.6476635932922363
Iteration 74: train_loss 1.6468839645385742
Iteration 75: train_loss 1.7204676866531372
Iteration 76: train_loss 1.6501885652542114
Iteration 77: train_loss 1.6565603017807007
Iteration 78: train_loss 1.6488902568817139
Iteration 79: train_loss 1.6067473888397217
Iteration 80: train_loss 1.6385197639465332
Iteration 81: train_loss 1.7443305253982544
Iteration 82: train_loss 1.641409993171692
Iteration 83: train_loss 1.6384694576263428
Iteration 84: train_loss 1.6796411275863647
Iteration 85: train_loss 1.7127476930618286
Iteration 86: train_loss 1.65220046043396
Iteration 87: train_loss 1.6302372217178345
Iteration 88: train_loss 1.6929833889007568
Iteration 89: train_loss 1.6959986686706543
Iteration 90: train_loss 1.6759026050567627
Iteration 91: train_loss 1.6963858604431152
Iteration 92: train_loss 1.735682487487793
Iteration 93: train_loss 1.735730767250061
Iteration 94: train_loss 1.7302910089492798
Iteration 95: train_loss 1.610158920288086
Iteration 96: train_loss 1.7321782112121582
Iteration 97: train_loss 1.6780251264572144
Iteration 98: train_loss 1.668691635131836
Iteration 99: train_loss 1.6072508096694946
Iteration 100: train_loss 1.6910240650177002
Iteration 101: train_loss 1.681112289428711
Iteration 102: train_loss 1.719452977180481
Iteration 103: train_loss 1.607729434967041
Iteration 104: train_loss 1.7298353910446167
Iteration 105: train_loss 1.696781873703003
Iteration 106: train_loss 1.7114512920379639
Iteration 107: train_loss 1.7216308116912842
Iteration 108: train_loss 1.6193342208862305
Iteration 109: train_loss 1.6892935037612915
Iteration 110: train_loss 1.7111562490463257
Iteration 111: train_loss 1.7427852153778076
Iteration 112: train_loss 1.608927607536316
Iteration 113: train_loss 1.7137620449066162
Iteration 114: train_loss 1.6680384874343872
Iteration 115: train_loss 1.6741074323654175
Iteration 116: train_loss 1.6796358823776245
Iteration 117: train_loss 1.6340359449386597
Iteration 118: train_loss 1.7381902933120728
Iteration 119: train_loss 1.6711550951004028
Iteration 120: train_loss 1.7523664236068726
Iteration 121: train_loss 1.7597466707229614
Iteration 122: train_loss 1.710710883140564
Iteration 123: train_loss 1.7129541635513306
Iteration 124: train_loss 1.7365444898605347
Iteration 125: train_loss 1.718420147895813
Iteration 126: train_loss 1.7444640398025513
Iteration 127: train_loss 1.6266711950302124
Iteration 128: train_loss 1.6000092029571533
Iteration 129: train_loss 1.6382546424865723
Iteration 130: train_loss 1.6585547924041748
Iteration 131: train_loss 1.6441609859466553
Iteration 132: train_loss 1.674180507659912
Iteration 133: train_loss 1.6525458097457886
Iteration 134: train_loss 1.7837059497833252
Iteration 135: train_loss 1.6657301187515259
Iteration 136: train_loss 1.7554117441177368
Iteration 137: train_loss 1.7241019010543823
Iteration 138: train_loss 1.704874038696289
Iteration 139: train_loss 1.6758755445480347
Iteration 140: train_loss 1.6980657577514648
Iteration 141: train_loss 1.6998603343963623
Iteration 142: train_loss 1.7187879085540771
Iteration 143: train_loss 1.7428562641143799
Iteration 144: train_loss 1.6984566450119019
Iteration 145: train_loss 1.7111842632293701
Iteration 146: train_loss 1.6446614265441895
Iteration 147: train_loss 1.7373676300048828
Iteration 148: train_loss 1.6755332946777344
Iteration 149: train_loss 1.73812997341156
Iteration 150: train_loss 1.741478443145752
Iteration 151: train_loss 1.6727849245071411
Iteration 152: train_loss 1.6964995861053467
Iteration 153: train_loss 1.6309534311294556
Iteration 154: train_loss 1.6280590295791626
Iteration 155: train_loss 1.668512225151062
Iteration 156: train_loss 1.6612792015075684
Iteration 157: train_loss 1.7134021520614624
Iteration 158: train_loss 1.6682528257369995
Iteration 159: train_loss 1.6186248064041138
Iteration 160: train_loss 1.7228857278823853
Iteration 161: train_loss 1.7614539861679077
Iteration 162: train_loss 1.6435173749923706
Iteration 163: train_loss 1.6491318941116333
Iteration 164: train_loss 1.6214542388916016
Iteration 165: train_loss 1.63898766040802
Iteration 166: train_loss 1.6848196983337402
Iteration 167: train_loss 1.6897616386413574
Iteration 168: train_loss 1.7007108926773071
Iteration 169: train_loss 1.6827197074890137
Iteration 170: train_loss 1.641553282737732
Iteration 171: train_loss 1.6611100435256958
Iteration 172: train_loss 1.6006124019622803
Iteration 173: train_loss 1.699543833732605
Iteration 174: train_loss 1.7143231630325317
Iteration 175: train_loss 1.695643663406372
Iteration 176: train_loss 1.704132080078125
Iteration 177: train_loss 1.758219838142395
Epoch 51: train_avg_loss 1.6751730280407404 eval_avg_acc: 0.33341274541010224 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:22:51] [32mIntermediate result: 0.33341274541010224  (Index 50)[0m
================Epoch: 52================
Iteration 1: train_loss 1.6329145431518555
Iteration 2: train_loss 1.745097041130066
Iteration 3: train_loss 1.589808702468872
Iteration 4: train_loss 1.7076114416122437
Iteration 5: train_loss 1.5954169034957886
Iteration 6: train_loss 1.6603091955184937
Iteration 7: train_loss 1.6110501289367676
Iteration 8: train_loss 1.665917992591858
Iteration 9: train_loss 1.5554252862930298
Iteration 10: train_loss 1.693129539489746
Iteration 11: train_loss 1.6285099983215332
Iteration 12: train_loss 1.61430025100708
Iteration 13: train_loss 1.6130869388580322
Iteration 14: train_loss 1.6587063074111938
Iteration 15: train_loss 1.6058638095855713
Iteration 16: train_loss 1.6560691595077515
Iteration 17: train_loss 1.660814881324768
Iteration 18: train_loss 1.6759575605392456
Iteration 19: train_loss 1.6159179210662842
Iteration 20: train_loss 1.6302882432937622
Iteration 21: train_loss 1.6395134925842285
Iteration 22: train_loss 1.701953411102295
Iteration 23: train_loss 1.6064453125
Iteration 24: train_loss 1.62771475315094
Iteration 25: train_loss 1.6582965850830078
Iteration 26: train_loss 1.6759357452392578
Iteration 27: train_loss 1.6754175424575806
Iteration 28: train_loss 1.6766327619552612
Iteration 29: train_loss 1.6141544580459595
Iteration 30: train_loss 1.662347674369812
Iteration 31: train_loss 1.6120069026947021
Iteration 32: train_loss 1.6403452157974243
Iteration 33: train_loss 1.653740406036377
Iteration 34: train_loss 1.5982242822647095
Iteration 35: train_loss 1.634503722190857
Iteration 36: train_loss 1.6595693826675415
Iteration 37: train_loss 1.719944715499878
Iteration 38: train_loss 1.6294786930084229
Iteration 39: train_loss 1.6781980991363525
Iteration 40: train_loss 1.6440508365631104
Iteration 41: train_loss 1.5947602987289429
Iteration 42: train_loss 1.6459912061691284
Iteration 43: train_loss 1.7117232084274292
Iteration 44: train_loss 1.5958466529846191
Iteration 45: train_loss 1.7628917694091797
Iteration 46: train_loss 1.6776148080825806
Iteration 47: train_loss 1.6333504915237427
Iteration 48: train_loss 1.6556369066238403
Iteration 49: train_loss 1.6283276081085205
Iteration 50: train_loss 1.6241309642791748
Iteration 51: train_loss 1.670920968055725
Iteration 52: train_loss 1.6831423044204712
Iteration 53: train_loss 1.640486478805542
Iteration 54: train_loss 1.589672565460205
Iteration 55: train_loss 1.6320210695266724
Iteration 56: train_loss 1.662529706954956
Iteration 57: train_loss 1.5869953632354736
Iteration 58: train_loss 1.6345884799957275
Iteration 59: train_loss 1.6732183694839478
Iteration 60: train_loss 1.6752816438674927
Iteration 61: train_loss 1.6090929508209229
Iteration 62: train_loss 1.6996997594833374
Iteration 63: train_loss 1.6241943836212158
Iteration 64: train_loss 1.6466726064682007
Iteration 65: train_loss 1.723418116569519
Iteration 66: train_loss 1.7189170122146606
Iteration 67: train_loss 1.663404941558838
Iteration 68: train_loss 1.7593631744384766
Iteration 69: train_loss 1.695764183998108
Iteration 70: train_loss 1.6424905061721802
Iteration 71: train_loss 1.5722655057907104
Iteration 72: train_loss 1.5889980792999268
Iteration 73: train_loss 1.6698857545852661
Iteration 74: train_loss 1.726807713508606
Iteration 75: train_loss 1.7062911987304688
Iteration 76: train_loss 1.6220104694366455
Iteration 77: train_loss 1.6375012397766113
Iteration 78: train_loss 1.6730767488479614
Iteration 79: train_loss 1.592228889465332
Iteration 80: train_loss 1.6416555643081665
Iteration 81: train_loss 1.6506561040878296
Iteration 82: train_loss 1.6611380577087402
Iteration 83: train_loss 1.601647138595581
Iteration 84: train_loss 1.676853895187378
Iteration 85: train_loss 1.669491171836853
Iteration 86: train_loss 1.6686536073684692
Iteration 87: train_loss 1.6404778957366943
Iteration 88: train_loss 1.6263912916183472
Iteration 89: train_loss 1.6799402236938477
Iteration 90: train_loss 1.7305521965026855
Iteration 91: train_loss 1.651985764503479
Iteration 92: train_loss 1.6797550916671753
Iteration 93: train_loss 1.6239478588104248
Iteration 94: train_loss 1.6790632009506226
Iteration 95: train_loss 1.6753699779510498
Iteration 96: train_loss 1.721524953842163
Iteration 97: train_loss 1.61619234085083
Iteration 98: train_loss 1.657508134841919
Iteration 99: train_loss 1.7097387313842773
Iteration 100: train_loss 1.6056146621704102
Iteration 101: train_loss 1.7472668886184692
Iteration 102: train_loss 1.672749638557434
Iteration 103: train_loss 1.6974782943725586
Iteration 104: train_loss 1.669039249420166
Iteration 105: train_loss 1.6077587604522705
Iteration 106: train_loss 1.7595953941345215
Iteration 107: train_loss 1.6394145488739014
Iteration 108: train_loss 1.7238123416900635
Iteration 109: train_loss 1.6375598907470703
Iteration 110: train_loss 1.593798279762268
Iteration 111: train_loss 1.7240831851959229
Iteration 112: train_loss 1.691428303718567
Iteration 113: train_loss 1.6954553127288818
Iteration 114: train_loss 1.6446151733398438
Iteration 115: train_loss 1.6332818269729614
Iteration 116: train_loss 1.6395677328109741
Iteration 117: train_loss 1.7213630676269531
Iteration 118: train_loss 1.664961338043213
Iteration 119: train_loss 1.6661096811294556
Iteration 120: train_loss 1.7303378582000732
Iteration 121: train_loss 1.607252597808838
Iteration 122: train_loss 1.7537858486175537
Iteration 123: train_loss 1.701173186302185
Iteration 124: train_loss 1.664404034614563
Iteration 125: train_loss 1.691780686378479
Iteration 126: train_loss 1.646736741065979
Iteration 127: train_loss 1.6887367963790894
Iteration 128: train_loss 1.7531136274337769
Iteration 129: train_loss 1.628915786743164
Iteration 130: train_loss 1.6530722379684448
Iteration 131: train_loss 1.6827198266983032
Iteration 132: train_loss 1.636821985244751
Iteration 133: train_loss 1.6950738430023193
Iteration 134: train_loss 1.6946909427642822
Iteration 135: train_loss 1.6817048788070679
Iteration 136: train_loss 1.6133697032928467
Iteration 137: train_loss 1.7535641193389893
Iteration 138: train_loss 1.6634180545806885
Iteration 139: train_loss 1.6706401109695435
Iteration 140: train_loss 1.5909078121185303
Iteration 141: train_loss 1.6619482040405273
Iteration 142: train_loss 1.7279150485992432
Iteration 143: train_loss 1.714827537536621
Iteration 144: train_loss 1.747623324394226
Iteration 145: train_loss 1.6604751348495483
Iteration 146: train_loss 1.6698923110961914
Iteration 147: train_loss 1.639613389968872
Iteration 148: train_loss 1.6653382778167725
Iteration 149: train_loss 1.6899595260620117
Iteration 150: train_loss 1.701749563217163
Iteration 151: train_loss 1.6689013242721558
Iteration 152: train_loss 1.66634202003479
Iteration 153: train_loss 1.7577334642410278
Iteration 154: train_loss 1.7257615327835083
Iteration 155: train_loss 1.719434142112732
Iteration 156: train_loss 1.6892173290252686
Iteration 157: train_loss 1.658699631690979
Iteration 158: train_loss 1.6829031705856323
Iteration 159: train_loss 1.663543939590454
Iteration 160: train_loss 1.644013524055481
Iteration 161: train_loss 1.7132598161697388
Iteration 162: train_loss 1.6769256591796875
Iteration 163: train_loss 1.7310597896575928
Iteration 164: train_loss 1.6933273077011108
Iteration 165: train_loss 1.7196128368377686
Iteration 166: train_loss 1.7051640748977661
Iteration 167: train_loss 1.6743320226669312
Iteration 168: train_loss 1.6145877838134766
Iteration 169: train_loss 1.689847469329834
Iteration 170: train_loss 1.7247661352157593
Iteration 171: train_loss 1.6679208278656006
Iteration 172: train_loss 1.709043025970459
Iteration 173: train_loss 1.6616239547729492
Iteration 174: train_loss 1.6819390058517456
Iteration 175: train_loss 1.7274500131607056
Iteration 176: train_loss 1.7319233417510986
Iteration 177: train_loss 1.6577439308166504
Epoch 52: train_avg_loss 1.6656046371675481 eval_avg_acc: 0.33963817538631974 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:23:30] [32mIntermediate result: 0.33963817538631974  (Index 51)[0m
================Epoch: 53================
Iteration 1: train_loss 1.6671487092971802
Iteration 2: train_loss 1.6893452405929565
Iteration 3: train_loss 1.6798003911972046
Iteration 4: train_loss 1.6002966165542603
Iteration 5: train_loss 1.6807082891464233
Iteration 6: train_loss 1.588858962059021
Iteration 7: train_loss 1.589855432510376
Iteration 8: train_loss 1.6355171203613281
Iteration 9: train_loss 1.6253255605697632
Iteration 10: train_loss 1.5295000076293945
Iteration 11: train_loss 1.6105154752731323
Iteration 12: train_loss 1.6235020160675049
Iteration 13: train_loss 1.5941838026046753
Iteration 14: train_loss 1.629921555519104
Iteration 15: train_loss 1.5965075492858887
Iteration 16: train_loss 1.5979270935058594
Iteration 17: train_loss 1.6539137363433838
Iteration 18: train_loss 1.6879435777664185
Iteration 19: train_loss 1.6786762475967407
Iteration 20: train_loss 1.6128565073013306
Iteration 21: train_loss 1.643128752708435
Iteration 22: train_loss 1.5923365354537964
Iteration 23: train_loss 1.6061131954193115
Iteration 24: train_loss 1.6753515005111694
Iteration 25: train_loss 1.6197295188903809
Iteration 26: train_loss 1.6093891859054565
Iteration 27: train_loss 1.5872803926467896
Iteration 28: train_loss 1.5713495016098022
Iteration 29: train_loss 1.6325916051864624
Iteration 30: train_loss 1.5517891645431519
Iteration 31: train_loss 1.616556167602539
Iteration 32: train_loss 1.5890707969665527
Iteration 33: train_loss 1.6711387634277344
Iteration 34: train_loss 1.684930682182312
Iteration 35: train_loss 1.6424329280853271
Iteration 36: train_loss 1.6163887977600098
Iteration 37: train_loss 1.6638737916946411
Iteration 38: train_loss 1.6822870969772339
Iteration 39: train_loss 1.6590272188186646
Iteration 40: train_loss 1.7965320348739624
Iteration 41: train_loss 1.7297807931900024
Iteration 42: train_loss 1.5801570415496826
Iteration 43: train_loss 1.6235603094100952
Iteration 44: train_loss 1.5914514064788818
Iteration 45: train_loss 1.7046433687210083
Iteration 46: train_loss 1.6201506853103638
Iteration 47: train_loss 1.6529018878936768
Iteration 48: train_loss 1.5911240577697754
Iteration 49: train_loss 1.5801335573196411
Iteration 50: train_loss 1.6886659860610962
Iteration 51: train_loss 1.561936616897583
Iteration 52: train_loss 1.6352319717407227
Iteration 53: train_loss 1.612850308418274
Iteration 54: train_loss 1.6513035297393799
Iteration 55: train_loss 1.571529746055603
Iteration 56: train_loss 1.6071051359176636
Iteration 57: train_loss 1.607088327407837
Iteration 58: train_loss 1.5986177921295166
Iteration 59: train_loss 1.6671535968780518
Iteration 60: train_loss 1.5928199291229248
Iteration 61: train_loss 1.6993614435195923
Iteration 62: train_loss 1.6100547313690186
Iteration 63: train_loss 1.6726996898651123
Iteration 64: train_loss 1.657968282699585
Iteration 65: train_loss 1.6740411520004272
Iteration 66: train_loss 1.5800156593322754
Iteration 67: train_loss 1.5694382190704346
Iteration 68: train_loss 1.6478532552719116
Iteration 69: train_loss 1.590535283088684
Iteration 70: train_loss 1.7117629051208496
Iteration 71: train_loss 1.689849853515625
Iteration 72: train_loss 1.5555973052978516
Iteration 73: train_loss 1.5714077949523926
Iteration 74: train_loss 1.5732823610305786
Iteration 75: train_loss 1.6080905199050903
Iteration 76: train_loss 1.6280832290649414
Iteration 77: train_loss 1.5978553295135498
Iteration 78: train_loss 1.5879058837890625
Iteration 79: train_loss 1.6170380115509033
Iteration 80: train_loss 1.78244948387146
Iteration 81: train_loss 1.6545437574386597
Iteration 82: train_loss 1.6735951900482178
Iteration 83: train_loss 1.666073203086853
Iteration 84: train_loss 1.7193481922149658
Iteration 85: train_loss 1.6611651182174683
Iteration 86: train_loss 1.7588717937469482
Iteration 87: train_loss 1.756427526473999
Iteration 88: train_loss 1.6760958433151245
Iteration 89: train_loss 1.7110413312911987
Iteration 90: train_loss 1.6526367664337158
Iteration 91: train_loss 1.6325019598007202
Iteration 92: train_loss 1.6419013738632202
Iteration 93: train_loss 1.6283169984817505
Iteration 94: train_loss 1.6025289297103882
Iteration 95: train_loss 1.5896556377410889
Iteration 96: train_loss 1.6062939167022705
Iteration 97: train_loss 1.607413649559021
Iteration 98: train_loss 1.6492159366607666
Iteration 99: train_loss 1.6406790018081665
Iteration 100: train_loss 1.6557257175445557
Iteration 101: train_loss 1.6481595039367676
Iteration 102: train_loss 1.5990926027297974
Iteration 103: train_loss 1.6802420616149902
Iteration 104: train_loss 1.6430816650390625
Iteration 105: train_loss 1.7066258192062378
Iteration 106: train_loss 1.6446902751922607
Iteration 107: train_loss 1.712793231010437
Iteration 108: train_loss 1.6423856019973755
Iteration 109: train_loss 1.6789470911026
Iteration 110: train_loss 1.7213959693908691
Iteration 111: train_loss 1.6800956726074219
Iteration 112: train_loss 1.6684552431106567
Iteration 113: train_loss 1.6787503957748413
Iteration 114: train_loss 1.633167028427124
Iteration 115: train_loss 1.6773613691329956
Iteration 116: train_loss 1.6245346069335938
Iteration 117: train_loss 1.6636415719985962
Iteration 118: train_loss 1.7178609371185303
Iteration 119: train_loss 1.665897250175476
Iteration 120: train_loss 1.5931475162506104
Iteration 121: train_loss 1.6625399589538574
Iteration 122: train_loss 1.7057974338531494
Iteration 123: train_loss 1.7586796283721924
Iteration 124: train_loss 1.629595398902893
Iteration 125: train_loss 1.5487076044082642
Iteration 126: train_loss 1.6455217599868774
Iteration 127: train_loss 1.74724280834198
Iteration 128: train_loss 1.6899017095565796
Iteration 129: train_loss 1.6408971548080444
Iteration 130: train_loss 1.7140525579452515
Iteration 131: train_loss 1.7053223848342896
Iteration 132: train_loss 1.63432776927948
Iteration 133: train_loss 1.7124032974243164
Iteration 134: train_loss 1.6123219728469849
Iteration 135: train_loss 1.6652915477752686
Iteration 136: train_loss 1.6349045038223267
Iteration 137: train_loss 1.7030094861984253
Iteration 138: train_loss 1.6771095991134644
Iteration 139: train_loss 1.6895174980163574
Iteration 140: train_loss 1.7344982624053955
Iteration 141: train_loss 1.669878363609314
Iteration 142: train_loss 1.668150782585144
Iteration 143: train_loss 1.6335961818695068
Iteration 144: train_loss 1.710403323173523
Iteration 145: train_loss 1.627173900604248
Iteration 146: train_loss 1.6986669301986694
Iteration 147: train_loss 1.680027723312378
Iteration 148: train_loss 1.789076328277588
Iteration 149: train_loss 1.7085020542144775
Iteration 150: train_loss 1.6561771631240845
Iteration 151: train_loss 1.6778022050857544
Iteration 152: train_loss 1.6504021883010864
Iteration 153: train_loss 1.6308542490005493
Iteration 154: train_loss 1.6610714197158813
Iteration 155: train_loss 1.6726802587509155
Iteration 156: train_loss 1.6563668251037598
Iteration 157: train_loss 1.6353731155395508
Iteration 158: train_loss 1.5894209146499634
Iteration 159: train_loss 1.6041666269302368
Iteration 160: train_loss 1.669295310974121
Iteration 161: train_loss 1.7526309490203857
Iteration 162: train_loss 1.652610182762146
Iteration 163: train_loss 1.7235585451126099
Iteration 164: train_loss 1.6273605823516846
Iteration 165: train_loss 1.755364179611206
Iteration 166: train_loss 1.6841309070587158
Iteration 167: train_loss 1.699523687362671
Iteration 168: train_loss 1.6889026165008545
Iteration 169: train_loss 1.665513515472412
Iteration 170: train_loss 1.6644318103790283
Iteration 171: train_loss 1.673915982246399
Iteration 172: train_loss 1.6606501340866089
Iteration 173: train_loss 1.6440457105636597
Iteration 174: train_loss 1.6827622652053833
Iteration 175: train_loss 1.7384759187698364
Iteration 176: train_loss 1.6587759256362915
Iteration 177: train_loss 1.7260491847991943
Epoch 53: train_avg_loss 1.651643421016844 eval_avg_acc: 0.33189879982586046 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:24:07] [32mIntermediate result: 0.33189879982586046  (Index 52)[0m
================Epoch: 54================
Iteration 1: train_loss 1.653420329093933
Iteration 2: train_loss 1.6553969383239746
Iteration 3: train_loss 1.7006703615188599
Iteration 4: train_loss 1.6359608173370361
Iteration 5: train_loss 1.6713950634002686
Iteration 6: train_loss 1.6295616626739502
Iteration 7: train_loss 1.6731362342834473
Iteration 8: train_loss 1.585615873336792
Iteration 9: train_loss 1.5779969692230225
Iteration 10: train_loss 1.6444917917251587
Iteration 11: train_loss 1.6194047927856445
Iteration 12: train_loss 1.6453723907470703
Iteration 13: train_loss 1.680924654006958
Iteration 14: train_loss 1.6461378335952759
Iteration 15: train_loss 1.6487796306610107
Iteration 16: train_loss 1.6000605821609497
Iteration 17: train_loss 1.5797486305236816
Iteration 18: train_loss 1.635637640953064
Iteration 19: train_loss 1.6443654298782349
Iteration 20: train_loss 1.671638011932373
Iteration 21: train_loss 1.6188914775848389
Iteration 22: train_loss 1.6381781101226807
Iteration 23: train_loss 1.624822735786438
Iteration 24: train_loss 1.5412260293960571
Iteration 25: train_loss 1.6633213758468628
Iteration 26: train_loss 1.5968482494354248
Iteration 27: train_loss 1.668697476387024
Iteration 28: train_loss 1.5644645690917969
Iteration 29: train_loss 1.6394850015640259
Iteration 30: train_loss 1.6176084280014038
Iteration 31: train_loss 1.6323834657669067
Iteration 32: train_loss 1.6652204990386963
Iteration 33: train_loss 1.6512670516967773
Iteration 34: train_loss 1.6004825830459595
Iteration 35: train_loss 1.5879874229431152
Iteration 36: train_loss 1.5970516204833984
Iteration 37: train_loss 1.6203738451004028
Iteration 38: train_loss 1.6668634414672852
Iteration 39: train_loss 1.6494253873825073
Iteration 40: train_loss 1.6712266206741333
Iteration 41: train_loss 1.6891131401062012
Iteration 42: train_loss 1.6621875762939453
Iteration 43: train_loss 1.637362003326416
Iteration 44: train_loss 1.6440125703811646
Iteration 45: train_loss 1.5994160175323486
Iteration 46: train_loss 1.6130924224853516
Iteration 47: train_loss 1.7006409168243408
Iteration 48: train_loss 1.6043074131011963
Iteration 49: train_loss 1.6862558126449585
Iteration 50: train_loss 1.638584852218628
Iteration 51: train_loss 1.6068756580352783
Iteration 52: train_loss 1.5814502239227295
Iteration 53: train_loss 1.6069129705429077
Iteration 54: train_loss 1.6545445919036865
Iteration 55: train_loss 1.5907959938049316
Iteration 56: train_loss 1.6666162014007568
Iteration 57: train_loss 1.5867094993591309
Iteration 58: train_loss 1.6168972253799438
Iteration 59: train_loss 1.6690469980239868
Iteration 60: train_loss 1.6188347339630127
Iteration 61: train_loss 1.5753207206726074
Iteration 62: train_loss 1.6029436588287354
Iteration 63: train_loss 1.692338228225708
Iteration 64: train_loss 1.624049425125122
Iteration 65: train_loss 1.613945484161377
Iteration 66: train_loss 1.6251670122146606
Iteration 67: train_loss 1.6445523500442505
Iteration 68: train_loss 1.6836369037628174
Iteration 69: train_loss 1.6844497919082642
Iteration 70: train_loss 1.5754914283752441
Iteration 71: train_loss 1.5770230293273926
Iteration 72: train_loss 1.575300693511963
Iteration 73: train_loss 1.651768684387207
Iteration 74: train_loss 1.6529346704483032
Iteration 75: train_loss 1.6895123720169067
Iteration 76: train_loss 1.675069808959961
Iteration 77: train_loss 1.632102131843567
Iteration 78: train_loss 1.6392217874526978
Iteration 79: train_loss 1.590633511543274
Iteration 80: train_loss 1.642290711402893
Iteration 81: train_loss 1.5622230768203735
Iteration 82: train_loss 1.7161206007003784
Iteration 83: train_loss 1.5699607133865356
Iteration 84: train_loss 1.6317864656448364
Iteration 85: train_loss 1.6277892589569092
Iteration 86: train_loss 1.651985764503479
Iteration 87: train_loss 1.7009769678115845
Iteration 88: train_loss 1.6472169160842896
Iteration 89: train_loss 1.6165870428085327
Iteration 90: train_loss 1.6629761457443237
Iteration 91: train_loss 1.654647707939148
Iteration 92: train_loss 1.6838490962982178
Iteration 93: train_loss 1.6586439609527588
Iteration 94: train_loss 1.7489269971847534
Iteration 95: train_loss 1.5483713150024414
Iteration 96: train_loss 1.689016342163086
Iteration 97: train_loss 1.688314437866211
Iteration 98: train_loss 1.6349009275436401
Iteration 99: train_loss 1.6505763530731201
Iteration 100: train_loss 1.6988039016723633
Iteration 101: train_loss 1.6809974908828735
Iteration 102: train_loss 1.7275737524032593
Iteration 103: train_loss 1.7045223712921143
Iteration 104: train_loss 1.6444116830825806
Iteration 105: train_loss 1.6186299324035645
Iteration 106: train_loss 1.5857223272323608
Iteration 107: train_loss 1.6586499214172363
Iteration 108: train_loss 1.6945356130599976
Iteration 109: train_loss 1.7141209840774536
Iteration 110: train_loss 1.694849967956543
Iteration 111: train_loss 1.6136524677276611
Iteration 112: train_loss 1.6781766414642334
Iteration 113: train_loss 1.602895975112915
Iteration 114: train_loss 1.6401703357696533
Iteration 115: train_loss 1.6155965328216553
Iteration 116: train_loss 1.651176929473877
Iteration 117: train_loss 1.6814250946044922
Iteration 118: train_loss 1.6444207429885864
Iteration 119: train_loss 1.649725317955017
Iteration 120: train_loss 1.649795651435852
Iteration 121: train_loss 1.6425164937973022
Iteration 122: train_loss 1.6210103034973145
Iteration 123: train_loss 1.6087578535079956
Iteration 124: train_loss 1.642338752746582
Iteration 125: train_loss 1.6666743755340576
Iteration 126: train_loss 1.6177589893341064
Iteration 127: train_loss 1.6044503450393677
Iteration 128: train_loss 1.6051766872406006
Iteration 129: train_loss 1.7026549577713013
Iteration 130: train_loss 1.6475335359573364
Iteration 131: train_loss 1.6174081563949585
Iteration 132: train_loss 1.6670154333114624
Iteration 133: train_loss 1.6428802013397217
Iteration 134: train_loss 1.7079538106918335
Iteration 135: train_loss 1.560694932937622
Iteration 136: train_loss 1.6278704404830933
Iteration 137: train_loss 1.6950894594192505
Iteration 138: train_loss 1.5984704494476318
Iteration 139: train_loss 1.647559642791748
Iteration 140: train_loss 1.6327093839645386
Iteration 141: train_loss 1.7238655090332031
Iteration 142: train_loss 1.634953260421753
Iteration 143: train_loss 1.6229084730148315
Iteration 144: train_loss 1.6149225234985352
Iteration 145: train_loss 1.7029935121536255
Iteration 146: train_loss 1.6415594816207886
Iteration 147: train_loss 1.6592804193496704
Iteration 148: train_loss 1.698384404182434
Iteration 149: train_loss 1.7343672513961792
Iteration 150: train_loss 1.7567555904388428
Iteration 151: train_loss 1.6183911561965942
Iteration 152: train_loss 1.691955804824829
Iteration 153: train_loss 1.6095504760742188
Iteration 154: train_loss 1.6355589628219604
Iteration 155: train_loss 1.6686934232711792
Iteration 156: train_loss 1.5501036643981934
Iteration 157: train_loss 1.6678563356399536
Iteration 158: train_loss 1.6513206958770752
Iteration 159: train_loss 1.670647144317627
Iteration 160: train_loss 1.6685985326766968
Iteration 161: train_loss 1.609136700630188
Iteration 162: train_loss 1.6463550329208374
Iteration 163: train_loss 1.5433986186981201
Iteration 164: train_loss 1.6510963439941406
Iteration 165: train_loss 1.6085609197616577
Iteration 166: train_loss 1.6573035717010498
Iteration 167: train_loss 1.7717145681381226
Iteration 168: train_loss 1.7661068439483643
Iteration 169: train_loss 1.6426787376403809
Iteration 170: train_loss 1.6650593280792236
Iteration 171: train_loss 1.6961971521377563
Iteration 172: train_loss 1.67324960231781
Iteration 173: train_loss 1.6369283199310303
Iteration 174: train_loss 1.66196870803833
Iteration 175: train_loss 1.7071441411972046
Iteration 176: train_loss 1.6450926065444946
Iteration 177: train_loss 1.7347277402877808
Epoch 54: train_avg_loss 1.644788608712665 eval_avg_acc: 0.3350812634888973 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:24:45] [32mIntermediate result: 0.3350812634888973  (Index 53)[0m
================Epoch: 55================
Iteration 1: train_loss 1.5946457386016846
Iteration 2: train_loss 1.5841535329818726
Iteration 3: train_loss 1.6109646558761597
Iteration 4: train_loss 1.5943372249603271
Iteration 5: train_loss 1.6797325611114502
Iteration 6: train_loss 1.6277055740356445
Iteration 7: train_loss 1.5964796543121338
Iteration 8: train_loss 1.681532382965088
Iteration 9: train_loss 1.6294056177139282
Iteration 10: train_loss 1.66375732421875
Iteration 11: train_loss 1.6073789596557617
Iteration 12: train_loss 1.647208333015442
Iteration 13: train_loss 1.632755160331726
Iteration 14: train_loss 1.5758455991744995
Iteration 15: train_loss 1.5990275144577026
Iteration 16: train_loss 1.6426455974578857
Iteration 17: train_loss 1.6137298345565796
Iteration 18: train_loss 1.6175788640975952
Iteration 19: train_loss 1.6011208295822144
Iteration 20: train_loss 1.674492359161377
Iteration 21: train_loss 1.524972677230835
Iteration 22: train_loss 1.6431466341018677
Iteration 23: train_loss 1.6578905582427979
Iteration 24: train_loss 1.715968132019043
Iteration 25: train_loss 1.6389583349227905
Iteration 26: train_loss 1.5568159818649292
Iteration 27: train_loss 1.5732930898666382
Iteration 28: train_loss 1.5917483568191528
Iteration 29: train_loss 1.65562903881073
Iteration 30: train_loss 1.6256682872772217
Iteration 31: train_loss 1.6966639757156372
Iteration 32: train_loss 1.6267539262771606
Iteration 33: train_loss 1.5997388362884521
Iteration 34: train_loss 1.6264861822128296
Iteration 35: train_loss 1.5950233936309814
Iteration 36: train_loss 1.6140681505203247
Iteration 37: train_loss 1.6030287742614746
Iteration 38: train_loss 1.6257587671279907
Iteration 39: train_loss 1.5487486124038696
Iteration 40: train_loss 1.5371994972229004
Iteration 41: train_loss 1.6139941215515137
Iteration 42: train_loss 1.6225897073745728
Iteration 43: train_loss 1.6608749628067017
Iteration 44: train_loss 1.564150333404541
Iteration 45: train_loss 1.6438833475112915
Iteration 46: train_loss 1.629884958267212
Iteration 47: train_loss 1.5767005681991577
Iteration 48: train_loss 1.6327826976776123
Iteration 49: train_loss 1.631953239440918
Iteration 50: train_loss 1.6125867366790771
Iteration 51: train_loss 1.5737403631210327
Iteration 52: train_loss 1.6888025999069214
Iteration 53: train_loss 1.6163889169692993
Iteration 54: train_loss 1.6469353437423706
Iteration 55: train_loss 1.6248221397399902
Iteration 56: train_loss 1.5777097940444946
Iteration 57: train_loss 1.61301851272583
Iteration 58: train_loss 1.635520100593567
Iteration 59: train_loss 1.6162608861923218
Iteration 60: train_loss 1.6130504608154297
Iteration 61: train_loss 1.6209580898284912
Iteration 62: train_loss 1.659454107284546
Iteration 63: train_loss 1.6543560028076172
Iteration 64: train_loss 1.5972141027450562
Iteration 65: train_loss 1.62113618850708
Iteration 66: train_loss 1.582824468612671
Iteration 67: train_loss 1.6298401355743408
Iteration 68: train_loss 1.6376409530639648
Iteration 69: train_loss 1.6776238679885864
Iteration 70: train_loss 1.6875489950180054
Iteration 71: train_loss 1.6414028406143188
Iteration 72: train_loss 1.6169615983963013
Iteration 73: train_loss 1.5867326259613037
Iteration 74: train_loss 1.618847131729126
Iteration 75: train_loss 1.596183180809021
Iteration 76: train_loss 1.604380488395691
Iteration 77: train_loss 1.7225747108459473
Iteration 78: train_loss 1.580898404121399
Iteration 79: train_loss 1.656612515449524
Iteration 80: train_loss 1.6298104524612427
Iteration 81: train_loss 1.6208956241607666
Iteration 82: train_loss 1.6222400665283203
Iteration 83: train_loss 1.6073079109191895
Iteration 84: train_loss 1.6369413137435913
Iteration 85: train_loss 1.639991283416748
Iteration 86: train_loss 1.673616886138916
Iteration 87: train_loss 1.6357018947601318
Iteration 88: train_loss 1.6332603693008423
Iteration 89: train_loss 1.676676630973816
Iteration 90: train_loss 1.664301872253418
Iteration 91: train_loss 1.6098562479019165
Iteration 92: train_loss 1.6160980463027954
Iteration 93: train_loss 1.6085268259048462
Iteration 94: train_loss 1.65224289894104
Iteration 95: train_loss 1.635991096496582
Iteration 96: train_loss 1.6362340450286865
Iteration 97: train_loss 1.7117493152618408
Iteration 98: train_loss 1.6348978281021118
Iteration 99: train_loss 1.6804883480072021
Iteration 100: train_loss 1.5868397951126099
Iteration 101: train_loss 1.6040925979614258
Iteration 102: train_loss 1.5840049982070923
Iteration 103: train_loss 1.6061829328536987
Iteration 104: train_loss 1.7164020538330078
Iteration 105: train_loss 1.6098352670669556
Iteration 106: train_loss 1.5622133016586304
Iteration 107: train_loss 1.6159406900405884
Iteration 108: train_loss 1.6719815731048584
Iteration 109: train_loss 1.5872467756271362
Iteration 110: train_loss 1.6321839094161987
Iteration 111: train_loss 1.672080636024475
Iteration 112: train_loss 1.5672709941864014
Iteration 113: train_loss 1.5803388357162476
Iteration 114: train_loss 1.583030343055725
Iteration 115: train_loss 1.5951828956604004
Iteration 116: train_loss 1.6164860725402832
Iteration 117: train_loss 1.6394342184066772
Iteration 118: train_loss 1.6016135215759277
Iteration 119: train_loss 1.6072639226913452
Iteration 120: train_loss 1.602839708328247
Iteration 121: train_loss 1.623286247253418
Iteration 122: train_loss 1.584985613822937
Iteration 123: train_loss 1.585507869720459
Iteration 124: train_loss 1.6288809776306152
Iteration 125: train_loss 1.5683034658432007
Iteration 126: train_loss 1.528789758682251
Iteration 127: train_loss 1.6002856492996216
Iteration 128: train_loss 1.6002427339553833
Iteration 129: train_loss 1.655787467956543
Iteration 130: train_loss 1.6390864849090576
Iteration 131: train_loss 1.6960655450820923
Iteration 132: train_loss 1.6814618110656738
Iteration 133: train_loss 1.6127421855926514
Iteration 134: train_loss 1.673887848854065
Iteration 135: train_loss 1.6166625022888184
Iteration 136: train_loss 1.70284104347229
Iteration 137: train_loss 1.584215760231018
Iteration 138: train_loss 1.7076481580734253
Iteration 139: train_loss 1.6143888235092163
Iteration 140: train_loss 1.6964508295059204
Iteration 141: train_loss 1.617692470550537
Iteration 142: train_loss 1.6312580108642578
Iteration 143: train_loss 1.6148508787155151
Iteration 144: train_loss 1.6909743547439575
Iteration 145: train_loss 1.6637588739395142
Iteration 146: train_loss 1.6394680738449097
Iteration 147: train_loss 1.5958982706069946
Iteration 148: train_loss 1.596197247505188
Iteration 149: train_loss 1.68136465549469
Iteration 150: train_loss 1.6112008094787598
Iteration 151: train_loss 1.6449052095413208
Iteration 152: train_loss 1.5889365673065186
Iteration 153: train_loss 1.6918392181396484
Iteration 154: train_loss 1.7192665338516235
Iteration 155: train_loss 1.677225947380066
Iteration 156: train_loss 1.6644327640533447
Iteration 157: train_loss 1.5867007970809937
Iteration 158: train_loss 1.583053469657898
Iteration 159: train_loss 1.6594595909118652
Iteration 160: train_loss 1.6616652011871338
Iteration 161: train_loss 1.6121349334716797
Iteration 162: train_loss 1.650464415550232
Iteration 163: train_loss 1.6154756546020508
Iteration 164: train_loss 1.6134649515151978
Iteration 165: train_loss 1.6192829608917236
Iteration 166: train_loss 1.6997480392456055
Iteration 167: train_loss 1.6154367923736572
Iteration 168: train_loss 1.602574110031128
Iteration 169: train_loss 1.6646758317947388
Iteration 170: train_loss 1.640480637550354
Iteration 171: train_loss 1.6897568702697754
Iteration 172: train_loss 1.6362833976745605
Iteration 173: train_loss 1.6149139404296875
Iteration 174: train_loss 1.57607102394104
Iteration 175: train_loss 1.7108302116394043
Iteration 176: train_loss 1.638715386390686
Iteration 177: train_loss 1.7047574520111084
Epoch 55: train_avg_loss 1.6277792601935608 eval_avg_acc: 0.3441338252089373 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:25:26] [32mIntermediate result: 0.3441338252089373  (Index 54)[0m
================Epoch: 56================
Iteration 1: train_loss 1.560572862625122
Iteration 2: train_loss 1.6004648208618164
Iteration 3: train_loss 1.5790389776229858
Iteration 4: train_loss 1.631253957748413
Iteration 5: train_loss 1.5502132177352905
Iteration 6: train_loss 1.5934420824050903
Iteration 7: train_loss 1.597876787185669
Iteration 8: train_loss 1.5926473140716553
Iteration 9: train_loss 1.5986794233322144
Iteration 10: train_loss 1.6019209623336792
Iteration 11: train_loss 1.6248077154159546
Iteration 12: train_loss 1.5673061609268188
Iteration 13: train_loss 1.5975093841552734
Iteration 14: train_loss 1.6060835123062134
Iteration 15: train_loss 1.6213500499725342
Iteration 16: train_loss 1.503338098526001
Iteration 17: train_loss 1.6599119901657104
Iteration 18: train_loss 1.6487287282943726
Iteration 19: train_loss 1.583907961845398
Iteration 20: train_loss 1.5522863864898682
Iteration 21: train_loss 1.6094831228256226
Iteration 22: train_loss 1.5578194856643677
Iteration 23: train_loss 1.5564144849777222
Iteration 24: train_loss 1.5730438232421875
Iteration 25: train_loss 1.6059015989303589
Iteration 26: train_loss 1.5657758712768555
Iteration 27: train_loss 1.5702064037322998
Iteration 28: train_loss 1.540999174118042
Iteration 29: train_loss 1.655901551246643
Iteration 30: train_loss 1.6538949012756348
Iteration 31: train_loss 1.5642441511154175
Iteration 32: train_loss 1.6241174936294556
Iteration 33: train_loss 1.5919469594955444
Iteration 34: train_loss 1.6136412620544434
Iteration 35: train_loss 1.6119818687438965
Iteration 36: train_loss 1.5468969345092773
Iteration 37: train_loss 1.6073625087738037
Iteration 38: train_loss 1.6305843591690063
Iteration 39: train_loss 1.5954965353012085
Iteration 40: train_loss 1.5779651403427124
Iteration 41: train_loss 1.6768219470977783
Iteration 42: train_loss 1.5345277786254883
Iteration 43: train_loss 1.621158242225647
Iteration 44: train_loss 1.5989290475845337
Iteration 45: train_loss 1.671082615852356
Iteration 46: train_loss 1.6054728031158447
Iteration 47: train_loss 1.5695977210998535
Iteration 48: train_loss 1.650095820426941
Iteration 49: train_loss 1.6757994890213013
Iteration 50: train_loss 1.5543017387390137
Iteration 51: train_loss 1.667346715927124
Iteration 52: train_loss 1.5829951763153076
Iteration 53: train_loss 1.6343116760253906
Iteration 54: train_loss 1.619274616241455
Iteration 55: train_loss 1.5506563186645508
Iteration 56: train_loss 1.6008341312408447
Iteration 57: train_loss 1.650714635848999
Iteration 58: train_loss 1.5953727960586548
Iteration 59: train_loss 1.5448395013809204
Iteration 60: train_loss 1.6099815368652344
Iteration 61: train_loss 1.6001263856887817
Iteration 62: train_loss 1.744513988494873
Iteration 63: train_loss 1.6170687675476074
Iteration 64: train_loss 1.6112388372421265
Iteration 65: train_loss 1.5656629800796509
Iteration 66: train_loss 1.617052674293518
Iteration 67: train_loss 1.625356912612915
Iteration 68: train_loss 1.6284253597259521
Iteration 69: train_loss 1.6320273876190186
Iteration 70: train_loss 1.6689012050628662
Iteration 71: train_loss 1.5745916366577148
Iteration 72: train_loss 1.7052778005599976
Iteration 73: train_loss 1.6255015134811401
Iteration 74: train_loss 1.6182732582092285
Iteration 75: train_loss 1.644057035446167
Iteration 76: train_loss 1.6552555561065674
Iteration 77: train_loss 1.625487208366394
Iteration 78: train_loss 1.6118123531341553
Iteration 79: train_loss 1.588887095451355
Iteration 80: train_loss 1.5422204732894897
Iteration 81: train_loss 1.5922430753707886
Iteration 82: train_loss 1.5969845056533813
Iteration 83: train_loss 1.5791127681732178
Iteration 84: train_loss 1.6241925954818726
Iteration 85: train_loss 1.5454716682434082
Iteration 86: train_loss 1.6496421098709106
Iteration 87: train_loss 1.6194418668746948
Iteration 88: train_loss 1.6229848861694336
Iteration 89: train_loss 1.6676417589187622
Iteration 90: train_loss 1.6421396732330322
Iteration 91: train_loss 1.587077260017395
Iteration 92: train_loss 1.6268001794815063
Iteration 93: train_loss 1.5771961212158203
Iteration 94: train_loss 1.5677716732025146
Iteration 95: train_loss 1.5969667434692383
Iteration 96: train_loss 1.689469814300537
Iteration 97: train_loss 1.6456795930862427
Iteration 98: train_loss 1.5866186618804932
Iteration 99: train_loss 1.6910004615783691
Iteration 100: train_loss 1.6591248512268066
Iteration 101: train_loss 1.7372431755065918
Iteration 102: train_loss 1.6835803985595703
Iteration 103: train_loss 1.6684112548828125
Iteration 104: train_loss 1.6415503025054932
Iteration 105: train_loss 1.5790760517120361
Iteration 106: train_loss 1.654611349105835
Iteration 107: train_loss 1.6124361753463745
Iteration 108: train_loss 1.6073858737945557
Iteration 109: train_loss 1.630854845046997
Iteration 110: train_loss 1.628231406211853
Iteration 111: train_loss 1.5599404573440552
Iteration 112: train_loss 1.6280659437179565
Iteration 113: train_loss 1.6025441884994507
Iteration 114: train_loss 1.537205457687378
Iteration 115: train_loss 1.6045359373092651
Iteration 116: train_loss 1.5727689266204834
Iteration 117: train_loss 1.5217602252960205
Iteration 118: train_loss 1.613677740097046
Iteration 119: train_loss 1.735988736152649
Iteration 120: train_loss 1.6311880350112915
Iteration 121: train_loss 1.6456091403961182
Iteration 122: train_loss 1.6150362491607666
Iteration 123: train_loss 1.6645206212997437
Iteration 124: train_loss 1.626178503036499
Iteration 125: train_loss 1.7278410196304321
Iteration 126: train_loss 1.6816843748092651
Iteration 127: train_loss 1.578836441040039
Iteration 128: train_loss 1.618306279182434
Iteration 129: train_loss 1.6493273973464966
Iteration 130: train_loss 1.6717844009399414
Iteration 131: train_loss 1.5739408731460571
Iteration 132: train_loss 1.701247215270996
Iteration 133: train_loss 1.6360548734664917
Iteration 134: train_loss 1.6760293245315552
Iteration 135: train_loss 1.658646583557129
Iteration 136: train_loss 1.578180193901062
Iteration 137: train_loss 1.6093391180038452
Iteration 138: train_loss 1.717436671257019
Iteration 139: train_loss 1.7020118236541748
Iteration 140: train_loss 1.589651107788086
Iteration 141: train_loss 1.6167175769805908
Iteration 142: train_loss 1.661205768585205
Iteration 143: train_loss 1.6784155368804932
Iteration 144: train_loss 1.7114139795303345
Iteration 145: train_loss 1.6170356273651123
Iteration 146: train_loss 1.61738121509552
Iteration 147: train_loss 1.7074381113052368
Iteration 148: train_loss 1.6625243425369263
Iteration 149: train_loss 1.699426293373108
Iteration 150: train_loss 1.65596342086792
Iteration 151: train_loss 1.58896803855896
Iteration 152: train_loss 1.647153377532959
Iteration 153: train_loss 1.7369437217712402
Iteration 154: train_loss 1.6221299171447754
Iteration 155: train_loss 1.6534347534179688
Iteration 156: train_loss 1.6592527627944946
Iteration 157: train_loss 1.5752469301223755
Iteration 158: train_loss 1.5763038396835327
Iteration 159: train_loss 1.6508750915527344
Iteration 160: train_loss 1.6734148263931274
Iteration 161: train_loss 1.6127296686172485
Iteration 162: train_loss 1.6153663396835327
Iteration 163: train_loss 1.5840965509414673
Iteration 164: train_loss 1.69602370262146
Iteration 165: train_loss 1.651110291481018
Iteration 166: train_loss 1.5911318063735962
Iteration 167: train_loss 1.5714629888534546
Iteration 168: train_loss 1.6822330951690674
Iteration 169: train_loss 1.607622504234314
Iteration 170: train_loss 1.6072741746902466
Iteration 171: train_loss 1.6295870542526245
Iteration 172: train_loss 1.6229420900344849
Iteration 173: train_loss 1.612777590751648
Iteration 174: train_loss 1.634015679359436
Iteration 175: train_loss 1.6506870985031128
Iteration 176: train_loss 1.7136505842208862
Iteration 177: train_loss 1.7309021949768066
Epoch 56: train_avg_loss 1.6215028715672466 eval_avg_acc: 0.34696224727921593 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:26:09] [32mIntermediate result: 0.34696224727921593  (Index 55)[0m
================Epoch: 57================
Iteration 1: train_loss 1.5612579584121704
Iteration 2: train_loss 1.5887541770935059
Iteration 3: train_loss 1.5788295269012451
Iteration 4: train_loss 1.5525245666503906
Iteration 5: train_loss 1.6165046691894531
Iteration 6: train_loss 1.6021409034729004
Iteration 7: train_loss 1.556363821029663
Iteration 8: train_loss 1.5451769828796387
Iteration 9: train_loss 1.5203362703323364
Iteration 10: train_loss 1.571142315864563
Iteration 11: train_loss 1.5397520065307617
Iteration 12: train_loss 1.5694607496261597
Iteration 13: train_loss 1.6228485107421875
Iteration 14: train_loss 1.622944951057434
Iteration 15: train_loss 1.6098425388336182
Iteration 16: train_loss 1.6336023807525635
Iteration 17: train_loss 1.643697738647461
Iteration 18: train_loss 1.5919708013534546
Iteration 19: train_loss 1.5611364841461182
Iteration 20: train_loss 1.6031466722488403
Iteration 21: train_loss 1.5620609521865845
Iteration 22: train_loss 1.599791169166565
Iteration 23: train_loss 1.5471251010894775
Iteration 24: train_loss 1.5803041458129883
Iteration 25: train_loss 1.532975196838379
Iteration 26: train_loss 1.5873469114303589
Iteration 27: train_loss 1.6142679452896118
Iteration 28: train_loss 1.618759274482727
Iteration 29: train_loss 1.5529953241348267
Iteration 30: train_loss 1.6003808975219727
Iteration 31: train_loss 1.6363859176635742
Iteration 32: train_loss 1.649938941001892
Iteration 33: train_loss 1.532809853553772
Iteration 34: train_loss 1.6097043752670288
Iteration 35: train_loss 1.6014617681503296
Iteration 36: train_loss 1.6344051361083984
Iteration 37: train_loss 1.5661247968673706
Iteration 38: train_loss 1.583520531654358
Iteration 39: train_loss 1.6037461757659912
Iteration 40: train_loss 1.5699185132980347
Iteration 41: train_loss 1.6732333898544312
Iteration 42: train_loss 1.5721805095672607
Iteration 43: train_loss 1.5746326446533203
Iteration 44: train_loss 1.631765604019165
Iteration 45: train_loss 1.602983832359314
Iteration 46: train_loss 1.717397689819336
Iteration 47: train_loss 1.623652696609497
Iteration 48: train_loss 1.6389864683151245
Iteration 49: train_loss 1.7524197101593018
Iteration 50: train_loss 1.6401697397232056
Iteration 51: train_loss 1.6305516958236694
Iteration 52: train_loss 1.5536686182022095
Iteration 53: train_loss 1.6095470190048218
Iteration 54: train_loss 1.5861294269561768
Iteration 55: train_loss 1.6454788446426392
Iteration 56: train_loss 1.5846612453460693
Iteration 57: train_loss 1.5996757745742798
Iteration 58: train_loss 1.5860438346862793
Iteration 59: train_loss 1.625128984451294
Iteration 60: train_loss 1.6648865938186646
Iteration 61: train_loss 1.6431982517242432
Iteration 62: train_loss 1.6384779214859009
Iteration 63: train_loss 1.5614250898361206
Iteration 64: train_loss 1.5759495496749878
Iteration 65: train_loss 1.6097521781921387
Iteration 66: train_loss 1.5949976444244385
Iteration 67: train_loss 1.5544124841690063
Iteration 68: train_loss 1.6520389318466187
Iteration 69: train_loss 1.625100016593933
Iteration 70: train_loss 1.6176055669784546
Iteration 71: train_loss 1.5741603374481201
Iteration 72: train_loss 1.5923535823822021
Iteration 73: train_loss 1.6318095922470093
Iteration 74: train_loss 1.6495695114135742
Iteration 75: train_loss 1.683379054069519
Iteration 76: train_loss 1.639244556427002
Iteration 77: train_loss 1.5564088821411133
Iteration 78: train_loss 1.618728756904602
Iteration 79: train_loss 1.6275931596755981
Iteration 80: train_loss 1.6202811002731323
Iteration 81: train_loss 1.591693639755249
Iteration 82: train_loss 1.593127965927124
Iteration 83: train_loss 1.6114615201950073
Iteration 84: train_loss 1.6039364337921143
Iteration 85: train_loss 1.5631812810897827
Iteration 86: train_loss 1.6097939014434814
Iteration 87: train_loss 1.6083964109420776
Iteration 88: train_loss 1.6283661127090454
Iteration 89: train_loss 1.6181422472000122
Iteration 90: train_loss 1.5707422494888306
Iteration 91: train_loss 1.6462956666946411
Iteration 92: train_loss 1.602169156074524
Iteration 93: train_loss 1.6224218606948853
Iteration 94: train_loss 1.624489188194275
Iteration 95: train_loss 1.5939788818359375
Iteration 96: train_loss 1.639976143836975
Iteration 97: train_loss 1.6282309293746948
Iteration 98: train_loss 1.5496580600738525
Iteration 99: train_loss 1.6506067514419556
Iteration 100: train_loss 1.6628886461257935
Iteration 101: train_loss 1.6409237384796143
Iteration 102: train_loss 1.645803451538086
Iteration 103: train_loss 1.60211181640625
Iteration 104: train_loss 1.602950096130371
Iteration 105: train_loss 1.7321654558181763
Iteration 106: train_loss 1.6390963792800903
Iteration 107: train_loss 1.6277133226394653
Iteration 108: train_loss 1.6536977291107178
Iteration 109: train_loss 1.6040749549865723
Iteration 110: train_loss 1.6123863458633423
Iteration 111: train_loss 1.7048897743225098
Iteration 112: train_loss 1.5868457555770874
Iteration 113: train_loss 1.653065800666809
Iteration 114: train_loss 1.688839316368103
Iteration 115: train_loss 1.6527047157287598
Iteration 116: train_loss 1.5982768535614014
Iteration 117: train_loss 1.6232119798660278
Iteration 118: train_loss 1.7030752897262573
Iteration 119: train_loss 1.6450068950653076
Iteration 120: train_loss 1.6052472591400146
Iteration 121: train_loss 1.6773287057876587
Iteration 122: train_loss 1.6128871440887451
Iteration 123: train_loss 1.7352917194366455
Iteration 124: train_loss 1.636161208152771
Iteration 125: train_loss 1.681233525276184
Iteration 126: train_loss 1.6861016750335693
Iteration 127: train_loss 1.6129735708236694
Iteration 128: train_loss 1.635368824005127
Iteration 129: train_loss 1.631927728652954
Iteration 130: train_loss 1.646085500717163
Iteration 131: train_loss 1.7040106058120728
Iteration 132: train_loss 1.6692490577697754
Iteration 133: train_loss 1.601029872894287
Iteration 134: train_loss 1.6356538534164429
Iteration 135: train_loss 1.6444076299667358
Iteration 136: train_loss 1.6760157346725464
Iteration 137: train_loss 1.687632441520691
Iteration 138: train_loss 1.6206637620925903
Iteration 139: train_loss 1.638279676437378
Iteration 140: train_loss 1.6449906826019287
Iteration 141: train_loss 1.6271897554397583
Iteration 142: train_loss 1.6154941320419312
Iteration 143: train_loss 1.5871254205703735
Iteration 144: train_loss 1.6342021226882935
Iteration 145: train_loss 1.6981000900268555
Iteration 146: train_loss 1.6731361150741577
Iteration 147: train_loss 1.6491121053695679
Iteration 148: train_loss 1.6103991270065308
Iteration 149: train_loss 1.623124361038208
Iteration 150: train_loss 1.6912951469421387
Iteration 151: train_loss 1.6132686138153076
Iteration 152: train_loss 1.6380512714385986
Iteration 153: train_loss 1.6360430717468262
Iteration 154: train_loss 1.7176908254623413
Iteration 155: train_loss 1.6012883186340332
Iteration 156: train_loss 1.6630460023880005
Iteration 157: train_loss 1.577206015586853
Iteration 158: train_loss 1.7032322883605957
Iteration 159: train_loss 1.5622100830078125
Iteration 160: train_loss 1.622523546218872
Iteration 161: train_loss 1.5974513292312622
Iteration 162: train_loss 1.7044917345046997
Iteration 163: train_loss 1.6142828464508057
Iteration 164: train_loss 1.6152359247207642
Iteration 165: train_loss 1.6052873134613037
Iteration 166: train_loss 1.5977672338485718
Iteration 167: train_loss 1.6982465982437134
Iteration 168: train_loss 1.6131970882415771
Iteration 169: train_loss 1.6471335887908936
Iteration 170: train_loss 1.6875368356704712
Iteration 171: train_loss 1.6683086156845093
Iteration 172: train_loss 1.6788597106933594
Iteration 173: train_loss 1.7039047479629517
Iteration 174: train_loss 1.600824236869812
Iteration 175: train_loss 1.577633261680603
Iteration 176: train_loss 1.5897142887115479
Iteration 177: train_loss 1.6713893413543701
Epoch 57: train_avg_loss 1.6214072172251124 eval_avg_acc: 0.32062454051657 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:26:50] [32mIntermediate result: 0.32062454051657  (Index 56)[0m
================Epoch: 58================
Iteration 1: train_loss 1.6652971506118774
Iteration 2: train_loss 1.6454557180404663
Iteration 3: train_loss 1.6826330423355103
Iteration 4: train_loss 1.6798616647720337
Iteration 5: train_loss 1.6073161363601685
Iteration 6: train_loss 1.5743950605392456
Iteration 7: train_loss 1.6024253368377686
Iteration 8: train_loss 1.6090203523635864
Iteration 9: train_loss 1.5951279401779175
Iteration 10: train_loss 1.5494087934494019
Iteration 11: train_loss 1.6058502197265625
Iteration 12: train_loss 1.5709902048110962
Iteration 13: train_loss 1.6224952936172485
Iteration 14: train_loss 1.6394562721252441
Iteration 15: train_loss 1.558253288269043
Iteration 16: train_loss 1.5979413986206055
Iteration 17: train_loss 1.5666972398757935
Iteration 18: train_loss 1.6218780279159546
Iteration 19: train_loss 1.5578280687332153
Iteration 20: train_loss 1.552683711051941
Iteration 21: train_loss 1.6184616088867188
Iteration 22: train_loss 1.5356535911560059
Iteration 23: train_loss 1.6371268033981323
Iteration 24: train_loss 1.6869630813598633
Iteration 25: train_loss 1.5928256511688232
Iteration 26: train_loss 1.5708926916122437
Iteration 27: train_loss 1.6134095191955566
Iteration 28: train_loss 1.6351436376571655
Iteration 29: train_loss 1.5806654691696167
Iteration 30: train_loss 1.633719801902771
Iteration 31: train_loss 1.5645352602005005
Iteration 32: train_loss 1.6034531593322754
Iteration 33: train_loss 1.6028944253921509
Iteration 34: train_loss 1.659940481185913
Iteration 35: train_loss 1.5919499397277832
Iteration 36: train_loss 1.634629249572754
Iteration 37: train_loss 1.604358196258545
Iteration 38: train_loss 1.534174919128418
Iteration 39: train_loss 1.59253990650177
Iteration 40: train_loss 1.6794382333755493
Iteration 41: train_loss 1.6195013523101807
Iteration 42: train_loss 1.5763084888458252
Iteration 43: train_loss 1.6108992099761963
Iteration 44: train_loss 1.6639364957809448
Iteration 45: train_loss 1.6140276193618774
Iteration 46: train_loss 1.58358633518219
Iteration 47: train_loss 1.6573708057403564
Iteration 48: train_loss 1.6056983470916748
Iteration 49: train_loss 1.6337072849273682
Iteration 50: train_loss 1.5925219058990479
Iteration 51: train_loss 1.6368927955627441
Iteration 52: train_loss 1.572120189666748
Iteration 53: train_loss 1.6111509799957275
Iteration 54: train_loss 1.6383154392242432
Iteration 55: train_loss 1.6490046977996826
Iteration 56: train_loss 1.5950318574905396
Iteration 57: train_loss 1.7483800649642944
Iteration 58: train_loss 1.6945537328720093
Iteration 59: train_loss 1.6375305652618408
Iteration 60: train_loss 1.5454576015472412
Iteration 61: train_loss 1.6426308155059814
Iteration 62: train_loss 1.685182809829712
Iteration 63: train_loss 1.6257635354995728
Iteration 64: train_loss 1.6041070222854614
Iteration 65: train_loss 1.6060608625411987
Iteration 66: train_loss 1.6766729354858398
Iteration 67: train_loss 1.5956647396087646
Iteration 68: train_loss 1.5803614854812622
Iteration 69: train_loss 1.5746831893920898
Iteration 70: train_loss 1.6168062686920166
Iteration 71: train_loss 1.6493518352508545
Iteration 72: train_loss 1.6570656299591064
Iteration 73: train_loss 1.6288962364196777
Iteration 74: train_loss 1.5346957445144653
Iteration 75: train_loss 1.6459157466888428
Iteration 76: train_loss 1.5978384017944336
Iteration 77: train_loss 1.5943028926849365
Iteration 78: train_loss 1.640229344367981
Iteration 79: train_loss 1.6424560546875
Iteration 80: train_loss 1.5946249961853027
Iteration 81: train_loss 1.6242291927337646
Iteration 82: train_loss 1.4903579950332642
Iteration 83: train_loss 1.595094084739685
Iteration 84: train_loss 1.5734730958938599
Iteration 85: train_loss 1.614780306816101
Iteration 86: train_loss 1.5914273262023926
Iteration 87: train_loss 1.6571611166000366
Iteration 88: train_loss 1.5875873565673828
Iteration 89: train_loss 1.625346064567566
Iteration 90: train_loss 1.6626865863800049
Iteration 91: train_loss 1.6430834531784058
Iteration 92: train_loss 1.6266916990280151
Iteration 93: train_loss 1.6100667715072632
Iteration 94: train_loss 1.615585207939148
Iteration 95: train_loss 1.6274152994155884
Iteration 96: train_loss 1.625064492225647
Iteration 97: train_loss 1.6572067737579346
Iteration 98: train_loss 1.6656899452209473
Iteration 99: train_loss 1.5677746534347534
Iteration 100: train_loss 1.64413321018219
Iteration 101: train_loss 1.6316531896591187
Iteration 102: train_loss 1.673172950744629
Iteration 103: train_loss 1.6627978086471558
Iteration 104: train_loss 1.6145998239517212
Iteration 105: train_loss 1.5491701364517212
Iteration 106: train_loss 1.7297062873840332
Iteration 107: train_loss 1.6626794338226318
Iteration 108: train_loss 1.5949116945266724
Iteration 109: train_loss 1.630941390991211
Iteration 110: train_loss 1.6735354661941528
Iteration 111: train_loss 1.6991645097732544
Iteration 112: train_loss 1.677364706993103
Iteration 113: train_loss 1.6189743280410767
Iteration 114: train_loss 1.5993188619613647
Iteration 115: train_loss 1.564544439315796
Iteration 116: train_loss 1.6471500396728516
Iteration 117: train_loss 1.6469357013702393
Iteration 118: train_loss 1.6021891832351685
Iteration 119: train_loss 1.6342357397079468
Iteration 120: train_loss 1.5998107194900513
Iteration 121: train_loss 1.6511256694793701
Iteration 122: train_loss 1.6340693235397339
Iteration 123: train_loss 1.5576597452163696
Iteration 124: train_loss 1.5619840621948242
Iteration 125: train_loss 1.6409382820129395
Iteration 126: train_loss 1.6263011693954468
Iteration 127: train_loss 1.5757622718811035
Iteration 128: train_loss 1.5683645009994507
Iteration 129: train_loss 1.5988677740097046
Iteration 130: train_loss 1.6702975034713745
Iteration 131: train_loss 1.607139229774475
Iteration 132: train_loss 1.63783860206604
Iteration 133: train_loss 1.6784037351608276
Iteration 134: train_loss 1.6325169801712036
Iteration 135: train_loss 1.556236982345581
Iteration 136: train_loss 1.677328109741211
Iteration 137: train_loss 1.6695640087127686
Iteration 138: train_loss 1.5966845750808716
Iteration 139: train_loss 1.6598478555679321
Iteration 140: train_loss 1.6839371919631958
Iteration 141: train_loss 1.580289363861084
Iteration 142: train_loss 1.6039766073226929
Iteration 143: train_loss 1.637725591659546
Iteration 144: train_loss 1.6380232572555542
Iteration 145: train_loss 1.6854963302612305
Iteration 146: train_loss 1.5974818468093872
Iteration 147: train_loss 1.6879409551620483
Iteration 148: train_loss 1.6688549518585205
Iteration 149: train_loss 1.6225422620773315
Iteration 150: train_loss 1.6693710088729858
Iteration 151: train_loss 1.6470988988876343
Iteration 152: train_loss 1.6883854866027832
Iteration 153: train_loss 1.611017107963562
Iteration 154: train_loss 1.551538348197937
Iteration 155: train_loss 1.5844192504882812
Iteration 156: train_loss 1.6223360300064087
Iteration 157: train_loss 1.5309090614318848
Iteration 158: train_loss 1.59565269947052
Iteration 159: train_loss 1.6607105731964111
Iteration 160: train_loss 1.7151581048965454
Iteration 161: train_loss 1.5916873216629028
Iteration 162: train_loss 1.6268751621246338
Iteration 163: train_loss 1.6241832971572876
Iteration 164: train_loss 1.6356499195098877
Iteration 165: train_loss 1.573053240776062
Iteration 166: train_loss 1.6705785989761353
Iteration 167: train_loss 1.5738153457641602
Iteration 168: train_loss 1.6530380249023438
Iteration 169: train_loss 1.643694519996643
Iteration 170: train_loss 1.5763320922851562
Iteration 171: train_loss 1.619887351989746
Iteration 172: train_loss 1.5928739309310913
Iteration 173: train_loss 1.6369119882583618
Iteration 174: train_loss 1.6068686246871948
Iteration 175: train_loss 1.6426265239715576
Iteration 176: train_loss 1.5941871404647827
Iteration 177: train_loss 1.710172414779663
Epoch 58: train_avg_loss 1.620514343013871 eval_avg_acc: 0.3143383381971109 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:27:32] [32mIntermediate result: 0.3143383381971109  (Index 57)[0m
================Epoch: 59================
Iteration 1: train_loss 1.6198714971542358
Iteration 2: train_loss 1.5697193145751953
Iteration 3: train_loss 1.5925884246826172
Iteration 4: train_loss 1.5573674440383911
Iteration 5: train_loss 1.552730917930603
Iteration 6: train_loss 1.5349311828613281
Iteration 7: train_loss 1.5499438047409058
Iteration 8: train_loss 1.5420219898223877
Iteration 9: train_loss 1.5479471683502197
Iteration 10: train_loss 1.5350492000579834
Iteration 11: train_loss 1.5721948146820068
Iteration 12: train_loss 1.560326337814331
Iteration 13: train_loss 1.557175874710083
Iteration 14: train_loss 1.5558794736862183
Iteration 15: train_loss 1.5843464136123657
Iteration 16: train_loss 1.6688791513442993
Iteration 17: train_loss 1.531795620918274
Iteration 18: train_loss 1.5071353912353516
Iteration 19: train_loss 1.5948944091796875
Iteration 20: train_loss 1.5830684900283813
Iteration 21: train_loss 1.552123785018921
Iteration 22: train_loss 1.573706030845642
Iteration 23: train_loss 1.6031196117401123
Iteration 24: train_loss 1.5509716272354126
Iteration 25: train_loss 1.5820084810256958
Iteration 26: train_loss 1.6343070268630981
Iteration 27: train_loss 1.589634895324707
Iteration 28: train_loss 1.5058280229568481
Iteration 29: train_loss 1.4986588954925537
Iteration 30: train_loss 1.6299309730529785
Iteration 31: train_loss 1.5174729824066162
Iteration 32: train_loss 1.5913152694702148
Iteration 33: train_loss 1.5737955570220947
Iteration 34: train_loss 1.6070499420166016
Iteration 35: train_loss 1.601289987564087
Iteration 36: train_loss 1.524055004119873
Iteration 37: train_loss 1.5174741744995117
Iteration 38: train_loss 1.5047013759613037
Iteration 39: train_loss 1.6141525506973267
Iteration 40: train_loss 1.6167840957641602
Iteration 41: train_loss 1.6336681842803955
Iteration 42: train_loss 1.533993124961853
Iteration 43: train_loss 1.580401062965393
Iteration 44: train_loss 1.541139006614685
Iteration 45: train_loss 1.5847020149230957
Iteration 46: train_loss 1.568758487701416
Iteration 47: train_loss 1.6084392070770264
Iteration 48: train_loss 1.634060025215149
Iteration 49: train_loss 1.632825493812561
Iteration 50: train_loss 1.6311839818954468
Iteration 51: train_loss 1.5099084377288818
Iteration 52: train_loss 1.6337482929229736
Iteration 53: train_loss 1.602118968963623
Iteration 54: train_loss 1.595417857170105
Iteration 55: train_loss 1.5684213638305664
Iteration 56: train_loss 1.584649920463562
Iteration 57: train_loss 1.5847041606903076
Iteration 58: train_loss 1.608452558517456
Iteration 59: train_loss 1.6449564695358276
Iteration 60: train_loss 1.5677515268325806
Iteration 61: train_loss 1.5664669275283813
Iteration 62: train_loss 1.6349009275436401
Iteration 63: train_loss 1.5593034029006958
Iteration 64: train_loss 1.558084487915039
Iteration 65: train_loss 1.6316359043121338
Iteration 66: train_loss 1.640692949295044
Iteration 67: train_loss 1.5941998958587646
Iteration 68: train_loss 1.6488581895828247
Iteration 69: train_loss 1.6077724695205688
Iteration 70: train_loss 1.6350469589233398
Iteration 71: train_loss 1.615322470664978
Iteration 72: train_loss 1.6864264011383057
Iteration 73: train_loss 1.605512022972107
Iteration 74: train_loss 1.6467721462249756
Iteration 75: train_loss 1.6179357767105103
Iteration 76: train_loss 1.596930980682373
Iteration 77: train_loss 1.5986067056655884
Iteration 78: train_loss 1.5999884605407715
Iteration 79: train_loss 1.52834153175354
Iteration 80: train_loss 1.627728819847107
Iteration 81: train_loss 1.6454670429229736
Iteration 82: train_loss 1.6700944900512695
Iteration 83: train_loss 1.669886589050293
Iteration 84: train_loss 1.6227445602416992
Iteration 85: train_loss 1.5920032262802124
Iteration 86: train_loss 1.6027735471725464
Iteration 87: train_loss 1.6214020252227783
Iteration 88: train_loss 1.6589146852493286
Iteration 89: train_loss 1.6637213230133057
Iteration 90: train_loss 1.5869396924972534
Iteration 91: train_loss 1.7099401950836182
Iteration 92: train_loss 1.6508119106292725
Iteration 93: train_loss 1.6467212438583374
Iteration 94: train_loss 1.6105194091796875
Iteration 95: train_loss 1.6435248851776123
Iteration 96: train_loss 1.5999480485916138
Iteration 97: train_loss 1.6821082830429077
Iteration 98: train_loss 1.6508065462112427
Iteration 99: train_loss 1.5979112386703491
Iteration 100: train_loss 1.6710535287857056
Iteration 101: train_loss 1.6093051433563232
Iteration 102: train_loss 1.5822110176086426
Iteration 103: train_loss 1.6057231426239014
Iteration 104: train_loss 1.5980949401855469
Iteration 105: train_loss 1.6017358303070068
Iteration 106: train_loss 1.6192903518676758
Iteration 107: train_loss 1.6591440439224243
Iteration 108: train_loss 1.576703429222107
Iteration 109: train_loss 1.6462156772613525
Iteration 110: train_loss 1.635879635810852
Iteration 111: train_loss 1.6131982803344727
Iteration 112: train_loss 1.637439250946045
Iteration 113: train_loss 1.6231282949447632
Iteration 114: train_loss 1.630301594734192
Iteration 115: train_loss 1.6001249551773071
Iteration 116: train_loss 1.6250874996185303
Iteration 117: train_loss 1.613519310951233
Iteration 118: train_loss 1.638898491859436
Iteration 119: train_loss 1.6291325092315674
Iteration 120: train_loss 1.630171298980713
Iteration 121: train_loss 1.6500744819641113
Iteration 122: train_loss 1.6329021453857422
Iteration 123: train_loss 1.624909520149231
Iteration 124: train_loss 1.6100876331329346
Iteration 125: train_loss 1.5999817848205566
Iteration 126: train_loss 1.5597038269042969
Iteration 127: train_loss 1.5660425424575806
Iteration 128: train_loss 1.5817824602127075
Iteration 129: train_loss 1.5799880027770996
Iteration 130: train_loss 1.6086989641189575
Iteration 131: train_loss 1.6680073738098145
Iteration 132: train_loss 1.6795929670333862
Iteration 133: train_loss 1.5580615997314453
Iteration 134: train_loss 1.6405161619186401
Iteration 135: train_loss 1.6283535957336426
Iteration 136: train_loss 1.6517082452774048
Iteration 137: train_loss 1.6740655899047852
Iteration 138: train_loss 1.5623081922531128
Iteration 139: train_loss 1.6092395782470703
Iteration 140: train_loss 1.621899962425232
Iteration 141: train_loss 1.6539559364318848
Iteration 142: train_loss 1.6547141075134277
Iteration 143: train_loss 1.653558373451233
Iteration 144: train_loss 1.6693429946899414
Iteration 145: train_loss 1.594744086265564
Iteration 146: train_loss 1.6527559757232666
Iteration 147: train_loss 1.6160674095153809
Iteration 148: train_loss 1.625348687171936
Iteration 149: train_loss 1.6223249435424805
Iteration 150: train_loss 1.668106198310852
Iteration 151: train_loss 1.5752692222595215
Iteration 152: train_loss 1.583109736442566
Iteration 153: train_loss 1.5904114246368408
Iteration 154: train_loss 1.6399288177490234
Iteration 155: train_loss 1.589266300201416
Iteration 156: train_loss 1.647485375404358
Iteration 157: train_loss 1.7342605590820312
Iteration 158: train_loss 1.6693261861801147
Iteration 159: train_loss 1.5911533832550049
Iteration 160: train_loss 1.6430401802062988
Iteration 161: train_loss 1.6162663698196411
Iteration 162: train_loss 1.6339341402053833
Iteration 163: train_loss 1.6569273471832275
Iteration 164: train_loss 1.6809524297714233
Iteration 165: train_loss 1.63363778591156
Iteration 166: train_loss 1.626021385192871
Iteration 167: train_loss 1.6665852069854736
Iteration 168: train_loss 1.595232605934143
Iteration 169: train_loss 1.6066482067108154
Iteration 170: train_loss 1.6821866035461426
Iteration 171: train_loss 1.6013907194137573
Iteration 172: train_loss 1.5443124771118164
Iteration 173: train_loss 1.6506564617156982
Iteration 174: train_loss 1.6533468961715698
Iteration 175: train_loss 1.6036454439163208
Iteration 176: train_loss 1.6559643745422363
Iteration 177: train_loss 1.6563900709152222
Epoch 59: train_avg_loss 1.6083325706632798 eval_avg_acc: 0.34348198694891585 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:28:13] [32mIntermediate result: 0.34348198694891585  (Index 58)[0m
================Epoch: 60================
Iteration 1: train_loss 1.5817722082138062
Iteration 2: train_loss 1.576414942741394
Iteration 3: train_loss 1.6161755323410034
Iteration 4: train_loss 1.634967565536499
Iteration 5: train_loss 1.5489474534988403
Iteration 6: train_loss 1.6122770309448242
Iteration 7: train_loss 1.5823208093643188
Iteration 8: train_loss 1.5008474588394165
Iteration 9: train_loss 1.5921709537506104
Iteration 10: train_loss 1.594287395477295
Iteration 11: train_loss 1.60910964012146
Iteration 12: train_loss 1.542839765548706
Iteration 13: train_loss 1.6064260005950928
Iteration 14: train_loss 1.5810344219207764
Iteration 15: train_loss 1.5553960800170898
Iteration 16: train_loss 1.5744819641113281
Iteration 17: train_loss 1.5257301330566406
Iteration 18: train_loss 1.5099482536315918
Iteration 19: train_loss 1.6091341972351074
Iteration 20: train_loss 1.5646270513534546
Iteration 21: train_loss 1.6260205507278442
Iteration 22: train_loss 1.5984584093093872
Iteration 23: train_loss 1.6117852926254272
Iteration 24: train_loss 1.5675712823867798
Iteration 25: train_loss 1.534255027770996
Iteration 26: train_loss 1.529097557067871
Iteration 27: train_loss 1.5336673259735107
Iteration 28: train_loss 1.5533095598220825
Iteration 29: train_loss 1.5777350664138794
Iteration 30: train_loss 1.574583888053894
Iteration 31: train_loss 1.643898367881775
Iteration 32: train_loss 1.550010085105896
Iteration 33: train_loss 1.5387011766433716
Iteration 34: train_loss 1.564078450202942
Iteration 35: train_loss 1.5533314943313599
Iteration 36: train_loss 1.535896897315979
Iteration 37: train_loss 1.5769305229187012
Iteration 38: train_loss 1.612368106842041
Iteration 39: train_loss 1.6605372428894043
Iteration 40: train_loss 1.6499075889587402
Iteration 41: train_loss 1.5931271314620972
Iteration 42: train_loss 1.6233457326889038
Iteration 43: train_loss 1.602246880531311
Iteration 44: train_loss 1.6377222537994385
Iteration 45: train_loss 1.6131089925765991
Iteration 46: train_loss 1.6990585327148438
Iteration 47: train_loss 1.5827579498291016
Iteration 48: train_loss 1.6064494848251343
Iteration 49: train_loss 1.6683249473571777
Iteration 50: train_loss 1.6639424562454224
Iteration 51: train_loss 1.5512617826461792
Iteration 52: train_loss 1.6389210224151611
Iteration 53: train_loss 1.6522315740585327
Iteration 54: train_loss 1.574988603591919
Iteration 55: train_loss 1.5863902568817139
Iteration 56: train_loss 1.5473525524139404
Iteration 57: train_loss 1.6054069995880127
Iteration 58: train_loss 1.5721231698989868
Iteration 59: train_loss 1.5476915836334229
Iteration 60: train_loss 1.6203047037124634
Iteration 61: train_loss 1.5737336874008179
Iteration 62: train_loss 1.5447152853012085
Iteration 63: train_loss 1.5941452980041504
Iteration 64: train_loss 1.5400876998901367
Iteration 65: train_loss 1.6480662822723389
Iteration 66: train_loss 1.6805369853973389
Iteration 67: train_loss 1.5989913940429688
Iteration 68: train_loss 1.5905927419662476
Iteration 69: train_loss 1.5892863273620605
Iteration 70: train_loss 1.5567591190338135
Iteration 71: train_loss 1.6145293712615967
Iteration 72: train_loss 1.490824818611145
Iteration 73: train_loss 1.5962470769882202
Iteration 74: train_loss 1.6343220472335815
Iteration 75: train_loss 1.5449504852294922
Iteration 76: train_loss 1.518445611000061
Iteration 77: train_loss 1.6052675247192383
Iteration 78: train_loss 1.5999443531036377
Iteration 79: train_loss 1.5360027551651
Iteration 80: train_loss 1.6234928369522095
Iteration 81: train_loss 1.6530717611312866
Iteration 82: train_loss 1.575137972831726
Iteration 83: train_loss 1.5666742324829102
Iteration 84: train_loss 1.6138726472854614
Iteration 85: train_loss 1.5950196981430054
Iteration 86: train_loss 1.721410870552063
Iteration 87: train_loss 1.654401421546936
Iteration 88: train_loss 1.6276837587356567
Iteration 89: train_loss 1.641358733177185
Iteration 90: train_loss 1.663610816001892
Iteration 91: train_loss 1.5379472970962524
Iteration 92: train_loss 1.639129638671875
Iteration 93: train_loss 1.5642660856246948
Iteration 94: train_loss 1.577346682548523
Iteration 95: train_loss 1.6518924236297607
Iteration 96: train_loss 1.5985283851623535
Iteration 97: train_loss 1.6173861026763916
Iteration 98: train_loss 1.584597110748291
Iteration 99: train_loss 1.5413413047790527
Iteration 100: train_loss 1.649008870124817
Iteration 101: train_loss 1.6463661193847656
Iteration 102: train_loss 1.540266513824463
Iteration 103: train_loss 1.629951000213623
Iteration 104: train_loss 1.5753910541534424
Iteration 105: train_loss 1.5577683448791504
Iteration 106: train_loss 1.625599980354309
Iteration 107: train_loss 1.6009931564331055
Iteration 108: train_loss 1.6298223733901978
Iteration 109: train_loss 1.6474393606185913
Iteration 110: train_loss 1.6074002981185913
Iteration 111: train_loss 1.6212438344955444
Iteration 112: train_loss 1.5807712078094482
Iteration 113: train_loss 1.5784063339233398
Iteration 114: train_loss 1.5802111625671387
Iteration 115: train_loss 1.597915530204773
Iteration 116: train_loss 1.6410659551620483
Iteration 117: train_loss 1.5995796918869019
Iteration 118: train_loss 1.6234437227249146
Iteration 119: train_loss 1.6274334192276
Iteration 120: train_loss 1.620545744895935
Iteration 121: train_loss 1.6692782640457153
Iteration 122: train_loss 1.630726933479309
Iteration 123: train_loss 1.6640554666519165
Iteration 124: train_loss 1.6512091159820557
Iteration 125: train_loss 1.6088494062423706
Iteration 126: train_loss 1.6098092794418335
Iteration 127: train_loss 1.565320611000061
Iteration 128: train_loss 1.6453007459640503
Iteration 129: train_loss 1.601962685585022
Iteration 130: train_loss 1.7275997400283813
Iteration 131: train_loss 1.6496127843856812
Iteration 132: train_loss 1.5948240756988525
Iteration 133: train_loss 1.5687503814697266
Iteration 134: train_loss 1.648101806640625
Iteration 135: train_loss 1.611967921257019
Iteration 136: train_loss 1.6932387351989746
Iteration 137: train_loss 1.6490989923477173
Iteration 138: train_loss 1.591578483581543
Iteration 139: train_loss 1.6150643825531006
Iteration 140: train_loss 1.6088758707046509
Iteration 141: train_loss 1.62396240234375
Iteration 142: train_loss 1.6134551763534546
Iteration 143: train_loss 1.619796872138977
Iteration 144: train_loss 1.6082019805908203
Iteration 145: train_loss 1.565988302230835
Iteration 146: train_loss 1.630061388015747
Iteration 147: train_loss 1.615261435508728
Iteration 148: train_loss 1.6222145557403564
Iteration 149: train_loss 1.6349159479141235
Iteration 150: train_loss 1.542223572731018
Iteration 151: train_loss 1.6085833311080933
Iteration 152: train_loss 1.623256802558899
Iteration 153: train_loss 1.578316569328308
Iteration 154: train_loss 1.7024437189102173
Iteration 155: train_loss 1.526900053024292
Iteration 156: train_loss 1.628724455833435
Iteration 157: train_loss 1.5869094133377075
Iteration 158: train_loss 1.661592721939087
Iteration 159: train_loss 1.67594575881958
Iteration 160: train_loss 1.6190834045410156
Iteration 161: train_loss 1.564339280128479
Iteration 162: train_loss 1.6797146797180176
Iteration 163: train_loss 1.5963385105133057
Iteration 164: train_loss 1.622086763381958
Iteration 165: train_loss 1.5350223779678345
Iteration 166: train_loss 1.5741544961929321
Iteration 167: train_loss 1.6240414381027222
Iteration 168: train_loss 1.629058837890625
Iteration 169: train_loss 1.6732395887374878
Iteration 170: train_loss 1.5937395095825195
Iteration 171: train_loss 1.5947470664978027
Iteration 172: train_loss 1.6033120155334473
Iteration 173: train_loss 1.629960060119629
Iteration 174: train_loss 1.5953257083892822
Iteration 175: train_loss 1.6088167428970337
Iteration 176: train_loss 1.555486798286438
Iteration 177: train_loss 1.579969882965088
Epoch 60: train_avg_loss 1.6019009547045002 eval_avg_acc: 0.34461927990214447 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:28:54] [32mIntermediate result: 0.34461927990214447  (Index 59)[0m
================Epoch: 61================
Iteration 1: train_loss 1.6053310632705688
Iteration 2: train_loss 1.5888473987579346
Iteration 3: train_loss 1.5649292469024658
Iteration 4: train_loss 1.5580798387527466
Iteration 5: train_loss 1.5714601278305054
Iteration 6: train_loss 1.5592821836471558
Iteration 7: train_loss 1.5353251695632935
Iteration 8: train_loss 1.5776606798171997
Iteration 9: train_loss 1.5723501443862915
Iteration 10: train_loss 1.5511093139648438
Iteration 11: train_loss 1.5198090076446533
Iteration 12: train_loss 1.606867790222168
Iteration 13: train_loss 1.5698058605194092
Iteration 14: train_loss 1.6374458074569702
Iteration 15: train_loss 1.558062195777893
Iteration 16: train_loss 1.5940083265304565
Iteration 17: train_loss 1.5345157384872437
Iteration 18: train_loss 1.5460197925567627
Iteration 19: train_loss 1.5272083282470703
Iteration 20: train_loss 1.5952975749969482
Iteration 21: train_loss 1.5072575807571411
Iteration 22: train_loss 1.4953685998916626
Iteration 23: train_loss 1.5391769409179688
Iteration 24: train_loss 1.5829973220825195
Iteration 25: train_loss 1.561530590057373
Iteration 26: train_loss 1.5189779996871948
Iteration 27: train_loss 1.5507563352584839
Iteration 28: train_loss 1.584847331047058
Iteration 29: train_loss 1.6218971014022827
Iteration 30: train_loss 1.5117231607437134
Iteration 31: train_loss 1.5129514932632446
Iteration 32: train_loss 1.5854697227478027
Iteration 33: train_loss 1.6241925954818726
Iteration 34: train_loss 1.5849802494049072
Iteration 35: train_loss 1.5413777828216553
Iteration 36: train_loss 1.4835280179977417
Iteration 37: train_loss 1.5983572006225586
Iteration 38: train_loss 1.6703838109970093
Iteration 39: train_loss 1.5506168603897095
Iteration 40: train_loss 1.5950608253479004
Iteration 41: train_loss 1.56974458694458
Iteration 42: train_loss 1.573712944984436
Iteration 43: train_loss 1.549220085144043
Iteration 44: train_loss 1.5621042251586914
Iteration 45: train_loss 1.5534049272537231
Iteration 46: train_loss 1.5508886575698853
Iteration 47: train_loss 1.5755385160446167
Iteration 48: train_loss 1.5980679988861084
Iteration 49: train_loss 1.5600744485855103
Iteration 50: train_loss 1.6328623294830322
Iteration 51: train_loss 1.578784465789795
Iteration 52: train_loss 1.5381840467453003
Iteration 53: train_loss 1.6198710203170776
Iteration 54: train_loss 1.5324218273162842
Iteration 55: train_loss 1.61357843875885
Iteration 56: train_loss 1.6397650241851807
Iteration 57: train_loss 1.5688371658325195
Iteration 58: train_loss 1.5682718753814697
Iteration 59: train_loss 1.5058236122131348
Iteration 60: train_loss 1.5746535062789917
Iteration 61: train_loss 1.5489295721054077
Iteration 62: train_loss 1.5645411014556885
Iteration 63: train_loss 1.5422463417053223
Iteration 64: train_loss 1.5629247426986694
Iteration 65: train_loss 1.5131186246871948
Iteration 66: train_loss 1.5722321271896362
Iteration 67: train_loss 1.5574496984481812
Iteration 68: train_loss 1.5953900814056396
Iteration 69: train_loss 1.6451700925827026
Iteration 70: train_loss 1.4990514516830444
Iteration 71: train_loss 1.582121729850769
Iteration 72: train_loss 1.5787204504013062
Iteration 73: train_loss 1.6809946298599243
Iteration 74: train_loss 1.587323546409607
Iteration 75: train_loss 1.6049779653549194
Iteration 76: train_loss 1.5594338178634644
Iteration 77: train_loss 1.6358416080474854
Iteration 78: train_loss 1.651574969291687
Iteration 79: train_loss 1.6216375827789307
Iteration 80: train_loss 1.5439484119415283
Iteration 81: train_loss 1.6274964809417725
Iteration 82: train_loss 1.5277581214904785
Iteration 83: train_loss 1.6085991859436035
Iteration 84: train_loss 1.615976333618164
Iteration 85: train_loss 1.6011238098144531
Iteration 86: train_loss 1.5928754806518555
Iteration 87: train_loss 1.6150072813034058
Iteration 88: train_loss 1.5696258544921875
Iteration 89: train_loss 1.5186538696289062
Iteration 90: train_loss 1.5463110208511353
Iteration 91: train_loss 1.6185953617095947
Iteration 92: train_loss 1.5545451641082764
Iteration 93: train_loss 1.5214024782180786
Iteration 94: train_loss 1.5548721551895142
Iteration 95: train_loss 1.5608915090560913
Iteration 96: train_loss 1.4874674081802368
Iteration 97: train_loss 1.5880262851715088
Iteration 98: train_loss 1.633566975593567
Iteration 99: train_loss 1.5856878757476807
Iteration 100: train_loss 1.6060031652450562
Iteration 101: train_loss 1.6413294076919556
Iteration 102: train_loss 1.6621938943862915
Iteration 103: train_loss 1.5731970071792603
Iteration 104: train_loss 1.6310644149780273
Iteration 105: train_loss 1.6042025089263916
Iteration 106: train_loss 1.5619292259216309
Iteration 107: train_loss 1.5993568897247314
Iteration 108: train_loss 1.574859380722046
Iteration 109: train_loss 1.6303532123565674
Iteration 110: train_loss 1.5812668800354004
Iteration 111: train_loss 1.5695714950561523
Iteration 112: train_loss 1.5944920778274536
Iteration 113: train_loss 1.6010401248931885
Iteration 114: train_loss 1.6573066711425781
Iteration 115: train_loss 1.5312341451644897
Iteration 116: train_loss 1.599724292755127
Iteration 117: train_loss 1.5857808589935303
Iteration 118: train_loss 1.572927474975586
Iteration 119: train_loss 1.5290881395339966
Iteration 120: train_loss 1.5202531814575195
Iteration 121: train_loss 1.6265685558319092
Iteration 122: train_loss 1.5665943622589111
Iteration 123: train_loss 1.6082185506820679
Iteration 124: train_loss 1.5101351737976074
Iteration 125: train_loss 1.6220932006835938
Iteration 126: train_loss 1.6091493368148804
Iteration 127: train_loss 1.5597316026687622
Iteration 128: train_loss 1.5787734985351562
Iteration 129: train_loss 1.5889939069747925
Iteration 130: train_loss 1.558414340019226
Iteration 131: train_loss 1.5560328960418701
Iteration 132: train_loss 1.594433307647705
Iteration 133: train_loss 1.626798152923584
Iteration 134: train_loss 1.4772670269012451
Iteration 135: train_loss 1.520627498626709
Iteration 136: train_loss 1.5435847043991089
Iteration 137: train_loss 1.6174449920654297
Iteration 138: train_loss 1.5525636672973633
Iteration 139: train_loss 1.5626071691513062
Iteration 140: train_loss 1.627194881439209
Iteration 141: train_loss 1.6734710931777954
Iteration 142: train_loss 1.5576695203781128
Iteration 143: train_loss 1.6424928903579712
Iteration 144: train_loss 1.6117792129516602
Iteration 145: train_loss 1.5873621702194214
Iteration 146: train_loss 1.497222900390625
Iteration 147: train_loss 1.558078408241272
Iteration 148: train_loss 1.5403803586959839
Iteration 149: train_loss 1.5979716777801514
Iteration 150: train_loss 1.625284194946289
Iteration 151: train_loss 1.6106833219528198
Iteration 152: train_loss 1.5664860010147095
Iteration 153: train_loss 1.6283032894134521
Iteration 154: train_loss 1.6367205381393433
Iteration 155: train_loss 1.597373604774475
Iteration 156: train_loss 1.592322826385498
Iteration 157: train_loss 1.6057473421096802
Iteration 158: train_loss 1.5687798261642456
Iteration 159: train_loss 1.657834768295288
Iteration 160: train_loss 1.596952199935913
Iteration 161: train_loss 1.6035863161087036
Iteration 162: train_loss 1.6035035848617554
Iteration 163: train_loss 1.5437979698181152
Iteration 164: train_loss 1.5621057748794556
Iteration 165: train_loss 1.677255630493164
Iteration 166: train_loss 1.6119136810302734
Iteration 167: train_loss 1.6143605709075928
Iteration 168: train_loss 1.636991024017334
Iteration 169: train_loss 1.6446454524993896
Iteration 170: train_loss 1.6369223594665527
Iteration 171: train_loss 1.582505464553833
Iteration 172: train_loss 1.622639536857605
Iteration 173: train_loss 1.6432920694351196
Iteration 174: train_loss 1.5724611282348633
Iteration 175: train_loss 1.6326788663864136
Iteration 176: train_loss 1.600777268409729
Iteration 177: train_loss 1.6075488328933716
Epoch 61: train_avg_loss 1.5814750901723311 eval_avg_acc: 0.3482587818365187 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:29:36] [32mIntermediate result: 0.3482587818365187  (Index 60)[0m
================Epoch: 62================
Iteration 1: train_loss 1.564789891242981
Iteration 2: train_loss 1.5923352241516113
Iteration 3: train_loss 1.5350488424301147
Iteration 4: train_loss 1.528388261795044
Iteration 5: train_loss 1.6066745519638062
Iteration 6: train_loss 1.5702217817306519
Iteration 7: train_loss 1.5277847051620483
Iteration 8: train_loss 1.562338948249817
Iteration 9: train_loss 1.5172767639160156
Iteration 10: train_loss 1.550991415977478
Iteration 11: train_loss 1.6148154735565186
Iteration 12: train_loss 1.5805879831314087
Iteration 13: train_loss 1.5604313611984253
Iteration 14: train_loss 1.5041656494140625
Iteration 15: train_loss 1.581724762916565
Iteration 16: train_loss 1.5669633150100708
Iteration 17: train_loss 1.599836826324463
Iteration 18: train_loss 1.5673969984054565
Iteration 19: train_loss 1.5017188787460327
Iteration 20: train_loss 1.5723621845245361
Iteration 21: train_loss 1.6037744283676147
Iteration 22: train_loss 1.5163737535476685
Iteration 23: train_loss 1.567795991897583
Iteration 24: train_loss 1.5022188425064087
Iteration 25: train_loss 1.491905689239502
Iteration 26: train_loss 1.669336199760437
Iteration 27: train_loss 1.5832850933074951
Iteration 28: train_loss 1.5833112001419067
Iteration 29: train_loss 1.5903236865997314
Iteration 30: train_loss 1.5560182332992554
Iteration 31: train_loss 1.4927101135253906
Iteration 32: train_loss 1.5630534887313843
Iteration 33: train_loss 1.5320473909378052
Iteration 34: train_loss 1.528312087059021
Iteration 35: train_loss 1.5660020112991333
Iteration 36: train_loss 1.5506024360656738
Iteration 37: train_loss 1.4966368675231934
Iteration 38: train_loss 1.5787830352783203
Iteration 39: train_loss 1.5950065851211548
Iteration 40: train_loss 1.6034127473831177
Iteration 41: train_loss 1.5561431646347046
Iteration 42: train_loss 1.5478111505508423
Iteration 43: train_loss 1.4875203371047974
Iteration 44: train_loss 1.5597409009933472
Iteration 45: train_loss 1.5613715648651123
Iteration 46: train_loss 1.5643662214279175
Iteration 47: train_loss 1.5163882970809937
Iteration 48: train_loss 1.4947874546051025
Iteration 49: train_loss 1.549556851387024
Iteration 50: train_loss 1.6095994710922241
Iteration 51: train_loss 1.5675748586654663
Iteration 52: train_loss 1.5336469411849976
Iteration 53: train_loss 1.569883108139038
Iteration 54: train_loss 1.6654512882232666
Iteration 55: train_loss 1.6468651294708252
Iteration 56: train_loss 1.6361020803451538
Iteration 57: train_loss 1.5860109329223633
Iteration 58: train_loss 1.608435034751892
Iteration 59: train_loss 1.567732334136963
Iteration 60: train_loss 1.5970475673675537
Iteration 61: train_loss 1.5840438604354858
Iteration 62: train_loss 1.577324390411377
Iteration 63: train_loss 1.5893467664718628
Iteration 64: train_loss 1.6470119953155518
Iteration 65: train_loss 1.550885558128357
Iteration 66: train_loss 1.5793520212173462
Iteration 67: train_loss 1.5760759115219116
Iteration 68: train_loss 1.5110796689987183
Iteration 69: train_loss 1.5996997356414795
Iteration 70: train_loss 1.6315125226974487
Iteration 71: train_loss 1.5746595859527588
Iteration 72: train_loss 1.5617609024047852
Iteration 73: train_loss 1.5893326997756958
Iteration 74: train_loss 1.620152473449707
Iteration 75: train_loss 1.5203866958618164
Iteration 76: train_loss 1.5326534509658813
Iteration 77: train_loss 1.6417059898376465
Iteration 78: train_loss 1.5733596086502075
Iteration 79: train_loss 1.6176652908325195
Iteration 80: train_loss 1.604420781135559
Iteration 81: train_loss 1.5519602298736572
Iteration 82: train_loss 1.6167629957199097
Iteration 83: train_loss 1.490867018699646
Iteration 84: train_loss 1.5951753854751587
Iteration 85: train_loss 1.5352928638458252
Iteration 86: train_loss 1.6167242527008057
Iteration 87: train_loss 1.691880464553833
Iteration 88: train_loss 1.6360993385314941
Iteration 89: train_loss 1.618564248085022
Iteration 90: train_loss 1.5437228679656982
Iteration 91: train_loss 1.5964152812957764
Iteration 92: train_loss 1.5955545902252197
Iteration 93: train_loss 1.5470917224884033
Iteration 94: train_loss 1.5289545059204102
Iteration 95: train_loss 1.6202149391174316
Iteration 96: train_loss 1.6178252696990967
Iteration 97: train_loss 1.5586354732513428
Iteration 98: train_loss 1.5286422967910767
Iteration 99: train_loss 1.6375640630722046
Iteration 100: train_loss 1.5696126222610474
Iteration 101: train_loss 1.559754729270935
Iteration 102: train_loss 1.5785038471221924
Iteration 103: train_loss 1.5743364095687866
Iteration 104: train_loss 1.6443567276000977
Iteration 105: train_loss 1.5482563972473145
Iteration 106: train_loss 1.5862787961959839
Iteration 107: train_loss 1.6150338649749756
Iteration 108: train_loss 1.606736183166504
Iteration 109: train_loss 1.6308529376983643
Iteration 110: train_loss 1.621929407119751
Iteration 111: train_loss 1.5460543632507324
Iteration 112: train_loss 1.5857887268066406
Iteration 113: train_loss 1.5581004619598389
Iteration 114: train_loss 1.613160252571106
Iteration 115: train_loss 1.573065161705017
Iteration 116: train_loss 1.5304760932922363
Iteration 117: train_loss 1.5420944690704346
Iteration 118: train_loss 1.599687099456787
Iteration 119: train_loss 1.600306749343872
Iteration 120: train_loss 1.620984435081482
Iteration 121: train_loss 1.6312522888183594
Iteration 122: train_loss 1.6382114887237549
Iteration 123: train_loss 1.6569002866744995
Iteration 124: train_loss 1.6571565866470337
Iteration 125: train_loss 1.6412086486816406
Iteration 126: train_loss 1.6010208129882812
Iteration 127: train_loss 1.607694149017334
Iteration 128: train_loss 1.6825097799301147
Iteration 129: train_loss 1.5943961143493652
Iteration 130: train_loss 1.6587344408035278
Iteration 131: train_loss 1.6053462028503418
Iteration 132: train_loss 1.6460896730422974
Iteration 133: train_loss 1.6643729209899902
Iteration 134: train_loss 1.5812574625015259
Iteration 135: train_loss 1.5945481061935425
Iteration 136: train_loss 1.6070916652679443
Iteration 137: train_loss 1.6004972457885742
Iteration 138: train_loss 1.5614594221115112
Iteration 139: train_loss 1.6278493404388428
Iteration 140: train_loss 1.60891592502594
Iteration 141: train_loss 1.5659276247024536
Iteration 142: train_loss 1.6044551134109497
Iteration 143: train_loss 1.564205527305603
Iteration 144: train_loss 1.4998385906219482
Iteration 145: train_loss 1.5259212255477905
Iteration 146: train_loss 1.6168417930603027
Iteration 147: train_loss 1.543927788734436
Iteration 148: train_loss 1.6254305839538574
Iteration 149: train_loss 1.5732436180114746
Iteration 150: train_loss 1.6483235359191895
Iteration 151: train_loss 1.6094279289245605
Iteration 152: train_loss 1.5920945405960083
Iteration 153: train_loss 1.6406499147415161
Iteration 154: train_loss 1.6044124364852905
Iteration 155: train_loss 1.5676530599594116
Iteration 156: train_loss 1.5742942094802856
Iteration 157: train_loss 1.578650951385498
Iteration 158: train_loss 1.5000355243682861
Iteration 159: train_loss 1.6119847297668457
Iteration 160: train_loss 1.60270094871521
Iteration 161: train_loss 1.6008483171463013
Iteration 162: train_loss 1.6326816082000732
Iteration 163: train_loss 1.6238369941711426
Iteration 164: train_loss 1.579192876815796
Iteration 165: train_loss 1.620639681816101
Iteration 166: train_loss 1.6048461198806763
Iteration 167: train_loss 1.6005263328552246
Iteration 168: train_loss 1.632099986076355
Iteration 169: train_loss 1.6930941343307495
Iteration 170: train_loss 1.6564606428146362
Iteration 171: train_loss 1.5818942785263062
Iteration 172: train_loss 1.5474704504013062
Iteration 173: train_loss 1.6603456735610962
Iteration 174: train_loss 1.6379364728927612
Iteration 175: train_loss 1.5975353717803955
Iteration 176: train_loss 1.6486740112304688
Iteration 177: train_loss 1.6001288890838623
Epoch 62: train_avg_loss 1.5850468355383576 eval_avg_acc: 0.31892297585172846 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:30:18] [32mIntermediate result: 0.31892297585172846  (Index 61)[0m
================Epoch: 63================
Iteration 1: train_loss 1.536560297012329
Iteration 2: train_loss 1.574220061302185
Iteration 3: train_loss 1.6187585592269897
Iteration 4: train_loss 1.5988174676895142
Iteration 5: train_loss 1.547575831413269
Iteration 6: train_loss 1.5881370306015015
Iteration 7: train_loss 1.6386654376983643
Iteration 8: train_loss 1.592344880104065
Iteration 9: train_loss 1.5916637182235718
Iteration 10: train_loss 1.5272167921066284
Iteration 11: train_loss 1.5536335706710815
Iteration 12: train_loss 1.6194645166397095
Iteration 13: train_loss 1.6128021478652954
Iteration 14: train_loss 1.5402188301086426
Iteration 15: train_loss 1.5209014415740967
Iteration 16: train_loss 1.5560030937194824
Iteration 17: train_loss 1.564294457435608
Iteration 18: train_loss 1.5793336629867554
Iteration 19: train_loss 1.5791549682617188
Iteration 20: train_loss 1.472046136856079
Iteration 21: train_loss 1.6079386472702026
Iteration 22: train_loss 1.5367220640182495
Iteration 23: train_loss 1.5907418727874756
Iteration 24: train_loss 1.5349647998809814
Iteration 25: train_loss 1.5857477188110352
Iteration 26: train_loss 1.5930522680282593
Iteration 27: train_loss 1.4904192686080933
Iteration 28: train_loss 1.5761842727661133
Iteration 29: train_loss 1.6133373975753784
Iteration 30: train_loss 1.5978862047195435
Iteration 31: train_loss 1.5274229049682617
Iteration 32: train_loss 1.5707588195800781
Iteration 33: train_loss 1.5567160844802856
Iteration 34: train_loss 1.5434246063232422
Iteration 35: train_loss 1.5223346948623657
Iteration 36: train_loss 1.6499199867248535
Iteration 37: train_loss 1.5635731220245361
Iteration 38: train_loss 1.570802927017212
Iteration 39: train_loss 1.5301364660263062
Iteration 40: train_loss 1.5219708681106567
Iteration 41: train_loss 1.5913782119750977
Iteration 42: train_loss 1.6384904384613037
Iteration 43: train_loss 1.594534158706665
Iteration 44: train_loss 1.613476276397705
Iteration 45: train_loss 1.5722389221191406
Iteration 46: train_loss 1.546342134475708
Iteration 47: train_loss 1.6242027282714844
Iteration 48: train_loss 1.5700403451919556
Iteration 49: train_loss 1.6490131616592407
Iteration 50: train_loss 1.5736254453659058
Iteration 51: train_loss 1.551621675491333
Iteration 52: train_loss 1.5985984802246094
Iteration 53: train_loss 1.5664093494415283
Iteration 54: train_loss 1.5384190082550049
Iteration 55: train_loss 1.5617574453353882
Iteration 56: train_loss 1.5930240154266357
Iteration 57: train_loss 1.595151662826538
Iteration 58: train_loss 1.572497844696045
Iteration 59: train_loss 1.5751209259033203
Iteration 60: train_loss 1.6790239810943604
Iteration 61: train_loss 1.5406123399734497
Iteration 62: train_loss 1.6937638521194458
Iteration 63: train_loss 1.5451538562774658
Iteration 64: train_loss 1.632936954498291
Iteration 65: train_loss 1.6707055568695068
Iteration 66: train_loss 1.650404691696167
Iteration 67: train_loss 1.5424984693527222
Iteration 68: train_loss 1.592151165008545
Iteration 69: train_loss 1.6160094738006592
Iteration 70: train_loss 1.5685741901397705
Iteration 71: train_loss 1.5287163257598877
Iteration 72: train_loss 1.548846960067749
Iteration 73: train_loss 1.490139126777649
Iteration 74: train_loss 1.57076895236969
Iteration 75: train_loss 1.5616775751113892
Iteration 76: train_loss 1.5470434427261353
Iteration 77: train_loss 1.592340350151062
Iteration 78: train_loss 1.5250728130340576
Iteration 79: train_loss 1.5681958198547363
Iteration 80: train_loss 1.525917887687683
Iteration 81: train_loss 1.5895020961761475
Iteration 82: train_loss 1.593861699104309
Iteration 83: train_loss 1.572821021080017
Iteration 84: train_loss 1.5461372137069702
Iteration 85: train_loss 1.6173772811889648
Iteration 86: train_loss 1.6221011877059937
Iteration 87: train_loss 1.570566177368164
Iteration 88: train_loss 1.5525434017181396
Iteration 89: train_loss 1.6029921770095825
Iteration 90: train_loss 1.5253771543502808
Iteration 91: train_loss 1.6253682374954224
Iteration 92: train_loss 1.6234136819839478
Iteration 93: train_loss 1.5765575170516968
Iteration 94: train_loss 1.648059368133545
Iteration 95: train_loss 1.603509783744812
Iteration 96: train_loss 1.5624449253082275
Iteration 97: train_loss 1.584534764289856
Iteration 98: train_loss 1.5008654594421387
Iteration 99: train_loss 1.5328373908996582
Iteration 100: train_loss 1.4833945035934448
Iteration 101: train_loss 1.5030971765518188
Iteration 102: train_loss 1.5676542520523071
Iteration 103: train_loss 1.5351516008377075
Iteration 104: train_loss 1.50556480884552
Iteration 105: train_loss 1.614938735961914
Iteration 106: train_loss 1.6042139530181885
Iteration 107: train_loss 1.5915676355361938
Iteration 108: train_loss 1.60288667678833
Iteration 109: train_loss 1.577478289604187
Iteration 110: train_loss 1.552673101425171
Iteration 111: train_loss 1.6024408340454102
Iteration 112: train_loss 1.6368250846862793
Iteration 113: train_loss 1.6418476104736328
Iteration 114: train_loss 1.5811351537704468
Iteration 115: train_loss 1.595318078994751
Iteration 116: train_loss 1.57759428024292
Iteration 117: train_loss 1.5961763858795166
Iteration 118: train_loss 1.6089695692062378
Iteration 119: train_loss 1.5372809171676636
Iteration 120: train_loss 1.5342439413070679
Iteration 121: train_loss 1.598222255706787
Iteration 122: train_loss 1.5894546508789062
Iteration 123: train_loss 1.5479503870010376
Iteration 124: train_loss 1.582684874534607
Iteration 125: train_loss 1.6059595346450806
Iteration 126: train_loss 1.5554587841033936
Iteration 127: train_loss 1.5255533456802368
Iteration 128: train_loss 1.5915447473526
Iteration 129: train_loss 1.599726676940918
Iteration 130: train_loss 1.6331747770309448
Iteration 131: train_loss 1.6509050130844116
Iteration 132: train_loss 1.5842318534851074
Iteration 133: train_loss 1.6285110712051392
Iteration 134: train_loss 1.6073285341262817
Iteration 135: train_loss 1.5469402074813843
Iteration 136: train_loss 1.6077710390090942
Iteration 137: train_loss 1.5604501962661743
Iteration 138: train_loss 1.6282649040222168
Iteration 139: train_loss 1.5986382961273193
Iteration 140: train_loss 1.5500394105911255
Iteration 141: train_loss 1.5652413368225098
Iteration 142: train_loss 1.5499168634414673
Iteration 143: train_loss 1.604567050933838
Iteration 144: train_loss 1.6389923095703125
Iteration 145: train_loss 1.5239286422729492
Iteration 146: train_loss 1.701554775238037
Iteration 147: train_loss 1.603968620300293
Iteration 148: train_loss 1.5834128856658936
Iteration 149: train_loss 1.6261848211288452
Iteration 150: train_loss 1.6331501007080078
Iteration 151: train_loss 1.5260957479476929
Iteration 152: train_loss 1.5215755701065063
Iteration 153: train_loss 1.5736111402511597
Iteration 154: train_loss 1.5116547346115112
Iteration 155: train_loss 1.5414248704910278
Iteration 156: train_loss 1.604921579360962
Iteration 157: train_loss 1.6268450021743774
Iteration 158: train_loss 1.5679666996002197
Iteration 159: train_loss 1.5812102556228638
Iteration 160: train_loss 1.536031723022461
Iteration 161: train_loss 1.5513113737106323
Iteration 162: train_loss 1.556809425354004
Iteration 163: train_loss 1.5336626768112183
Iteration 164: train_loss 1.5075677633285522
Iteration 165: train_loss 1.6759055852890015
Iteration 166: train_loss 1.6040773391723633
Iteration 167: train_loss 1.5996614694595337
Iteration 168: train_loss 1.631696343421936
Iteration 169: train_loss 1.6320998668670654
Iteration 170: train_loss 1.6547819375991821
Iteration 171: train_loss 1.5592801570892334
Iteration 172: train_loss 1.6066539287567139
Iteration 173: train_loss 1.6458005905151367
Iteration 174: train_loss 1.6147414445877075
Iteration 175: train_loss 1.4661773443222046
Iteration 176: train_loss 1.5663775205612183
Iteration 177: train_loss 1.4973448514938354
Epoch 63: train_avg_loss 1.5787158301994626 eval_avg_acc: 0.347092754841375 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:31:01] [32mIntermediate result: 0.347092754841375  (Index 62)[0m
================Epoch: 64================
Iteration 1: train_loss 1.512778401374817
Iteration 2: train_loss 1.5623087882995605
Iteration 3: train_loss 1.5637880563735962
Iteration 4: train_loss 1.5270966291427612
Iteration 5: train_loss 1.5676683187484741
Iteration 6: train_loss 1.6040364503860474
Iteration 7: train_loss 1.493720293045044
Iteration 8: train_loss 1.5480047464370728
Iteration 9: train_loss 1.5545743703842163
Iteration 10: train_loss 1.5952311754226685
Iteration 11: train_loss 1.447811484336853
Iteration 12: train_loss 1.457018494606018
Iteration 13: train_loss 1.538318157196045
Iteration 14: train_loss 1.53921639919281
Iteration 15: train_loss 1.5201152563095093
Iteration 16: train_loss 1.4944484233856201
Iteration 17: train_loss 1.4864734411239624
Iteration 18: train_loss 1.5493487119674683
Iteration 19: train_loss 1.528730869293213
Iteration 20: train_loss 1.5581742525100708
Iteration 21: train_loss 1.5443521738052368
Iteration 22: train_loss 1.5256931781768799
Iteration 23: train_loss 1.555661678314209
Iteration 24: train_loss 1.4767946004867554
Iteration 25: train_loss 1.5614292621612549
Iteration 26: train_loss 1.515919804573059
Iteration 27: train_loss 1.5599033832550049
Iteration 28: train_loss 1.5952835083007812
Iteration 29: train_loss 1.5848532915115356
Iteration 30: train_loss 1.4722933769226074
Iteration 31: train_loss 1.5777307748794556
Iteration 32: train_loss 1.591317057609558
Iteration 33: train_loss 1.6141035556793213
Iteration 34: train_loss 1.5028560161590576
Iteration 35: train_loss 1.595310926437378
Iteration 36: train_loss 1.5905123949050903
Iteration 37: train_loss 1.5718787908554077
Iteration 38: train_loss 1.5601463317871094
Iteration 39: train_loss 1.5831176042556763
Iteration 40: train_loss 1.570907473564148
Iteration 41: train_loss 1.556005597114563
Iteration 42: train_loss 1.5604255199432373
Iteration 43: train_loss 1.5356111526489258
Iteration 44: train_loss 1.6241079568862915
Iteration 45: train_loss 1.6446844339370728
Iteration 46: train_loss 1.5785244703292847
Iteration 47: train_loss 1.5819333791732788
Iteration 48: train_loss 1.5313948392868042
Iteration 49: train_loss 1.5692719221115112
Iteration 50: train_loss 1.5446385145187378
Iteration 51: train_loss 1.5993000268936157
Iteration 52: train_loss 1.599593162536621
Iteration 53: train_loss 1.6124167442321777
Iteration 54: train_loss 1.5233300924301147
Iteration 55: train_loss 1.5960036516189575
Iteration 56: train_loss 1.6018198728561401
Iteration 57: train_loss 1.55577552318573
Iteration 58: train_loss 1.5898613929748535
Iteration 59: train_loss 1.49722421169281
Iteration 60: train_loss 1.5620862245559692
Iteration 61: train_loss 1.585226058959961
Iteration 62: train_loss 1.5954347848892212
Iteration 63: train_loss 1.5473614931106567
Iteration 64: train_loss 1.6493929624557495
Iteration 65: train_loss 1.6395068168640137
Iteration 66: train_loss 1.5606569051742554
Iteration 67: train_loss 1.53206467628479
Iteration 68: train_loss 1.5243240594863892
Iteration 69: train_loss 1.5900083780288696
Iteration 70: train_loss 1.5339916944503784
Iteration 71: train_loss 1.6283016204833984
Iteration 72: train_loss 1.5935770273208618
Iteration 73: train_loss 1.6117753982543945
Iteration 74: train_loss 1.658186912536621
Iteration 75: train_loss 1.6138410568237305
Iteration 76: train_loss 1.527956485748291
Iteration 77: train_loss 1.5867533683776855
Iteration 78: train_loss 1.5869988203048706
Iteration 79: train_loss 1.5485618114471436
Iteration 80: train_loss 1.5927009582519531
Iteration 81: train_loss 1.5775318145751953
Iteration 82: train_loss 1.5790514945983887
Iteration 83: train_loss 1.5607386827468872
Iteration 84: train_loss 1.5717566013336182
Iteration 85: train_loss 1.6348450183868408
Iteration 86: train_loss 1.5672427415847778
Iteration 87: train_loss 1.564171552658081
Iteration 88: train_loss 1.5137757062911987
Iteration 89: train_loss 1.515065312385559
Iteration 90: train_loss 1.5434770584106445
Iteration 91: train_loss 1.621171236038208
Iteration 92: train_loss 1.559775948524475
Iteration 93: train_loss 1.603031873703003
Iteration 94: train_loss 1.5619760751724243
Iteration 95: train_loss 1.6239582300186157
Iteration 96: train_loss 1.6950289011001587
Iteration 97: train_loss 1.5697708129882812
Iteration 98: train_loss 1.5202277898788452
Iteration 99: train_loss 1.5891547203063965
Iteration 100: train_loss 1.658835768699646
Iteration 101: train_loss 1.5781935453414917
Iteration 102: train_loss 1.5601873397827148
Iteration 103: train_loss 1.5579016208648682
Iteration 104: train_loss 1.5728521347045898
Iteration 105: train_loss 1.5663269758224487
Iteration 106: train_loss 1.5631654262542725
Iteration 107: train_loss 1.5970464944839478
Iteration 108: train_loss 1.5304138660430908
Iteration 109: train_loss 1.6017345190048218
Iteration 110: train_loss 1.5233389139175415
Iteration 111: train_loss 1.628395915031433
Iteration 112: train_loss 1.5298110246658325
Iteration 113: train_loss 1.5538229942321777
Iteration 114: train_loss 1.585113763809204
Iteration 115: train_loss 1.5802035331726074
Iteration 116: train_loss 1.5736517906188965
Iteration 117: train_loss 1.5230381488800049
Iteration 118: train_loss 1.5938372611999512
Iteration 119: train_loss 1.5442763566970825
Iteration 120: train_loss 1.5736255645751953
Iteration 121: train_loss 1.5659253597259521
Iteration 122: train_loss 1.5713080167770386
Iteration 123: train_loss 1.5686721801757812
Iteration 124: train_loss 1.5829745531082153
Iteration 125: train_loss 1.5961668491363525
Iteration 126: train_loss 1.5679692029953003
Iteration 127: train_loss 1.546006679534912
Iteration 128: train_loss 1.5557126998901367
Iteration 129: train_loss 1.5400725603103638
Iteration 130: train_loss 1.5791682004928589
Iteration 131: train_loss 1.624843716621399
Iteration 132: train_loss 1.5640283823013306
Iteration 133: train_loss 1.621694564819336
Iteration 134: train_loss 1.6113799810409546
Iteration 135: train_loss 1.6103553771972656
Iteration 136: train_loss 1.6050211191177368
Iteration 137: train_loss 1.6130127906799316
Iteration 138: train_loss 1.5110806226730347
Iteration 139: train_loss 1.5505956411361694
Iteration 140: train_loss 1.6055911779403687
Iteration 141: train_loss 1.587882399559021
Iteration 142: train_loss 1.5489144325256348
Iteration 143: train_loss 1.5704631805419922
Iteration 144: train_loss 1.5856984853744507
Iteration 145: train_loss 1.6358678340911865
Iteration 146: train_loss 1.5671924352645874
Iteration 147: train_loss 1.5327847003936768
Iteration 148: train_loss 1.592389464378357
Iteration 149: train_loss 1.669926404953003
Iteration 150: train_loss 1.5523958206176758
Iteration 151: train_loss 1.5600719451904297
Iteration 152: train_loss 1.659590721130371
Iteration 153: train_loss 1.5907559394836426
Iteration 154: train_loss 1.5142018795013428
Iteration 155: train_loss 1.6716022491455078
Iteration 156: train_loss 1.5833691358566284
Iteration 157: train_loss 1.6082016229629517
Iteration 158: train_loss 1.6039997339248657
Iteration 159: train_loss 1.6107943058013916
Iteration 160: train_loss 1.5352743864059448
Iteration 161: train_loss 1.5400351285934448
Iteration 162: train_loss 1.5661362409591675
Iteration 163: train_loss 1.5655951499938965
Iteration 164: train_loss 1.5891170501708984
Iteration 165: train_loss 1.5303783416748047
Iteration 166: train_loss 1.6289031505584717
Iteration 167: train_loss 1.5539424419403076
Iteration 168: train_loss 1.6172165870666504
Iteration 169: train_loss 1.5981364250183105
Iteration 170: train_loss 1.5629866123199463
Iteration 171: train_loss 1.6117937564849854
Iteration 172: train_loss 1.5442028045654297
Iteration 173: train_loss 1.5620707273483276
Iteration 174: train_loss 1.598906397819519
Iteration 175: train_loss 1.5470705032348633
Iteration 176: train_loss 1.5891300439834595
Iteration 177: train_loss 1.5099681615829468
Epoch 64: train_avg_loss 1.5707662637624364 eval_avg_acc: 0.3322468883745382 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:31:43] [32mIntermediate result: 0.3322468883745382  (Index 63)[0m
================Epoch: 65================
Iteration 1: train_loss 1.482110857963562
Iteration 2: train_loss 1.5731008052825928
Iteration 3: train_loss 1.5750017166137695
Iteration 4: train_loss 1.5606615543365479
Iteration 5: train_loss 1.5213948488235474
Iteration 6: train_loss 1.5427401065826416
Iteration 7: train_loss 1.5611923933029175
Iteration 8: train_loss 1.608422875404358
Iteration 9: train_loss 1.5328869819641113
Iteration 10: train_loss 1.5719918012619019
Iteration 11: train_loss 1.5785000324249268
Iteration 12: train_loss 1.548352837562561
Iteration 13: train_loss 1.6544172763824463
Iteration 14: train_loss 1.5698034763336182
Iteration 15: train_loss 1.4756605625152588
Iteration 16: train_loss 1.5758280754089355
Iteration 17: train_loss 1.6489646434783936
Iteration 18: train_loss 1.569893717765808
Iteration 19: train_loss 1.566989779472351
Iteration 20: train_loss 1.5371432304382324
Iteration 21: train_loss 1.5799883604049683
Iteration 22: train_loss 1.513790488243103
Iteration 23: train_loss 1.578634262084961
Iteration 24: train_loss 1.5844272375106812
Iteration 25: train_loss 1.5016177892684937
Iteration 26: train_loss 1.5320467948913574
Iteration 27: train_loss 1.5112886428833008
Iteration 28: train_loss 1.5610402822494507
Iteration 29: train_loss 1.5396275520324707
Iteration 30: train_loss 1.5819743871688843
Iteration 31: train_loss 1.508623480796814
Iteration 32: train_loss 1.6644799709320068
Iteration 33: train_loss 1.530014991760254
Iteration 34: train_loss 1.5166856050491333
Iteration 35: train_loss 1.5326623916625977
Iteration 36: train_loss 1.4763318300247192
Iteration 37: train_loss 1.4919131994247437
Iteration 38: train_loss 1.5128552913665771
Iteration 39: train_loss 1.5169448852539062
Iteration 40: train_loss 1.4938920736312866
Iteration 41: train_loss 1.5041176080703735
Iteration 42: train_loss 1.6088749170303345
Iteration 43: train_loss 1.5054823160171509
Iteration 44: train_loss 1.5526551008224487
Iteration 45: train_loss 1.481598973274231
Iteration 46: train_loss 1.5477620363235474
Iteration 47: train_loss 1.580865502357483
Iteration 48: train_loss 1.5824098587036133
Iteration 49: train_loss 1.5086073875427246
Iteration 50: train_loss 1.452691674232483
Iteration 51: train_loss 1.6052416563034058
Iteration 52: train_loss 1.5356167554855347
Iteration 53: train_loss 1.5597189664840698
Iteration 54: train_loss 1.5340912342071533
Iteration 55: train_loss 1.5295343399047852
Iteration 56: train_loss 1.5681232213974
Iteration 57: train_loss 1.5215721130371094
Iteration 58: train_loss 1.6114306449890137
Iteration 59: train_loss 1.563423752784729
Iteration 60: train_loss 1.5495702028274536
Iteration 61: train_loss 1.5562301874160767
Iteration 62: train_loss 1.5817269086837769
Iteration 63: train_loss 1.5293327569961548
Iteration 64: train_loss 1.4837872982025146
Iteration 65: train_loss 1.5618393421173096
Iteration 66: train_loss 1.5863302946090698
Iteration 67: train_loss 1.5991159677505493
Iteration 68: train_loss 1.52675199508667
Iteration 69: train_loss 1.5369051694869995
Iteration 70: train_loss 1.6262263059616089
Iteration 71: train_loss 1.5491282939910889
Iteration 72: train_loss 1.5693258047103882
Iteration 73: train_loss 1.5473582744598389
Iteration 74: train_loss 1.6060914993286133
Iteration 75: train_loss 1.5157232284545898
Iteration 76: train_loss 1.5525667667388916
Iteration 77: train_loss 1.555625081062317
Iteration 78: train_loss 1.5282448530197144
Iteration 79: train_loss 1.5822476148605347
Iteration 80: train_loss 1.514115333557129
Iteration 81: train_loss 1.6016643047332764
Iteration 82: train_loss 1.6362272500991821
Iteration 83: train_loss 1.6084413528442383
Iteration 84: train_loss 1.53371262550354
Iteration 85: train_loss 1.5358365774154663
Iteration 86: train_loss 1.5875300168991089
Iteration 87: train_loss 1.5596425533294678
Iteration 88: train_loss 1.5821582078933716
Iteration 89: train_loss 1.5879360437393188
Iteration 90: train_loss 1.5443154573440552
Iteration 91: train_loss 1.57459557056427
Iteration 92: train_loss 1.5638301372528076
Iteration 93: train_loss 1.6210402250289917
Iteration 94: train_loss 1.6251314878463745
Iteration 95: train_loss 1.534205436706543
Iteration 96: train_loss 1.5817766189575195
Iteration 97: train_loss 1.5758811235427856
Iteration 98: train_loss 1.5978235006332397
Iteration 99: train_loss 1.5764816999435425
Iteration 100: train_loss 1.645550012588501
Iteration 101: train_loss 1.5632926225662231
Iteration 102: train_loss 1.604181170463562
Iteration 103: train_loss 1.5153430700302124
Iteration 104: train_loss 1.5727406740188599
Iteration 105: train_loss 1.518683671951294
Iteration 106: train_loss 1.5843875408172607
Iteration 107: train_loss 1.5408602952957153
Iteration 108: train_loss 1.551770806312561
Iteration 109: train_loss 1.5543357133865356
Iteration 110: train_loss 1.5618945360183716
Iteration 111: train_loss 1.5280184745788574
Iteration 112: train_loss 1.6285029649734497
Iteration 113: train_loss 1.546372890472412
Iteration 114: train_loss 1.6052454710006714
Iteration 115: train_loss 1.5799981355667114
Iteration 116: train_loss 1.5787310600280762
Iteration 117: train_loss 1.591741681098938
Iteration 118: train_loss 1.587720513343811
Iteration 119: train_loss 1.535893201828003
Iteration 120: train_loss 1.5971823930740356
Iteration 121: train_loss 1.6326251029968262
Iteration 122: train_loss 1.6151179075241089
Iteration 123: train_loss 1.5787843465805054
Iteration 124: train_loss 1.5922741889953613
Iteration 125: train_loss 1.6233614683151245
Iteration 126: train_loss 1.6307090520858765
Iteration 127: train_loss 1.5214580297470093
Iteration 128: train_loss 1.5959044694900513
Iteration 129: train_loss 1.562746524810791
Iteration 130: train_loss 1.5175414085388184
Iteration 131: train_loss 1.5296540260314941
Iteration 132: train_loss 1.6033530235290527
Iteration 133: train_loss 1.5231984853744507
Iteration 134: train_loss 1.559450387954712
Iteration 135: train_loss 1.513962745666504
Iteration 136: train_loss 1.536981463432312
Iteration 137: train_loss 1.5486297607421875
Iteration 138: train_loss 1.5652714967727661
Iteration 139: train_loss 1.4935122728347778
Iteration 140: train_loss 1.6035505533218384
Iteration 141: train_loss 1.5666669607162476
Iteration 142: train_loss 1.585847020149231
Iteration 143: train_loss 1.567469596862793
Iteration 144: train_loss 1.5777931213378906
Iteration 145: train_loss 1.5009291172027588
Iteration 146: train_loss 1.5229030847549438
Iteration 147: train_loss 1.6176886558532715
Iteration 148: train_loss 1.5257303714752197
Iteration 149: train_loss 1.644775390625
Iteration 150: train_loss 1.5920368432998657
Iteration 151: train_loss 1.5562623739242554
Iteration 152: train_loss 1.5528099536895752
Iteration 153: train_loss 1.5428186655044556
Iteration 154: train_loss 1.571423888206482
Iteration 155: train_loss 1.5602291822433472
Iteration 156: train_loss 1.561814308166504
Iteration 157: train_loss 1.5147103071212769
Iteration 158: train_loss 1.5255935192108154
Iteration 159: train_loss 1.5991507768630981
Iteration 160: train_loss 1.547957181930542
Iteration 161: train_loss 1.5822967290878296
Iteration 162: train_loss 1.6388896703720093
Iteration 163: train_loss 1.5952016115188599
Iteration 164: train_loss 1.5791083574295044
Iteration 165: train_loss 1.5432071685791016
Iteration 166: train_loss 1.5824717283248901
Iteration 167: train_loss 1.5535106658935547
Iteration 168: train_loss 1.5782361030578613
Iteration 169: train_loss 1.594794511795044
Iteration 170: train_loss 1.5757453441619873
Iteration 171: train_loss 1.5847811698913574
Iteration 172: train_loss 1.5525662899017334
Iteration 173: train_loss 1.6071983575820923
Iteration 174: train_loss 1.5850366353988647
Iteration 175: train_loss 1.5490349531173706
Iteration 176: train_loss 1.6036760807037354
Iteration 177: train_loss 1.4469856023788452
Epoch 65: train_avg_loss 1.5613111493277685 eval_avg_acc: 0.3390600275475183 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:32:24] [32mIntermediate result: 0.3390600275475183  (Index 64)[0m
================Epoch: 66================
Iteration 1: train_loss 1.6505866050720215
Iteration 2: train_loss 1.601141333580017
Iteration 3: train_loss 1.5525646209716797
Iteration 4: train_loss 1.5676978826522827
Iteration 5: train_loss 1.4842476844787598
Iteration 6: train_loss 1.558843970298767
Iteration 7: train_loss 1.4782378673553467
Iteration 8: train_loss 1.5421360731124878
Iteration 9: train_loss 1.554457426071167
Iteration 10: train_loss 1.4801627397537231
Iteration 11: train_loss 1.5593732595443726
Iteration 12: train_loss 1.5882352590560913
Iteration 13: train_loss 1.560629963874817
Iteration 14: train_loss 1.5721087455749512
Iteration 15: train_loss 1.5370335578918457
Iteration 16: train_loss 1.5177658796310425
Iteration 17: train_loss 1.5579575300216675
Iteration 18: train_loss 1.491422414779663
Iteration 19: train_loss 1.556013584136963
Iteration 20: train_loss 1.5258359909057617
Iteration 21: train_loss 1.5301614999771118
Iteration 22: train_loss 1.5215749740600586
Iteration 23: train_loss 1.5357751846313477
Iteration 24: train_loss 1.5776195526123047
Iteration 25: train_loss 1.5169546604156494
Iteration 26: train_loss 1.6632680892944336
Iteration 27: train_loss 1.5855482816696167
Iteration 28: train_loss 1.6242268085479736
Iteration 29: train_loss 1.561479091644287
Iteration 30: train_loss 1.52792489528656
Iteration 31: train_loss 1.5271848440170288
Iteration 32: train_loss 1.5358006954193115
Iteration 33: train_loss 1.4952852725982666
Iteration 34: train_loss 1.5546135902404785
Iteration 35: train_loss 1.497162938117981
Iteration 36: train_loss 1.4952588081359863
Iteration 37: train_loss 1.5075007677078247
Iteration 38: train_loss 1.573681354522705
Iteration 39: train_loss 1.51787531375885
Iteration 40: train_loss 1.604277491569519
Iteration 41: train_loss 1.5997469425201416
Iteration 42: train_loss 1.5544682741165161
Iteration 43: train_loss 1.566554307937622
Iteration 44: train_loss 1.5819357633590698
Iteration 45: train_loss 1.5506279468536377
Iteration 46: train_loss 1.6063792705535889
Iteration 47: train_loss 1.6059170961380005
Iteration 48: train_loss 1.4894458055496216
Iteration 49: train_loss 1.5314884185791016
Iteration 50: train_loss 1.5880019664764404
Iteration 51: train_loss 1.5545257329940796
Iteration 52: train_loss 1.5723668336868286
Iteration 53: train_loss 1.5779166221618652
Iteration 54: train_loss 1.6524975299835205
Iteration 55: train_loss 1.6188021898269653
Iteration 56: train_loss 1.5482025146484375
Iteration 57: train_loss 1.526825189590454
Iteration 58: train_loss 1.5268440246582031
Iteration 59: train_loss 1.5292402505874634
Iteration 60: train_loss 1.487938642501831
Iteration 61: train_loss 1.5249524116516113
Iteration 62: train_loss 1.570374846458435
Iteration 63: train_loss 1.49662446975708
Iteration 64: train_loss 1.5453511476516724
Iteration 65: train_loss 1.4993335008621216
Iteration 66: train_loss 1.5527712106704712
Iteration 67: train_loss 1.5595836639404297
Iteration 68: train_loss 1.5143587589263916
Iteration 69: train_loss 1.5755420923233032
Iteration 70: train_loss 1.585755467414856
Iteration 71: train_loss 1.596910834312439
Iteration 72: train_loss 1.5662320852279663
Iteration 73: train_loss 1.599334955215454
Iteration 74: train_loss 1.5215929746627808
Iteration 75: train_loss 1.5629079341888428
Iteration 76: train_loss 1.5307234525680542
Iteration 77: train_loss 1.6811697483062744
Iteration 78: train_loss 1.6129926443099976
Iteration 79: train_loss 1.587613582611084
Iteration 80: train_loss 1.5591588020324707
Iteration 81: train_loss 1.5396206378936768
Iteration 82: train_loss 1.5569190979003906
Iteration 83: train_loss 1.603076696395874
Iteration 84: train_loss 1.6083018779754639
Iteration 85: train_loss 1.5986407995224
Iteration 86: train_loss 1.5682227611541748
Iteration 87: train_loss 1.5876643657684326
Iteration 88: train_loss 1.5348024368286133
Iteration 89: train_loss 1.5915803909301758
Iteration 90: train_loss 1.6446738243103027
Iteration 91: train_loss 1.6349574327468872
Iteration 92: train_loss 1.5333951711654663
Iteration 93: train_loss 1.5713000297546387
Iteration 94: train_loss 1.5721906423568726
Iteration 95: train_loss 1.6416547298431396
Iteration 96: train_loss 1.5675400495529175
Iteration 97: train_loss 1.5425347089767456
Iteration 98: train_loss 1.526949405670166
Iteration 99: train_loss 1.5055841207504272
Iteration 100: train_loss 1.5204994678497314
Iteration 101: train_loss 1.6147129535675049
Iteration 102: train_loss 1.5783580541610718
Iteration 103: train_loss 1.5688228607177734
Iteration 104: train_loss 1.5570216178894043
Iteration 105: train_loss 1.4950404167175293
Iteration 106: train_loss 1.5338304042816162
Iteration 107: train_loss 1.5631046295166016
Iteration 108: train_loss 1.5164238214492798
Iteration 109: train_loss 1.5185219049453735
Iteration 110: train_loss 1.4895038604736328
Iteration 111: train_loss 1.530381441116333
Iteration 112: train_loss 1.5308904647827148
Iteration 113: train_loss 1.6359461545944214
Iteration 114: train_loss 1.5415925979614258
Iteration 115: train_loss 1.5259202718734741
Iteration 116: train_loss 1.562557578086853
Iteration 117: train_loss 1.47001051902771
Iteration 118: train_loss 1.6322084665298462
Iteration 119: train_loss 1.5582466125488281
Iteration 120: train_loss 1.5479676723480225
Iteration 121: train_loss 1.5847924947738647
Iteration 122: train_loss 1.4888973236083984
Iteration 123: train_loss 1.541260838508606
Iteration 124: train_loss 1.5256149768829346
Iteration 125: train_loss 1.5114796161651611
Iteration 126: train_loss 1.4835690259933472
Iteration 127: train_loss 1.6029257774353027
Iteration 128: train_loss 1.516898512840271
Iteration 129: train_loss 1.4968794584274292
Iteration 130: train_loss 1.5652095079421997
Iteration 131: train_loss 1.5878684520721436
Iteration 132: train_loss 1.56687593460083
Iteration 133: train_loss 1.572024941444397
Iteration 134: train_loss 1.5227389335632324
Iteration 135: train_loss 1.6056113243103027
Iteration 136: train_loss 1.5095667839050293
Iteration 137: train_loss 1.5347931385040283
Iteration 138: train_loss 1.565421462059021
Iteration 139: train_loss 1.65162193775177
Iteration 140: train_loss 1.5756770372390747
Iteration 141: train_loss 1.5638633966445923
Iteration 142: train_loss 1.5631730556488037
Iteration 143: train_loss 1.5740104913711548
Iteration 144: train_loss 1.5840952396392822
Iteration 145: train_loss 1.5505390167236328
Iteration 146: train_loss 1.5532478094100952
Iteration 147: train_loss 1.559459924697876
Iteration 148: train_loss 1.536486268043518
Iteration 149: train_loss 1.5649137496948242
Iteration 150: train_loss 1.5385239124298096
Iteration 151: train_loss 1.5327026844024658
Iteration 152: train_loss 1.587770700454712
Iteration 153: train_loss 1.5920655727386475
Iteration 154: train_loss 1.559706449508667
Iteration 155: train_loss 1.5715616941452026
Iteration 156: train_loss 1.527688980102539
Iteration 157: train_loss 1.5114003419876099
Iteration 158: train_loss 1.5149359703063965
Iteration 159: train_loss 1.5975077152252197
Iteration 160: train_loss 1.643542766571045
Iteration 161: train_loss 1.6079474687576294
Iteration 162: train_loss 1.5626814365386963
Iteration 163: train_loss 1.6353000402450562
Iteration 164: train_loss 1.610177993774414
Iteration 165: train_loss 1.5905866622924805
Iteration 166: train_loss 1.627335548400879
Iteration 167: train_loss 1.697247862815857
Iteration 168: train_loss 1.6143525838851929
Iteration 169: train_loss 1.6006402969360352
Iteration 170: train_loss 1.6098675727844238
Iteration 171: train_loss 1.5842506885528564
Iteration 172: train_loss 1.633487343788147
Iteration 173: train_loss 1.5661307573318481
Iteration 174: train_loss 1.5866187810897827
Iteration 175: train_loss 1.6037839651107788
Iteration 176: train_loss 1.6343275308609009
Iteration 177: train_loss 1.5061253309249878
Epoch 66: train_avg_loss 1.5611954375175432 eval_avg_acc: 0.3446924280483956 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:33:05] [32mIntermediate result: 0.3446924280483956  (Index 65)[0m
================Epoch: 67================
Iteration 1: train_loss 1.5461781024932861
Iteration 2: train_loss 1.5206286907196045
Iteration 3: train_loss 1.5712600946426392
Iteration 4: train_loss 1.5111099481582642
Iteration 5: train_loss 1.5150306224822998
Iteration 6: train_loss 1.5839289426803589
Iteration 7: train_loss 1.5244728326797485
Iteration 8: train_loss 1.525274395942688
Iteration 9: train_loss 1.4776424169540405
Iteration 10: train_loss 1.48496413230896
Iteration 11: train_loss 1.554404616355896
Iteration 12: train_loss 1.556188702583313
Iteration 13: train_loss 1.5547471046447754
Iteration 14: train_loss 1.4777952432632446
Iteration 15: train_loss 1.481503963470459
Iteration 16: train_loss 1.5303682088851929
Iteration 17: train_loss 1.5285283327102661
Iteration 18: train_loss 1.478508472442627
Iteration 19: train_loss 1.5716488361358643
Iteration 20: train_loss 1.5221375226974487
Iteration 21: train_loss 1.5459238290786743
Iteration 22: train_loss 1.595772624015808
Iteration 23: train_loss 1.5813074111938477
Iteration 24: train_loss 1.5664209127426147
Iteration 25: train_loss 1.544907569885254
Iteration 26: train_loss 1.4957189559936523
Iteration 27: train_loss 1.6059224605560303
Iteration 28: train_loss 1.513807773590088
Iteration 29: train_loss 1.4860305786132812
Iteration 30: train_loss 1.4910173416137695
Iteration 31: train_loss 1.530103325843811
Iteration 32: train_loss 1.56467866897583
Iteration 33: train_loss 1.5395561456680298
Iteration 34: train_loss 1.5558682680130005
Iteration 35: train_loss 1.5558383464813232
Iteration 36: train_loss 1.5217442512512207
Iteration 37: train_loss 1.516728401184082
Iteration 38: train_loss 1.5038821697235107
Iteration 39: train_loss 1.4764008522033691
Iteration 40: train_loss 1.5384544134140015
Iteration 41: train_loss 1.5197464227676392
Iteration 42: train_loss 1.5810471773147583
Iteration 43: train_loss 1.5573539733886719
Iteration 44: train_loss 1.616850733757019
Iteration 45: train_loss 1.5878514051437378
Iteration 46: train_loss 1.5719003677368164
Iteration 47: train_loss 1.6190426349639893
Iteration 48: train_loss 1.570163369178772
Iteration 49: train_loss 1.534850001335144
Iteration 50: train_loss 1.520335078239441
Iteration 51: train_loss 1.5684404373168945
Iteration 52: train_loss 1.519629955291748
Iteration 53: train_loss 1.5698058605194092
Iteration 54: train_loss 1.5298935174942017
Iteration 55: train_loss 1.5233564376831055
Iteration 56: train_loss 1.5300698280334473
Iteration 57: train_loss 1.5410778522491455
Iteration 58: train_loss 1.5691440105438232
Iteration 59: train_loss 1.5418094396591187
Iteration 60: train_loss 1.5578875541687012
Iteration 61: train_loss 1.531637191772461
Iteration 62: train_loss 1.5507540702819824
Iteration 63: train_loss 1.5499154329299927
Iteration 64: train_loss 1.536118984222412
Iteration 65: train_loss 1.5234246253967285
Iteration 66: train_loss 1.58168363571167
Iteration 67: train_loss 1.5522661209106445
Iteration 68: train_loss 1.5207170248031616
Iteration 69: train_loss 1.600744605064392
Iteration 70: train_loss 1.6227056980133057
Iteration 71: train_loss 1.506238579750061
Iteration 72: train_loss 1.464500069618225
Iteration 73: train_loss 1.590083122253418
Iteration 74: train_loss 1.5582596063613892
Iteration 75: train_loss 1.5929560661315918
Iteration 76: train_loss 1.572058916091919
Iteration 77: train_loss 1.543803334236145
Iteration 78: train_loss 1.562502145767212
Iteration 79: train_loss 1.4852620363235474
Iteration 80: train_loss 1.5689903497695923
Iteration 81: train_loss 1.6361844539642334
Iteration 82: train_loss 1.5913293361663818
Iteration 83: train_loss 1.5221325159072876
Iteration 84: train_loss 1.5973645448684692
Iteration 85: train_loss 1.6460787057876587
Iteration 86: train_loss 1.5973972082138062
Iteration 87: train_loss 1.6153266429901123
Iteration 88: train_loss 1.5906316041946411
Iteration 89: train_loss 1.6322236061096191
Iteration 90: train_loss 1.5517692565917969
Iteration 91: train_loss 1.539707064628601
Iteration 92: train_loss 1.6127660274505615
Iteration 93: train_loss 1.5515844821929932
Iteration 94: train_loss 1.5114848613739014
Iteration 95: train_loss 1.5816030502319336
Iteration 96: train_loss 1.5984681844711304
Iteration 97: train_loss 1.548830270767212
Iteration 98: train_loss 1.496958613395691
Iteration 99: train_loss 1.5636351108551025
Iteration 100: train_loss 1.5854250192642212
Iteration 101: train_loss 1.5353893041610718
Iteration 102: train_loss 1.5117442607879639
Iteration 103: train_loss 1.50243079662323
Iteration 104: train_loss 1.535311222076416
Iteration 105: train_loss 1.5661828517913818
Iteration 106: train_loss 1.559847116470337
Iteration 107: train_loss 1.5819134712219238
Iteration 108: train_loss 1.6311663389205933
Iteration 109: train_loss 1.550927758216858
Iteration 110: train_loss 1.604907512664795
Iteration 111: train_loss 1.5932214260101318
Iteration 112: train_loss 1.7207871675491333
Iteration 113: train_loss 1.5587797164916992
Iteration 114: train_loss 1.5230140686035156
Iteration 115: train_loss 1.5550531148910522
Iteration 116: train_loss 1.562027931213379
Iteration 117: train_loss 1.5031557083129883
Iteration 118: train_loss 1.5536916255950928
Iteration 119: train_loss 1.5759963989257812
Iteration 120: train_loss 1.642659306526184
Iteration 121: train_loss 1.6093380451202393
Iteration 122: train_loss 1.546528935432434
Iteration 123: train_loss 1.463188886642456
Iteration 124: train_loss 1.5978889465332031
Iteration 125: train_loss 1.4867349863052368
Iteration 126: train_loss 1.471365213394165
Iteration 127: train_loss 1.5533945560455322
Iteration 128: train_loss 1.539818286895752
Iteration 129: train_loss 1.4884653091430664
Iteration 130: train_loss 1.5663233995437622
Iteration 131: train_loss 1.5658998489379883
Iteration 132: train_loss 1.5380491018295288
Iteration 133: train_loss 1.5114742517471313
Iteration 134: train_loss 1.577120304107666
Iteration 135: train_loss 1.5802345275878906
Iteration 136: train_loss 1.6724436283111572
Iteration 137: train_loss 1.59699547290802
Iteration 138: train_loss 1.5541229248046875
Iteration 139: train_loss 1.5571445226669312
Iteration 140: train_loss 1.6142218112945557
Iteration 141: train_loss 1.5795257091522217
Iteration 142: train_loss 1.563860535621643
Iteration 143: train_loss 1.5595461130142212
Iteration 144: train_loss 1.6278337240219116
Iteration 145: train_loss 1.576823115348816
Iteration 146: train_loss 1.5718226432800293
Iteration 147: train_loss 1.5172220468521118
Iteration 148: train_loss 1.573569416999817
Iteration 149: train_loss 1.541975975036621
Iteration 150: train_loss 1.5769821405410767
Iteration 151: train_loss 1.6226016283035278
Iteration 152: train_loss 1.492229700088501
Iteration 153: train_loss 1.6486905813217163
Iteration 154: train_loss 1.6011303663253784
Iteration 155: train_loss 1.5238596200942993
Iteration 156: train_loss 1.6272187232971191
Iteration 157: train_loss 1.5571808815002441
Iteration 158: train_loss 1.5797888040542603
Iteration 159: train_loss 1.590902328491211
Iteration 160: train_loss 1.5959608554840088
Iteration 161: train_loss 1.5304174423217773
Iteration 162: train_loss 1.5335243940353394
Iteration 163: train_loss 1.569271445274353
Iteration 164: train_loss 1.5007176399230957
Iteration 165: train_loss 1.5583717823028564
Iteration 166: train_loss 1.480972409248352
Iteration 167: train_loss 1.5608534812927246
Iteration 168: train_loss 1.5438554286956787
Iteration 169: train_loss 1.5177028179168701
Iteration 170: train_loss 1.5977609157562256
Iteration 171: train_loss 1.5772020816802979
Iteration 172: train_loss 1.5007601976394653
Iteration 173: train_loss 1.5666879415512085
Iteration 174: train_loss 1.5626829862594604
Iteration 175: train_loss 1.5245466232299805
Iteration 176: train_loss 1.5357481241226196
Iteration 177: train_loss 1.57923424243927
Epoch 67: train_avg_loss 1.5547467719363628 eval_avg_acc: 0.3479739150253877 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:33:46] [32mIntermediate result: 0.3479739150253877  (Index 66)[0m
================Epoch: 68================
Iteration 1: train_loss 1.5125184059143066
Iteration 2: train_loss 1.5724499225616455
Iteration 3: train_loss 1.5092312097549438
Iteration 4: train_loss 1.523774266242981
Iteration 5: train_loss 1.567988395690918
Iteration 6: train_loss 1.5492215156555176
Iteration 7: train_loss 1.5351890325546265
Iteration 8: train_loss 1.5226542949676514
Iteration 9: train_loss 1.5270586013793945
Iteration 10: train_loss 1.5197460651397705
Iteration 11: train_loss 1.546160340309143
Iteration 12: train_loss 1.51815927028656
Iteration 13: train_loss 1.5943511724472046
Iteration 14: train_loss 1.58837890625
Iteration 15: train_loss 1.4327001571655273
Iteration 16: train_loss 1.5140968561172485
Iteration 17: train_loss 1.5616569519042969
Iteration 18: train_loss 1.5409743785858154
Iteration 19: train_loss 1.5705612897872925
Iteration 20: train_loss 1.4724922180175781
Iteration 21: train_loss 1.5056427717208862
Iteration 22: train_loss 1.5042399168014526
Iteration 23: train_loss 1.5029534101486206
Iteration 24: train_loss 1.5064955949783325
Iteration 25: train_loss 1.5248384475708008
Iteration 26: train_loss 1.5115735530853271
Iteration 27: train_loss 1.536019206047058
Iteration 28: train_loss 1.5089777708053589
Iteration 29: train_loss 1.4821528196334839
Iteration 30: train_loss 1.4958674907684326
Iteration 31: train_loss 1.5296387672424316
Iteration 32: train_loss 1.5203897953033447
Iteration 33: train_loss 1.5458984375
Iteration 34: train_loss 1.5119588375091553
Iteration 35: train_loss 1.5972174406051636
Iteration 36: train_loss 1.5380570888519287
Iteration 37: train_loss 1.53719162940979
Iteration 38: train_loss 1.5267804861068726
Iteration 39: train_loss 1.5524623394012451
Iteration 40: train_loss 1.4968136548995972
Iteration 41: train_loss 1.4842751026153564
Iteration 42: train_loss 1.5354580879211426
Iteration 43: train_loss 1.5188558101654053
Iteration 44: train_loss 1.5145530700683594
Iteration 45: train_loss 1.558164358139038
Iteration 46: train_loss 1.5157957077026367
Iteration 47: train_loss 1.522773265838623
Iteration 48: train_loss 1.5319654941558838
Iteration 49: train_loss 1.4859778881072998
Iteration 50: train_loss 1.50206458568573
Iteration 51: train_loss 1.5635895729064941
Iteration 52: train_loss 1.482289433479309
Iteration 53: train_loss 1.4569594860076904
Iteration 54: train_loss 1.506050705909729
Iteration 55: train_loss 1.5067471265792847
Iteration 56: train_loss 1.5592255592346191
Iteration 57: train_loss 1.5554447174072266
Iteration 58: train_loss 1.529097080230713
Iteration 59: train_loss 1.6258814334869385
Iteration 60: train_loss 1.5150583982467651
Iteration 61: train_loss 1.4756141901016235
Iteration 62: train_loss 1.541530728340149
Iteration 63: train_loss 1.4805676937103271
Iteration 64: train_loss 1.5176461935043335
Iteration 65: train_loss 1.4497965574264526
Iteration 66: train_loss 1.6107494831085205
Iteration 67: train_loss 1.60701584815979
Iteration 68: train_loss 1.5372849702835083
Iteration 69: train_loss 1.5950533151626587
Iteration 70: train_loss 1.5666855573654175
Iteration 71: train_loss 1.6254856586456299
Iteration 72: train_loss 1.510267972946167
Iteration 73: train_loss 1.5281131267547607
Iteration 74: train_loss 1.563391923904419
Iteration 75: train_loss 1.5404486656188965
Iteration 76: train_loss 1.5022025108337402
Iteration 77: train_loss 1.5747236013412476
Iteration 78: train_loss 1.5254709720611572
Iteration 79: train_loss 1.5522756576538086
Iteration 80: train_loss 1.4849745035171509
Iteration 81: train_loss 1.537063717842102
Iteration 82: train_loss 1.5060725212097168
Iteration 83: train_loss 1.5701892375946045
Iteration 84: train_loss 1.543486475944519
Iteration 85: train_loss 1.618809461593628
Iteration 86: train_loss 1.5770177841186523
Iteration 87: train_loss 1.4884017705917358
Iteration 88: train_loss 1.5060151815414429
Iteration 89: train_loss 1.5702546834945679
Iteration 90: train_loss 1.5732814073562622
Iteration 91: train_loss 1.5557810068130493
Iteration 92: train_loss 1.5069383382797241
Iteration 93: train_loss 1.5058766603469849
Iteration 94: train_loss 1.578758955001831
Iteration 95: train_loss 1.5462942123413086
Iteration 96: train_loss 1.5918878316879272
Iteration 97: train_loss 1.536604881286621
Iteration 98: train_loss 1.5074517726898193
Iteration 99: train_loss 1.5843034982681274
Iteration 100: train_loss 1.566774606704712
Iteration 101: train_loss 1.5087940692901611
Iteration 102: train_loss 1.5747873783111572
Iteration 103: train_loss 1.522344946861267
Iteration 104: train_loss 1.5350874662399292
Iteration 105: train_loss 1.5352189540863037
Iteration 106: train_loss 1.6209138631820679
Iteration 107: train_loss 1.5372706651687622
Iteration 108: train_loss 1.585860252380371
Iteration 109: train_loss 1.540681004524231
Iteration 110: train_loss 1.5633435249328613
Iteration 111: train_loss 1.5874539613723755
Iteration 112: train_loss 1.5324771404266357
Iteration 113: train_loss 1.5348683595657349
Iteration 114: train_loss 1.5109153985977173
Iteration 115: train_loss 1.4775867462158203
Iteration 116: train_loss 1.5869848728179932
Iteration 117: train_loss 1.568787932395935
Iteration 118: train_loss 1.5869481563568115
Iteration 119: train_loss 1.5939435958862305
Iteration 120: train_loss 1.5720106363296509
Iteration 121: train_loss 1.584559679031372
Iteration 122: train_loss 1.4845709800720215
Iteration 123: train_loss 1.485837459564209
Iteration 124: train_loss 1.5805835723876953
Iteration 125: train_loss 1.450103759765625
Iteration 126: train_loss 1.5380440950393677
Iteration 127: train_loss 1.5618442296981812
Iteration 128: train_loss 1.5843793153762817
Iteration 129: train_loss 1.581892728805542
Iteration 130: train_loss 1.5652509927749634
Iteration 131: train_loss 1.5768147706985474
Iteration 132: train_loss 1.584831714630127
Iteration 133: train_loss 1.5120751857757568
Iteration 134: train_loss 1.6473740339279175
Iteration 135: train_loss 1.5389875173568726
Iteration 136: train_loss 1.5490915775299072
Iteration 137: train_loss 1.5707504749298096
Iteration 138: train_loss 1.487794280052185
Iteration 139: train_loss 1.531043291091919
Iteration 140: train_loss 1.5253334045410156
Iteration 141: train_loss 1.5944126844406128
Iteration 142: train_loss 1.5600916147232056
Iteration 143: train_loss 1.581822395324707
Iteration 144: train_loss 1.62774658203125
Iteration 145: train_loss 1.5547446012496948
Iteration 146: train_loss 1.557332992553711
Iteration 147: train_loss 1.5494797229766846
Iteration 148: train_loss 1.5765585899353027
Iteration 149: train_loss 1.5138050317764282
Iteration 150: train_loss 1.4764479398727417
Iteration 151: train_loss 1.592092752456665
Iteration 152: train_loss 1.5002837181091309
Iteration 153: train_loss 1.563865303993225
Iteration 154: train_loss 1.5283761024475098
Iteration 155: train_loss 1.5526787042617798
Iteration 156: train_loss 1.5667495727539062
Iteration 157: train_loss 1.5250600576400757
Iteration 158: train_loss 1.5878441333770752
Iteration 159: train_loss 1.530146837234497
Iteration 160: train_loss 1.508440375328064
Iteration 161: train_loss 1.5498968362808228
Iteration 162: train_loss 1.5842453241348267
Iteration 163: train_loss 1.5431287288665771
Iteration 164: train_loss 1.5710978507995605
Iteration 165: train_loss 1.6463416814804077
Iteration 166: train_loss 1.5553719997406006
Iteration 167: train_loss 1.5804657936096191
Iteration 168: train_loss 1.586662769317627
Iteration 169: train_loss 1.5389105081558228
Iteration 170: train_loss 1.5591548681259155
Iteration 171: train_loss 1.590286374092102
Iteration 172: train_loss 1.5935795307159424
Iteration 173: train_loss 1.5484710931777954
Iteration 174: train_loss 1.5440123081207275
Iteration 175: train_loss 1.5419920682907104
Iteration 176: train_loss 1.5500892400741577
Iteration 177: train_loss 1.6881496906280518
Epoch 68: train_avg_loss 1.5434045259561915 eval_avg_acc: 0.3287686985943428 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:34:28] [32mIntermediate result: 0.3287686985943428  (Index 67)[0m
================Epoch: 69================
Iteration 1: train_loss 1.5854604244232178
Iteration 2: train_loss 1.6206880807876587
Iteration 3: train_loss 1.5351920127868652
Iteration 4: train_loss 1.5682405233383179
Iteration 5: train_loss 1.5153284072875977
Iteration 6: train_loss 1.5620338916778564
Iteration 7: train_loss 1.5540528297424316
Iteration 8: train_loss 1.5533767938613892
Iteration 9: train_loss 1.4866054058074951
Iteration 10: train_loss 1.5623167753219604
Iteration 11: train_loss 1.4967434406280518
Iteration 12: train_loss 1.517001986503601
Iteration 13: train_loss 1.5569616556167603
Iteration 14: train_loss 1.4811457395553589
Iteration 15: train_loss 1.5085029602050781
Iteration 16: train_loss 1.5179105997085571
Iteration 17: train_loss 1.5192196369171143
Iteration 18: train_loss 1.4903135299682617
Iteration 19: train_loss 1.5511326789855957
Iteration 20: train_loss 1.5236841440200806
Iteration 21: train_loss 1.5139946937561035
Iteration 22: train_loss 1.510135293006897
Iteration 23: train_loss 1.5057306289672852
Iteration 24: train_loss 1.5196346044540405
Iteration 25: train_loss 1.5852879285812378
Iteration 26: train_loss 1.600514531135559
Iteration 27: train_loss 1.5210018157958984
Iteration 28: train_loss 1.51590096950531
Iteration 29: train_loss 1.4734840393066406
Iteration 30: train_loss 1.562394618988037
Iteration 31: train_loss 1.550402283668518
Iteration 32: train_loss 1.5998249053955078
Iteration 33: train_loss 1.5684391260147095
Iteration 34: train_loss 1.5326157808303833
Iteration 35: train_loss 1.5732319355010986
Iteration 36: train_loss 1.5209401845932007
Iteration 37: train_loss 1.548895239830017
Iteration 38: train_loss 1.5096226930618286
Iteration 39: train_loss 1.5822199583053589
Iteration 40: train_loss 1.5244107246398926
Iteration 41: train_loss 1.554944634437561
Iteration 42: train_loss 1.509173035621643
Iteration 43: train_loss 1.5034854412078857
Iteration 44: train_loss 1.4815418720245361
Iteration 45: train_loss 1.6005669832229614
Iteration 46: train_loss 1.5034055709838867
Iteration 47: train_loss 1.5252516269683838
Iteration 48: train_loss 1.4934698343276978
Iteration 49: train_loss 1.5655837059020996
Iteration 50: train_loss 1.5913628339767456
Iteration 51: train_loss 1.5314100980758667
Iteration 52: train_loss 1.54373300075531
Iteration 53: train_loss 1.5735208988189697
Iteration 54: train_loss 1.5065768957138062
Iteration 55: train_loss 1.5015662908554077
Iteration 56: train_loss 1.4539512395858765
Iteration 57: train_loss 1.5349494218826294
Iteration 58: train_loss 1.5338423252105713
Iteration 59: train_loss 1.4846175909042358
Iteration 60: train_loss 1.5615729093551636
Iteration 61: train_loss 1.520555019378662
Iteration 62: train_loss 1.5162196159362793
Iteration 63: train_loss 1.5128505229949951
Iteration 64: train_loss 1.517396330833435
Iteration 65: train_loss 1.5395548343658447
Iteration 66: train_loss 1.5174599885940552
Iteration 67: train_loss 1.5721566677093506
Iteration 68: train_loss 1.5899758338928223
Iteration 69: train_loss 1.5545986890792847
Iteration 70: train_loss 1.5872749090194702
Iteration 71: train_loss 1.4954841136932373
Iteration 72: train_loss 1.5203667879104614
Iteration 73: train_loss 1.5050572156906128
Iteration 74: train_loss 1.5278065204620361
Iteration 75: train_loss 1.4714510440826416
Iteration 76: train_loss 1.4831947088241577
Iteration 77: train_loss 1.5238053798675537
Iteration 78: train_loss 1.5144128799438477
Iteration 79: train_loss 1.5208933353424072
Iteration 80: train_loss 1.5873886346817017
Iteration 81: train_loss 1.4657683372497559
Iteration 82: train_loss 1.5841044187545776
Iteration 83: train_loss 1.526275873184204
Iteration 84: train_loss 1.5390996932983398
Iteration 85: train_loss 1.4872665405273438
Iteration 86: train_loss 1.5182173252105713
Iteration 87: train_loss 1.5826427936553955
Iteration 88: train_loss 1.505952000617981
Iteration 89: train_loss 1.573756217956543
Iteration 90: train_loss 1.4907069206237793
Iteration 91: train_loss 1.592930555343628
Iteration 92: train_loss 1.6338050365447998
Iteration 93: train_loss 1.5312422513961792
Iteration 94: train_loss 1.5260119438171387
Iteration 95: train_loss 1.551819086074829
Iteration 96: train_loss 1.5617761611938477
Iteration 97: train_loss 1.511913776397705
Iteration 98: train_loss 1.5258592367172241
Iteration 99: train_loss 1.5778824090957642
Iteration 100: train_loss 1.5444722175598145
Iteration 101: train_loss 1.5268927812576294
Iteration 102: train_loss 1.5000240802764893
Iteration 103: train_loss 1.4716569185256958
Iteration 104: train_loss 1.5964899063110352
Iteration 105: train_loss 1.5000064373016357
Iteration 106: train_loss 1.480099081993103
Iteration 107: train_loss 1.470922589302063
Iteration 108: train_loss 1.5401966571807861
Iteration 109: train_loss 1.5593072175979614
Iteration 110: train_loss 1.4593311548233032
Iteration 111: train_loss 1.504331111907959
Iteration 112: train_loss 1.5199164152145386
Iteration 113: train_loss 1.5107961893081665
Iteration 114: train_loss 1.4724183082580566
Iteration 115: train_loss 1.5366101264953613
Iteration 116: train_loss 1.4923936128616333
Iteration 117: train_loss 1.559716820716858
Iteration 118: train_loss 1.5519518852233887
Iteration 119: train_loss 1.5733587741851807
Iteration 120: train_loss 1.592232346534729
Iteration 121: train_loss 1.5574194192886353
Iteration 122: train_loss 1.5515629053115845
Iteration 123: train_loss 1.553611159324646
Iteration 124: train_loss 1.551515817642212
Iteration 125: train_loss 1.5807827711105347
Iteration 126: train_loss 1.5321608781814575
Iteration 127: train_loss 1.5685285329818726
Iteration 128: train_loss 1.5117436647415161
Iteration 129: train_loss 1.5502053499221802
Iteration 130: train_loss 1.6089692115783691
Iteration 131: train_loss 1.5530381202697754
Iteration 132: train_loss 1.5429859161376953
Iteration 133: train_loss 1.4979164600372314
Iteration 134: train_loss 1.4785135984420776
Iteration 135: train_loss 1.560826301574707
Iteration 136: train_loss 1.5369523763656616
Iteration 137: train_loss 1.550506353378296
Iteration 138: train_loss 1.5203707218170166
Iteration 139: train_loss 1.4934499263763428
Iteration 140: train_loss 1.5829222202301025
Iteration 141: train_loss 1.6539623737335205
Iteration 142: train_loss 1.563581109046936
Iteration 143: train_loss 1.592445969581604
Iteration 144: train_loss 1.501584529876709
Iteration 145: train_loss 1.5721145868301392
Iteration 146: train_loss 1.5720138549804688
Iteration 147: train_loss 1.5384665727615356
Iteration 148: train_loss 1.5152815580368042
Iteration 149: train_loss 1.558831810951233
Iteration 150: train_loss 1.5717586278915405
Iteration 151: train_loss 1.4840362071990967
Iteration 152: train_loss 1.600860357284546
Iteration 153: train_loss 1.5770797729492188
Iteration 154: train_loss 1.5048363208770752
Iteration 155: train_loss 1.600448727607727
Iteration 156: train_loss 1.5455063581466675
Iteration 157: train_loss 1.5233032703399658
Iteration 158: train_loss 1.5847581624984741
Iteration 159: train_loss 1.570557713508606
Iteration 160: train_loss 1.603617787361145
Iteration 161: train_loss 1.5128209590911865
Iteration 162: train_loss 1.5736812353134155
Iteration 163: train_loss 1.5944823026657104
Iteration 164: train_loss 1.5710362195968628
Iteration 165: train_loss 1.5148416757583618
Iteration 166: train_loss 1.6156214475631714
Iteration 167: train_loss 1.5953426361083984
Iteration 168: train_loss 1.5309522151947021
Iteration 169: train_loss 1.6142690181732178
Iteration 170: train_loss 1.5909931659698486
Iteration 171: train_loss 1.5639708042144775
Iteration 172: train_loss 1.592043399810791
Iteration 173: train_loss 1.616115689277649
Iteration 174: train_loss 1.5397201776504517
Iteration 175: train_loss 1.5553237199783325
Iteration 176: train_loss 1.5640437602996826
Iteration 177: train_loss 1.5851900577545166
Epoch 69: train_avg_loss 1.540998043987037 eval_avg_acc: 0.3392780223069808 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:35:10] [32mIntermediate result: 0.3392780223069808  (Index 68)[0m
================Epoch: 70================
Iteration 1: train_loss 1.4299403429031372
Iteration 2: train_loss 1.4930024147033691
Iteration 3: train_loss 1.5098947286605835
Iteration 4: train_loss 1.5143742561340332
Iteration 5: train_loss 1.5106000900268555
Iteration 6: train_loss 1.4868136644363403
Iteration 7: train_loss 1.4901142120361328
Iteration 8: train_loss 1.519133448600769
Iteration 9: train_loss 1.4853967428207397
Iteration 10: train_loss 1.5735002756118774
Iteration 11: train_loss 1.5421473979949951
Iteration 12: train_loss 1.5418304204940796
Iteration 13: train_loss 1.5945440530776978
Iteration 14: train_loss 1.5282549858093262
Iteration 15: train_loss 1.5404995679855347
Iteration 16: train_loss 1.4938561916351318
Iteration 17: train_loss 1.5963406562805176
Iteration 18: train_loss 1.544508457183838
Iteration 19: train_loss 1.5780357122421265
Iteration 20: train_loss 1.5642986297607422
Iteration 21: train_loss 1.5696603059768677
Iteration 22: train_loss 1.4797316789627075
Iteration 23: train_loss 1.524304986000061
Iteration 24: train_loss 1.6180381774902344
Iteration 25: train_loss 1.486024022102356
Iteration 26: train_loss 1.4752354621887207
Iteration 27: train_loss 1.5232658386230469
Iteration 28: train_loss 1.4736427068710327
Iteration 29: train_loss 1.4729290008544922
Iteration 30: train_loss 1.4959932565689087
Iteration 31: train_loss 1.5061695575714111
Iteration 32: train_loss 1.488078236579895
Iteration 33: train_loss 1.473706841468811
Iteration 34: train_loss 1.5781351327896118
Iteration 35: train_loss 1.4613087177276611
Iteration 36: train_loss 1.4466198682785034
Iteration 37: train_loss 1.4342509508132935
Iteration 38: train_loss 1.4679441452026367
Iteration 39: train_loss 1.445210576057434
Iteration 40: train_loss 1.4632816314697266
Iteration 41: train_loss 1.561387300491333
Iteration 42: train_loss 1.5126581192016602
Iteration 43: train_loss 1.544276475906372
Iteration 44: train_loss 1.528146743774414
Iteration 45: train_loss 1.4686144590377808
Iteration 46: train_loss 1.4840562343597412
Iteration 47: train_loss 1.490444302558899
Iteration 48: train_loss 1.5072513818740845
Iteration 49: train_loss 1.5332305431365967
Iteration 50: train_loss 1.4711191654205322
Iteration 51: train_loss 1.4841234683990479
Iteration 52: train_loss 1.4973297119140625
Iteration 53: train_loss 1.5326513051986694
Iteration 54: train_loss 1.534606695175171
Iteration 55: train_loss 1.5341049432754517
Iteration 56: train_loss 1.5293961763381958
Iteration 57: train_loss 1.5353599786758423
Iteration 58: train_loss 1.4891502857208252
Iteration 59: train_loss 1.5094677209854126
Iteration 60: train_loss 1.4910993576049805
Iteration 61: train_loss 1.5909732580184937
Iteration 62: train_loss 1.581283688545227
Iteration 63: train_loss 1.5092161893844604
Iteration 64: train_loss 1.5369298458099365
Iteration 65: train_loss 1.4520734548568726
Iteration 66: train_loss 1.502529501914978
Iteration 67: train_loss 1.5484042167663574
Iteration 68: train_loss 1.4985207319259644
Iteration 69: train_loss 1.535028338432312
Iteration 70: train_loss 1.6283504962921143
Iteration 71: train_loss 1.5857335329055786
Iteration 72: train_loss 1.4975930452346802
Iteration 73: train_loss 1.5570954084396362
Iteration 74: train_loss 1.5135645866394043
Iteration 75: train_loss 1.500567078590393
Iteration 76: train_loss 1.5298811197280884
Iteration 77: train_loss 1.531572699546814
Iteration 78: train_loss 1.4966011047363281
Iteration 79: train_loss 1.5287293195724487
Iteration 80: train_loss 1.5048848390579224
Iteration 81: train_loss 1.5589019060134888
Iteration 82: train_loss 1.570833444595337
Iteration 83: train_loss 1.513445258140564
Iteration 84: train_loss 1.5181457996368408
Iteration 85: train_loss 1.530286431312561
Iteration 86: train_loss 1.5439058542251587
Iteration 87: train_loss 1.5637925863265991
Iteration 88: train_loss 1.5118390321731567
Iteration 89: train_loss 1.4956371784210205
Iteration 90: train_loss 1.4732800722122192
Iteration 91: train_loss 1.493065357208252
Iteration 92: train_loss 1.6056246757507324
Iteration 93: train_loss 1.5255069732666016
Iteration 94: train_loss 1.4852585792541504
Iteration 95: train_loss 1.5785140991210938
Iteration 96: train_loss 1.4732505083084106
Iteration 97: train_loss 1.4485746622085571
Iteration 98: train_loss 1.4574135541915894
Iteration 99: train_loss 1.5214684009552002
Iteration 100: train_loss 1.5358260869979858
Iteration 101: train_loss 1.5276658535003662
Iteration 102: train_loss 1.5143173933029175
Iteration 103: train_loss 1.4871125221252441
Iteration 104: train_loss 1.5563174486160278
Iteration 105: train_loss 1.5529470443725586
Iteration 106: train_loss 1.5145286321640015
Iteration 107: train_loss 1.5033236742019653
Iteration 108: train_loss 1.4723089933395386
Iteration 109: train_loss 1.5335716009140015
Iteration 110: train_loss 1.5264849662780762
Iteration 111: train_loss 1.5153448581695557
Iteration 112: train_loss 1.542637586593628
Iteration 113: train_loss 1.571832537651062
Iteration 114: train_loss 1.5371187925338745
Iteration 115: train_loss 1.5206314325332642
Iteration 116: train_loss 1.5468997955322266
Iteration 117: train_loss 1.5713392496109009
Iteration 118: train_loss 1.5505279302597046
Iteration 119: train_loss 1.5703107118606567
Iteration 120: train_loss 1.4837696552276611
Iteration 121: train_loss 1.5540157556533813
Iteration 122: train_loss 1.527208685874939
Iteration 123: train_loss 1.5859934091567993
Iteration 124: train_loss 1.5195056200027466
Iteration 125: train_loss 1.55616295337677
Iteration 126: train_loss 1.542306661605835
Iteration 127: train_loss 1.5975152254104614
Iteration 128: train_loss 1.5705797672271729
Iteration 129: train_loss 1.5588817596435547
Iteration 130: train_loss 1.5808225870132446
Iteration 131: train_loss 1.5169909000396729
Iteration 132: train_loss 1.478225588798523
Iteration 133: train_loss 1.5191545486450195
Iteration 134: train_loss 1.561989188194275
Iteration 135: train_loss 1.547772765159607
Iteration 136: train_loss 1.4871052503585815
Iteration 137: train_loss 1.534196376800537
Iteration 138: train_loss 1.4650604724884033
Iteration 139: train_loss 1.5644054412841797
Iteration 140: train_loss 1.5329351425170898
Iteration 141: train_loss 1.5704880952835083
Iteration 142: train_loss 1.5728449821472168
Iteration 143: train_loss 1.5094618797302246
Iteration 144: train_loss 1.5227875709533691
Iteration 145: train_loss 1.6086537837982178
Iteration 146: train_loss 1.5483609437942505
Iteration 147: train_loss 1.5061806440353394
Iteration 148: train_loss 1.564726710319519
Iteration 149: train_loss 1.6023041009902954
Iteration 150: train_loss 1.518228530883789
Iteration 151: train_loss 1.5512621402740479
Iteration 152: train_loss 1.5869948863983154
Iteration 153: train_loss 1.4956560134887695
Iteration 154: train_loss 1.55461847782135
Iteration 155: train_loss 1.4849870204925537
Iteration 156: train_loss 1.5558005571365356
Iteration 157: train_loss 1.4816590547561646
Iteration 158: train_loss 1.5266848802566528
Iteration 159: train_loss 1.5662904977798462
Iteration 160: train_loss 1.546924352645874
Iteration 161: train_loss 1.513771891593933
Iteration 162: train_loss 1.5619317293167114
Iteration 163: train_loss 1.5335780382156372
Iteration 164: train_loss 1.5801666975021362
Iteration 165: train_loss 1.5286247730255127
Iteration 166: train_loss 1.6027374267578125
Iteration 167: train_loss 1.5940091609954834
Iteration 168: train_loss 1.5656495094299316
Iteration 169: train_loss 1.5703786611557007
Iteration 170: train_loss 1.565795660018921
Iteration 171: train_loss 1.5807665586471558
Iteration 172: train_loss 1.516594648361206
Iteration 173: train_loss 1.5963165760040283
Iteration 174: train_loss 1.5409226417541504
Iteration 175: train_loss 1.627476692199707
Iteration 176: train_loss 1.597705602645874
Iteration 177: train_loss 1.5132681131362915
Epoch 70: train_avg_loss 1.5285741407318978 eval_avg_acc: 0.33297184691753573 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:35:51] [32mIntermediate result: 0.33297184691753573  (Index 69)[0m
================Epoch: 71================
Iteration 1: train_loss 1.537505865097046
Iteration 2: train_loss 1.5739262104034424
Iteration 3: train_loss 1.567294716835022
Iteration 4: train_loss 1.59251070022583
Iteration 5: train_loss 1.5257128477096558
Iteration 6: train_loss 1.5251364707946777
Iteration 7: train_loss 1.5464190244674683
Iteration 8: train_loss 1.5662821531295776
Iteration 9: train_loss 1.5227330923080444
Iteration 10: train_loss 1.534340500831604
Iteration 11: train_loss 1.5108164548873901
Iteration 12: train_loss 1.4802528619766235
Iteration 13: train_loss 1.4390193223953247
Iteration 14: train_loss 1.5415819883346558
Iteration 15: train_loss 1.4737457036972046
Iteration 16: train_loss 1.5582987070083618
Iteration 17: train_loss 1.5206279754638672
Iteration 18: train_loss 1.5062955617904663
Iteration 19: train_loss 1.527538776397705
Iteration 20: train_loss 1.4929182529449463
Iteration 21: train_loss 1.5078656673431396
Iteration 22: train_loss 1.5309621095657349
Iteration 23: train_loss 1.4740581512451172
Iteration 24: train_loss 1.4687248468399048
Iteration 25: train_loss 1.5242326259613037
Iteration 26: train_loss 1.534751296043396
Iteration 27: train_loss 1.4711967706680298
Iteration 28: train_loss 1.4703723192214966
Iteration 29: train_loss 1.484747290611267
Iteration 30: train_loss 1.5134999752044678
Iteration 31: train_loss 1.5239278078079224
Iteration 32: train_loss 1.4554105997085571
Iteration 33: train_loss 1.519922137260437
Iteration 34: train_loss 1.482954502105713
Iteration 35: train_loss 1.4880800247192383
Iteration 36: train_loss 1.4853318929672241
Iteration 37: train_loss 1.5099517107009888
Iteration 38: train_loss 1.569566011428833
Iteration 39: train_loss 1.5006519556045532
Iteration 40: train_loss 1.4897819757461548
Iteration 41: train_loss 1.4138972759246826
Iteration 42: train_loss 1.4457286596298218
Iteration 43: train_loss 1.4968891143798828
Iteration 44: train_loss 1.423371434211731
Iteration 45: train_loss 1.4671671390533447
Iteration 46: train_loss 1.4709655046463013
Iteration 47: train_loss 1.4653334617614746
Iteration 48: train_loss 1.4870860576629639
Iteration 49: train_loss 1.515028715133667
Iteration 50: train_loss 1.5534766912460327
Iteration 51: train_loss 1.4926787614822388
Iteration 52: train_loss 1.543164610862732
Iteration 53: train_loss 1.5191584825515747
Iteration 54: train_loss 1.4894940853118896
Iteration 55: train_loss 1.4831228256225586
Iteration 56: train_loss 1.5800979137420654
Iteration 57: train_loss 1.521715521812439
Iteration 58: train_loss 1.5500439405441284
Iteration 59: train_loss 1.5017949342727661
Iteration 60: train_loss 1.5683317184448242
Iteration 61: train_loss 1.528780460357666
Iteration 62: train_loss 1.5065208673477173
Iteration 63: train_loss 1.5285313129425049
Iteration 64: train_loss 1.5728317499160767
Iteration 65: train_loss 1.5251668691635132
Iteration 66: train_loss 1.4967460632324219
Iteration 67: train_loss 1.4977071285247803
Iteration 68: train_loss 1.4962012767791748
Iteration 69: train_loss 1.4301306009292603
Iteration 70: train_loss 1.4550466537475586
Iteration 71: train_loss 1.5009729862213135
Iteration 72: train_loss 1.5464786291122437
Iteration 73: train_loss 1.5040010213851929
Iteration 74: train_loss 1.5716941356658936
Iteration 75: train_loss 1.487868309020996
Iteration 76: train_loss 1.5324262380599976
Iteration 77: train_loss 1.600280523300171
Iteration 78: train_loss 1.4975756406784058
Iteration 79: train_loss 1.5004621744155884
Iteration 80: train_loss 1.5310533046722412
Iteration 81: train_loss 1.5212808847427368
Iteration 82: train_loss 1.4841781854629517
Iteration 83: train_loss 1.5562154054641724
Iteration 84: train_loss 1.5414822101593018
Iteration 85: train_loss 1.5184680223464966
Iteration 86: train_loss 1.5417871475219727
Iteration 87: train_loss 1.566544532775879
Iteration 88: train_loss 1.4993196725845337
Iteration 89: train_loss 1.5134927034378052
Iteration 90: train_loss 1.463635802268982
Iteration 91: train_loss 1.4368717670440674
Iteration 92: train_loss 1.4987720251083374
Iteration 93: train_loss 1.4693076610565186
Iteration 94: train_loss 1.5095499753952026
Iteration 95: train_loss 1.5227410793304443
Iteration 96: train_loss 1.4972362518310547
Iteration 97: train_loss 1.504599928855896
Iteration 98: train_loss 1.483286738395691
Iteration 99: train_loss 1.4989534616470337
Iteration 100: train_loss 1.5046206712722778
Iteration 101: train_loss 1.502285122871399
Iteration 102: train_loss 1.5185937881469727
Iteration 103: train_loss 1.5425890684127808
Iteration 104: train_loss 1.4861377477645874
Iteration 105: train_loss 1.5924326181411743
Iteration 106: train_loss 1.5355437994003296
Iteration 107: train_loss 1.5253385305404663
Iteration 108: train_loss 1.5548912286758423
Iteration 109: train_loss 1.5342357158660889
Iteration 110: train_loss 1.5153783559799194
Iteration 111: train_loss 1.4957534074783325
Iteration 112: train_loss 1.5289756059646606
Iteration 113: train_loss 1.5185046195983887
Iteration 114: train_loss 1.5372587442398071
Iteration 115: train_loss 1.5749554634094238
Iteration 116: train_loss 1.5475480556488037
Iteration 117: train_loss 1.4850050210952759
Iteration 118: train_loss 1.5792075395584106
Iteration 119: train_loss 1.53590989112854
Iteration 120: train_loss 1.4990544319152832
Iteration 121: train_loss 1.5497688055038452
Iteration 122: train_loss 1.6061019897460938
Iteration 123: train_loss 1.506277084350586
Iteration 124: train_loss 1.5774348974227905
Iteration 125: train_loss 1.517790675163269
Iteration 126: train_loss 1.4890594482421875
Iteration 127: train_loss 1.6126363277435303
Iteration 128: train_loss 1.5611439943313599
Iteration 129: train_loss 1.4597365856170654
Iteration 130: train_loss 1.5325145721435547
Iteration 131: train_loss 1.530860185623169
Iteration 132: train_loss 1.5368119478225708
Iteration 133: train_loss 1.5825809240341187
Iteration 134: train_loss 1.5392345190048218
Iteration 135: train_loss 1.509096384048462
Iteration 136: train_loss 1.5009335279464722
Iteration 137: train_loss 1.5604835748672485
Iteration 138: train_loss 1.5296791791915894
Iteration 139: train_loss 1.4800643920898438
Iteration 140: train_loss 1.5814405679702759
Iteration 141: train_loss 1.5527070760726929
Iteration 142: train_loss 1.545831322669983
Iteration 143: train_loss 1.5538454055786133
Iteration 144: train_loss 1.5384700298309326
Iteration 145: train_loss 1.5589745044708252
Iteration 146: train_loss 1.524247646331787
Iteration 147: train_loss 1.5932979583740234
Iteration 148: train_loss 1.5285993814468384
Iteration 149: train_loss 1.4951726198196411
Iteration 150: train_loss 1.5742124319076538
Iteration 151: train_loss 1.5328878164291382
Iteration 152: train_loss 1.5501854419708252
Iteration 153: train_loss 1.6508879661560059
Iteration 154: train_loss 1.4450578689575195
Iteration 155: train_loss 1.600300908088684
Iteration 156: train_loss 1.6053341627120972
Iteration 157: train_loss 1.5502135753631592
Iteration 158: train_loss 1.5473278760910034
Iteration 159: train_loss 1.5857696533203125
Iteration 160: train_loss 1.5868371725082397
Iteration 161: train_loss 1.477366328239441
Iteration 162: train_loss 1.5432432889938354
Iteration 163: train_loss 1.5826746225357056
Iteration 164: train_loss 1.5949918031692505
Iteration 165: train_loss 1.5884971618652344
Iteration 166: train_loss 1.5604661703109741
Iteration 167: train_loss 1.5082464218139648
Iteration 168: train_loss 1.4812959432601929
Iteration 169: train_loss 1.6022834777832031
Iteration 170: train_loss 1.526018500328064
Iteration 171: train_loss 1.5834300518035889
Iteration 172: train_loss 1.4845539331436157
Iteration 173: train_loss 1.5699371099472046
Iteration 174: train_loss 1.5813566446304321
Iteration 175: train_loss 1.53966224193573
Iteration 176: train_loss 1.6054496765136719
Iteration 177: train_loss 1.5894209146499634
Epoch 71: train_avg_loss 1.5248170464725819 eval_avg_acc: 0.3493520441525773 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:36:32] [32mIntermediate result: 0.3493520441525773  (Index 70)[0m
================Epoch: 72================
Iteration 1: train_loss 1.51530122756958
Iteration 2: train_loss 1.5585445165634155
Iteration 3: train_loss 1.4977139234542847
Iteration 4: train_loss 1.4534549713134766
Iteration 5: train_loss 1.4859129190444946
Iteration 6: train_loss 1.433113694190979
Iteration 7: train_loss 1.4845222234725952
Iteration 8: train_loss 1.4355311393737793
Iteration 9: train_loss 1.4646685123443604
Iteration 10: train_loss 1.559007167816162
Iteration 11: train_loss 1.4740351438522339
Iteration 12: train_loss 1.4758176803588867
Iteration 13: train_loss 1.4986209869384766
Iteration 14: train_loss 1.5078966617584229
Iteration 15: train_loss 1.5223032236099243
Iteration 16: train_loss 1.4549835920333862
Iteration 17: train_loss 1.4890170097351074
Iteration 18: train_loss 1.4535958766937256
Iteration 19: train_loss 1.469408631324768
Iteration 20: train_loss 1.5120809078216553
Iteration 21: train_loss 1.5078442096710205
Iteration 22: train_loss 1.4583035707473755
Iteration 23: train_loss 1.5497944355010986
Iteration 24: train_loss 1.524709939956665
Iteration 25: train_loss 1.5274665355682373
Iteration 26: train_loss 1.516717791557312
Iteration 27: train_loss 1.5124248266220093
Iteration 28: train_loss 1.5433862209320068
Iteration 29: train_loss 1.5678741931915283
Iteration 30: train_loss 1.4953571557998657
Iteration 31: train_loss 1.4944146871566772
Iteration 32: train_loss 1.5247278213500977
Iteration 33: train_loss 1.515040397644043
Iteration 34: train_loss 1.5432206392288208
Iteration 35: train_loss 1.5379782915115356
Iteration 36: train_loss 1.564331293106079
Iteration 37: train_loss 1.559185266494751
Iteration 38: train_loss 1.4549983739852905
Iteration 39: train_loss 1.5724163055419922
Iteration 40: train_loss 1.4608319997787476
Iteration 41: train_loss 1.5336893796920776
Iteration 42: train_loss 1.49934720993042
Iteration 43: train_loss 1.5422906875610352
Iteration 44: train_loss 1.5063276290893555
Iteration 45: train_loss 1.5726509094238281
Iteration 46: train_loss 1.585871934890747
Iteration 47: train_loss 1.5100902318954468
Iteration 48: train_loss 1.5104938745498657
Iteration 49: train_loss 1.5637576580047607
Iteration 50: train_loss 1.5482641458511353
Iteration 51: train_loss 1.494421362876892
Iteration 52: train_loss 1.5189439058303833
Iteration 53: train_loss 1.459035038948059
Iteration 54: train_loss 1.4799180030822754
Iteration 55: train_loss 1.5180563926696777
Iteration 56: train_loss 1.531468391418457
Iteration 57: train_loss 1.4141931533813477
Iteration 58: train_loss 1.481369137763977
Iteration 59: train_loss 1.4758269786834717
Iteration 60: train_loss 1.506317138671875
Iteration 61: train_loss 1.4930744171142578
Iteration 62: train_loss 1.5083820819854736
Iteration 63: train_loss 1.5455008745193481
Iteration 64: train_loss 1.566515564918518
Iteration 65: train_loss 1.5210504531860352
Iteration 66: train_loss 1.5022189617156982
Iteration 67: train_loss 1.5214104652404785
Iteration 68: train_loss 1.5782325267791748
Iteration 69: train_loss 1.4985244274139404
Iteration 70: train_loss 1.488370656967163
Iteration 71: train_loss 1.5120677947998047
Iteration 72: train_loss 1.523616075515747
Iteration 73: train_loss 1.5210957527160645
Iteration 74: train_loss 1.4934955835342407
Iteration 75: train_loss 1.5006498098373413
Iteration 76: train_loss 1.4468233585357666
Iteration 77: train_loss 1.4817289113998413
Iteration 78: train_loss 1.4855332374572754
Iteration 79: train_loss 1.461500883102417
Iteration 80: train_loss 1.4612703323364258
Iteration 81: train_loss 1.5458285808563232
Iteration 82: train_loss 1.4736021757125854
Iteration 83: train_loss 1.5408703088760376
Iteration 84: train_loss 1.526627540588379
Iteration 85: train_loss 1.468558430671692
Iteration 86: train_loss 1.5244925022125244
Iteration 87: train_loss 1.5500770807266235
Iteration 88: train_loss 1.5538338422775269
Iteration 89: train_loss 1.5328127145767212
Iteration 90: train_loss 1.541833758354187
Iteration 91: train_loss 1.5104386806488037
Iteration 92: train_loss 1.5623629093170166
Iteration 93: train_loss 1.5648037195205688
Iteration 94: train_loss 1.5771993398666382
Iteration 95: train_loss 1.4648650884628296
Iteration 96: train_loss 1.5116101503372192
Iteration 97: train_loss 1.4950729608535767
Iteration 98: train_loss 1.5337016582489014
Iteration 99: train_loss 1.553776741027832
Iteration 100: train_loss 1.5101165771484375
Iteration 101: train_loss 1.5254981517791748
Iteration 102: train_loss 1.5792380571365356
Iteration 103: train_loss 1.5186254978179932
Iteration 104: train_loss 1.5329774618148804
Iteration 105: train_loss 1.4440962076187134
Iteration 106: train_loss 1.4554402828216553
Iteration 107: train_loss 1.5358554124832153
Iteration 108: train_loss 1.5231976509094238
Iteration 109: train_loss 1.5042113065719604
Iteration 110: train_loss 1.5453519821166992
Iteration 111: train_loss 1.5524483919143677
Iteration 112: train_loss 1.5247224569320679
Iteration 113: train_loss 1.5183453559875488
Iteration 114: train_loss 1.4998024702072144
Iteration 115: train_loss 1.5158318281173706
Iteration 116: train_loss 1.5485085248947144
Iteration 117: train_loss 1.5478928089141846
Iteration 118: train_loss 1.555232048034668
Iteration 119: train_loss 1.543426275253296
Iteration 120: train_loss 1.5563688278198242
Iteration 121: train_loss 1.4957693815231323
Iteration 122: train_loss 1.5529946088790894
Iteration 123: train_loss 1.5407224893569946
Iteration 124: train_loss 1.6330156326293945
Iteration 125: train_loss 1.551533818244934
Iteration 126: train_loss 1.5292590856552124
Iteration 127: train_loss 1.5517295598983765
Iteration 128: train_loss 1.5466760396957397
Iteration 129: train_loss 1.5312682390213013
Iteration 130: train_loss 1.5056229829788208
Iteration 131: train_loss 1.4705064296722412
Iteration 132: train_loss 1.5346335172653198
Iteration 133: train_loss 1.4639006853103638
Iteration 134: train_loss 1.5301891565322876
Iteration 135: train_loss 1.4884623289108276
Iteration 136: train_loss 1.586777925491333
Iteration 137: train_loss 1.4777566194534302
Iteration 138: train_loss 1.536497950553894
Iteration 139: train_loss 1.462028980255127
Iteration 140: train_loss 1.5205035209655762
Iteration 141: train_loss 1.5503411293029785
Iteration 142: train_loss 1.5039010047912598
Iteration 143: train_loss 1.50557541847229
Iteration 144: train_loss 1.5379011631011963
Iteration 145: train_loss 1.5369551181793213
Iteration 146: train_loss 1.5041463375091553
Iteration 147: train_loss 1.5926296710968018
Iteration 148: train_loss 1.4935961961746216
Iteration 149: train_loss 1.5826663970947266
Iteration 150: train_loss 1.5499647855758667
Iteration 151: train_loss 1.5359854698181152
Iteration 152: train_loss 1.5358294248580933
Iteration 153: train_loss 1.5138943195343018
Iteration 154: train_loss 1.5452558994293213
Iteration 155: train_loss 1.5160574913024902
Iteration 156: train_loss 1.5683292150497437
Iteration 157: train_loss 1.5046197175979614
Iteration 158: train_loss 1.5702561140060425
Iteration 159: train_loss 1.5899239778518677
Iteration 160: train_loss 1.4958884716033936
Iteration 161: train_loss 1.5474780797958374
Iteration 162: train_loss 1.6055680513381958
Iteration 163: train_loss 1.5242290496826172
Iteration 164: train_loss 1.5543384552001953
Iteration 165: train_loss 1.5423860549926758
Iteration 166: train_loss 1.5809369087219238
Iteration 167: train_loss 1.5755542516708374
Iteration 168: train_loss 1.5714657306671143
Iteration 169: train_loss 1.45992112159729
Iteration 170: train_loss 1.5148483514785767
Iteration 171: train_loss 1.5716570615768433
Iteration 172: train_loss 1.5433586835861206
Iteration 173: train_loss 1.5726534128189087
Iteration 174: train_loss 1.5223026275634766
Iteration 175: train_loss 1.5220884084701538
Iteration 176: train_loss 1.5366257429122925
Iteration 177: train_loss 1.478745698928833
Epoch 72: train_avg_loss 1.5202103334631623 eval_avg_acc: 0.32811339412146406 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:37:14] [32mIntermediate result: 0.32811339412146406  (Index 71)[0m
================Epoch: 73================
Iteration 1: train_loss 1.5307502746582031
Iteration 2: train_loss 1.518834114074707
Iteration 3: train_loss 1.5457416772842407
Iteration 4: train_loss 1.4403181076049805
Iteration 5: train_loss 1.5217500925064087
Iteration 6: train_loss 1.5082120895385742
Iteration 7: train_loss 1.4510170221328735
Iteration 8: train_loss 1.4947117567062378
Iteration 9: train_loss 1.4309442043304443
Iteration 10: train_loss 1.4819499254226685
Iteration 11: train_loss 1.5014855861663818
Iteration 12: train_loss 1.5092823505401611
Iteration 13: train_loss 1.523288369178772
Iteration 14: train_loss 1.5020726919174194
Iteration 15: train_loss 1.4563968181610107
Iteration 16: train_loss 1.5321648120880127
Iteration 17: train_loss 1.5004737377166748
Iteration 18: train_loss 1.5006728172302246
Iteration 19: train_loss 1.5773627758026123
Iteration 20: train_loss 1.5440047979354858
Iteration 21: train_loss 1.468390941619873
Iteration 22: train_loss 1.5320944786071777
Iteration 23: train_loss 1.5368626117706299
Iteration 24: train_loss 1.4907572269439697
Iteration 25: train_loss 1.4782599210739136
Iteration 26: train_loss 1.4774621725082397
Iteration 27: train_loss 1.458897352218628
Iteration 28: train_loss 1.6001272201538086
Iteration 29: train_loss 1.493173599243164
Iteration 30: train_loss 1.5307109355926514
Iteration 31: train_loss 1.4462031126022339
Iteration 32: train_loss 1.5251429080963135
Iteration 33: train_loss 1.5700958967208862
Iteration 34: train_loss 1.526708960533142
Iteration 35: train_loss 1.5186574459075928
Iteration 36: train_loss 1.4978346824645996
Iteration 37: train_loss 1.4877970218658447
Iteration 38: train_loss 1.5382664203643799
Iteration 39: train_loss 1.5059876441955566
Iteration 40: train_loss 1.4976671934127808
Iteration 41: train_loss 1.4844213724136353
Iteration 42: train_loss 1.5007282495498657
Iteration 43: train_loss 1.5319665670394897
Iteration 44: train_loss 1.5316390991210938
Iteration 45: train_loss 1.5394405126571655
Iteration 46: train_loss 1.437928318977356
Iteration 47: train_loss 1.5229809284210205
Iteration 48: train_loss 1.4931119680404663
Iteration 49: train_loss 1.4604524374008179
Iteration 50: train_loss 1.464368462562561
Iteration 51: train_loss 1.4130632877349854
Iteration 52: train_loss 1.451141357421875
Iteration 53: train_loss 1.4976001977920532
Iteration 54: train_loss 1.5289195775985718
Iteration 55: train_loss 1.4534698724746704
Iteration 56: train_loss 1.5046296119689941
Iteration 57: train_loss 1.4864671230316162
Iteration 58: train_loss 1.4829716682434082
Iteration 59: train_loss 1.5137312412261963
Iteration 60: train_loss 1.4663755893707275
Iteration 61: train_loss 1.4941329956054688
Iteration 62: train_loss 1.4461970329284668
Iteration 63: train_loss 1.4886386394500732
Iteration 64: train_loss 1.5013556480407715
Iteration 65: train_loss 1.5492210388183594
Iteration 66: train_loss 1.506718397140503
Iteration 67: train_loss 1.5545246601104736
Iteration 68: train_loss 1.466601848602295
Iteration 69: train_loss 1.595733880996704
Iteration 70: train_loss 1.5876481533050537
Iteration 71: train_loss 1.5477656126022339
Iteration 72: train_loss 1.555413842201233
Iteration 73: train_loss 1.5559805631637573
Iteration 74: train_loss 1.5167648792266846
Iteration 75: train_loss 1.5082385540008545
Iteration 76: train_loss 1.5552994012832642
Iteration 77: train_loss 1.483330488204956
Iteration 78: train_loss 1.5441688299179077
Iteration 79: train_loss 1.5217688083648682
Iteration 80: train_loss 1.4665943384170532
Iteration 81: train_loss 1.5271104574203491
Iteration 82: train_loss 1.4672131538391113
Iteration 83: train_loss 1.513532280921936
Iteration 84: train_loss 1.4960743188858032
Iteration 85: train_loss 1.5070183277130127
Iteration 86: train_loss 1.5515122413635254
Iteration 87: train_loss 1.5619356632232666
Iteration 88: train_loss 1.470966100692749
Iteration 89: train_loss 1.5663386583328247
Iteration 90: train_loss 1.498246192932129
Iteration 91: train_loss 1.5292510986328125
Iteration 92: train_loss 1.5172282457351685
Iteration 93: train_loss 1.4583561420440674
Iteration 94: train_loss 1.4725528955459595
Iteration 95: train_loss 1.439743995666504
Iteration 96: train_loss 1.5257543325424194
Iteration 97: train_loss 1.451765537261963
Iteration 98: train_loss 1.5342111587524414
Iteration 99: train_loss 1.506746530532837
Iteration 100: train_loss 1.4353764057159424
Iteration 101: train_loss 1.4808568954467773
Iteration 102: train_loss 1.5117487907409668
Iteration 103: train_loss 1.4527497291564941
Iteration 104: train_loss 1.5390373468399048
Iteration 105: train_loss 1.531269907951355
Iteration 106: train_loss 1.4465550184249878
Iteration 107: train_loss 1.5758627653121948
Iteration 108: train_loss 1.5394673347473145
Iteration 109: train_loss 1.5165725946426392
Iteration 110: train_loss 1.4999476671218872
Iteration 111: train_loss 1.5102611780166626
Iteration 112: train_loss 1.5205676555633545
Iteration 113: train_loss 1.4684104919433594
Iteration 114: train_loss 1.4677839279174805
Iteration 115: train_loss 1.4905750751495361
Iteration 116: train_loss 1.5545830726623535
Iteration 117: train_loss 1.5242037773132324
Iteration 118: train_loss 1.4646272659301758
Iteration 119: train_loss 1.5244522094726562
Iteration 120: train_loss 1.4829574823379517
Iteration 121: train_loss 1.4557204246520996
Iteration 122: train_loss 1.5499945878982544
Iteration 123: train_loss 1.4673937559127808
Iteration 124: train_loss 1.5140081644058228
Iteration 125: train_loss 1.5237678289413452
Iteration 126: train_loss 1.500423550605774
Iteration 127: train_loss 1.502052664756775
Iteration 128: train_loss 1.4925702810287476
Iteration 129: train_loss 1.5006227493286133
Iteration 130: train_loss 1.4805494546890259
Iteration 131: train_loss 1.530914068222046
Iteration 132: train_loss 1.4166584014892578
Iteration 133: train_loss 1.521779179573059
Iteration 134: train_loss 1.5008885860443115
Iteration 135: train_loss 1.4934860467910767
Iteration 136: train_loss 1.5642682313919067
Iteration 137: train_loss 1.49003267288208
Iteration 138: train_loss 1.4554425477981567
Iteration 139: train_loss 1.4246468544006348
Iteration 140: train_loss 1.4911879301071167
Iteration 141: train_loss 1.5549404621124268
Iteration 142: train_loss 1.4529625177383423
Iteration 143: train_loss 1.493145227432251
Iteration 144: train_loss 1.484666109085083
Iteration 145: train_loss 1.6015863418579102
Iteration 146: train_loss 1.4424387216567993
Iteration 147: train_loss 1.480656385421753
Iteration 148: train_loss 1.5311084985733032
Iteration 149: train_loss 1.5003682374954224
Iteration 150: train_loss 1.5186089277267456
Iteration 151: train_loss 1.489255428314209
Iteration 152: train_loss 1.4554800987243652
Iteration 153: train_loss 1.4674334526062012
Iteration 154: train_loss 1.536531925201416
Iteration 155: train_loss 1.5270001888275146
Iteration 156: train_loss 1.5370560884475708
Iteration 157: train_loss 1.5015220642089844
Iteration 158: train_loss 1.5401397943496704
Iteration 159: train_loss 1.5903401374816895
Iteration 160: train_loss 1.482683777809143
Iteration 161: train_loss 1.5067975521087646
Iteration 162: train_loss 1.517616868019104
Iteration 163: train_loss 1.545069694519043
Iteration 164: train_loss 1.5781031847000122
Iteration 165: train_loss 1.5128988027572632
Iteration 166: train_loss 1.5053375959396362
Iteration 167: train_loss 1.570930004119873
Iteration 168: train_loss 1.5263093709945679
Iteration 169: train_loss 1.4679570198059082
Iteration 170: train_loss 1.4860692024230957
Iteration 171: train_loss 1.5272308588027954
Iteration 172: train_loss 1.543944239616394
Iteration 173: train_loss 1.5257341861724854
Iteration 174: train_loss 1.4823554754257202
Iteration 175: train_loss 1.4830490350723267
Iteration 176: train_loss 1.5129855871200562
Iteration 177: train_loss 1.5260593891143799
Epoch 73: train_avg_loss 1.5055380857596963 eval_avg_acc: 0.3496600354743909 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:37:54] [32mIntermediate result: 0.3496600354743909  (Index 72)[0m
================Epoch: 74================
Iteration 1: train_loss 1.5531047582626343
Iteration 2: train_loss 1.4292047023773193
Iteration 3: train_loss 1.3787641525268555
Iteration 4: train_loss 1.5158116817474365
Iteration 5: train_loss 1.4287164211273193
Iteration 6: train_loss 1.4876173734664917
Iteration 7: train_loss 1.4634186029434204
Iteration 8: train_loss 1.4187359809875488
Iteration 9: train_loss 1.4594073295593262
Iteration 10: train_loss 1.5077067613601685
Iteration 11: train_loss 1.4640449285507202
Iteration 12: train_loss 1.481335997581482
Iteration 13: train_loss 1.5074034929275513
Iteration 14: train_loss 1.4479796886444092
Iteration 15: train_loss 1.5297294855117798
Iteration 16: train_loss 1.4458478689193726
Iteration 17: train_loss 1.512455701828003
Iteration 18: train_loss 1.4686198234558105
Iteration 19: train_loss 1.4285094738006592
Iteration 20: train_loss 1.5170871019363403
Iteration 21: train_loss 1.5500125885009766
Iteration 22: train_loss 1.4554191827774048
Iteration 23: train_loss 1.502487063407898
Iteration 24: train_loss 1.4715651273727417
Iteration 25: train_loss 1.4471831321716309
Iteration 26: train_loss 1.4868335723876953
Iteration 27: train_loss 1.4571502208709717
Iteration 28: train_loss 1.461238980293274
Iteration 29: train_loss 1.4206302165985107
Iteration 30: train_loss 1.5250754356384277
Iteration 31: train_loss 1.4518921375274658
Iteration 32: train_loss 1.4640775918960571
Iteration 33: train_loss 1.419010043144226
Iteration 34: train_loss 1.4668121337890625
Iteration 35: train_loss 1.4349744319915771
Iteration 36: train_loss 1.5314804315567017
Iteration 37: train_loss 1.513893723487854
Iteration 38: train_loss 1.4952309131622314
Iteration 39: train_loss 1.4401658773422241
Iteration 40: train_loss 1.53103506565094
Iteration 41: train_loss 1.4872032403945923
Iteration 42: train_loss 1.5673158168792725
Iteration 43: train_loss 1.4989814758300781
Iteration 44: train_loss 1.5623143911361694
Iteration 45: train_loss 1.5128198862075806
Iteration 46: train_loss 1.4815549850463867
Iteration 47: train_loss 1.5291271209716797
Iteration 48: train_loss 1.5467833280563354
Iteration 49: train_loss 1.5446157455444336
Iteration 50: train_loss 1.5162850618362427
Iteration 51: train_loss 1.4669338464736938
Iteration 52: train_loss 1.526049017906189
Iteration 53: train_loss 1.4589273929595947
Iteration 54: train_loss 1.4721040725708008
Iteration 55: train_loss 1.4444611072540283
Iteration 56: train_loss 1.5681606531143188
Iteration 57: train_loss 1.5468125343322754
Iteration 58: train_loss 1.45918607711792
Iteration 59: train_loss 1.542712688446045
Iteration 60: train_loss 1.438852310180664
Iteration 61: train_loss 1.502987027168274
Iteration 62: train_loss 1.4688465595245361
Iteration 63: train_loss 1.57186758518219
Iteration 64: train_loss 1.4409228563308716
Iteration 65: train_loss 1.543154239654541
Iteration 66: train_loss 1.5206499099731445
Iteration 67: train_loss 1.4918198585510254
Iteration 68: train_loss 1.441536784172058
Iteration 69: train_loss 1.4981433153152466
Iteration 70: train_loss 1.5155926942825317
Iteration 71: train_loss 1.5207794904708862
Iteration 72: train_loss 1.4956912994384766
Iteration 73: train_loss 1.5664011240005493
Iteration 74: train_loss 1.5042495727539062
Iteration 75: train_loss 1.5042130947113037
Iteration 76: train_loss 1.4235502481460571
Iteration 77: train_loss 1.5040757656097412
Iteration 78: train_loss 1.532752275466919
Iteration 79: train_loss 1.5596836805343628
Iteration 80: train_loss 1.467813491821289
Iteration 81: train_loss 1.47441828250885
Iteration 82: train_loss 1.4849673509597778
Iteration 83: train_loss 1.4891167879104614
Iteration 84: train_loss 1.5223640203475952
Iteration 85: train_loss 1.5202339887619019
Iteration 86: train_loss 1.5108858346939087
Iteration 87: train_loss 1.4993091821670532
Iteration 88: train_loss 1.5399771928787231
Iteration 89: train_loss 1.5036966800689697
Iteration 90: train_loss 1.525308609008789
Iteration 91: train_loss 1.4630423784255981
Iteration 92: train_loss 1.4379487037658691
Iteration 93: train_loss 1.5048928260803223
Iteration 94: train_loss 1.4423147439956665
Iteration 95: train_loss 1.418325424194336
Iteration 96: train_loss 1.516350269317627
Iteration 97: train_loss 1.5421050786972046
Iteration 98: train_loss 1.5632474422454834
Iteration 99: train_loss 1.485206961631775
Iteration 100: train_loss 1.507675051689148
Iteration 101: train_loss 1.524059772491455
Iteration 102: train_loss 1.5104275941848755
Iteration 103: train_loss 1.4918673038482666
Iteration 104: train_loss 1.4573315382003784
Iteration 105: train_loss 1.5249037742614746
Iteration 106: train_loss 1.5383139848709106
Iteration 107: train_loss 1.5785036087036133
Iteration 108: train_loss 1.5742920637130737
Iteration 109: train_loss 1.5592598915100098
Iteration 110: train_loss 1.4686986207962036
Iteration 111: train_loss 1.5373280048370361
Iteration 112: train_loss 1.536254644393921
Iteration 113: train_loss 1.6069371700286865
Iteration 114: train_loss 1.5392626523971558
Iteration 115: train_loss 1.5113450288772583
Iteration 116: train_loss 1.4752506017684937
Iteration 117: train_loss 1.554604172706604
Iteration 118: train_loss 1.486535906791687
Iteration 119: train_loss 1.5476208925247192
Iteration 120: train_loss 1.4988946914672852
Iteration 121: train_loss 1.5188175439834595
Iteration 122: train_loss 1.5117473602294922
Iteration 123: train_loss 1.5172356367111206
Iteration 124: train_loss 1.538024663925171
Iteration 125: train_loss 1.5240858793258667
Iteration 126: train_loss 1.519046664237976
Iteration 127: train_loss 1.4596068859100342
Iteration 128: train_loss 1.5194827318191528
Iteration 129: train_loss 1.539445161819458
Iteration 130: train_loss 1.5402776002883911
Iteration 131: train_loss 1.5398238897323608
Iteration 132: train_loss 1.5193142890930176
Iteration 133: train_loss 1.5039862394332886
Iteration 134: train_loss 1.5369473695755005
Iteration 135: train_loss 1.5578596591949463
Iteration 136: train_loss 1.5516488552093506
Iteration 137: train_loss 1.5843842029571533
Iteration 138: train_loss 1.4998396635055542
Iteration 139: train_loss 1.4710077047348022
Iteration 140: train_loss 1.4956532716751099
Iteration 141: train_loss 1.5182182788848877
Iteration 142: train_loss 1.5231496095657349
Iteration 143: train_loss 1.498878836631775
Iteration 144: train_loss 1.5389258861541748
Iteration 145: train_loss 1.5056471824645996
Iteration 146: train_loss 1.5054864883422852
Iteration 147: train_loss 1.5112797021865845
Iteration 148: train_loss 1.4968432188034058
Iteration 149: train_loss 1.504142165184021
Iteration 150: train_loss 1.5032144784927368
Iteration 151: train_loss 1.5672622919082642
Iteration 152: train_loss 1.5903794765472412
Iteration 153: train_loss 1.54884672164917
Iteration 154: train_loss 1.5239899158477783
Iteration 155: train_loss 1.5125857591629028
Iteration 156: train_loss 1.4515315294265747
Iteration 157: train_loss 1.5072141885757446
Iteration 158: train_loss 1.5049675703048706
Iteration 159: train_loss 1.486733078956604
Iteration 160: train_loss 1.5040159225463867
Iteration 161: train_loss 1.3991353511810303
Iteration 162: train_loss 1.4710670709609985
Iteration 163: train_loss 1.575363278388977
Iteration 164: train_loss 1.483320951461792
Iteration 165: train_loss 1.50731360912323
Iteration 166: train_loss 1.4655615091323853
Iteration 167: train_loss 1.5193629264831543
Iteration 168: train_loss 1.4377738237380981
Iteration 169: train_loss 1.5011012554168701
Iteration 170: train_loss 1.4824086427688599
Iteration 171: train_loss 1.4591337442398071
Iteration 172: train_loss 1.5127198696136475
Iteration 173: train_loss 1.534174919128418
Iteration 174: train_loss 1.5034453868865967
Iteration 175: train_loss 1.5443333387374878
Iteration 176: train_loss 1.557339072227478
Iteration 177: train_loss 1.5696039199829102
Epoch 74: train_avg_loss 1.5026292982748 eval_avg_acc: 0.3482130908572318 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:38:35] [32mIntermediate result: 0.3482130908572318  (Index 73)[0m
================Epoch: 75================
Iteration 1: train_loss 1.4958770275115967
Iteration 2: train_loss 1.4575570821762085
Iteration 3: train_loss 1.402933955192566
Iteration 4: train_loss 1.4724243879318237
Iteration 5: train_loss 1.5004138946533203
Iteration 6: train_loss 1.4798036813735962
Iteration 7: train_loss 1.483220100402832
Iteration 8: train_loss 1.4745737314224243
Iteration 9: train_loss 1.4787895679473877
Iteration 10: train_loss 1.4630060195922852
Iteration 11: train_loss 1.4634532928466797
Iteration 12: train_loss 1.4674676656723022
Iteration 13: train_loss 1.4842352867126465
Iteration 14: train_loss 1.4274613857269287
Iteration 15: train_loss 1.5077177286148071
Iteration 16: train_loss 1.5097947120666504
Iteration 17: train_loss 1.436432957649231
Iteration 18: train_loss 1.4642583131790161
Iteration 19: train_loss 1.464376449584961
Iteration 20: train_loss 1.4259910583496094
Iteration 21: train_loss 1.5118446350097656
Iteration 22: train_loss 1.5054439306259155
Iteration 23: train_loss 1.4530415534973145
Iteration 24: train_loss 1.4682316780090332
Iteration 25: train_loss 1.4291434288024902
Iteration 26: train_loss 1.5005650520324707
Iteration 27: train_loss 1.4571510553359985
Iteration 28: train_loss 1.4462270736694336
Iteration 29: train_loss 1.474747896194458
Iteration 30: train_loss 1.476338505744934
Iteration 31: train_loss 1.408839464187622
Iteration 32: train_loss 1.4385085105895996
Iteration 33: train_loss 1.5662178993225098
Iteration 34: train_loss 1.450165033340454
Iteration 35: train_loss 1.4471731185913086
Iteration 36: train_loss 1.4361644983291626
Iteration 37: train_loss 1.4094738960266113
Iteration 38: train_loss 1.4051766395568848
Iteration 39: train_loss 1.4850332736968994
Iteration 40: train_loss 1.460142731666565
Iteration 41: train_loss 1.4723597764968872
Iteration 42: train_loss 1.5366580486297607
Iteration 43: train_loss 1.4287742376327515
Iteration 44: train_loss 1.4220889806747437
Iteration 45: train_loss 1.4681987762451172
Iteration 46: train_loss 1.4328352212905884
Iteration 47: train_loss 1.5829827785491943
Iteration 48: train_loss 1.4522852897644043
Iteration 49: train_loss 1.4626003503799438
Iteration 50: train_loss 1.4775574207305908
Iteration 51: train_loss 1.4921067953109741
Iteration 52: train_loss 1.449236273765564
Iteration 53: train_loss 1.5128545761108398
Iteration 54: train_loss 1.5087941884994507
Iteration 55: train_loss 1.51870858669281
Iteration 56: train_loss 1.585602879524231
Iteration 57: train_loss 1.4847943782806396
Iteration 58: train_loss 1.5010567903518677
Iteration 59: train_loss 1.540541410446167
Iteration 60: train_loss 1.4953689575195312
Iteration 61: train_loss 1.491965413093567
Iteration 62: train_loss 1.525300145149231
Iteration 63: train_loss 1.43523371219635
Iteration 64: train_loss 1.5173192024230957
Iteration 65: train_loss 1.4562385082244873
Iteration 66: train_loss 1.4992179870605469
Iteration 67: train_loss 1.5364229679107666
Iteration 68: train_loss 1.45253324508667
Iteration 69: train_loss 1.4564905166625977
Iteration 70: train_loss 1.536712646484375
Iteration 71: train_loss 1.514525055885315
Iteration 72: train_loss 1.5096631050109863
Iteration 73: train_loss 1.4781101942062378
Iteration 74: train_loss 1.4799731969833374
Iteration 75: train_loss 1.4611756801605225
Iteration 76: train_loss 1.456225037574768
Iteration 77: train_loss 1.5015991926193237
Iteration 78: train_loss 1.5035680532455444
Iteration 79: train_loss 1.4327243566513062
Iteration 80: train_loss 1.4784023761749268
Iteration 81: train_loss 1.4995644092559814
Iteration 82: train_loss 1.4837018251419067
Iteration 83: train_loss 1.5343384742736816
Iteration 84: train_loss 1.4830176830291748
Iteration 85: train_loss 1.4653325080871582
Iteration 86: train_loss 1.5559664964675903
Iteration 87: train_loss 1.4342395067214966
Iteration 88: train_loss 1.5076320171356201
Iteration 89: train_loss 1.454694390296936
Iteration 90: train_loss 1.5644505023956299
Iteration 91: train_loss 1.4862995147705078
Iteration 92: train_loss 1.5272055864334106
Iteration 93: train_loss 1.4921001195907593
Iteration 94: train_loss 1.5282479524612427
Iteration 95: train_loss 1.53434419631958
Iteration 96: train_loss 1.5535789728164673
Iteration 97: train_loss 1.4527308940887451
Iteration 98: train_loss 1.4275782108306885
Iteration 99: train_loss 1.4733210802078247
Iteration 100: train_loss 1.486026406288147
Iteration 101: train_loss 1.5002833604812622
Iteration 102: train_loss 1.5554393529891968
Iteration 103: train_loss 1.5088024139404297
Iteration 104: train_loss 1.4738500118255615
Iteration 105: train_loss 1.470733642578125
Iteration 106: train_loss 1.4758604764938354
Iteration 107: train_loss 1.4452437162399292
Iteration 108: train_loss 1.445117712020874
Iteration 109: train_loss 1.4794076681137085
Iteration 110: train_loss 1.5315420627593994
Iteration 111: train_loss 1.5408928394317627
Iteration 112: train_loss 1.4653728008270264
Iteration 113: train_loss 1.4666352272033691
Iteration 114: train_loss 1.5133674144744873
Iteration 115: train_loss 1.5074915885925293
Iteration 116: train_loss 1.5192235708236694
Iteration 117: train_loss 1.4681504964828491
Iteration 118: train_loss 1.4991265535354614
Iteration 119: train_loss 1.5372285842895508
Iteration 120: train_loss 1.488938331604004
Iteration 121: train_loss 1.5208793878555298
Iteration 122: train_loss 1.4591059684753418
Iteration 123: train_loss 1.4632502794265747
Iteration 124: train_loss 1.491091251373291
Iteration 125: train_loss 1.4867825508117676
Iteration 126: train_loss 1.5086771249771118
Iteration 127: train_loss 1.5091031789779663
Iteration 128: train_loss 1.5596553087234497
Iteration 129: train_loss 1.4978853464126587
Iteration 130: train_loss 1.453471302986145
Iteration 131: train_loss 1.4630403518676758
Iteration 132: train_loss 1.5773842334747314
Iteration 133: train_loss 1.5008275508880615
Iteration 134: train_loss 1.4886481761932373
Iteration 135: train_loss 1.5496021509170532
Iteration 136: train_loss 1.5216373205184937
Iteration 137: train_loss 1.4636573791503906
Iteration 138: train_loss 1.5599982738494873
Iteration 139: train_loss 1.5125097036361694
Iteration 140: train_loss 1.583682894706726
Iteration 141: train_loss 1.5355839729309082
Iteration 142: train_loss 1.4950519800186157
Iteration 143: train_loss 1.5745012760162354
Iteration 144: train_loss 1.572454810142517
Iteration 145: train_loss 1.5032048225402832
Iteration 146: train_loss 1.527264952659607
Iteration 147: train_loss 1.4771270751953125
Iteration 148: train_loss 1.550789713859558
Iteration 149: train_loss 1.4715254306793213
Iteration 150: train_loss 1.476577877998352
Iteration 151: train_loss 1.5573852062225342
Iteration 152: train_loss 1.4883294105529785
Iteration 153: train_loss 1.519504427909851
Iteration 154: train_loss 1.4776827096939087
Iteration 155: train_loss 1.5458664894104004
Iteration 156: train_loss 1.5515543222427368
Iteration 157: train_loss 1.5291774272918701
Iteration 158: train_loss 1.5122140645980835
Iteration 159: train_loss 1.579052209854126
Iteration 160: train_loss 1.5133676528930664
Iteration 161: train_loss 1.5455025434494019
Iteration 162: train_loss 1.4975855350494385
Iteration 163: train_loss 1.5557637214660645
Iteration 164: train_loss 1.4987919330596924
Iteration 165: train_loss 1.5443716049194336
Iteration 166: train_loss 1.5914264917373657
Iteration 167: train_loss 1.4773166179656982
Iteration 168: train_loss 1.5258386135101318
Iteration 169: train_loss 1.4888715744018555
Iteration 170: train_loss 1.4986339807510376
Iteration 171: train_loss 1.4620219469070435
Iteration 172: train_loss 1.5188864469528198
Iteration 173: train_loss 1.526230812072754
Iteration 174: train_loss 1.5717785358428955
Iteration 175: train_loss 1.4959288835525513
Iteration 176: train_loss 1.5307393074035645
Iteration 177: train_loss 1.524785041809082
Epoch 75: train_avg_loss 1.4941179786024794 eval_avg_acc: 0.33730629769692544 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:39:17] [32mIntermediate result: 0.33730629769692544  (Index 74)[0m
================Epoch: 76================
Iteration 1: train_loss 1.519315242767334
Iteration 2: train_loss 1.5346057415008545
Iteration 3: train_loss 1.534348487854004
Iteration 4: train_loss 1.5335826873779297
Iteration 5: train_loss 1.4379854202270508
Iteration 6: train_loss 1.4158552885055542
Iteration 7: train_loss 1.4946794509887695
Iteration 8: train_loss 1.4495747089385986
Iteration 9: train_loss 1.5020068883895874
Iteration 10: train_loss 1.473332166671753
Iteration 11: train_loss 1.4487521648406982
Iteration 12: train_loss 1.4474302530288696
Iteration 13: train_loss 1.4887564182281494
Iteration 14: train_loss 1.4642328023910522
Iteration 15: train_loss 1.5052675008773804
Iteration 16: train_loss 1.446238398551941
Iteration 17: train_loss 1.5057498216629028
Iteration 18: train_loss 1.456079125404358
Iteration 19: train_loss 1.4955424070358276
Iteration 20: train_loss 1.5268760919570923
Iteration 21: train_loss 1.468688726425171
Iteration 22: train_loss 1.5291719436645508
Iteration 23: train_loss 1.5410597324371338
Iteration 24: train_loss 1.4187490940093994
Iteration 25: train_loss 1.4609826803207397
Iteration 26: train_loss 1.50547194480896
Iteration 27: train_loss 1.46150803565979
Iteration 28: train_loss 1.433658242225647
Iteration 29: train_loss 1.5109477043151855
Iteration 30: train_loss 1.495571494102478
Iteration 31: train_loss 1.5127519369125366
Iteration 32: train_loss 1.441176414489746
Iteration 33: train_loss 1.5127073526382446
Iteration 34: train_loss 1.4120527505874634
Iteration 35: train_loss 1.4641841650009155
Iteration 36: train_loss 1.4198646545410156
Iteration 37: train_loss 1.5033632516860962
Iteration 38: train_loss 1.4341912269592285
Iteration 39: train_loss 1.4879037141799927
Iteration 40: train_loss 1.4385467767715454
Iteration 41: train_loss 1.4351516962051392
Iteration 42: train_loss 1.488777756690979
Iteration 43: train_loss 1.513170599937439
Iteration 44: train_loss 1.5028367042541504
Iteration 45: train_loss 1.4530835151672363
Iteration 46: train_loss 1.508225679397583
Iteration 47: train_loss 1.4693775177001953
Iteration 48: train_loss 1.4272373914718628
Iteration 49: train_loss 1.4108853340148926
Iteration 50: train_loss 1.5055968761444092
Iteration 51: train_loss 1.480092167854309
Iteration 52: train_loss 1.3846025466918945
Iteration 53: train_loss 1.4826970100402832
Iteration 54: train_loss 1.4839712381362915
Iteration 55: train_loss 1.5011416673660278
Iteration 56: train_loss 1.5001051425933838
Iteration 57: train_loss 1.5227696895599365
Iteration 58: train_loss 1.4691896438598633
Iteration 59: train_loss 1.50187349319458
Iteration 60: train_loss 1.54487943649292
Iteration 61: train_loss 1.412073016166687
Iteration 62: train_loss 1.475730299949646
Iteration 63: train_loss 1.5377731323242188
Iteration 64: train_loss 1.476295828819275
Iteration 65: train_loss 1.4946233034133911
Iteration 66: train_loss 1.4544003009796143
Iteration 67: train_loss 1.5217978954315186
Iteration 68: train_loss 1.5094451904296875
Iteration 69: train_loss 1.474989652633667
Iteration 70: train_loss 1.477864146232605
Iteration 71: train_loss 1.519525170326233
Iteration 72: train_loss 1.4641178846359253
Iteration 73: train_loss 1.4588590860366821
Iteration 74: train_loss 1.5384795665740967
Iteration 75: train_loss 1.5506651401519775
Iteration 76: train_loss 1.4570012092590332
Iteration 77: train_loss 1.5099767446517944
Iteration 78: train_loss 1.4397735595703125
Iteration 79: train_loss 1.4839344024658203
Iteration 80: train_loss 1.4868377447128296
Iteration 81: train_loss 1.5152720212936401
Iteration 82: train_loss 1.5238937139511108
Iteration 83: train_loss 1.52664053440094
Iteration 84: train_loss 1.4722625017166138
Iteration 85: train_loss 1.516893982887268
Iteration 86: train_loss 1.5439821481704712
Iteration 87: train_loss 1.4604475498199463
Iteration 88: train_loss 1.515722393989563
Iteration 89: train_loss 1.4995653629302979
Iteration 90: train_loss 1.498726487159729
Iteration 91: train_loss 1.5397014617919922
Iteration 92: train_loss 1.479053258895874
Iteration 93: train_loss 1.4934815168380737
Iteration 94: train_loss 1.4865303039550781
Iteration 95: train_loss 1.4477721452713013
Iteration 96: train_loss 1.5320050716400146
Iteration 97: train_loss 1.573334813117981
Iteration 98: train_loss 1.4637548923492432
Iteration 99: train_loss 1.4984207153320312
Iteration 100: train_loss 1.4957815408706665
Iteration 101: train_loss 1.519736647605896
Iteration 102: train_loss 1.4836171865463257
Iteration 103: train_loss 1.551761269569397
Iteration 104: train_loss 1.5190880298614502
Iteration 105: train_loss 1.4947161674499512
Iteration 106: train_loss 1.4558607339859009
Iteration 107: train_loss 1.4966245889663696
Iteration 108: train_loss 1.5022499561309814
Iteration 109: train_loss 1.556066632270813
Iteration 110: train_loss 1.5053247213363647
Iteration 111: train_loss 1.4880940914154053
Iteration 112: train_loss 1.471532940864563
Iteration 113: train_loss 1.540786623954773
Iteration 114: train_loss 1.5321612358093262
Iteration 115: train_loss 1.4617180824279785
Iteration 116: train_loss 1.5227257013320923
Iteration 117: train_loss 1.5358999967575073
Iteration 118: train_loss 1.5005912780761719
Iteration 119: train_loss 1.604067087173462
Iteration 120: train_loss 1.5127389430999756
Iteration 121: train_loss 1.5602772235870361
Iteration 122: train_loss 1.5372368097305298
Iteration 123: train_loss 1.4877651929855347
Iteration 124: train_loss 1.4810898303985596
Iteration 125: train_loss 1.5035160779953003
Iteration 126: train_loss 1.5465319156646729
Iteration 127: train_loss 1.5485891103744507
Iteration 128: train_loss 1.5597026348114014
Iteration 129: train_loss 1.5144739151000977
Iteration 130: train_loss 1.5396108627319336
Iteration 131: train_loss 1.5883506536483765
Iteration 132: train_loss 1.4652870893478394
Iteration 133: train_loss 1.5481078624725342
Iteration 134: train_loss 1.5538294315338135
Iteration 135: train_loss 1.5111292600631714
Iteration 136: train_loss 1.5285067558288574
Iteration 137: train_loss 1.5184262990951538
Iteration 138: train_loss 1.5333482027053833
Iteration 139: train_loss 1.5027830600738525
Iteration 140: train_loss 1.546480655670166
Iteration 141: train_loss 1.549439787864685
Iteration 142: train_loss 1.5315310955047607
Iteration 143: train_loss 1.477804183959961
Iteration 144: train_loss 1.482251763343811
Iteration 145: train_loss 1.5260156393051147
Iteration 146: train_loss 1.535980463027954
Iteration 147: train_loss 1.457617998123169
Iteration 148: train_loss 1.472632884979248
Iteration 149: train_loss 1.4335638284683228
Iteration 150: train_loss 1.5066800117492676
Iteration 151: train_loss 1.4687211513519287
Iteration 152: train_loss 1.396747350692749
Iteration 153: train_loss 1.533392310142517
Iteration 154: train_loss 1.504235863685608
Iteration 155: train_loss 1.5092235803604126
Iteration 156: train_loss 1.494110107421875
Iteration 157: train_loss 1.4622746706008911
Iteration 158: train_loss 1.4763679504394531
Iteration 159: train_loss 1.541373372077942
Iteration 160: train_loss 1.4943556785583496
Iteration 161: train_loss 1.465093970298767
Iteration 162: train_loss 1.4865938425064087
Iteration 163: train_loss 1.529905915260315
Iteration 164: train_loss 1.4704171419143677
Iteration 165: train_loss 1.514678716659546
Iteration 166: train_loss 1.5049978494644165
Iteration 167: train_loss 1.476976990699768
Iteration 168: train_loss 1.5579692125320435
Iteration 169: train_loss 1.5284496545791626
Iteration 170: train_loss 1.5034831762313843
Iteration 171: train_loss 1.4959602355957031
Iteration 172: train_loss 1.557997226715088
Iteration 173: train_loss 1.5744044780731201
Iteration 174: train_loss 1.5196374654769897
Iteration 175: train_loss 1.450243592262268
Iteration 176: train_loss 1.4384253025054932
Iteration 177: train_loss 1.340770959854126
Epoch 76: train_avg_loss 1.4951783270485657 eval_avg_acc: 0.3361344534247037 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:39:57] [32mIntermediate result: 0.3361344534247037  (Index 75)[0m
================Epoch: 77================
Iteration 1: train_loss 1.476580262184143
Iteration 2: train_loss 1.463306188583374
Iteration 3: train_loss 1.500424861907959
Iteration 4: train_loss 1.474599003791809
Iteration 5: train_loss 1.4547955989837646
Iteration 6: train_loss 1.4653079509735107
Iteration 7: train_loss 1.496235966682434
Iteration 8: train_loss 1.4713172912597656
Iteration 9: train_loss 1.4533929824829102
Iteration 10: train_loss 1.4521526098251343
Iteration 11: train_loss 1.4332082271575928
Iteration 12: train_loss 1.463721752166748
Iteration 13: train_loss 1.4840277433395386
Iteration 14: train_loss 1.3902549743652344
Iteration 15: train_loss 1.412129521369934
Iteration 16: train_loss 1.485745906829834
Iteration 17: train_loss 1.3986891508102417
Iteration 18: train_loss 1.4641828536987305
Iteration 19: train_loss 1.461484670639038
Iteration 20: train_loss 1.4184778928756714
Iteration 21: train_loss 1.5141345262527466
Iteration 22: train_loss 1.495606780052185
Iteration 23: train_loss 1.4576433897018433
Iteration 24: train_loss 1.4847185611724854
Iteration 25: train_loss 1.4032647609710693
Iteration 26: train_loss 1.331952691078186
Iteration 27: train_loss 1.4328583478927612
Iteration 28: train_loss 1.447830080986023
Iteration 29: train_loss 1.430163025856018
Iteration 30: train_loss 1.4410687685012817
Iteration 31: train_loss 1.5059177875518799
Iteration 32: train_loss 1.465702772140503
Iteration 33: train_loss 1.4785010814666748
Iteration 34: train_loss 1.438635230064392
Iteration 35: train_loss 1.4427727460861206
Iteration 36: train_loss 1.4703218936920166
Iteration 37: train_loss 1.4791338443756104
Iteration 38: train_loss 1.4694494009017944
Iteration 39: train_loss 1.5351306200027466
Iteration 40: train_loss 1.5194653272628784
Iteration 41: train_loss 1.5008717775344849
Iteration 42: train_loss 1.467464804649353
Iteration 43: train_loss 1.5183899402618408
Iteration 44: train_loss 1.5568130016326904
Iteration 45: train_loss 1.4868354797363281
Iteration 46: train_loss 1.4663673639297485
Iteration 47: train_loss 1.5257149934768677
Iteration 48: train_loss 1.4632142782211304
Iteration 49: train_loss 1.4874991178512573
Iteration 50: train_loss 1.4519180059432983
Iteration 51: train_loss 1.4797720909118652
Iteration 52: train_loss 1.4170323610305786
Iteration 53: train_loss 1.5333689451217651
Iteration 54: train_loss 1.5202828645706177
Iteration 55: train_loss 1.4187091588974
Iteration 56: train_loss 1.4765466451644897
Iteration 57: train_loss 1.4814128875732422
Iteration 58: train_loss 1.5092823505401611
Iteration 59: train_loss 1.5184850692749023
Iteration 60: train_loss 1.4642752408981323
Iteration 61: train_loss 1.498511791229248
Iteration 62: train_loss 1.499135971069336
Iteration 63: train_loss 1.4754960536956787
Iteration 64: train_loss 1.452592372894287
Iteration 65: train_loss 1.4329787492752075
Iteration 66: train_loss 1.4111428260803223
Iteration 67: train_loss 1.5095345973968506
Iteration 68: train_loss 1.4338312149047852
Iteration 69: train_loss 1.4845153093338013
Iteration 70: train_loss 1.4995356798171997
Iteration 71: train_loss 1.550288200378418
Iteration 72: train_loss 1.4995191097259521
Iteration 73: train_loss 1.545046329498291
Iteration 74: train_loss 1.5073009729385376
Iteration 75: train_loss 1.4404003620147705
Iteration 76: train_loss 1.5079524517059326
Iteration 77: train_loss 1.5014798641204834
Iteration 78: train_loss 1.4871574640274048
Iteration 79: train_loss 1.4984465837478638
Iteration 80: train_loss 1.423938274383545
Iteration 81: train_loss 1.4342533349990845
Iteration 82: train_loss 1.478804588317871
Iteration 83: train_loss 1.51213538646698
Iteration 84: train_loss 1.4908291101455688
Iteration 85: train_loss 1.6068336963653564
Iteration 86: train_loss 1.5308774709701538
Iteration 87: train_loss 1.4528722763061523
Iteration 88: train_loss 1.5344271659851074
Iteration 89: train_loss 1.5174107551574707
Iteration 90: train_loss 1.4730019569396973
Iteration 91: train_loss 1.5714263916015625
Iteration 92: train_loss 1.5395667552947998
Iteration 93: train_loss 1.509714126586914
Iteration 94: train_loss 1.4670411348342896
Iteration 95: train_loss 1.524280071258545
Iteration 96: train_loss 1.5145907402038574
Iteration 97: train_loss 1.471130132675171
Iteration 98: train_loss 1.4759396314620972
Iteration 99: train_loss 1.5048902034759521
Iteration 100: train_loss 1.5217244625091553
Iteration 101: train_loss 1.4834630489349365
Iteration 102: train_loss 1.5041908025741577
Iteration 103: train_loss 1.461288332939148
Iteration 104: train_loss 1.577904462814331
Iteration 105: train_loss 1.4820647239685059
Iteration 106: train_loss 1.5151315927505493
Iteration 107: train_loss 1.5466288328170776
Iteration 108: train_loss 1.5103510618209839
Iteration 109: train_loss 1.549616813659668
Iteration 110: train_loss 1.5766613483428955
Iteration 111: train_loss 1.4571231603622437
Iteration 112: train_loss 1.5049989223480225
Iteration 113: train_loss 1.4436259269714355
Iteration 114: train_loss 1.482069969177246
Iteration 115: train_loss 1.544251799583435
Iteration 116: train_loss 1.5472995042800903
Iteration 117: train_loss 1.5299426317214966
Iteration 118: train_loss 1.5041871070861816
Iteration 119: train_loss 1.4898982048034668
Iteration 120: train_loss 1.4807652235031128
Iteration 121: train_loss 1.5217459201812744
Iteration 122: train_loss 1.5306875705718994
Iteration 123: train_loss 1.5195820331573486
Iteration 124: train_loss 1.4674433469772339
Iteration 125: train_loss 1.4941154718399048
Iteration 126: train_loss 1.5291447639465332
Iteration 127: train_loss 1.5913166999816895
Iteration 128: train_loss 1.5413098335266113
Iteration 129: train_loss 1.3777990341186523
Iteration 130: train_loss 1.5230387449264526
Iteration 131: train_loss 1.48689603805542
Iteration 132: train_loss 1.5935883522033691
Iteration 133: train_loss 1.6131844520568848
Iteration 134: train_loss 1.5530927181243896
Iteration 135: train_loss 1.543735384941101
Iteration 136: train_loss 1.5748488903045654
Iteration 137: train_loss 1.5302075147628784
Iteration 138: train_loss 1.5904958248138428
Iteration 139: train_loss 1.5237088203430176
Iteration 140: train_loss 1.5962116718292236
Iteration 141: train_loss 1.4858280420303345
Iteration 142: train_loss 1.4975154399871826
Iteration 143: train_loss 1.5033795833587646
Iteration 144: train_loss 1.509682536125183
Iteration 145: train_loss 1.53839111328125
Iteration 146: train_loss 1.445071816444397
Iteration 147: train_loss 1.4576964378356934
Iteration 148: train_loss 1.5061314105987549
Iteration 149: train_loss 1.5018486976623535
Iteration 150: train_loss 1.5217427015304565
Iteration 151: train_loss 1.4873197078704834
Iteration 152: train_loss 1.4778772592544556
Iteration 153: train_loss 1.481232762336731
Iteration 154: train_loss 1.4684884548187256
Iteration 155: train_loss 1.5435974597930908
Iteration 156: train_loss 1.5848801136016846
Iteration 157: train_loss 1.4581106901168823
Iteration 158: train_loss 1.5076566934585571
Iteration 159: train_loss 1.459282636642456
Iteration 160: train_loss 1.5146640539169312
Iteration 161: train_loss 1.5196008682250977
Iteration 162: train_loss 1.5017706155776978
Iteration 163: train_loss 1.562252163887024
Iteration 164: train_loss 1.4706056118011475
Iteration 165: train_loss 1.4942541122436523
Iteration 166: train_loss 1.4943386316299438
Iteration 167: train_loss 1.5423367023468018
Iteration 168: train_loss 1.466830849647522
Iteration 169: train_loss 1.4301092624664307
Iteration 170: train_loss 1.4961062669754028
Iteration 171: train_loss 1.51374351978302
Iteration 172: train_loss 1.5033454895019531
Iteration 173: train_loss 1.5522739887237549
Iteration 174: train_loss 1.5078365802764893
Iteration 175: train_loss 1.4877737760543823
Iteration 176: train_loss 1.4719125032424927
Iteration 177: train_loss 1.6300508975982666
Epoch 77: train_avg_loss 1.4937190565012268 eval_avg_acc: 0.3309647597979496 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:40:38] [32mIntermediate result: 0.3309647597979496  (Index 76)[0m
================Epoch: 78================
Iteration 1: train_loss 1.50115966796875
Iteration 2: train_loss 1.4808496236801147
Iteration 3: train_loss 1.5144009590148926
Iteration 4: train_loss 1.5427204370498657
Iteration 5: train_loss 1.4695641994476318
Iteration 6: train_loss 1.4270539283752441
Iteration 7: train_loss 1.3771699666976929
Iteration 8: train_loss 1.4741675853729248
Iteration 9: train_loss 1.5112459659576416
Iteration 10: train_loss 1.4113909006118774
Iteration 11: train_loss 1.4773805141448975
Iteration 12: train_loss 1.4936290979385376
Iteration 13: train_loss 1.450913906097412
Iteration 14: train_loss 1.460923433303833
Iteration 15: train_loss 1.5487011671066284
Iteration 16: train_loss 1.4993475675582886
Iteration 17: train_loss 1.4940892457962036
Iteration 18: train_loss 1.5053386688232422
Iteration 19: train_loss 1.4717997312545776
Iteration 20: train_loss 1.4766658544540405
Iteration 21: train_loss 1.4939261674880981
Iteration 22: train_loss 1.4367338418960571
Iteration 23: train_loss 1.5075087547302246
Iteration 24: train_loss 1.5156774520874023
Iteration 25: train_loss 1.4738446474075317
Iteration 26: train_loss 1.4887008666992188
Iteration 27: train_loss 1.5251284837722778
Iteration 28: train_loss 1.4579949378967285
Iteration 29: train_loss 1.4163697957992554
Iteration 30: train_loss 1.4920902252197266
Iteration 31: train_loss 1.486325979232788
Iteration 32: train_loss 1.4654182195663452
Iteration 33: train_loss 1.470680594444275
Iteration 34: train_loss 1.4563969373703003
Iteration 35: train_loss 1.4923244714736938
Iteration 36: train_loss 1.4963440895080566
Iteration 37: train_loss 1.4743311405181885
Iteration 38: train_loss 1.5165655612945557
Iteration 39: train_loss 1.5018962621688843
Iteration 40: train_loss 1.4404619932174683
Iteration 41: train_loss 1.4346964359283447
Iteration 42: train_loss 1.4357185363769531
Iteration 43: train_loss 1.5247151851654053
Iteration 44: train_loss 1.4636062383651733
Iteration 45: train_loss 1.4978595972061157
Iteration 46: train_loss 1.422350525856018
Iteration 47: train_loss 1.461533546447754
Iteration 48: train_loss 1.477256417274475
Iteration 49: train_loss 1.4635995626449585
Iteration 50: train_loss 1.441420555114746
Iteration 51: train_loss 1.462110161781311
Iteration 52: train_loss 1.5731065273284912
Iteration 53: train_loss 1.5048996210098267
Iteration 54: train_loss 1.463078498840332
Iteration 55: train_loss 1.4087568521499634
Iteration 56: train_loss 1.4259474277496338
Iteration 57: train_loss 1.464343786239624
Iteration 58: train_loss 1.506946325302124
Iteration 59: train_loss 1.495879888534546
Iteration 60: train_loss 1.491492509841919
Iteration 61: train_loss 1.4175128936767578
Iteration 62: train_loss 1.477790355682373
Iteration 63: train_loss 1.476578712463379
Iteration 64: train_loss 1.5062386989593506
Iteration 65: train_loss 1.4517500400543213
Iteration 66: train_loss 1.466181755065918
Iteration 67: train_loss 1.4990161657333374
Iteration 68: train_loss 1.5453630685806274
Iteration 69: train_loss 1.447714924812317
Iteration 70: train_loss 1.4639577865600586
Iteration 71: train_loss 1.4478896856307983
Iteration 72: train_loss 1.4416780471801758
Iteration 73: train_loss 1.5332683324813843
Iteration 74: train_loss 1.420620083808899
Iteration 75: train_loss 1.5206516981124878
Iteration 76: train_loss 1.4983885288238525
Iteration 77: train_loss 1.4570688009262085
Iteration 78: train_loss 1.4425805807113647
Iteration 79: train_loss 1.4909629821777344
Iteration 80: train_loss 1.4692822694778442
Iteration 81: train_loss 1.4646100997924805
Iteration 82: train_loss 1.5217186212539673
Iteration 83: train_loss 1.5029349327087402
Iteration 84: train_loss 1.5128189325332642
Iteration 85: train_loss 1.5141814947128296
Iteration 86: train_loss 1.4446712732315063
Iteration 87: train_loss 1.4835666418075562
Iteration 88: train_loss 1.5180647373199463
Iteration 89: train_loss 1.4793806076049805
Iteration 90: train_loss 1.5298556089401245
Iteration 91: train_loss 1.4848487377166748
Iteration 92: train_loss 1.4390383958816528
Iteration 93: train_loss 1.444108009338379
Iteration 94: train_loss 1.4616496562957764
Iteration 95: train_loss 1.4289144277572632
Iteration 96: train_loss 1.4617747068405151
Iteration 97: train_loss 1.4415427446365356
Iteration 98: train_loss 1.439820408821106
Iteration 99: train_loss 1.4330884218215942
Iteration 100: train_loss 1.5137094259262085
Iteration 101: train_loss 1.4852344989776611
Iteration 102: train_loss 1.4818055629730225
Iteration 103: train_loss 1.4732065200805664
Iteration 104: train_loss 1.4613081216812134
Iteration 105: train_loss 1.5531744956970215
Iteration 106: train_loss 1.5124739408493042
Iteration 107: train_loss 1.4559388160705566
Iteration 108: train_loss 1.548507809638977
Iteration 109: train_loss 1.466188907623291
Iteration 110: train_loss 1.4952949285507202
Iteration 111: train_loss 1.5867810249328613
Iteration 112: train_loss 1.5346710681915283
Iteration 113: train_loss 1.4498381614685059
Iteration 114: train_loss 1.5144574642181396
Iteration 115: train_loss 1.4999784231185913
Iteration 116: train_loss 1.511440396308899
Iteration 117: train_loss 1.4340003728866577
Iteration 118: train_loss 1.4651542901992798
Iteration 119: train_loss 1.5124914646148682
Iteration 120: train_loss 1.5486871004104614
Iteration 121: train_loss 1.4785460233688354
Iteration 122: train_loss 1.513777256011963
Iteration 123: train_loss 1.4492841958999634
Iteration 124: train_loss 1.4985238313674927
Iteration 125: train_loss 1.4972766637802124
Iteration 126: train_loss 1.424479365348816
Iteration 127: train_loss 1.4574323892593384
Iteration 128: train_loss 1.495091199874878
Iteration 129: train_loss 1.4867850542068481
Iteration 130: train_loss 1.5324296951293945
Iteration 131: train_loss 1.5366274118423462
Iteration 132: train_loss 1.5280282497406006
Iteration 133: train_loss 1.5381945371627808
Iteration 134: train_loss 1.4435629844665527
Iteration 135: train_loss 1.4461984634399414
Iteration 136: train_loss 1.4931186437606812
Iteration 137: train_loss 1.4763644933700562
Iteration 138: train_loss 1.5057125091552734
Iteration 139: train_loss 1.4947731494903564
Iteration 140: train_loss 1.4950225353240967
Iteration 141: train_loss 1.4758188724517822
Iteration 142: train_loss 1.4838443994522095
Iteration 143: train_loss 1.529659390449524
Iteration 144: train_loss 1.5401602983474731
Iteration 145: train_loss 1.4958417415618896
Iteration 146: train_loss 1.5069520473480225
Iteration 147: train_loss 1.4694710969924927
Iteration 148: train_loss 1.5185400247573853
Iteration 149: train_loss 1.4642999172210693
Iteration 150: train_loss 1.453547477722168
Iteration 151: train_loss 1.5287688970565796
Iteration 152: train_loss 1.5175514221191406
Iteration 153: train_loss 1.463149905204773
Iteration 154: train_loss 1.4796552658081055
Iteration 155: train_loss 1.5167018175125122
Iteration 156: train_loss 1.5071439743041992
Iteration 157: train_loss 1.4788931608200073
Iteration 158: train_loss 1.4594272375106812
Iteration 159: train_loss 1.5033644437789917
Iteration 160: train_loss 1.517656683921814
Iteration 161: train_loss 1.4663963317871094
Iteration 162: train_loss 1.462003231048584
Iteration 163: train_loss 1.5394214391708374
Iteration 164: train_loss 1.5011579990386963
Iteration 165: train_loss 1.5401021242141724
Iteration 166: train_loss 1.4957282543182373
Iteration 167: train_loss 1.4822064638137817
Iteration 168: train_loss 1.4987393617630005
Iteration 169: train_loss 1.5421760082244873
Iteration 170: train_loss 1.5062686204910278
Iteration 171: train_loss 1.5441447496414185
Iteration 172: train_loss 1.504446029663086
Iteration 173: train_loss 1.5313668251037598
Iteration 174: train_loss 1.4576719999313354
Iteration 175: train_loss 1.4304262399673462
Iteration 176: train_loss 1.5218449831008911
Iteration 177: train_loss 1.4943393468856812
Epoch 78: train_avg_loss 1.4848705900590973 eval_avg_acc: 0.33963783084862936 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:41:19] [32mIntermediate result: 0.33963783084862936  (Index 77)[0m
================Epoch: 79================
Iteration 1: train_loss 1.4973114728927612
Iteration 2: train_loss 1.4506149291992188
Iteration 3: train_loss 1.465470790863037
Iteration 4: train_loss 1.4992278814315796
Iteration 5: train_loss 1.4810972213745117
Iteration 6: train_loss 1.5441144704818726
Iteration 7: train_loss 1.4205838441848755
Iteration 8: train_loss 1.4266222715377808
Iteration 9: train_loss 1.4669488668441772
Iteration 10: train_loss 1.4116106033325195
Iteration 11: train_loss 1.4531883001327515
Iteration 12: train_loss 1.460976004600525
Iteration 13: train_loss 1.4735699892044067
Iteration 14: train_loss 1.4630447626113892
Iteration 15: train_loss 1.4072939157485962
Iteration 16: train_loss 1.4735403060913086
Iteration 17: train_loss 1.4539293050765991
Iteration 18: train_loss 1.4591796398162842
Iteration 19: train_loss 1.5102782249450684
Iteration 20: train_loss 1.370627999305725
Iteration 21: train_loss 1.4556686878204346
Iteration 22: train_loss 1.385253667831421
Iteration 23: train_loss 1.4900997877120972
Iteration 24: train_loss 1.4976180791854858
Iteration 25: train_loss 1.4372540712356567
Iteration 26: train_loss 1.4456698894500732
Iteration 27: train_loss 1.4380035400390625
Iteration 28: train_loss 1.4487340450286865
Iteration 29: train_loss 1.5420918464660645
Iteration 30: train_loss 1.4625263214111328
Iteration 31: train_loss 1.4731451272964478
Iteration 32: train_loss 1.4509696960449219
Iteration 33: train_loss 1.4386320114135742
Iteration 34: train_loss 1.4682927131652832
Iteration 35: train_loss 1.443016529083252
Iteration 36: train_loss 1.4976775646209717
Iteration 37: train_loss 1.4884270429611206
Iteration 38: train_loss 1.435520052909851
Iteration 39: train_loss 1.3789409399032593
Iteration 40: train_loss 1.4516308307647705
Iteration 41: train_loss 1.494904637336731
Iteration 42: train_loss 1.4479728937149048
Iteration 43: train_loss 1.4987388849258423
Iteration 44: train_loss 1.4981220960617065
Iteration 45: train_loss 1.4276537895202637
Iteration 46: train_loss 1.469327449798584
Iteration 47: train_loss 1.466589093208313
Iteration 48: train_loss 1.3942137956619263
Iteration 49: train_loss 1.4672808647155762
Iteration 50: train_loss 1.4502023458480835
Iteration 51: train_loss 1.4870330095291138
Iteration 52: train_loss 1.5197428464889526
Iteration 53: train_loss 1.44675874710083
Iteration 54: train_loss 1.4745460748672485
Iteration 55: train_loss 1.4108408689498901
Iteration 56: train_loss 1.5195459127426147
Iteration 57: train_loss 1.4848698377609253
Iteration 58: train_loss 1.440937876701355
Iteration 59: train_loss 1.4720618724822998
Iteration 60: train_loss 1.446122169494629
Iteration 61: train_loss 1.4950191974639893
Iteration 62: train_loss 1.4928715229034424
Iteration 63: train_loss 1.5236454010009766
Iteration 64: train_loss 1.5344045162200928
Iteration 65: train_loss 1.511499047279358
Iteration 66: train_loss 1.5030308961868286
Iteration 67: train_loss 1.4877780675888062
Iteration 68: train_loss 1.5049430131912231
Iteration 69: train_loss 1.4765124320983887
Iteration 70: train_loss 1.5442836284637451
Iteration 71: train_loss 1.5391135215759277
Iteration 72: train_loss 1.5120445489883423
Iteration 73: train_loss 1.5075469017028809
Iteration 74: train_loss 1.4495394229888916
Iteration 75: train_loss 1.4387924671173096
Iteration 76: train_loss 1.462866187095642
Iteration 77: train_loss 1.5206372737884521
Iteration 78: train_loss 1.4721107482910156
Iteration 79: train_loss 1.4517014026641846
Iteration 80: train_loss 1.515509009361267
Iteration 81: train_loss 1.5153735876083374
Iteration 82: train_loss 1.4573931694030762
Iteration 83: train_loss 1.4953116178512573
Iteration 84: train_loss 1.4381134510040283
Iteration 85: train_loss 1.4899711608886719
Iteration 86: train_loss 1.4569380283355713
Iteration 87: train_loss 1.4717061519622803
Iteration 88: train_loss 1.4760724306106567
Iteration 89: train_loss 1.5206602811813354
Iteration 90: train_loss 1.4466856718063354
Iteration 91: train_loss 1.4894505739212036
Iteration 92: train_loss 1.521958351135254
Iteration 93: train_loss 1.4808025360107422
Iteration 94: train_loss 1.470267653465271
Iteration 95: train_loss 1.4408646821975708
Iteration 96: train_loss 1.5137299299240112
Iteration 97: train_loss 1.5041691064834595
Iteration 98: train_loss 1.4261106252670288
Iteration 99: train_loss 1.5521893501281738
Iteration 100: train_loss 1.4126416444778442
Iteration 101: train_loss 1.509438395500183
Iteration 102: train_loss 1.5390064716339111
Iteration 103: train_loss 1.4830310344696045
Iteration 104: train_loss 1.5032844543457031
Iteration 105: train_loss 1.5090724229812622
Iteration 106: train_loss 1.5289583206176758
Iteration 107: train_loss 1.5042479038238525
Iteration 108: train_loss 1.4603643417358398
Iteration 109: train_loss 1.5213286876678467
Iteration 110: train_loss 1.5389455556869507
Iteration 111: train_loss 1.4229744672775269
Iteration 112: train_loss 1.4952515363693237
Iteration 113: train_loss 1.4932266473770142
Iteration 114: train_loss 1.4557219743728638
Iteration 115: train_loss 1.4705954790115356
Iteration 116: train_loss 1.5071935653686523
Iteration 117: train_loss 1.5754231214523315
Iteration 118: train_loss 1.4840915203094482
Iteration 119: train_loss 1.4559602737426758
Iteration 120: train_loss 1.470063328742981
Iteration 121: train_loss 1.604372262954712
Iteration 122: train_loss 1.4659839868545532
Iteration 123: train_loss 1.5085090398788452
Iteration 124: train_loss 1.458560585975647
Iteration 125: train_loss 1.429470181465149
Iteration 126: train_loss 1.4243141412734985
Iteration 127: train_loss 1.4731615781784058
Iteration 128: train_loss 1.443518877029419
Iteration 129: train_loss 1.4513497352600098
Iteration 130: train_loss 1.5059841871261597
Iteration 131: train_loss 1.4991523027420044
Iteration 132: train_loss 1.4601341485977173
Iteration 133: train_loss 1.5221662521362305
Iteration 134: train_loss 1.5079127550125122
Iteration 135: train_loss 1.4824460744857788
Iteration 136: train_loss 1.4912135601043701
Iteration 137: train_loss 1.4305766820907593
Iteration 138: train_loss 1.4581115245819092
Iteration 139: train_loss 1.4762588739395142
Iteration 140: train_loss 1.4549903869628906
Iteration 141: train_loss 1.5446215867996216
Iteration 142: train_loss 1.4754135608673096
Iteration 143: train_loss 1.478316068649292
Iteration 144: train_loss 1.4608854055404663
Iteration 145: train_loss 1.4451290369033813
Iteration 146: train_loss 1.4784942865371704
Iteration 147: train_loss 1.4437092542648315
Iteration 148: train_loss 1.481458067893982
Iteration 149: train_loss 1.5156760215759277
Iteration 150: train_loss 1.384168028831482
Iteration 151: train_loss 1.4464151859283447
Iteration 152: train_loss 1.4576774835586548
Iteration 153: train_loss 1.4495245218276978
Iteration 154: train_loss 1.5798040628433228
Iteration 155: train_loss 1.5001050233840942
Iteration 156: train_loss 1.5073776245117188
Iteration 157: train_loss 1.563676357269287
Iteration 158: train_loss 1.5161948204040527
Iteration 159: train_loss 1.4730772972106934
Iteration 160: train_loss 1.4510977268218994
Iteration 161: train_loss 1.5008611679077148
Iteration 162: train_loss 1.5223039388656616
Iteration 163: train_loss 1.5197879076004028
Iteration 164: train_loss 1.501326084136963
Iteration 165: train_loss 1.506942868232727
Iteration 166: train_loss 1.438716173171997
Iteration 167: train_loss 1.5010185241699219
Iteration 168: train_loss 1.4853793382644653
Iteration 169: train_loss 1.4878146648406982
Iteration 170: train_loss 1.468842625617981
Iteration 171: train_loss 1.5438350439071655
Iteration 172: train_loss 1.4772557020187378
Iteration 173: train_loss 1.5001338720321655
Iteration 174: train_loss 1.4485255479812622
Iteration 175: train_loss 1.5229649543762207
Iteration 176: train_loss 1.448181390762329
Iteration 177: train_loss 1.419799566268921
Epoch 79: train_avg_loss 1.4778700844716217 eval_avg_acc: 0.34244939280504744 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:42:00] [32mIntermediate result: 0.34244939280504744  (Index 78)[0m
================Epoch: 80================
Iteration 1: train_loss 1.4855910539627075
Iteration 2: train_loss 1.4762682914733887
Iteration 3: train_loss 1.4724849462509155
Iteration 4: train_loss 1.472380518913269
Iteration 5: train_loss 1.4732306003570557
Iteration 6: train_loss 1.4613308906555176
Iteration 7: train_loss 1.4543968439102173
Iteration 8: train_loss 1.4619982242584229
Iteration 9: train_loss 1.4562960863113403
Iteration 10: train_loss 1.506773591041565
Iteration 11: train_loss 1.4867748022079468
Iteration 12: train_loss 1.532891035079956
Iteration 13: train_loss 1.4814049005508423
Iteration 14: train_loss 1.4783885478973389
Iteration 15: train_loss 1.5019944906234741
Iteration 16: train_loss 1.4920718669891357
Iteration 17: train_loss 1.4103134870529175
Iteration 18: train_loss 1.4505634307861328
Iteration 19: train_loss 1.44974684715271
Iteration 20: train_loss 1.3988498449325562
Iteration 21: train_loss 1.4683762788772583
Iteration 22: train_loss 1.4368740320205688
Iteration 23: train_loss 1.5247875452041626
Iteration 24: train_loss 1.4765825271606445
Iteration 25: train_loss 1.5407825708389282
Iteration 26: train_loss 1.4835007190704346
Iteration 27: train_loss 1.447746753692627
Iteration 28: train_loss 1.478882908821106
Iteration 29: train_loss 1.4392269849777222
Iteration 30: train_loss 1.405608892440796
Iteration 31: train_loss 1.4500222206115723
Iteration 32: train_loss 1.4153378009796143
Iteration 33: train_loss 1.4761879444122314
Iteration 34: train_loss 1.4830104112625122
Iteration 35: train_loss 1.3999754190444946
Iteration 36: train_loss 1.4390976428985596
Iteration 37: train_loss 1.471178412437439
Iteration 38: train_loss 1.4432462453842163
Iteration 39: train_loss 1.4571549892425537
Iteration 40: train_loss 1.5000079870224
Iteration 41: train_loss 1.4018181562423706
Iteration 42: train_loss 1.4892833232879639
Iteration 43: train_loss 1.4748282432556152
Iteration 44: train_loss 1.473428726196289
Iteration 45: train_loss 1.5024771690368652
Iteration 46: train_loss 1.4634056091308594
Iteration 47: train_loss 1.5098305940628052
Iteration 48: train_loss 1.509046196937561
Iteration 49: train_loss 1.5205737352371216
Iteration 50: train_loss 1.4500080347061157
Iteration 51: train_loss 1.4431722164154053
Iteration 52: train_loss 1.5031794309616089
Iteration 53: train_loss 1.4717899560928345
Iteration 54: train_loss 1.4969370365142822
Iteration 55: train_loss 1.507523536682129
Iteration 56: train_loss 1.4405895471572876
Iteration 57: train_loss 1.4927115440368652
Iteration 58: train_loss 1.4863290786743164
Iteration 59: train_loss 1.5183085203170776
Iteration 60: train_loss 1.4660247564315796
Iteration 61: train_loss 1.4388346672058105
Iteration 62: train_loss 1.4522826671600342
Iteration 63: train_loss 1.427284598350525
Iteration 64: train_loss 1.4499603509902954
Iteration 65: train_loss 1.4339210987091064
Iteration 66: train_loss 1.416043996810913
Iteration 67: train_loss 1.453136682510376
Iteration 68: train_loss 1.4720820188522339
Iteration 69: train_loss 1.459500789642334
Iteration 70: train_loss 1.4502614736557007
Iteration 71: train_loss 1.4591883420944214
Iteration 72: train_loss 1.4729840755462646
Iteration 73: train_loss 1.510912537574768
Iteration 74: train_loss 1.4649690389633179
Iteration 75: train_loss 1.4540132284164429
Iteration 76: train_loss 1.4753034114837646
Iteration 77: train_loss 1.4094631671905518
Iteration 78: train_loss 1.4974557161331177
Iteration 79: train_loss 1.5275834798812866
Iteration 80: train_loss 1.5392553806304932
Iteration 81: train_loss 1.4215586185455322
Iteration 82: train_loss 1.4469983577728271
Iteration 83: train_loss 1.4656380414962769
Iteration 84: train_loss 1.4339516162872314
Iteration 85: train_loss 1.5034085512161255
Iteration 86: train_loss 1.4633787870407104
Iteration 87: train_loss 1.4915599822998047
Iteration 88: train_loss 1.5057250261306763
Iteration 89: train_loss 1.4839016199111938
Iteration 90: train_loss 1.4800881147384644
Iteration 91: train_loss 1.4689851999282837
Iteration 92: train_loss 1.4564961194992065
Iteration 93: train_loss 1.446933627128601
Iteration 94: train_loss 1.540222406387329
Iteration 95: train_loss 1.5167895555496216
Iteration 96: train_loss 1.5223777294158936
Iteration 97: train_loss 1.4536845684051514
Iteration 98: train_loss 1.4777051210403442
Iteration 99: train_loss 1.4795787334442139
Iteration 100: train_loss 1.4024381637573242
Iteration 101: train_loss 1.476759433746338
Iteration 102: train_loss 1.438364028930664
Iteration 103: train_loss 1.4480321407318115
Iteration 104: train_loss 1.425148367881775
Iteration 105: train_loss 1.4302725791931152
Iteration 106: train_loss 1.435705304145813
Iteration 107: train_loss 1.4333500862121582
Iteration 108: train_loss 1.43330979347229
Iteration 109: train_loss 1.4510655403137207
Iteration 110: train_loss 1.454005241394043
Iteration 111: train_loss 1.448771357536316
Iteration 112: train_loss 1.5301473140716553
Iteration 113: train_loss 1.451703667640686
Iteration 114: train_loss 1.493106722831726
Iteration 115: train_loss 1.4764560461044312
Iteration 116: train_loss 1.407373070716858
Iteration 117: train_loss 1.4449939727783203
Iteration 118: train_loss 1.5062901973724365
Iteration 119: train_loss 1.4572365283966064
Iteration 120: train_loss 1.478349208831787
Iteration 121: train_loss 1.4187430143356323
Iteration 122: train_loss 1.4848357439041138
Iteration 123: train_loss 1.4519413709640503
Iteration 124: train_loss 1.4513111114501953
Iteration 125: train_loss 1.4136980772018433
Iteration 126: train_loss 1.4311364889144897
Iteration 127: train_loss 1.4514418840408325
Iteration 128: train_loss 1.4500749111175537
Iteration 129: train_loss 1.4908605813980103
Iteration 130: train_loss 1.494971513748169
Iteration 131: train_loss 1.4611010551452637
Iteration 132: train_loss 1.4448567628860474
Iteration 133: train_loss 1.4522823095321655
Iteration 134: train_loss 1.4514029026031494
Iteration 135: train_loss 1.4652738571166992
Iteration 136: train_loss 1.4817272424697876
Iteration 137: train_loss 1.4374182224273682
Iteration 138: train_loss 1.4006195068359375
Iteration 139: train_loss 1.4737234115600586
Iteration 140: train_loss 1.486265778541565
Iteration 141: train_loss 1.4320842027664185
Iteration 142: train_loss 1.3946237564086914
Iteration 143: train_loss 1.5344092845916748
Iteration 144: train_loss 1.4347286224365234
Iteration 145: train_loss 1.4430975914001465
Iteration 146: train_loss 1.4202229976654053
Iteration 147: train_loss 1.4337053298950195
Iteration 148: train_loss 1.457327127456665
Iteration 149: train_loss 1.4911259412765503
Iteration 150: train_loss 1.4259406328201294
Iteration 151: train_loss 1.4756484031677246
Iteration 152: train_loss 1.457612156867981
Iteration 153: train_loss 1.424317479133606
Iteration 154: train_loss 1.4611334800720215
Iteration 155: train_loss 1.4601867198944092
Iteration 156: train_loss 1.4701215028762817
Iteration 157: train_loss 1.4692834615707397
Iteration 158: train_loss 1.4420591592788696
Iteration 159: train_loss 1.483459711074829
Iteration 160: train_loss 1.522282600402832
Iteration 161: train_loss 1.487349510192871
Iteration 162: train_loss 1.482313632965088
Iteration 163: train_loss 1.4548516273498535
Iteration 164: train_loss 1.5184812545776367
Iteration 165: train_loss 1.4802607297897339
Iteration 166: train_loss 1.5480928421020508
Iteration 167: train_loss 1.4570882320404053
Iteration 168: train_loss 1.5258781909942627
Iteration 169: train_loss 1.5561310052871704
Iteration 170: train_loss 1.536890983581543
Iteration 171: train_loss 1.5137356519699097
Iteration 172: train_loss 1.5817582607269287
Iteration 173: train_loss 1.5121076107025146
Iteration 174: train_loss 1.5483429431915283
Iteration 175: train_loss 1.4453328847885132
Iteration 176: train_loss 1.4698243141174316
Iteration 177: train_loss 1.5635261535644531
Epoch 80: train_avg_loss 1.4690278135450547 eval_avg_acc: 0.3123292521874063 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:42:43] [32mIntermediate result: 0.3123292521874063  (Index 79)[0m
================Epoch: 81================
Iteration 1: train_loss 1.4583317041397095
Iteration 2: train_loss 1.4723281860351562
Iteration 3: train_loss 1.471391201019287
Iteration 4: train_loss 1.4916789531707764
Iteration 5: train_loss 1.5254571437835693
Iteration 6: train_loss 1.4224978685379028
Iteration 7: train_loss 1.4617739915847778
Iteration 8: train_loss 1.493095874786377
Iteration 9: train_loss 1.4144153594970703
Iteration 10: train_loss 1.3818650245666504
Iteration 11: train_loss 1.399086356163025
Iteration 12: train_loss 1.4140855073928833
Iteration 13: train_loss 1.4651033878326416
Iteration 14: train_loss 1.4963395595550537
Iteration 15: train_loss 1.4780447483062744
Iteration 16: train_loss 1.4346938133239746
Iteration 17: train_loss 1.3924944400787354
Iteration 18: train_loss 1.408060908317566
Iteration 19: train_loss 1.4479695558547974
Iteration 20: train_loss 1.4372031688690186
Iteration 21: train_loss 1.4754810333251953
Iteration 22: train_loss 1.4385395050048828
Iteration 23: train_loss 1.4528088569641113
Iteration 24: train_loss 1.4369890689849854
Iteration 25: train_loss 1.3899730443954468
Iteration 26: train_loss 1.4608354568481445
Iteration 27: train_loss 1.4493861198425293
Iteration 28: train_loss 1.506510615348816
Iteration 29: train_loss 1.5234202146530151
Iteration 30: train_loss 1.4074974060058594
Iteration 31: train_loss 1.4350982904434204
Iteration 32: train_loss 1.4055259227752686
Iteration 33: train_loss 1.4674063920974731
Iteration 34: train_loss 1.4708865880966187
Iteration 35: train_loss 1.4825198650360107
Iteration 36: train_loss 1.450903058052063
Iteration 37: train_loss 1.4308191537857056
Iteration 38: train_loss 1.421566367149353
Iteration 39: train_loss 1.3963559865951538
Iteration 40: train_loss 1.472696304321289
Iteration 41: train_loss 1.436017394065857
Iteration 42: train_loss 1.5010777711868286
Iteration 43: train_loss 1.4325727224349976
Iteration 44: train_loss 1.5374903678894043
Iteration 45: train_loss 1.4351187944412231
Iteration 46: train_loss 1.438124418258667
Iteration 47: train_loss 1.3710150718688965
Iteration 48: train_loss 1.448533296585083
Iteration 49: train_loss 1.4137005805969238
Iteration 50: train_loss 1.4680266380310059
Iteration 51: train_loss 1.3920241594314575
Iteration 52: train_loss 1.5084409713745117
Iteration 53: train_loss 1.3679733276367188
Iteration 54: train_loss 1.406073808670044
Iteration 55: train_loss 1.469749927520752
Iteration 56: train_loss 1.4414640665054321
Iteration 57: train_loss 1.440340518951416
Iteration 58: train_loss 1.4343960285186768
Iteration 59: train_loss 1.456563949584961
Iteration 60: train_loss 1.3909409046173096
Iteration 61: train_loss 1.4649944305419922
Iteration 62: train_loss 1.4370135068893433
Iteration 63: train_loss 1.4761497974395752
Iteration 64: train_loss 1.4581819772720337
Iteration 65: train_loss 1.3780561685562134
Iteration 66: train_loss 1.4976824522018433
Iteration 67: train_loss 1.453818917274475
Iteration 68: train_loss 1.4503722190856934
Iteration 69: train_loss 1.3769888877868652
Iteration 70: train_loss 1.5078638792037964
Iteration 71: train_loss 1.4155800342559814
Iteration 72: train_loss 1.4989835023880005
Iteration 73: train_loss 1.46576726436615
Iteration 74: train_loss 1.448056936264038
Iteration 75: train_loss 1.4307827949523926
Iteration 76: train_loss 1.5436623096466064
Iteration 77: train_loss 1.5443439483642578
Iteration 78: train_loss 1.454972743988037
Iteration 79: train_loss 1.515194058418274
Iteration 80: train_loss 1.4705743789672852
Iteration 81: train_loss 1.4285085201263428
Iteration 82: train_loss 1.427108645439148
Iteration 83: train_loss 1.3693057298660278
Iteration 84: train_loss 1.3701691627502441
Iteration 85: train_loss 1.4651713371276855
Iteration 86: train_loss 1.4684003591537476
Iteration 87: train_loss 1.4655873775482178
Iteration 88: train_loss 1.4634944200515747
Iteration 89: train_loss 1.436189889907837
Iteration 90: train_loss 1.43791925907135
Iteration 91: train_loss 1.4518202543258667
Iteration 92: train_loss 1.4940803050994873
Iteration 93: train_loss 1.4694007635116577
Iteration 94: train_loss 1.4248697757720947
Iteration 95: train_loss 1.4747728109359741
Iteration 96: train_loss 1.4276680946350098
Iteration 97: train_loss 1.5625989437103271
Iteration 98: train_loss 1.4457170963287354
Iteration 99: train_loss 1.4815561771392822
Iteration 100: train_loss 1.4916408061981201
Iteration 101: train_loss 1.4692778587341309
Iteration 102: train_loss 1.4777345657348633
Iteration 103: train_loss 1.5307010412216187
Iteration 104: train_loss 1.4799723625183105
Iteration 105: train_loss 1.491167664527893
Iteration 106: train_loss 1.46605384349823
Iteration 107: train_loss 1.505571722984314
Iteration 108: train_loss 1.445489764213562
Iteration 109: train_loss 1.448153018951416
Iteration 110: train_loss 1.5036040544509888
Iteration 111: train_loss 1.438193678855896
Iteration 112: train_loss 1.5716381072998047
Iteration 113: train_loss 1.4967825412750244
Iteration 114: train_loss 1.4226347208023071
Iteration 115: train_loss 1.5194214582443237
Iteration 116: train_loss 1.5057905912399292
Iteration 117: train_loss 1.4544627666473389
Iteration 118: train_loss 1.485366702079773
Iteration 119: train_loss 1.4822930097579956
Iteration 120: train_loss 1.3838589191436768
Iteration 121: train_loss 1.5025861263275146
Iteration 122: train_loss 1.4801338911056519
Iteration 123: train_loss 1.4552603960037231
Iteration 124: train_loss 1.482168436050415
Iteration 125: train_loss 1.4427261352539062
Iteration 126: train_loss 1.4444071054458618
Iteration 127: train_loss 1.4470670223236084
Iteration 128: train_loss 1.5043622255325317
Iteration 129: train_loss 1.4674638509750366
Iteration 130: train_loss 1.5296311378479004
Iteration 131: train_loss 1.498387336730957
Iteration 132: train_loss 1.4926247596740723
Iteration 133: train_loss 1.521856427192688
Iteration 134: train_loss 1.4967131614685059
Iteration 135: train_loss 1.525561809539795
Iteration 136: train_loss 1.5622341632843018
Iteration 137: train_loss 1.462857961654663
Iteration 138: train_loss 1.5753012895584106
Iteration 139: train_loss 1.438887119293213
Iteration 140: train_loss 1.4549659490585327
Iteration 141: train_loss 1.4762550592422485
Iteration 142: train_loss 1.4643597602844238
Iteration 143: train_loss 1.487040400505066
Iteration 144: train_loss 1.4242922067642212
Iteration 145: train_loss 1.4825623035430908
Iteration 146: train_loss 1.5103943347930908
Iteration 147: train_loss 1.5612834692001343
Iteration 148: train_loss 1.5295319557189941
Iteration 149: train_loss 1.4872316122055054
Iteration 150: train_loss 1.4604705572128296
Iteration 151: train_loss 1.4573273658752441
Iteration 152: train_loss 1.5899438858032227
Iteration 153: train_loss 1.4963048696517944
Iteration 154: train_loss 1.5350176095962524
Iteration 155: train_loss 1.5015276670455933
Iteration 156: train_loss 1.4820897579193115
Iteration 157: train_loss 1.4844623804092407
Iteration 158: train_loss 1.451548457145691
Iteration 159: train_loss 1.5084879398345947
Iteration 160: train_loss 1.5131568908691406
Iteration 161: train_loss 1.4517134428024292
Iteration 162: train_loss 1.4505698680877686
Iteration 163: train_loss 1.4641369581222534
Iteration 164: train_loss 1.4627478122711182
Iteration 165: train_loss 1.521529197692871
Iteration 166: train_loss 1.5156611204147339
Iteration 167: train_loss 1.4708596467971802
Iteration 168: train_loss 1.4970993995666504
Iteration 169: train_loss 1.5029908418655396
Iteration 170: train_loss 1.4530400037765503
Iteration 171: train_loss 1.4440453052520752
Iteration 172: train_loss 1.475306749343872
Iteration 173: train_loss 1.53500235080719
Iteration 174: train_loss 1.4701943397521973
Iteration 175: train_loss 1.4474562406539917
Iteration 176: train_loss 1.4206016063690186
Iteration 177: train_loss 1.5403215885162354
Epoch 81: train_avg_loss 1.465908080844556 eval_avg_acc: 0.34976007550961014 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:43:22] [32mIntermediate result: 0.34976007550961014  (Index 80)[0m
================Epoch: 82================
Iteration 1: train_loss 1.4164496660232544
Iteration 2: train_loss 1.454383134841919
Iteration 3: train_loss 1.4813854694366455
Iteration 4: train_loss 1.4146201610565186
Iteration 5: train_loss 1.3828225135803223
Iteration 6: train_loss 1.4516961574554443
Iteration 7: train_loss 1.4999945163726807
Iteration 8: train_loss 1.5161528587341309
Iteration 9: train_loss 1.432849645614624
Iteration 10: train_loss 1.3906514644622803
Iteration 11: train_loss 1.5092202425003052
Iteration 12: train_loss 1.4895585775375366
Iteration 13: train_loss 1.388132929801941
Iteration 14: train_loss 1.4705767631530762
Iteration 15: train_loss 1.4270637035369873
Iteration 16: train_loss 1.438387155532837
Iteration 17: train_loss 1.4923886060714722
Iteration 18: train_loss 1.4893152713775635
Iteration 19: train_loss 1.3580029010772705
Iteration 20: train_loss 1.4817512035369873
Iteration 21: train_loss 1.407509446144104
Iteration 22: train_loss 1.4965487718582153
Iteration 23: train_loss 1.4204046726226807
Iteration 24: train_loss 1.4152376651763916
Iteration 25: train_loss 1.433508038520813
Iteration 26: train_loss 1.5026785135269165
Iteration 27: train_loss 1.4594727754592896
Iteration 28: train_loss 1.4621695280075073
Iteration 29: train_loss 1.4135785102844238
Iteration 30: train_loss 1.4652425050735474
Iteration 31: train_loss 1.5003454685211182
Iteration 32: train_loss 1.4937784671783447
Iteration 33: train_loss 1.4686118364334106
Iteration 34: train_loss 1.4400490522384644
Iteration 35: train_loss 1.4500657320022583
Iteration 36: train_loss 1.4026758670806885
Iteration 37: train_loss 1.3548014163970947
Iteration 38: train_loss 1.441019058227539
Iteration 39: train_loss 1.483872413635254
Iteration 40: train_loss 1.5148026943206787
Iteration 41: train_loss 1.5213067531585693
Iteration 42: train_loss 1.4399476051330566
Iteration 43: train_loss 1.4446017742156982
Iteration 44: train_loss 1.4158220291137695
Iteration 45: train_loss 1.498835802078247
Iteration 46: train_loss 1.4158003330230713
Iteration 47: train_loss 1.3351131677627563
Iteration 48: train_loss 1.4969913959503174
Iteration 49: train_loss 1.5137159824371338
Iteration 50: train_loss 1.433435082435608
Iteration 51: train_loss 1.461389422416687
Iteration 52: train_loss 1.427985429763794
Iteration 53: train_loss 1.4923478364944458
Iteration 54: train_loss 1.4434391260147095
Iteration 55: train_loss 1.4662375450134277
Iteration 56: train_loss 1.4833824634552002
Iteration 57: train_loss 1.4122517108917236
Iteration 58: train_loss 1.4403626918792725
Iteration 59: train_loss 1.3711086511611938
Iteration 60: train_loss 1.4936041831970215
Iteration 61: train_loss 1.409352421760559
Iteration 62: train_loss 1.4393726587295532
Iteration 63: train_loss 1.4211763143539429
Iteration 64: train_loss 1.4876469373703003
Iteration 65: train_loss 1.447212815284729
Iteration 66: train_loss 1.4080486297607422
Iteration 67: train_loss 1.4772162437438965
Iteration 68: train_loss 1.4029096364974976
Iteration 69: train_loss 1.4714430570602417
Iteration 70: train_loss 1.4447453022003174
Iteration 71: train_loss 1.4195610284805298
Iteration 72: train_loss 1.462543249130249
Iteration 73: train_loss 1.4170476198196411
Iteration 74: train_loss 1.4311227798461914
Iteration 75: train_loss 1.3975862264633179
Iteration 76: train_loss 1.4692001342773438
Iteration 77: train_loss 1.4072116613388062
Iteration 78: train_loss 1.40803861618042
Iteration 79: train_loss 1.4485760927200317
Iteration 80: train_loss 1.4122697114944458
Iteration 81: train_loss 1.3944216966629028
Iteration 82: train_loss 1.4624764919281006
Iteration 83: train_loss 1.3914982080459595
Iteration 84: train_loss 1.4563461542129517
Iteration 85: train_loss 1.3590121269226074
Iteration 86: train_loss 1.4395757913589478
Iteration 87: train_loss 1.428436279296875
Iteration 88: train_loss 1.4216458797454834
Iteration 89: train_loss 1.5040098428726196
Iteration 90: train_loss 1.4017423391342163
Iteration 91: train_loss 1.4455678462982178
Iteration 92: train_loss 1.4916797876358032
Iteration 93: train_loss 1.4752382040023804
Iteration 94: train_loss 1.475894808769226
Iteration 95: train_loss 1.4072741270065308
Iteration 96: train_loss 1.4452123641967773
Iteration 97: train_loss 1.4050424098968506
Iteration 98: train_loss 1.4857696294784546
Iteration 99: train_loss 1.4602787494659424
Iteration 100: train_loss 1.4860457181930542
Iteration 101: train_loss 1.4433481693267822
Iteration 102: train_loss 1.4683729410171509
Iteration 103: train_loss 1.4593143463134766
Iteration 104: train_loss 1.4424247741699219
Iteration 105: train_loss 1.4854532480239868
Iteration 106: train_loss 1.4707483053207397
Iteration 107: train_loss 1.3687286376953125
Iteration 108: train_loss 1.439711332321167
Iteration 109: train_loss 1.4156490564346313
Iteration 110: train_loss 1.4869661331176758
Iteration 111: train_loss 1.4349260330200195
Iteration 112: train_loss 1.4375627040863037
Iteration 113: train_loss 1.448817491531372
Iteration 114: train_loss 1.4781805276870728
Iteration 115: train_loss 1.4211870431900024
Iteration 116: train_loss 1.5002896785736084
Iteration 117: train_loss 1.5271518230438232
Iteration 118: train_loss 1.4495798349380493
Iteration 119: train_loss 1.4869049787521362
Iteration 120: train_loss 1.4872132539749146
Iteration 121: train_loss 1.4754725694656372
Iteration 122: train_loss 1.482462763786316
Iteration 123: train_loss 1.4901082515716553
Iteration 124: train_loss 1.5355379581451416
Iteration 125: train_loss 1.4447234869003296
Iteration 126: train_loss 1.5172810554504395
Iteration 127: train_loss 1.515890121459961
Iteration 128: train_loss 1.535258412361145
Iteration 129: train_loss 1.5427545309066772
Iteration 130: train_loss 1.5573877096176147
Iteration 131: train_loss 1.5605665445327759
Iteration 132: train_loss 1.4931318759918213
Iteration 133: train_loss 1.5282537937164307
Iteration 134: train_loss 1.4812053442001343
Iteration 135: train_loss 1.5034942626953125
Iteration 136: train_loss 1.4671735763549805
Iteration 137: train_loss 1.493694543838501
Iteration 138: train_loss 1.5286370515823364
Iteration 139: train_loss 1.5531814098358154
Iteration 140: train_loss 1.4760799407958984
Iteration 141: train_loss 1.523807406425476
Iteration 142: train_loss 1.4650086164474487
Iteration 143: train_loss 1.4878028631210327
Iteration 144: train_loss 1.5146681070327759
Iteration 145: train_loss 1.478217363357544
Iteration 146: train_loss 1.4971058368682861
Iteration 147: train_loss 1.4429643154144287
Iteration 148: train_loss 1.5141559839248657
Iteration 149: train_loss 1.396654486656189
Iteration 150: train_loss 1.469115138053894
Iteration 151: train_loss 1.452156662940979
Iteration 152: train_loss 1.4675641059875488
Iteration 153: train_loss 1.52927827835083
Iteration 154: train_loss 1.4654790163040161
Iteration 155: train_loss 1.4814070463180542
Iteration 156: train_loss 1.5237419605255127
Iteration 157: train_loss 1.3894648551940918
Iteration 158: train_loss 1.4791449308395386
Iteration 159: train_loss 1.3994466066360474
Iteration 160: train_loss 1.469441294670105
Iteration 161: train_loss 1.4959325790405273
Iteration 162: train_loss 1.5172374248504639
Iteration 163: train_loss 1.4801727533340454
Iteration 164: train_loss 1.437548041343689
Iteration 165: train_loss 1.4718892574310303
Iteration 166: train_loss 1.4037535190582275
Iteration 167: train_loss 1.445366382598877
Iteration 168: train_loss 1.4770220518112183
Iteration 169: train_loss 1.4729083776474
Iteration 170: train_loss 1.4386498928070068
Iteration 171: train_loss 1.4570047855377197
Iteration 172: train_loss 1.44155752658844
Iteration 173: train_loss 1.4856702089309692
Iteration 174: train_loss 1.4499261379241943
Iteration 175: train_loss 1.4404586553573608
Iteration 176: train_loss 1.4898771047592163
Iteration 177: train_loss 1.5353105068206787
Epoch 82: train_avg_loss 1.4590996584649814 eval_avg_acc: 0.3377929918669903 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:44:04] [32mIntermediate result: 0.3377929918669903  (Index 81)[0m
================Epoch: 83================
Iteration 1: train_loss 1.444474458694458
Iteration 2: train_loss 1.4073171615600586
Iteration 3: train_loss 1.4628326892852783
Iteration 4: train_loss 1.4699920415878296
Iteration 5: train_loss 1.3810641765594482
Iteration 6: train_loss 1.4578324556350708
Iteration 7: train_loss 1.4598627090454102
Iteration 8: train_loss 1.5267285108566284
Iteration 9: train_loss 1.4276624917984009
Iteration 10: train_loss 1.4974852800369263
Iteration 11: train_loss 1.4590420722961426
Iteration 12: train_loss 1.4975980520248413
Iteration 13: train_loss 1.4595698118209839
Iteration 14: train_loss 1.516886591911316
Iteration 15: train_loss 1.4456424713134766
Iteration 16: train_loss 1.4807584285736084
Iteration 17: train_loss 1.3624904155731201
Iteration 18: train_loss 1.4658699035644531
Iteration 19: train_loss 1.4591104984283447
Iteration 20: train_loss 1.3924849033355713
Iteration 21: train_loss 1.4324723482131958
Iteration 22: train_loss 1.4817614555358887
Iteration 23: train_loss 1.4050759077072144
Iteration 24: train_loss 1.4209160804748535
Iteration 25: train_loss 1.4382998943328857
Iteration 26: train_loss 1.3920989036560059
Iteration 27: train_loss 1.404451847076416
Iteration 28: train_loss 1.4033933877944946
Iteration 29: train_loss 1.5021849870681763
Iteration 30: train_loss 1.4486647844314575
Iteration 31: train_loss 1.4277729988098145
Iteration 32: train_loss 1.4686369895935059
Iteration 33: train_loss 1.4106072187423706
Iteration 34: train_loss 1.4669386148452759
Iteration 35: train_loss 1.4540992975234985
Iteration 36: train_loss 1.4841114282608032
Iteration 37: train_loss 1.4144030809402466
Iteration 38: train_loss 1.3954359292984009
Iteration 39: train_loss 1.4562783241271973
Iteration 40: train_loss 1.4958692789077759
Iteration 41: train_loss 1.4872450828552246
Iteration 42: train_loss 1.4597307443618774
Iteration 43: train_loss 1.4164434671401978
Iteration 44: train_loss 1.4812147617340088
Iteration 45: train_loss 1.422208547592163
Iteration 46: train_loss 1.4696764945983887
Iteration 47: train_loss 1.4848437309265137
Iteration 48: train_loss 1.421654462814331
Iteration 49: train_loss 1.3883103132247925
Iteration 50: train_loss 1.4697643518447876
Iteration 51: train_loss 1.4844000339508057
Iteration 52: train_loss 1.5240148305892944
Iteration 53: train_loss 1.494361400604248
Iteration 54: train_loss 1.5203492641448975
Iteration 55: train_loss 1.4968777894973755
Iteration 56: train_loss 1.4858710765838623
Iteration 57: train_loss 1.44207763671875
Iteration 58: train_loss 1.4367419481277466
Iteration 59: train_loss 1.4186084270477295
Iteration 60: train_loss 1.4867274761199951
Iteration 61: train_loss 1.4141888618469238
Iteration 62: train_loss 1.5018764734268188
Iteration 63: train_loss 1.4484001398086548
Iteration 64: train_loss 1.460039496421814
Iteration 65: train_loss 1.4451245069503784
Iteration 66: train_loss 1.494056224822998
Iteration 67: train_loss 1.407955527305603
Iteration 68: train_loss 1.4724031686782837
Iteration 69: train_loss 1.4743585586547852
Iteration 70: train_loss 1.477522611618042
Iteration 71: train_loss 1.4283740520477295
Iteration 72: train_loss 1.37306547164917
Iteration 73: train_loss 1.3354477882385254
Iteration 74: train_loss 1.4815430641174316
Iteration 75: train_loss 1.4048709869384766
Iteration 76: train_loss 1.4832730293273926
Iteration 77: train_loss 1.3751002550125122
Iteration 78: train_loss 1.4483250379562378
Iteration 79: train_loss 1.3452688455581665
Iteration 80: train_loss 1.457293152809143
Iteration 81: train_loss 1.4560015201568604
Iteration 82: train_loss 1.3413089513778687
Iteration 83: train_loss 1.3820831775665283
Iteration 84: train_loss 1.4458191394805908
Iteration 85: train_loss 1.426551103591919
Iteration 86: train_loss 1.4266618490219116
Iteration 87: train_loss 1.4596378803253174
Iteration 88: train_loss 1.438538670539856
Iteration 89: train_loss 1.4656918048858643
Iteration 90: train_loss 1.4246125221252441
Iteration 91: train_loss 1.4490453004837036
Iteration 92: train_loss 1.4056220054626465
Iteration 93: train_loss 1.4180747270584106
Iteration 94: train_loss 1.456794261932373
Iteration 95: train_loss 1.4977935552597046
Iteration 96: train_loss 1.4056731462478638
Iteration 97: train_loss 1.4482029676437378
Iteration 98: train_loss 1.4241441488265991
Iteration 99: train_loss 1.4311609268188477
Iteration 100: train_loss 1.4419008493423462
Iteration 101: train_loss 1.4278960227966309
Iteration 102: train_loss 1.5061004161834717
Iteration 103: train_loss 1.4842519760131836
Iteration 104: train_loss 1.421729326248169
Iteration 105: train_loss 1.4617252349853516
Iteration 106: train_loss 1.4777952432632446
Iteration 107: train_loss 1.4482486248016357
Iteration 108: train_loss 1.4420599937438965
Iteration 109: train_loss 1.4325865507125854
Iteration 110: train_loss 1.4713064432144165
Iteration 111: train_loss 1.5285004377365112
Iteration 112: train_loss 1.4773435592651367
Iteration 113: train_loss 1.486920714378357
Iteration 114: train_loss 1.448035717010498
Iteration 115: train_loss 1.4194649457931519
Iteration 116: train_loss 1.4606046676635742
Iteration 117: train_loss 1.4843776226043701
Iteration 118: train_loss 1.486021876335144
Iteration 119: train_loss 1.4680935144424438
Iteration 120: train_loss 1.4775114059448242
Iteration 121: train_loss 1.4625053405761719
Iteration 122: train_loss 1.4578630924224854
Iteration 123: train_loss 1.505635142326355
Iteration 124: train_loss 1.4382743835449219
Iteration 125: train_loss 1.4550132751464844
Iteration 126: train_loss 1.4508646726608276
Iteration 127: train_loss 1.4564415216445923
Iteration 128: train_loss 1.4195092916488647
Iteration 129: train_loss 1.4435430765151978
Iteration 130: train_loss 1.4699327945709229
Iteration 131: train_loss 1.5177339315414429
Iteration 132: train_loss 1.3920165300369263
Iteration 133: train_loss 1.3839143514633179
Iteration 134: train_loss 1.4439215660095215
Iteration 135: train_loss 1.4777411222457886
Iteration 136: train_loss 1.4948005676269531
Iteration 137: train_loss 1.4814471006393433
Iteration 138: train_loss 1.4027788639068604
Iteration 139: train_loss 1.4954721927642822
Iteration 140: train_loss 1.5044490098953247
Iteration 141: train_loss 1.40870201587677
Iteration 142: train_loss 1.5151963233947754
Iteration 143: train_loss 1.4663939476013184
Iteration 144: train_loss 1.4958337545394897
Iteration 145: train_loss 1.4462108612060547
Iteration 146: train_loss 1.5476229190826416
Iteration 147: train_loss 1.4191274642944336
Iteration 148: train_loss 1.4592167139053345
Iteration 149: train_loss 1.4737457036972046
Iteration 150: train_loss 1.453061580657959
Iteration 151: train_loss 1.4163810014724731
Iteration 152: train_loss 1.496452808380127
Iteration 153: train_loss 1.4843432903289795
Iteration 154: train_loss 1.460127592086792
Iteration 155: train_loss 1.4588788747787476
Iteration 156: train_loss 1.5104106664657593
Iteration 157: train_loss 1.510971188545227
Iteration 158: train_loss 1.4229611158370972
Iteration 159: train_loss 1.467538595199585
Iteration 160: train_loss 1.4546265602111816
Iteration 161: train_loss 1.430971622467041
Iteration 162: train_loss 1.4493420124053955
Iteration 163: train_loss 1.4394035339355469
Iteration 164: train_loss 1.5198436975479126
Iteration 165: train_loss 1.351631760597229
Iteration 166: train_loss 1.4753687381744385
Iteration 167: train_loss 1.4359533786773682
Iteration 168: train_loss 1.4249556064605713
Iteration 169: train_loss 1.4952678680419922
Iteration 170: train_loss 1.5154412984848022
Iteration 171: train_loss 1.418460488319397
Iteration 172: train_loss 1.437041163444519
Iteration 173: train_loss 1.4346009492874146
Iteration 174: train_loss 1.4544472694396973
Iteration 175: train_loss 1.4947385787963867
Iteration 176: train_loss 1.460461974143982
Iteration 177: train_loss 1.513418436050415
Epoch 83: train_avg_loss 1.4526931579503637 eval_avg_acc: 0.3405462172954152 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:44:44] [32mIntermediate result: 0.3405462172954152  (Index 82)[0m
================Epoch: 84================
Iteration 1: train_loss 1.4122390747070312
Iteration 2: train_loss 1.3703871965408325
Iteration 3: train_loss 1.405503273010254
Iteration 4: train_loss 1.4868487119674683
Iteration 5: train_loss 1.4083141088485718
Iteration 6: train_loss 1.446025013923645
Iteration 7: train_loss 1.4395182132720947
Iteration 8: train_loss 1.4717411994934082
Iteration 9: train_loss 1.4027190208435059
Iteration 10: train_loss 1.446321964263916
Iteration 11: train_loss 1.4118348360061646
Iteration 12: train_loss 1.379793405532837
Iteration 13: train_loss 1.4426860809326172
Iteration 14: train_loss 1.4177236557006836
Iteration 15: train_loss 1.3928899765014648
Iteration 16: train_loss 1.4542899131774902
Iteration 17: train_loss 1.4708969593048096
Iteration 18: train_loss 1.461262822151184
Iteration 19: train_loss 1.4856226444244385
Iteration 20: train_loss 1.454446792602539
Iteration 21: train_loss 1.5154094696044922
Iteration 22: train_loss 1.4897013902664185
Iteration 23: train_loss 1.456721305847168
Iteration 24: train_loss 1.4662176370620728
Iteration 25: train_loss 1.493669033050537
Iteration 26: train_loss 1.4526737928390503
Iteration 27: train_loss 1.5636241436004639
Iteration 28: train_loss 1.4773404598236084
Iteration 29: train_loss 1.4013539552688599
Iteration 30: train_loss 1.4728007316589355
Iteration 31: train_loss 1.3989313840866089
Iteration 32: train_loss 1.3908458948135376
Iteration 33: train_loss 1.4608676433563232
Iteration 34: train_loss 1.5271790027618408
Iteration 35: train_loss 1.4243381023406982
Iteration 36: train_loss 1.491357684135437
Iteration 37: train_loss 1.394667387008667
Iteration 38: train_loss 1.4172921180725098
Iteration 39: train_loss 1.3930816650390625
Iteration 40: train_loss 1.4569542407989502
Iteration 41: train_loss 1.423770785331726
Iteration 42: train_loss 1.408682942390442
Iteration 43: train_loss 1.4287493228912354
Iteration 44: train_loss 1.463923454284668
Iteration 45: train_loss 1.447760820388794
Iteration 46: train_loss 1.4630343914031982
Iteration 47: train_loss 1.477977991104126
Iteration 48: train_loss 1.4883779287338257
Iteration 49: train_loss 1.5143911838531494
Iteration 50: train_loss 1.4991434812545776
Iteration 51: train_loss 1.4548828601837158
Iteration 52: train_loss 1.4428893327713013
Iteration 53: train_loss 1.5294588804244995
Iteration 54: train_loss 1.4819061756134033
Iteration 55: train_loss 1.4550883769989014
Iteration 56: train_loss 1.4415591955184937
Iteration 57: train_loss 1.3950704336166382
Iteration 58: train_loss 1.4504941701889038
Iteration 59: train_loss 1.560496211051941
Iteration 60: train_loss 1.4775733947753906
Iteration 61: train_loss 1.387683391571045
Iteration 62: train_loss 1.4301930665969849
Iteration 63: train_loss 1.4365968704223633
Iteration 64: train_loss 1.4450201988220215
Iteration 65: train_loss 1.4128996133804321
Iteration 66: train_loss 1.4520666599273682
Iteration 67: train_loss 1.3843086957931519
Iteration 68: train_loss 1.4511911869049072
Iteration 69: train_loss 1.4321260452270508
Iteration 70: train_loss 1.42497718334198
Iteration 71: train_loss 1.4465298652648926
Iteration 72: train_loss 1.4691863059997559
Iteration 73: train_loss 1.4620825052261353
Iteration 74: train_loss 1.490168571472168
Iteration 75: train_loss 1.4291423559188843
Iteration 76: train_loss 1.4673765897750854
Iteration 77: train_loss 1.543756127357483
Iteration 78: train_loss 1.4410779476165771
Iteration 79: train_loss 1.5241025686264038
Iteration 80: train_loss 1.5413936376571655
Iteration 81: train_loss 1.4280463457107544
Iteration 82: train_loss 1.4824756383895874
Iteration 83: train_loss 1.510013461112976
Iteration 84: train_loss 1.555435061454773
Iteration 85: train_loss 1.4775807857513428
Iteration 86: train_loss 1.4653172492980957
Iteration 87: train_loss 1.4627753496170044
Iteration 88: train_loss 1.4620827436447144
Iteration 89: train_loss 1.4869028329849243
Iteration 90: train_loss 1.4901319742202759
Iteration 91: train_loss 1.393742561340332
Iteration 92: train_loss 1.3715683221817017
Iteration 93: train_loss 1.452099323272705
Iteration 94: train_loss 1.4607371091842651
Iteration 95: train_loss 1.4139474630355835
Iteration 96: train_loss 1.4554996490478516
Iteration 97: train_loss 1.3686861991882324
Iteration 98: train_loss 1.488059639930725
Iteration 99: train_loss 1.474581241607666
Iteration 100: train_loss 1.411935567855835
Iteration 101: train_loss 1.3720792531967163
Iteration 102: train_loss 1.477035641670227
Iteration 103: train_loss 1.4369456768035889
Iteration 104: train_loss 1.4548965692520142
Iteration 105: train_loss 1.4085760116577148
Iteration 106: train_loss 1.3889657258987427
Iteration 107: train_loss 1.4563103914260864
Iteration 108: train_loss 1.4626883268356323
Iteration 109: train_loss 1.4131883382797241
Iteration 110: train_loss 1.4039525985717773
Iteration 111: train_loss 1.408588171005249
Iteration 112: train_loss 1.3854976892471313
Iteration 113: train_loss 1.445309042930603
Iteration 114: train_loss 1.422594428062439
Iteration 115: train_loss 1.4919794797897339
Iteration 116: train_loss 1.3951162099838257
Iteration 117: train_loss 1.414023756980896
Iteration 118: train_loss 1.433361291885376
Iteration 119: train_loss 1.3833706378936768
Iteration 120: train_loss 1.4571866989135742
Iteration 121: train_loss 1.4430882930755615
Iteration 122: train_loss 1.4669380187988281
Iteration 123: train_loss 1.4797059297561646
Iteration 124: train_loss 1.4420084953308105
Iteration 125: train_loss 1.448306918144226
Iteration 126: train_loss 1.4261091947555542
Iteration 127: train_loss 1.5311495065689087
Iteration 128: train_loss 1.512731671333313
Iteration 129: train_loss 1.4778788089752197
Iteration 130: train_loss 1.4417273998260498
Iteration 131: train_loss 1.4211570024490356
Iteration 132: train_loss 1.455027461051941
Iteration 133: train_loss 1.4949922561645508
Iteration 134: train_loss 1.448546051979065
Iteration 135: train_loss 1.4157124757766724
Iteration 136: train_loss 1.5047223567962646
Iteration 137: train_loss 1.4854917526245117
Iteration 138: train_loss 1.4517854452133179
Iteration 139: train_loss 1.490426778793335
Iteration 140: train_loss 1.465863823890686
Iteration 141: train_loss 1.482679009437561
Iteration 142: train_loss 1.4332906007766724
Iteration 143: train_loss 1.4670474529266357
Iteration 144: train_loss 1.5139702558517456
Iteration 145: train_loss 1.4674798250198364
Iteration 146: train_loss 1.4571011066436768
Iteration 147: train_loss 1.4716702699661255
Iteration 148: train_loss 1.4558820724487305
Iteration 149: train_loss 1.419548511505127
Iteration 150: train_loss 1.5033026933670044
Iteration 151: train_loss 1.418160319328308
Iteration 152: train_loss 1.4946361780166626
Iteration 153: train_loss 1.441514253616333
Iteration 154: train_loss 1.4356263875961304
Iteration 155: train_loss 1.4871386289596558
Iteration 156: train_loss 1.4421025514602661
Iteration 157: train_loss 1.5351717472076416
Iteration 158: train_loss 1.4386292695999146
Iteration 159: train_loss 1.4777216911315918
Iteration 160: train_loss 1.4273872375488281
Iteration 161: train_loss 1.4494218826293945
Iteration 162: train_loss 1.5092723369598389
Iteration 163: train_loss 1.4439436197280884
Iteration 164: train_loss 1.4864016771316528
Iteration 165: train_loss 1.5217362642288208
Iteration 166: train_loss 1.4385520219802856
Iteration 167: train_loss 1.483121395111084
Iteration 168: train_loss 1.4445796012878418
Iteration 169: train_loss 1.369994878768921
Iteration 170: train_loss 1.4154423475265503
Iteration 171: train_loss 1.4901728630065918
Iteration 172: train_loss 1.4573653936386108
Iteration 173: train_loss 1.534368872642517
Iteration 174: train_loss 1.4892851114273071
Iteration 175: train_loss 1.4842311143875122
Iteration 176: train_loss 1.4768683910369873
Iteration 177: train_loss 1.5085707902908325
Epoch 84: train_avg_loss 1.4541426290900021 eval_avg_acc: 0.3228159293357875 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:45:25] [32mIntermediate result: 0.3228159293357875  (Index 83)[0m
================Epoch: 85================
Iteration 1: train_loss 1.4692291021347046
Iteration 2: train_loss 1.4890614748001099
Iteration 3: train_loss 1.4011961221694946
Iteration 4: train_loss 1.4692919254302979
Iteration 5: train_loss 1.3957167863845825
Iteration 6: train_loss 1.4514976739883423
Iteration 7: train_loss 1.4779077768325806
Iteration 8: train_loss 1.4313993453979492
Iteration 9: train_loss 1.4311869144439697
Iteration 10: train_loss 1.4516972303390503
Iteration 11: train_loss 1.4480336904525757
Iteration 12: train_loss 1.4548940658569336
Iteration 13: train_loss 1.488757848739624
Iteration 14: train_loss 1.4065866470336914
Iteration 15: train_loss 1.4766111373901367
Iteration 16: train_loss 1.4495494365692139
Iteration 17: train_loss 1.4804933071136475
Iteration 18: train_loss 1.4478365182876587
Iteration 19: train_loss 1.345648169517517
Iteration 20: train_loss 1.4143598079681396
Iteration 21: train_loss 1.415186882019043
Iteration 22: train_loss 1.4027273654937744
Iteration 23: train_loss 1.504828929901123
Iteration 24: train_loss 1.4110186100006104
Iteration 25: train_loss 1.3634741306304932
Iteration 26: train_loss 1.4442750215530396
Iteration 27: train_loss 1.3924304246902466
Iteration 28: train_loss 1.412499189376831
Iteration 29: train_loss 1.4332152605056763
Iteration 30: train_loss 1.391010046005249
Iteration 31: train_loss 1.3377022743225098
Iteration 32: train_loss 1.439361333847046
Iteration 33: train_loss 1.4138970375061035
Iteration 34: train_loss 1.399162769317627
Iteration 35: train_loss 1.3222092390060425
Iteration 36: train_loss 1.4619098901748657
Iteration 37: train_loss 1.4097973108291626
Iteration 38: train_loss 1.4730935096740723
Iteration 39: train_loss 1.4214452505111694
Iteration 40: train_loss 1.3716598749160767
Iteration 41: train_loss 1.4763551950454712
Iteration 42: train_loss 1.4365837574005127
Iteration 43: train_loss 1.3730868101119995
Iteration 44: train_loss 1.394482135772705
Iteration 45: train_loss 1.4462158679962158
Iteration 46: train_loss 1.3775219917297363
Iteration 47: train_loss 1.4134351015090942
Iteration 48: train_loss 1.4284106492996216
Iteration 49: train_loss 1.4077479839324951
Iteration 50: train_loss 1.4042117595672607
Iteration 51: train_loss 1.4783647060394287
Iteration 52: train_loss 1.4395445585250854
Iteration 53: train_loss 1.424087643623352
Iteration 54: train_loss 1.3821395635604858
Iteration 55: train_loss 1.4704854488372803
Iteration 56: train_loss 1.3716508150100708
Iteration 57: train_loss 1.452376365661621
Iteration 58: train_loss 1.3836990594863892
Iteration 59: train_loss 1.4269870519638062
Iteration 60: train_loss 1.4509254693984985
Iteration 61: train_loss 1.4424405097961426
Iteration 62: train_loss 1.4681971073150635
Iteration 63: train_loss 1.41916024684906
Iteration 64: train_loss 1.415482997894287
Iteration 65: train_loss 1.454933762550354
Iteration 66: train_loss 1.4383677244186401
Iteration 67: train_loss 1.42240309715271
Iteration 68: train_loss 1.4627432823181152
Iteration 69: train_loss 1.5169345140457153
Iteration 70: train_loss 1.425081491470337
Iteration 71: train_loss 1.3875232934951782
Iteration 72: train_loss 1.4768991470336914
Iteration 73: train_loss 1.4378236532211304
Iteration 74: train_loss 1.4105794429779053
Iteration 75: train_loss 1.404611587524414
Iteration 76: train_loss 1.411810040473938
Iteration 77: train_loss 1.3856290578842163
Iteration 78: train_loss 1.4318561553955078
Iteration 79: train_loss 1.5354543924331665
Iteration 80: train_loss 1.478001356124878
Iteration 81: train_loss 1.4716507196426392
Iteration 82: train_loss 1.4197925329208374
Iteration 83: train_loss 1.5276646614074707
Iteration 84: train_loss 1.424587368965149
Iteration 85: train_loss 1.450556993484497
Iteration 86: train_loss 1.4034563302993774
Iteration 87: train_loss 1.4101378917694092
Iteration 88: train_loss 1.4637993574142456
Iteration 89: train_loss 1.4472806453704834
Iteration 90: train_loss 1.450445532798767
Iteration 91: train_loss 1.5136629343032837
Iteration 92: train_loss 1.4787356853485107
Iteration 93: train_loss 1.4719154834747314
Iteration 94: train_loss 1.4700584411621094
Iteration 95: train_loss 1.4345165491104126
Iteration 96: train_loss 1.4347370862960815
Iteration 97: train_loss 1.4144394397735596
Iteration 98: train_loss 1.4711593389511108
Iteration 99: train_loss 1.404516339302063
Iteration 100: train_loss 1.4502911567687988
Iteration 101: train_loss 1.4892466068267822
Iteration 102: train_loss 1.4982150793075562
Iteration 103: train_loss 1.431287407875061
Iteration 104: train_loss 1.4243165254592896
Iteration 105: train_loss 1.435367465019226
Iteration 106: train_loss 1.408705234527588
Iteration 107: train_loss 1.4763206243515015
Iteration 108: train_loss 1.4620505571365356
Iteration 109: train_loss 1.3707994222640991
Iteration 110: train_loss 1.463273048400879
Iteration 111: train_loss 1.4893736839294434
Iteration 112: train_loss 1.4489344358444214
Iteration 113: train_loss 1.4462167024612427
Iteration 114: train_loss 1.4192702770233154
Iteration 115: train_loss 1.4733200073242188
Iteration 116: train_loss 1.464563012123108
Iteration 117: train_loss 1.4664318561553955
Iteration 118: train_loss 1.4868824481964111
Iteration 119: train_loss 1.4486079216003418
Iteration 120: train_loss 1.4642044305801392
Iteration 121: train_loss 1.4408602714538574
Iteration 122: train_loss 1.3814963102340698
Iteration 123: train_loss 1.4587796926498413
Iteration 124: train_loss 1.524175763130188
Iteration 125: train_loss 1.4709042310714722
Iteration 126: train_loss 1.4677529335021973
Iteration 127: train_loss 1.5185128450393677
Iteration 128: train_loss 1.4498369693756104
Iteration 129: train_loss 1.4866620302200317
Iteration 130: train_loss 1.4637234210968018
Iteration 131: train_loss 1.4626991748809814
Iteration 132: train_loss 1.4463096857070923
Iteration 133: train_loss 1.3647983074188232
Iteration 134: train_loss 1.4067636728286743
Iteration 135: train_loss 1.4096550941467285
Iteration 136: train_loss 1.4295711517333984
Iteration 137: train_loss 1.434950828552246
Iteration 138: train_loss 1.4605008363723755
Iteration 139: train_loss 1.4508721828460693
Iteration 140: train_loss 1.4594935178756714
Iteration 141: train_loss 1.4689948558807373
Iteration 142: train_loss 1.3972134590148926
Iteration 143: train_loss 1.4870774745941162
Iteration 144: train_loss 1.4530221223831177
Iteration 145: train_loss 1.5047627687454224
Iteration 146: train_loss 1.514751672744751
Iteration 147: train_loss 1.5073715448379517
Iteration 148: train_loss 1.4272868633270264
Iteration 149: train_loss 1.467954397201538
Iteration 150: train_loss 1.4703634977340698
Iteration 151: train_loss 1.3911234140396118
Iteration 152: train_loss 1.3808856010437012
Iteration 153: train_loss 1.3767884969711304
Iteration 154: train_loss 1.4280812740325928
Iteration 155: train_loss 1.4481078386306763
Iteration 156: train_loss 1.4365684986114502
Iteration 157: train_loss 1.531840205192566
Iteration 158: train_loss 1.4001885652542114
Iteration 159: train_loss 1.4242385625839233
Iteration 160: train_loss 1.4480879306793213
Iteration 161: train_loss 1.482688069343567
Iteration 162: train_loss 1.4848823547363281
Iteration 163: train_loss 1.4843066930770874
Iteration 164: train_loss 1.394097924232483
Iteration 165: train_loss 1.4105037450790405
Iteration 166: train_loss 1.473437786102295
Iteration 167: train_loss 1.4935884475708008
Iteration 168: train_loss 1.416448950767517
Iteration 169: train_loss 1.4755079746246338
Iteration 170: train_loss 1.5111148357391357
Iteration 171: train_loss 1.4736322164535522
Iteration 172: train_loss 1.4609675407409668
Iteration 173: train_loss 1.4564539194107056
Iteration 174: train_loss 1.4378291368484497
Iteration 175: train_loss 1.439204216003418
Iteration 176: train_loss 1.4669679403305054
Iteration 177: train_loss 1.4571373462677002
Epoch 85: train_avg_loss 1.441913516507984 eval_avg_acc: 0.34446210722242543 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:46:07] [32mIntermediate result: 0.34446210722242543  (Index 84)[0m
================Epoch: 86================
Iteration 1: train_loss 1.373629093170166
Iteration 2: train_loss 1.4080079793930054
Iteration 3: train_loss 1.4334511756896973
Iteration 4: train_loss 1.3560186624526978
Iteration 5: train_loss 1.423882246017456
Iteration 6: train_loss 1.3588186502456665
Iteration 7: train_loss 1.4489814043045044
Iteration 8: train_loss 1.4049779176712036
Iteration 9: train_loss 1.4114999771118164
Iteration 10: train_loss 1.4172582626342773
Iteration 11: train_loss 1.4736483097076416
Iteration 12: train_loss 1.4585291147232056
Iteration 13: train_loss 1.458936095237732
Iteration 14: train_loss 1.4103467464447021
Iteration 15: train_loss 1.4693063497543335
Iteration 16: train_loss 1.4352585077285767
Iteration 17: train_loss 1.405816674232483
Iteration 18: train_loss 1.4561724662780762
Iteration 19: train_loss 1.4126492738723755
Iteration 20: train_loss 1.444719910621643
Iteration 21: train_loss 1.494890809059143
Iteration 22: train_loss 1.3919583559036255
Iteration 23: train_loss 1.4324603080749512
Iteration 24: train_loss 1.3958594799041748
Iteration 25: train_loss 1.4049946069717407
Iteration 26: train_loss 1.4518927335739136
Iteration 27: train_loss 1.449279546737671
Iteration 28: train_loss 1.4234652519226074
Iteration 29: train_loss 1.4270201921463013
Iteration 30: train_loss 1.3776456117630005
Iteration 31: train_loss 1.4043593406677246
Iteration 32: train_loss 1.4301140308380127
Iteration 33: train_loss 1.4004034996032715
Iteration 34: train_loss 1.3285589218139648
Iteration 35: train_loss 1.4292699098587036
Iteration 36: train_loss 1.4580941200256348
Iteration 37: train_loss 1.3571380376815796
Iteration 38: train_loss 1.401534080505371
Iteration 39: train_loss 1.4284348487854004
Iteration 40: train_loss 1.3721482753753662
Iteration 41: train_loss 1.3412216901779175
Iteration 42: train_loss 1.4036654233932495
Iteration 43: train_loss 1.4710506200790405
Iteration 44: train_loss 1.4034974575042725
Iteration 45: train_loss 1.4249821901321411
Iteration 46: train_loss 1.4109498262405396
Iteration 47: train_loss 1.3737298250198364
Iteration 48: train_loss 1.4207085371017456
Iteration 49: train_loss 1.4362177848815918
Iteration 50: train_loss 1.3534276485443115
Iteration 51: train_loss 1.4487102031707764
Iteration 52: train_loss 1.4622259140014648
Iteration 53: train_loss 1.4308325052261353
Iteration 54: train_loss 1.4667389392852783
Iteration 55: train_loss 1.4174339771270752
Iteration 56: train_loss 1.3769184350967407
Iteration 57: train_loss 1.4354242086410522
Iteration 58: train_loss 1.444818139076233
Iteration 59: train_loss 1.4443891048431396
Iteration 60: train_loss 1.4233397245407104
Iteration 61: train_loss 1.4645754098892212
Iteration 62: train_loss 1.4382784366607666
Iteration 63: train_loss 1.4394631385803223
Iteration 64: train_loss 1.4973242282867432
Iteration 65: train_loss 1.4381457567214966
Iteration 66: train_loss 1.4362188577651978
Iteration 67: train_loss 1.4563007354736328
Iteration 68: train_loss 1.4382346868515015
Iteration 69: train_loss 1.4029426574707031
Iteration 70: train_loss 1.418847918510437
Iteration 71: train_loss 1.407383918762207
Iteration 72: train_loss 1.4549133777618408
Iteration 73: train_loss 1.4403769969940186
Iteration 74: train_loss 1.4342272281646729
Iteration 75: train_loss 1.3960762023925781
Iteration 76: train_loss 1.3949223756790161
Iteration 77: train_loss 1.4059348106384277
Iteration 78: train_loss 1.3844268321990967
Iteration 79: train_loss 1.4548709392547607
Iteration 80: train_loss 1.4285446405410767
Iteration 81: train_loss 1.4391236305236816
Iteration 82: train_loss 1.4703177213668823
Iteration 83: train_loss 1.466831088066101
Iteration 84: train_loss 1.3778374195098877
Iteration 85: train_loss 1.4711271524429321
Iteration 86: train_loss 1.4249540567398071
Iteration 87: train_loss 1.429496169090271
Iteration 88: train_loss 1.4536528587341309
Iteration 89: train_loss 1.4945356845855713
Iteration 90: train_loss 1.4952150583267212
Iteration 91: train_loss 1.5982661247253418
Iteration 92: train_loss 1.4256715774536133
Iteration 93: train_loss 1.473039150238037
Iteration 94: train_loss 1.4935187101364136
Iteration 95: train_loss 1.461197853088379
Iteration 96: train_loss 1.476493239402771
Iteration 97: train_loss 1.4721812009811401
Iteration 98: train_loss 1.4369326829910278
Iteration 99: train_loss 1.4133037328720093
Iteration 100: train_loss 1.3908718824386597
Iteration 101: train_loss 1.392657995223999
Iteration 102: train_loss 1.4632174968719482
Iteration 103: train_loss 1.4312278032302856
Iteration 104: train_loss 1.4168672561645508
Iteration 105: train_loss 1.4997273683547974
Iteration 106: train_loss 1.3931028842926025
Iteration 107: train_loss 1.4015940427780151
Iteration 108: train_loss 1.4710991382598877
Iteration 109: train_loss 1.4667598009109497
Iteration 110: train_loss 1.4358981847763062
Iteration 111: train_loss 1.4354020357131958
Iteration 112: train_loss 1.4747314453125
Iteration 113: train_loss 1.4481720924377441
Iteration 114: train_loss 1.4645711183547974
Iteration 115: train_loss 1.4666874408721924
Iteration 116: train_loss 1.4520896673202515
Iteration 117: train_loss 1.4213542938232422
Iteration 118: train_loss 1.4521396160125732
Iteration 119: train_loss 1.5083129405975342
Iteration 120: train_loss 1.4672536849975586
Iteration 121: train_loss 1.4331388473510742
Iteration 122: train_loss 1.492653727531433
Iteration 123: train_loss 1.4213168621063232
Iteration 124: train_loss 1.443515419960022
Iteration 125: train_loss 1.4147411584854126
Iteration 126: train_loss 1.477761149406433
Iteration 127: train_loss 1.4487345218658447
Iteration 128: train_loss 1.513189673423767
Iteration 129: train_loss 1.457603096961975
Iteration 130: train_loss 1.4596577882766724
Iteration 131: train_loss 1.458186149597168
Iteration 132: train_loss 1.4485188722610474
Iteration 133: train_loss 1.451434850692749
Iteration 134: train_loss 1.4426151514053345
Iteration 135: train_loss 1.412351369857788
Iteration 136: train_loss 1.4790947437286377
Iteration 137: train_loss 1.430991768836975
Iteration 138: train_loss 1.4876946210861206
Iteration 139: train_loss 1.4771311283111572
Iteration 140: train_loss 1.3948544263839722
Iteration 141: train_loss 1.4600563049316406
Iteration 142: train_loss 1.4427831172943115
Iteration 143: train_loss 1.4281290769577026
Iteration 144: train_loss 1.5259826183319092
Iteration 145: train_loss 1.4140387773513794
Iteration 146: train_loss 1.4294917583465576
Iteration 147: train_loss 1.4812016487121582
Iteration 148: train_loss 1.5092521905899048
Iteration 149: train_loss 1.4909780025482178
Iteration 150: train_loss 1.4676331281661987
Iteration 151: train_loss 1.4125295877456665
Iteration 152: train_loss 1.3948181867599487
Iteration 153: train_loss 1.387853741645813
Iteration 154: train_loss 1.5023369789123535
Iteration 155: train_loss 1.481528401374817
Iteration 156: train_loss 1.4216512441635132
Iteration 157: train_loss 1.4555567502975464
Iteration 158: train_loss 1.4577155113220215
Iteration 159: train_loss 1.455098271369934
Iteration 160: train_loss 1.5050541162490845
Iteration 161: train_loss 1.3948848247528076
Iteration 162: train_loss 1.4294544458389282
Iteration 163: train_loss 1.4720096588134766
Iteration 164: train_loss 1.4606419801712036
Iteration 165: train_loss 1.4596173763275146
Iteration 166: train_loss 1.4515925645828247
Iteration 167: train_loss 1.4607352018356323
Iteration 168: train_loss 1.4637857675552368
Iteration 169: train_loss 1.4761099815368652
Iteration 170: train_loss 1.3553075790405273
Iteration 171: train_loss 1.438775658607483
Iteration 172: train_loss 1.4291163682937622
Iteration 173: train_loss 1.4027923345565796
Iteration 174: train_loss 1.4742045402526855
Iteration 175: train_loss 1.460250973701477
Iteration 176: train_loss 1.4507925510406494
Iteration 177: train_loss 1.5047096014022827
Epoch 86: train_avg_loss 1.4385582572322781 eval_avg_acc: 0.3462012746371914 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:46:47] [32mIntermediate result: 0.3462012746371914  (Index 85)[0m
================Epoch: 87================
Iteration 1: train_loss 1.3877151012420654
Iteration 2: train_loss 1.3790340423583984
Iteration 3: train_loss 1.4732228517532349
Iteration 4: train_loss 1.4011496305465698
Iteration 5: train_loss 1.436787486076355
Iteration 6: train_loss 1.3699930906295776
Iteration 7: train_loss 1.4117745161056519
Iteration 8: train_loss 1.3742672204971313
Iteration 9: train_loss 1.3826221227645874
Iteration 10: train_loss 1.4259033203125
Iteration 11: train_loss 1.372517704963684
Iteration 12: train_loss 1.3609675168991089
Iteration 13: train_loss 1.3050092458724976
Iteration 14: train_loss 1.4419499635696411
Iteration 15: train_loss 1.3923795223236084
Iteration 16: train_loss 1.4779993295669556
Iteration 17: train_loss 1.4661717414855957
Iteration 18: train_loss 1.4217863082885742
Iteration 19: train_loss 1.385123372077942
Iteration 20: train_loss 1.3662735223770142
Iteration 21: train_loss 1.4663968086242676
Iteration 22: train_loss 1.4464044570922852
Iteration 23: train_loss 1.4145621061325073
Iteration 24: train_loss 1.3955292701721191
Iteration 25: train_loss 1.467717170715332
Iteration 26: train_loss 1.4273149967193604
Iteration 27: train_loss 1.449737310409546
Iteration 28: train_loss 1.4526478052139282
Iteration 29: train_loss 1.4562232494354248
Iteration 30: train_loss 1.488545298576355
Iteration 31: train_loss 1.4309195280075073
Iteration 32: train_loss 1.4163451194763184
Iteration 33: train_loss 1.3716961145401
Iteration 34: train_loss 1.4835509061813354
Iteration 35: train_loss 1.375848650932312
Iteration 36: train_loss 1.4477999210357666
Iteration 37: train_loss 1.4522874355316162
Iteration 38: train_loss 1.370415449142456
Iteration 39: train_loss 1.423432469367981
Iteration 40: train_loss 1.4738876819610596
Iteration 41: train_loss 1.4676724672317505
Iteration 42: train_loss 1.4209634065628052
Iteration 43: train_loss 1.420696496963501
Iteration 44: train_loss 1.4299432039260864
Iteration 45: train_loss 1.423690915107727
Iteration 46: train_loss 1.4407706260681152
Iteration 47: train_loss 1.409730076789856
Iteration 48: train_loss 1.4456725120544434
Iteration 49: train_loss 1.4274123907089233
Iteration 50: train_loss 1.3994442224502563
Iteration 51: train_loss 1.3936408758163452
Iteration 52: train_loss 1.4442604780197144
Iteration 53: train_loss 1.5069626569747925
Iteration 54: train_loss 1.4081511497497559
Iteration 55: train_loss 1.4184073209762573
Iteration 56: train_loss 1.4032912254333496
Iteration 57: train_loss 1.4786062240600586
Iteration 58: train_loss 1.4002355337142944
Iteration 59: train_loss 1.501013159751892
Iteration 60: train_loss 1.4492617845535278
Iteration 61: train_loss 1.4528896808624268
Iteration 62: train_loss 1.4162508249282837
Iteration 63: train_loss 1.4007117748260498
Iteration 64: train_loss 1.365277886390686
Iteration 65: train_loss 1.4311178922653198
Iteration 66: train_loss 1.4422708749771118
Iteration 67: train_loss 1.5035077333450317
Iteration 68: train_loss 1.4843357801437378
Iteration 69: train_loss 1.4044890403747559
Iteration 70: train_loss 1.499592661857605
Iteration 71: train_loss 1.4160315990447998
Iteration 72: train_loss 1.416008472442627
Iteration 73: train_loss 1.4365520477294922
Iteration 74: train_loss 1.45118248462677
Iteration 75: train_loss 1.420737385749817
Iteration 76: train_loss 1.3874043226242065
Iteration 77: train_loss 1.4611817598342896
Iteration 78: train_loss 1.5283418893814087
Iteration 79: train_loss 1.4781845808029175
Iteration 80: train_loss 1.440373420715332
Iteration 81: train_loss 1.3810603618621826
Iteration 82: train_loss 1.4596620798110962
Iteration 83: train_loss 1.4713865518569946
Iteration 84: train_loss 1.444884181022644
Iteration 85: train_loss 1.4407262802124023
Iteration 86: train_loss 1.4576867818832397
Iteration 87: train_loss 1.4670555591583252
Iteration 88: train_loss 1.4298499822616577
Iteration 89: train_loss 1.4507055282592773
Iteration 90: train_loss 1.4388501644134521
Iteration 91: train_loss 1.4279582500457764
Iteration 92: train_loss 1.4752819538116455
Iteration 93: train_loss 1.5167782306671143
Iteration 94: train_loss 1.3775193691253662
Iteration 95: train_loss 1.4113011360168457
Iteration 96: train_loss 1.378381371498108
Iteration 97: train_loss 1.3897782564163208
Iteration 98: train_loss 1.461105465888977
Iteration 99: train_loss 1.4767545461654663
Iteration 100: train_loss 1.3693081140518188
Iteration 101: train_loss 1.4319467544555664
Iteration 102: train_loss 1.4015289545059204
Iteration 103: train_loss 1.4226014614105225
Iteration 104: train_loss 1.4342732429504395
Iteration 105: train_loss 1.4532641172409058
Iteration 106: train_loss 1.4552273750305176
Iteration 107: train_loss 1.427176594734192
Iteration 108: train_loss 1.4218966960906982
Iteration 109: train_loss 1.4272836446762085
Iteration 110: train_loss 1.4822906255722046
Iteration 111: train_loss 1.467563271522522
Iteration 112: train_loss 1.401474118232727
Iteration 113: train_loss 1.4625251293182373
Iteration 114: train_loss 1.4183213710784912
Iteration 115: train_loss 1.4443765878677368
Iteration 116: train_loss 1.4425534009933472
Iteration 117: train_loss 1.3589335680007935
Iteration 118: train_loss 1.43212890625
Iteration 119: train_loss 1.4687039852142334
Iteration 120: train_loss 1.3460907936096191
Iteration 121: train_loss 1.4401696920394897
Iteration 122: train_loss 1.4750542640686035
Iteration 123: train_loss 1.4497900009155273
Iteration 124: train_loss 1.4359420537948608
Iteration 125: train_loss 1.3705135583877563
Iteration 126: train_loss 1.4052234888076782
Iteration 127: train_loss 1.4339027404785156
Iteration 128: train_loss 1.4871169328689575
Iteration 129: train_loss 1.47907292842865
Iteration 130: train_loss 1.4784326553344727
Iteration 131: train_loss 1.4630776643753052
Iteration 132: train_loss 1.4282054901123047
Iteration 133: train_loss 1.4580714702606201
Iteration 134: train_loss 1.4268786907196045
Iteration 135: train_loss 1.4795573949813843
Iteration 136: train_loss 1.539792537689209
Iteration 137: train_loss 1.4598262310028076
Iteration 138: train_loss 1.4815409183502197
Iteration 139: train_loss 1.4003069400787354
Iteration 140: train_loss 1.3522754907608032
Iteration 141: train_loss 1.4866191148757935
Iteration 142: train_loss 1.4737818241119385
Iteration 143: train_loss 1.3948830366134644
Iteration 144: train_loss 1.413403868675232
Iteration 145: train_loss 1.5165479183197021
Iteration 146: train_loss 1.4779802560806274
Iteration 147: train_loss 1.441298246383667
Iteration 148: train_loss 1.451051950454712
Iteration 149: train_loss 1.4508506059646606
Iteration 150: train_loss 1.463657259941101
Iteration 151: train_loss 1.4624357223510742
Iteration 152: train_loss 1.4947102069854736
Iteration 153: train_loss 1.4721183776855469
Iteration 154: train_loss 1.516787052154541
Iteration 155: train_loss 1.4495021104812622
Iteration 156: train_loss 1.4858900308609009
Iteration 157: train_loss 1.4422467947006226
Iteration 158: train_loss 1.4657703638076782
Iteration 159: train_loss 1.4657853841781616
Iteration 160: train_loss 1.444736123085022
Iteration 161: train_loss 1.4694528579711914
Iteration 162: train_loss 1.4305408000946045
Iteration 163: train_loss 1.4809157848358154
Iteration 164: train_loss 1.428280234336853
Iteration 165: train_loss 1.4760617017745972
Iteration 166: train_loss 1.4882272481918335
Iteration 167: train_loss 1.4327541589736938
Iteration 168: train_loss 1.4189677238464355
Iteration 169: train_loss 1.508050560951233
Iteration 170: train_loss 1.4344619512557983
Iteration 171: train_loss 1.4389482736587524
Iteration 172: train_loss 1.435543179512024
Iteration 173: train_loss 1.454688549041748
Iteration 174: train_loss 1.440019130706787
Iteration 175: train_loss 1.4365421533584595
Iteration 176: train_loss 1.4635363817214966
Iteration 177: train_loss 1.4349535703659058
Epoch 87: train_avg_loss 1.4377577661794458 eval_avg_acc: 0.3434635742781461 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:47:29] [32mIntermediate result: 0.3434635742781461  (Index 86)[0m
================Epoch: 88================
Iteration 1: train_loss 1.3905750513076782
Iteration 2: train_loss 1.3782825469970703
Iteration 3: train_loss 1.3944149017333984
Iteration 4: train_loss 1.4426298141479492
Iteration 5: train_loss 1.4331188201904297
Iteration 6: train_loss 1.4155508279800415
Iteration 7: train_loss 1.454209566116333
Iteration 8: train_loss 1.377110481262207
Iteration 9: train_loss 1.4352933168411255
Iteration 10: train_loss 1.4596277475357056
Iteration 11: train_loss 1.3930420875549316
Iteration 12: train_loss 1.43716299533844
Iteration 13: train_loss 1.4357980489730835
Iteration 14: train_loss 1.4570919275283813
Iteration 15: train_loss 1.4679681062698364
Iteration 16: train_loss 1.4603025913238525
Iteration 17: train_loss 1.4229978322982788
Iteration 18: train_loss 1.3249834775924683
Iteration 19: train_loss 1.4871855974197388
Iteration 20: train_loss 1.4082987308502197
Iteration 21: train_loss 1.4035155773162842
Iteration 22: train_loss 1.4929066896438599
Iteration 23: train_loss 1.4397504329681396
Iteration 24: train_loss 1.4094241857528687
Iteration 25: train_loss 1.4977407455444336
Iteration 26: train_loss 1.4039514064788818
Iteration 27: train_loss 1.394474744796753
Iteration 28: train_loss 1.477762222290039
Iteration 29: train_loss 1.4109077453613281
Iteration 30: train_loss 1.38485848903656
Iteration 31: train_loss 1.4364595413208008
Iteration 32: train_loss 1.4237502813339233
Iteration 33: train_loss 1.4396425485610962
Iteration 34: train_loss 1.4802184104919434
Iteration 35: train_loss 1.4118165969848633
Iteration 36: train_loss 1.4364176988601685
Iteration 37: train_loss 1.4512680768966675
Iteration 38: train_loss 1.4782055616378784
Iteration 39: train_loss 1.493361234664917
Iteration 40: train_loss 1.4133578538894653
Iteration 41: train_loss 1.4720746278762817
Iteration 42: train_loss 1.4521853923797607
Iteration 43: train_loss 1.4003578424453735
Iteration 44: train_loss 1.4217462539672852
Iteration 45: train_loss 1.4853713512420654
Iteration 46: train_loss 1.421118140220642
Iteration 47: train_loss 1.4121733903884888
Iteration 48: train_loss 1.47774076461792
Iteration 49: train_loss 1.5492002964019775
Iteration 50: train_loss 1.4409923553466797
Iteration 51: train_loss 1.457821249961853
Iteration 52: train_loss 1.4261130094528198
Iteration 53: train_loss 1.4404830932617188
Iteration 54: train_loss 1.3871698379516602
Iteration 55: train_loss 1.4149988889694214
Iteration 56: train_loss 1.4407325983047485
Iteration 57: train_loss 1.4491263628005981
Iteration 58: train_loss 1.5094610452651978
Iteration 59: train_loss 1.509271502494812
Iteration 60: train_loss 1.4835612773895264
Iteration 61: train_loss 1.4680427312850952
Iteration 62: train_loss 1.4873380661010742
Iteration 63: train_loss 1.4923611879348755
Iteration 64: train_loss 1.401148796081543
Iteration 65: train_loss 1.4531688690185547
Iteration 66: train_loss 1.4590487480163574
Iteration 67: train_loss 1.4101066589355469
Iteration 68: train_loss 1.428773283958435
Iteration 69: train_loss 1.510520339012146
Iteration 70: train_loss 1.433412790298462
Iteration 71: train_loss 1.4415098428726196
Iteration 72: train_loss 1.4279570579528809
Iteration 73: train_loss 1.4737926721572876
Iteration 74: train_loss 1.435718059539795
Iteration 75: train_loss 1.5118674039840698
Iteration 76: train_loss 1.3422476053237915
Iteration 77: train_loss 1.5353227853775024
Iteration 78: train_loss 1.4469538927078247
Iteration 79: train_loss 1.460296392440796
Iteration 80: train_loss 1.4201231002807617
Iteration 81: train_loss 1.4480478763580322
Iteration 82: train_loss 1.3746384382247925
Iteration 83: train_loss 1.3949042558670044
Iteration 84: train_loss 1.3955016136169434
Iteration 85: train_loss 1.4274035692214966
Iteration 86: train_loss 1.3874359130859375
Iteration 87: train_loss 1.419053316116333
Iteration 88: train_loss 1.3871824741363525
Iteration 89: train_loss 1.467538595199585
Iteration 90: train_loss 1.4374346733093262
Iteration 91: train_loss 1.5049818754196167
Iteration 92: train_loss 1.4636365175247192
Iteration 93: train_loss 1.381028413772583
Iteration 94: train_loss 1.3972967863082886
Iteration 95: train_loss 1.3949360847473145
Iteration 96: train_loss 1.4054229259490967
Iteration 97: train_loss 1.4207481145858765
Iteration 98: train_loss 1.4584354162216187
Iteration 99: train_loss 1.5032025575637817
Iteration 100: train_loss 1.4381754398345947
Iteration 101: train_loss 1.5274854898452759
Iteration 102: train_loss 1.4339407682418823
Iteration 103: train_loss 1.464991807937622
Iteration 104: train_loss 1.5087134838104248
Iteration 105: train_loss 1.5003219842910767
Iteration 106: train_loss 1.3875458240509033
Iteration 107: train_loss 1.4071729183197021
Iteration 108: train_loss 1.4196445941925049
Iteration 109: train_loss 1.425489068031311
Iteration 110: train_loss 1.4464236497879028
Iteration 111: train_loss 1.4343451261520386
Iteration 112: train_loss 1.4483582973480225
Iteration 113: train_loss 1.442250370979309
Iteration 114: train_loss 1.349258542060852
Iteration 115: train_loss 1.431596279144287
Iteration 116: train_loss 1.4063678979873657
Iteration 117: train_loss 1.4155771732330322
Iteration 118: train_loss 1.4678077697753906
Iteration 119: train_loss 1.4200001955032349
Iteration 120: train_loss 1.431671380996704
Iteration 121: train_loss 1.4345297813415527
Iteration 122: train_loss 1.3986014127731323
Iteration 123: train_loss 1.4268896579742432
Iteration 124: train_loss 1.4607435464859009
Iteration 125: train_loss 1.4217380285263062
Iteration 126: train_loss 1.4110366106033325
Iteration 127: train_loss 1.4052671194076538
Iteration 128: train_loss 1.3727301359176636
Iteration 129: train_loss 1.4621716737747192
Iteration 130: train_loss 1.4637848138809204
Iteration 131: train_loss 1.4217662811279297
Iteration 132: train_loss 1.4553290605545044
Iteration 133: train_loss 1.4230190515518188
Iteration 134: train_loss 1.4118977785110474
Iteration 135: train_loss 1.4669677019119263
Iteration 136: train_loss 1.4715064764022827
Iteration 137: train_loss 1.422336220741272
Iteration 138: train_loss 1.3617223501205444
Iteration 139: train_loss 1.48202383518219
Iteration 140: train_loss 1.4465322494506836
Iteration 141: train_loss 1.4326627254486084
Iteration 142: train_loss 1.4727424383163452
Iteration 143: train_loss 1.4499330520629883
Iteration 144: train_loss 1.522400140762329
Iteration 145: train_loss 1.4233709573745728
Iteration 146: train_loss 1.4086992740631104
Iteration 147: train_loss 1.4717024564743042
Iteration 148: train_loss 1.4412977695465088
Iteration 149: train_loss 1.4614315032958984
Iteration 150: train_loss 1.4185054302215576
Iteration 151: train_loss 1.477104902267456
Iteration 152: train_loss 1.4414061307907104
Iteration 153: train_loss 1.4121164083480835
Iteration 154: train_loss 1.4572243690490723
Iteration 155: train_loss 1.4129016399383545
Iteration 156: train_loss 1.458824634552002
Iteration 157: train_loss 1.4718544483184814
Iteration 158: train_loss 1.4118435382843018
Iteration 159: train_loss 1.5104701519012451
Iteration 160: train_loss 1.4671214818954468
Iteration 161: train_loss 1.5031253099441528
Iteration 162: train_loss 1.4322270154953003
Iteration 163: train_loss 1.4661459922790527
Iteration 164: train_loss 1.4660699367523193
Iteration 165: train_loss 1.573002815246582
Iteration 166: train_loss 1.4120206832885742
Iteration 167: train_loss 1.377434253692627
Iteration 168: train_loss 1.5143848657608032
Iteration 169: train_loss 1.4795494079589844
Iteration 170: train_loss 1.5355579853057861
Iteration 171: train_loss 1.4472776651382446
Iteration 172: train_loss 1.4370181560516357
Iteration 173: train_loss 1.4882276058197021
Iteration 174: train_loss 1.407402515411377
Iteration 175: train_loss 1.4585232734680176
Iteration 176: train_loss 1.4652321338653564
Iteration 177: train_loss 1.5267360210418701
Epoch 88: train_avg_loss 1.4421296860538633 eval_avg_acc: 0.3234034678600562 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:48:09] [32mIntermediate result: 0.3234034678600562  (Index 87)[0m
================Epoch: 89================
Iteration 1: train_loss 1.3992366790771484
Iteration 2: train_loss 1.46480131149292
Iteration 3: train_loss 1.4261600971221924
Iteration 4: train_loss 1.4035812616348267
Iteration 5: train_loss 1.465675711631775
Iteration 6: train_loss 1.47063148021698
Iteration 7: train_loss 1.4457067251205444
Iteration 8: train_loss 1.4722788333892822
Iteration 9: train_loss 1.476264238357544
Iteration 10: train_loss 1.3507812023162842
Iteration 11: train_loss 1.3799245357513428
Iteration 12: train_loss 1.4021435976028442
Iteration 13: train_loss 1.4194031953811646
Iteration 14: train_loss 1.325488805770874
Iteration 15: train_loss 1.4295969009399414
Iteration 16: train_loss 1.3516287803649902
Iteration 17: train_loss 1.4232523441314697
Iteration 18: train_loss 1.4165823459625244
Iteration 19: train_loss 1.415245532989502
Iteration 20: train_loss 1.3810789585113525
Iteration 21: train_loss 1.3919471502304077
Iteration 22: train_loss 1.4389269351959229
Iteration 23: train_loss 1.4005285501480103
Iteration 24: train_loss 1.4064373970031738
Iteration 25: train_loss 1.3934324979782104
Iteration 26: train_loss 1.3807058334350586
Iteration 27: train_loss 1.4209380149841309
Iteration 28: train_loss 1.4150338172912598
Iteration 29: train_loss 1.4125285148620605
Iteration 30: train_loss 1.3861844539642334
Iteration 31: train_loss 1.47758150100708
Iteration 32: train_loss 1.3926039934158325
Iteration 33: train_loss 1.3660293817520142
Iteration 34: train_loss 1.4808955192565918
Iteration 35: train_loss 1.4108860492706299
Iteration 36: train_loss 1.4317883253097534
Iteration 37: train_loss 1.4063708782196045
Iteration 38: train_loss 1.351424217224121
Iteration 39: train_loss 1.404818058013916
Iteration 40: train_loss 1.4284889698028564
Iteration 41: train_loss 1.4383422136306763
Iteration 42: train_loss 1.3820343017578125
Iteration 43: train_loss 1.4374059438705444
Iteration 44: train_loss 1.4808913469314575
Iteration 45: train_loss 1.4349335432052612
Iteration 46: train_loss 1.486700177192688
Iteration 47: train_loss 1.4711915254592896
Iteration 48: train_loss 1.4884099960327148
Iteration 49: train_loss 1.410430669784546
Iteration 50: train_loss 1.4325352907180786
Iteration 51: train_loss 1.4005142450332642
Iteration 52: train_loss 1.4416024684906006
Iteration 53: train_loss 1.4892650842666626
Iteration 54: train_loss 1.4363471269607544
Iteration 55: train_loss 1.430249810218811
Iteration 56: train_loss 1.4001250267028809
Iteration 57: train_loss 1.457688570022583
Iteration 58: train_loss 1.3930957317352295
Iteration 59: train_loss 1.3885256052017212
Iteration 60: train_loss 1.320109248161316
Iteration 61: train_loss 1.360407829284668
Iteration 62: train_loss 1.4159173965454102
Iteration 63: train_loss 1.3742926120758057
Iteration 64: train_loss 1.3275268077850342
Iteration 65: train_loss 1.393256425857544
Iteration 66: train_loss 1.4246779680252075
Iteration 67: train_loss 1.3830196857452393
Iteration 68: train_loss 1.4203212261199951
Iteration 69: train_loss 1.364740014076233
Iteration 70: train_loss 1.3815696239471436
Iteration 71: train_loss 1.4134594202041626
Iteration 72: train_loss 1.3606148958206177
Iteration 73: train_loss 1.3972047567367554
Iteration 74: train_loss 1.4067537784576416
Iteration 75: train_loss 1.4310309886932373
Iteration 76: train_loss 1.4202444553375244
Iteration 77: train_loss 1.4234156608581543
Iteration 78: train_loss 1.4405360221862793
Iteration 79: train_loss 1.3714556694030762
Iteration 80: train_loss 1.3905385732650757
Iteration 81: train_loss 1.3441357612609863
Iteration 82: train_loss 1.359309196472168
Iteration 83: train_loss 1.4131028652191162
Iteration 84: train_loss 1.3262075185775757
Iteration 85: train_loss 1.3738749027252197
Iteration 86: train_loss 1.3884437084197998
Iteration 87: train_loss 1.384218454360962
Iteration 88: train_loss 1.370897650718689
Iteration 89: train_loss 1.3853394985198975
Iteration 90: train_loss 1.3816542625427246
Iteration 91: train_loss 1.448933482170105
Iteration 92: train_loss 1.411091923713684
Iteration 93: train_loss 1.3985904455184937
Iteration 94: train_loss 1.4032185077667236
Iteration 95: train_loss 1.4422718286514282
Iteration 96: train_loss 1.4183861017227173
Iteration 97: train_loss 1.4351255893707275
Iteration 98: train_loss 1.4778075218200684
Iteration 99: train_loss 1.4566195011138916
Iteration 100: train_loss 1.3437973260879517
Iteration 101: train_loss 1.491155743598938
Iteration 102: train_loss 1.3946679830551147
Iteration 103: train_loss 1.5207571983337402
Iteration 104: train_loss 1.469181776046753
Iteration 105: train_loss 1.404672622680664
Iteration 106: train_loss 1.4451518058776855
Iteration 107: train_loss 1.4610918760299683
Iteration 108: train_loss 1.4540156126022339
Iteration 109: train_loss 1.427884817123413
Iteration 110: train_loss 1.4218639135360718
Iteration 111: train_loss 1.4582926034927368
Iteration 112: train_loss 1.4796950817108154
Iteration 113: train_loss 1.4008005857467651
Iteration 114: train_loss 1.4364216327667236
Iteration 115: train_loss 1.4121748208999634
Iteration 116: train_loss 1.3931739330291748
Iteration 117: train_loss 1.4466781616210938
Iteration 118: train_loss 1.5271095037460327
Iteration 119: train_loss 1.4042893648147583
Iteration 120: train_loss 1.5010321140289307
Iteration 121: train_loss 1.3642897605895996
Iteration 122: train_loss 1.4474459886550903
Iteration 123: train_loss 1.4185155630111694
Iteration 124: train_loss 1.4513509273529053
Iteration 125: train_loss 1.456983208656311
Iteration 126: train_loss 1.3772556781768799
Iteration 127: train_loss 1.4505103826522827
Iteration 128: train_loss 1.4142974615097046
Iteration 129: train_loss 1.4305797815322876
Iteration 130: train_loss 1.4724711179733276
Iteration 131: train_loss 1.3243017196655273
Iteration 132: train_loss 1.4602086544036865
Iteration 133: train_loss 1.4204756021499634
Iteration 134: train_loss 1.4209694862365723
Iteration 135: train_loss 1.491906762123108
Iteration 136: train_loss 1.4639917612075806
Iteration 137: train_loss 1.4243717193603516
Iteration 138: train_loss 1.4386237859725952
Iteration 139: train_loss 1.3954845666885376
Iteration 140: train_loss 1.4206030368804932
Iteration 141: train_loss 1.324669599533081
Iteration 142: train_loss 1.4292705059051514
Iteration 143: train_loss 1.4091711044311523
Iteration 144: train_loss 1.4097329378128052
Iteration 145: train_loss 1.3739745616912842
Iteration 146: train_loss 1.4038951396942139
Iteration 147: train_loss 1.4495633840560913
Iteration 148: train_loss 1.417385458946228
Iteration 149: train_loss 1.4102704524993896
Iteration 150: train_loss 1.4391456842422485
Iteration 151: train_loss 1.391424298286438
Iteration 152: train_loss 1.4463783502578735
Iteration 153: train_loss 1.442552924156189
Iteration 154: train_loss 1.4702366590499878
Iteration 155: train_loss 1.4161335229873657
Iteration 156: train_loss 1.4159244298934937
Iteration 157: train_loss 1.4098403453826904
Iteration 158: train_loss 1.387054681777954
Iteration 159: train_loss 1.3889906406402588
Iteration 160: train_loss 1.4274568557739258
Iteration 161: train_loss 1.4276909828186035
Iteration 162: train_loss 1.4050853252410889
Iteration 163: train_loss 1.442705750465393
Iteration 164: train_loss 1.4485151767730713
Iteration 165: train_loss 1.3992289304733276
Iteration 166: train_loss 1.4825026988983154
Iteration 167: train_loss 1.4580001831054688
Iteration 168: train_loss 1.458634853363037
Iteration 169: train_loss 1.477853536605835
Iteration 170: train_loss 1.3793810606002808
Iteration 171: train_loss 1.4320324659347534
Iteration 172: train_loss 1.4356663227081299
Iteration 173: train_loss 1.4902225732803345
Iteration 174: train_loss 1.4904712438583374
Iteration 175: train_loss 1.452982783317566
Iteration 176: train_loss 1.437033772468567
Iteration 177: train_loss 1.3518049716949463
Epoch 89: train_avg_loss 1.419373178886155 eval_avg_acc: 0.3463479466090251 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:48:50] [32mIntermediate result: 0.3463479466090251  (Index 88)[0m
================Epoch: 90================
Iteration 1: train_loss 1.4450348615646362
Iteration 2: train_loss 1.486611008644104
Iteration 3: train_loss 1.4813045263290405
Iteration 4: train_loss 1.4630968570709229
Iteration 5: train_loss 1.3792705535888672
Iteration 6: train_loss 1.5035654306411743
Iteration 7: train_loss 1.4518591165542603
Iteration 8: train_loss 1.4989758729934692
Iteration 9: train_loss 1.3955233097076416
Iteration 10: train_loss 1.4194056987762451
Iteration 11: train_loss 1.4266374111175537
Iteration 12: train_loss 1.3293923139572144
Iteration 13: train_loss 1.3917250633239746
Iteration 14: train_loss 1.4382039308547974
Iteration 15: train_loss 1.3687857389450073
Iteration 16: train_loss 1.4007389545440674
Iteration 17: train_loss 1.4202029705047607
Iteration 18: train_loss 1.419641137123108
Iteration 19: train_loss 1.4099277257919312
Iteration 20: train_loss 1.439393162727356
Iteration 21: train_loss 1.3925246000289917
Iteration 22: train_loss 1.4344185590744019
Iteration 23: train_loss 1.417488694190979
Iteration 24: train_loss 1.450334072113037
Iteration 25: train_loss 1.35740327835083
Iteration 26: train_loss 1.43436598777771
Iteration 27: train_loss 1.4240072965621948
Iteration 28: train_loss 1.4540280103683472
Iteration 29: train_loss 1.3966246843338013
Iteration 30: train_loss 1.4574090242385864
Iteration 31: train_loss 1.3869296312332153
Iteration 32: train_loss 1.4412758350372314
Iteration 33: train_loss 1.4104026556015015
Iteration 34: train_loss 1.447080135345459
Iteration 35: train_loss 1.4175488948822021
Iteration 36: train_loss 1.4044033288955688
Iteration 37: train_loss 1.4289895296096802
Iteration 38: train_loss 1.4280998706817627
Iteration 39: train_loss 1.3459219932556152
Iteration 40: train_loss 1.396525502204895
Iteration 41: train_loss 1.3938014507293701
Iteration 42: train_loss 1.4759646654129028
Iteration 43: train_loss 1.4283097982406616
Iteration 44: train_loss 1.4247864484786987
Iteration 45: train_loss 1.4068515300750732
Iteration 46: train_loss 1.4093568325042725
Iteration 47: train_loss 1.4444316625595093
Iteration 48: train_loss 1.4582034349441528
Iteration 49: train_loss 1.415582537651062
Iteration 50: train_loss 1.4482605457305908
Iteration 51: train_loss 1.3981273174285889
Iteration 52: train_loss 1.4142863750457764
Iteration 53: train_loss 1.4368488788604736
Iteration 54: train_loss 1.419020652770996
Iteration 55: train_loss 1.391563057899475
Iteration 56: train_loss 1.3482214212417603
Iteration 57: train_loss 1.354654312133789
Iteration 58: train_loss 1.3932044506072998
Iteration 59: train_loss 1.4206246137619019
Iteration 60: train_loss 1.3392198085784912
Iteration 61: train_loss 1.3904043436050415
Iteration 62: train_loss 1.3931511640548706
Iteration 63: train_loss 1.4260993003845215
Iteration 64: train_loss 1.3958179950714111
Iteration 65: train_loss 1.3990107774734497
Iteration 66: train_loss 1.396577000617981
Iteration 67: train_loss 1.3614801168441772
Iteration 68: train_loss 1.3557718992233276
Iteration 69: train_loss 1.36691153049469
Iteration 70: train_loss 1.3810714483261108
Iteration 71: train_loss 1.3673704862594604
Iteration 72: train_loss 1.3443297147750854
Iteration 73: train_loss 1.4117401838302612
Iteration 74: train_loss 1.3332126140594482
Iteration 75: train_loss 1.4069063663482666
Iteration 76: train_loss 1.3959803581237793
Iteration 77: train_loss 1.3994123935699463
Iteration 78: train_loss 1.372849702835083
Iteration 79: train_loss 1.377185583114624
Iteration 80: train_loss 1.3732080459594727
Iteration 81: train_loss 1.4078062772750854
Iteration 82: train_loss 1.3678267002105713
Iteration 83: train_loss 1.4118678569793701
Iteration 84: train_loss 1.4108432531356812
Iteration 85: train_loss 1.3925666809082031
Iteration 86: train_loss 1.38323175907135
Iteration 87: train_loss 1.4517842531204224
Iteration 88: train_loss 1.3852366209030151
Iteration 89: train_loss 1.395599126815796
Iteration 90: train_loss 1.3722760677337646
Iteration 91: train_loss 1.3537108898162842
Iteration 92: train_loss 1.3721811771392822
Iteration 93: train_loss 1.393344759941101
Iteration 94: train_loss 1.4545464515686035
Iteration 95: train_loss 1.4146686792373657
Iteration 96: train_loss 1.3908300399780273
Iteration 97: train_loss 1.422120451927185
Iteration 98: train_loss 1.410298466682434
Iteration 99: train_loss 1.4599937200546265
Iteration 100: train_loss 1.4494987726211548
Iteration 101: train_loss 1.4480361938476562
Iteration 102: train_loss 1.4696664810180664
Iteration 103: train_loss 1.408380389213562
Iteration 104: train_loss 1.4366437196731567
Iteration 105: train_loss 1.426769733428955
Iteration 106: train_loss 1.417470097541809
Iteration 107: train_loss 1.4677906036376953
Iteration 108: train_loss 1.4390548467636108
Iteration 109: train_loss 1.4624793529510498
Iteration 110: train_loss 1.424278974533081
Iteration 111: train_loss 1.4177035093307495
Iteration 112: train_loss 1.4102373123168945
Iteration 113: train_loss 1.362027883529663
Iteration 114: train_loss 1.4737553596496582
Iteration 115: train_loss 1.4611259698867798
Iteration 116: train_loss 1.463404655456543
Iteration 117: train_loss 1.489847183227539
Iteration 118: train_loss 1.407095193862915
Iteration 119: train_loss 1.4725908041000366
Iteration 120: train_loss 1.3980493545532227
Iteration 121: train_loss 1.3689148426055908
Iteration 122: train_loss 1.416650414466858
Iteration 123: train_loss 1.4688721895217896
Iteration 124: train_loss 1.4238579273223877
Iteration 125: train_loss 1.4903106689453125
Iteration 126: train_loss 1.3972376585006714
Iteration 127: train_loss 1.445374846458435
Iteration 128: train_loss 1.342706322669983
Iteration 129: train_loss 1.4393922090530396
Iteration 130: train_loss 1.4406025409698486
Iteration 131: train_loss 1.4761244058609009
Iteration 132: train_loss 1.502128005027771
Iteration 133: train_loss 1.457895040512085
Iteration 134: train_loss 1.4923514127731323
Iteration 135: train_loss 1.4843357801437378
Iteration 136: train_loss 1.4675620794296265
Iteration 137: train_loss 1.3928707838058472
Iteration 138: train_loss 1.363885760307312
Iteration 139: train_loss 1.3918371200561523
Iteration 140: train_loss 1.3900578022003174
Iteration 141: train_loss 1.3955211639404297
Iteration 142: train_loss 1.3518242835998535
Iteration 143: train_loss 1.4337224960327148
Iteration 144: train_loss 1.455256700515747
Iteration 145: train_loss 1.422316312789917
Iteration 146: train_loss 1.4269999265670776
Iteration 147: train_loss 1.3725414276123047
Iteration 148: train_loss 1.474798321723938
Iteration 149: train_loss 1.4140905141830444
Iteration 150: train_loss 1.447053074836731
Iteration 151: train_loss 1.4422554969787598
Iteration 152: train_loss 1.4159698486328125
Iteration 153: train_loss 1.505488634109497
Iteration 154: train_loss 1.525925874710083
Iteration 155: train_loss 1.410718560218811
Iteration 156: train_loss 1.4251266717910767
Iteration 157: train_loss 1.460813045501709
Iteration 158: train_loss 1.4256342649459839
Iteration 159: train_loss 1.3916044235229492
Iteration 160: train_loss 1.4935723543167114
Iteration 161: train_loss 1.4028617143630981
Iteration 162: train_loss 1.3376106023788452
Iteration 163: train_loss 1.3777358531951904
Iteration 164: train_loss 1.4345728158950806
Iteration 165: train_loss 1.4531192779541016
Iteration 166: train_loss 1.4624420404434204
Iteration 167: train_loss 1.369230031967163
Iteration 168: train_loss 1.4728164672851562
Iteration 169: train_loss 1.520336627960205
Iteration 170: train_loss 1.419086217880249
Iteration 171: train_loss 1.4276658296585083
Iteration 172: train_loss 1.4716551303863525
Iteration 173: train_loss 1.4747262001037598
Iteration 174: train_loss 1.4359362125396729
Iteration 175: train_loss 1.420498251914978
Iteration 176: train_loss 1.420344352722168
Iteration 177: train_loss 1.3503658771514893
Epoch 90: train_avg_loss 1.419303572784036 eval_avg_acc: 0.34750365972703595 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:49:30] [32mIntermediate result: 0.34750365972703595  (Index 89)[0m
================Epoch: 91================
Iteration 1: train_loss 1.376766324043274
Iteration 2: train_loss 1.376739263534546
Iteration 3: train_loss 1.4329004287719727
Iteration 4: train_loss 1.3996922969818115
Iteration 5: train_loss 1.4435417652130127
Iteration 6: train_loss 1.412639856338501
Iteration 7: train_loss 1.424362063407898
Iteration 8: train_loss 1.4093446731567383
Iteration 9: train_loss 1.394018530845642
Iteration 10: train_loss 1.4459699392318726
Iteration 11: train_loss 1.3338329792022705
Iteration 12: train_loss 1.4074634313583374
Iteration 13: train_loss 1.401875376701355
Iteration 14: train_loss 1.3641890287399292
Iteration 15: train_loss 1.3851571083068848
Iteration 16: train_loss 1.4487340450286865
Iteration 17: train_loss 1.3899372816085815
Iteration 18: train_loss 1.3888938426971436
Iteration 19: train_loss 1.4001121520996094
Iteration 20: train_loss 1.4611402750015259
Iteration 21: train_loss 1.3427096605300903
Iteration 22: train_loss 1.461520791053772
Iteration 23: train_loss 1.3955729007720947
Iteration 24: train_loss 1.373526692390442
Iteration 25: train_loss 1.4353697299957275
Iteration 26: train_loss 1.420707106590271
Iteration 27: train_loss 1.3023555278778076
Iteration 28: train_loss 1.4370191097259521
Iteration 29: train_loss 1.4211454391479492
Iteration 30: train_loss 1.4475704431533813
Iteration 31: train_loss 1.402541995048523
Iteration 32: train_loss 1.4548462629318237
Iteration 33: train_loss 1.3746849298477173
Iteration 34: train_loss 1.3437950611114502
Iteration 35: train_loss 1.3032232522964478
Iteration 36: train_loss 1.33706796169281
Iteration 37: train_loss 1.4061951637268066
Iteration 38: train_loss 1.4245656728744507
Iteration 39: train_loss 1.3903155326843262
Iteration 40: train_loss 1.367968201637268
Iteration 41: train_loss 1.3836721181869507
Iteration 42: train_loss 1.3634616136550903
Iteration 43: train_loss 1.3647514581680298
Iteration 44: train_loss 1.3726381063461304
Iteration 45: train_loss 1.34302818775177
Iteration 46: train_loss 1.4201586246490479
Iteration 47: train_loss 1.4259711503982544
Iteration 48: train_loss 1.4027340412139893
Iteration 49: train_loss 1.3732678890228271
Iteration 50: train_loss 1.4479925632476807
Iteration 51: train_loss 1.4039735794067383
Iteration 52: train_loss 1.3797178268432617
Iteration 53: train_loss 1.4125862121582031
Iteration 54: train_loss 1.381237506866455
Iteration 55: train_loss 1.3845593929290771
Iteration 56: train_loss 1.3623300790786743
Iteration 57: train_loss 1.3872132301330566
Iteration 58: train_loss 1.408213496208191
Iteration 59: train_loss 1.3789948225021362
Iteration 60: train_loss 1.4716136455535889
Iteration 61: train_loss 1.362821102142334
Iteration 62: train_loss 1.3826175928115845
Iteration 63: train_loss 1.4485609531402588
Iteration 64: train_loss 1.3810299634933472
Iteration 65: train_loss 1.3754305839538574
Iteration 66: train_loss 1.3248411417007446
Iteration 67: train_loss 1.4479378461837769
Iteration 68: train_loss 1.3874220848083496
Iteration 69: train_loss 1.4269647598266602
Iteration 70: train_loss 1.3834245204925537
Iteration 71: train_loss 1.4079915285110474
Iteration 72: train_loss 1.4292546510696411
Iteration 73: train_loss 1.409031867980957
Iteration 74: train_loss 1.4012880325317383
Iteration 75: train_loss 1.4046379327774048
Iteration 76: train_loss 1.3146661520004272
Iteration 77: train_loss 1.4629499912261963
Iteration 78: train_loss 1.3506370782852173
Iteration 79: train_loss 1.4103814363479614
Iteration 80: train_loss 1.4121311902999878
Iteration 81: train_loss 1.412150502204895
Iteration 82: train_loss 1.4560960531234741
Iteration 83: train_loss 1.3958606719970703
Iteration 84: train_loss 1.4288262128829956
Iteration 85: train_loss 1.3825255632400513
Iteration 86: train_loss 1.4279218912124634
Iteration 87: train_loss 1.492789626121521
Iteration 88: train_loss 1.4585039615631104
Iteration 89: train_loss 1.4398001432418823
Iteration 90: train_loss 1.4184215068817139
Iteration 91: train_loss 1.4459916353225708
Iteration 92: train_loss 1.4122920036315918
Iteration 93: train_loss 1.3414183855056763
Iteration 94: train_loss 1.431380271911621
Iteration 95: train_loss 1.4638488292694092
Iteration 96: train_loss 1.4457134008407593
Iteration 97: train_loss 1.4214801788330078
Iteration 98: train_loss 1.3800526857376099
Iteration 99: train_loss 1.44075345993042
Iteration 100: train_loss 1.4411975145339966
Iteration 101: train_loss 1.3996260166168213
Iteration 102: train_loss 1.3175801038742065
Iteration 103: train_loss 1.3967721462249756
Iteration 104: train_loss 1.3951917886734009
Iteration 105: train_loss 1.3442107439041138
Iteration 106: train_loss 1.4056370258331299
Iteration 107: train_loss 1.3730065822601318
Iteration 108: train_loss 1.3919546604156494
Iteration 109: train_loss 1.4186726808547974
Iteration 110: train_loss 1.411646842956543
Iteration 111: train_loss 1.408356785774231
Iteration 112: train_loss 1.4442031383514404
Iteration 113: train_loss 1.465085744857788
Iteration 114: train_loss 1.4439551830291748
Iteration 115: train_loss 1.369089961051941
Iteration 116: train_loss 1.3457354307174683
Iteration 117: train_loss 1.4081511497497559
Iteration 118: train_loss 1.4150232076644897
Iteration 119: train_loss 1.4321368932724
Iteration 120: train_loss 1.433441400527954
Iteration 121: train_loss 1.420146107673645
Iteration 122: train_loss 1.4341495037078857
Iteration 123: train_loss 1.41242253780365
Iteration 124: train_loss 1.3522050380706787
Iteration 125: train_loss 1.3830920457839966
Iteration 126: train_loss 1.382436990737915
Iteration 127: train_loss 1.3901113271713257
Iteration 128: train_loss 1.3663822412490845
Iteration 129: train_loss 1.3995420932769775
Iteration 130: train_loss 1.4150359630584717
Iteration 131: train_loss 1.4544414281845093
Iteration 132: train_loss 1.4154553413391113
Iteration 133: train_loss 1.4285680055618286
Iteration 134: train_loss 1.3898863792419434
Iteration 135: train_loss 1.5127545595169067
Iteration 136: train_loss 1.5175354480743408
Iteration 137: train_loss 1.487884521484375
Iteration 138: train_loss 1.4797724485397339
Iteration 139: train_loss 1.45970618724823
Iteration 140: train_loss 1.4181203842163086
Iteration 141: train_loss 1.4479260444641113
Iteration 142: train_loss 1.3979153633117676
Iteration 143: train_loss 1.4912081956863403
Iteration 144: train_loss 1.413230061531067
Iteration 145: train_loss 1.403191089630127
Iteration 146: train_loss 1.369099497795105
Iteration 147: train_loss 1.3749388456344604
Iteration 148: train_loss 1.4603888988494873
Iteration 149: train_loss 1.3985766172409058
Iteration 150: train_loss 1.448775291442871
Iteration 151: train_loss 1.401092767715454
Iteration 152: train_loss 1.4242558479309082
Iteration 153: train_loss 1.3793408870697021
Iteration 154: train_loss 1.4317797422409058
Iteration 155: train_loss 1.348940372467041
Iteration 156: train_loss 1.3795686960220337
Iteration 157: train_loss 1.4466348886489868
Iteration 158: train_loss 1.389467477798462
Iteration 159: train_loss 1.4168306589126587
Iteration 160: train_loss 1.4381046295166016
Iteration 161: train_loss 1.4175868034362793
Iteration 162: train_loss 1.4578906297683716
Iteration 163: train_loss 1.3989847898483276
Iteration 164: train_loss 1.4552340507507324
Iteration 165: train_loss 1.3240562677383423
Iteration 166: train_loss 1.415992259979248
Iteration 167: train_loss 1.366727352142334
Iteration 168: train_loss 1.4139354228973389
Iteration 169: train_loss 1.4620027542114258
Iteration 170: train_loss 1.3812382221221924
Iteration 171: train_loss 1.4423924684524536
Iteration 172: train_loss 1.4259905815124512
Iteration 173: train_loss 1.4991412162780762
Iteration 174: train_loss 1.413638710975647
Iteration 175: train_loss 1.4715467691421509
Iteration 176: train_loss 1.4124261140823364
Iteration 177: train_loss 1.4591764211654663
Epoch 91: train_avg_loss 1.4084040977187076 eval_avg_acc: 0.34611605673961504 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:50:10] [32mIntermediate result: 0.34611605673961504  (Index 90)[0m
================Epoch: 92================
Iteration 1: train_loss 1.3880869150161743
Iteration 2: train_loss 1.3360674381256104
Iteration 3: train_loss 1.363737940788269
Iteration 4: train_loss 1.4041657447814941
Iteration 5: train_loss 1.443480134010315
Iteration 6: train_loss 1.4188300371170044
Iteration 7: train_loss 1.4290632009506226
Iteration 8: train_loss 1.3622444868087769
Iteration 9: train_loss 1.443158745765686
Iteration 10: train_loss 1.3569200038909912
Iteration 11: train_loss 1.35188627243042
Iteration 12: train_loss 1.4204705953598022
Iteration 13: train_loss 1.430997610092163
Iteration 14: train_loss 1.397992491722107
Iteration 15: train_loss 1.3849719762802124
Iteration 16: train_loss 1.390402913093567
Iteration 17: train_loss 1.4262409210205078
Iteration 18: train_loss 1.369223713874817
Iteration 19: train_loss 1.329392910003662
Iteration 20: train_loss 1.372964859008789
Iteration 21: train_loss 1.3495562076568604
Iteration 22: train_loss 1.4451320171356201
Iteration 23: train_loss 1.3766283988952637
Iteration 24: train_loss 1.3628126382827759
Iteration 25: train_loss 1.3241233825683594
Iteration 26: train_loss 1.3721816539764404
Iteration 27: train_loss 1.3595232963562012
Iteration 28: train_loss 1.375644326210022
Iteration 29: train_loss 1.4007976055145264
Iteration 30: train_loss 1.4471527338027954
Iteration 31: train_loss 1.3774367570877075
Iteration 32: train_loss 1.40770423412323
Iteration 33: train_loss 1.435293197631836
Iteration 34: train_loss 1.4137957096099854
Iteration 35: train_loss 1.4163068532943726
Iteration 36: train_loss 1.3878940343856812
Iteration 37: train_loss 1.3930995464324951
Iteration 38: train_loss 1.3538579940795898
Iteration 39: train_loss 1.3501362800598145
Iteration 40: train_loss 1.4141931533813477
Iteration 41: train_loss 1.380677580833435
Iteration 42: train_loss 1.445516586303711
Iteration 43: train_loss 1.3483548164367676
Iteration 44: train_loss 1.4016022682189941
Iteration 45: train_loss 1.4262208938598633
Iteration 46: train_loss 1.4199659824371338
Iteration 47: train_loss 1.4178311824798584
Iteration 48: train_loss 1.3734796047210693
Iteration 49: train_loss 1.3568522930145264
Iteration 50: train_loss 1.3925973176956177
Iteration 51: train_loss 1.36308753490448
Iteration 52: train_loss 1.4220173358917236
Iteration 53: train_loss 1.390418291091919
Iteration 54: train_loss 1.3532099723815918
Iteration 55: train_loss 1.3597097396850586
Iteration 56: train_loss 1.3972032070159912
Iteration 57: train_loss 1.3844496011734009
Iteration 58: train_loss 1.3666049242019653
Iteration 59: train_loss 1.4298052787780762
Iteration 60: train_loss 1.4236962795257568
Iteration 61: train_loss 1.423539400100708
Iteration 62: train_loss 1.3377946615219116
Iteration 63: train_loss 1.3664201498031616
Iteration 64: train_loss 1.3984566926956177
Iteration 65: train_loss 1.4269143342971802
Iteration 66: train_loss 1.4120063781738281
Iteration 67: train_loss 1.3575962781906128
Iteration 68: train_loss 1.3994486331939697
Iteration 69: train_loss 1.4477407932281494
Iteration 70: train_loss 1.3959661722183228
Iteration 71: train_loss 1.4246586561203003
Iteration 72: train_loss 1.3783077001571655
Iteration 73: train_loss 1.3514432907104492
Iteration 74: train_loss 1.4054529666900635
Iteration 75: train_loss 1.4101067781448364
Iteration 76: train_loss 1.4173288345336914
Iteration 77: train_loss 1.388680338859558
Iteration 78: train_loss 1.4372847080230713
Iteration 79: train_loss 1.3842291831970215
Iteration 80: train_loss 1.408555507659912
Iteration 81: train_loss 1.4350370168685913
Iteration 82: train_loss 1.3830021619796753
Iteration 83: train_loss 1.362810492515564
Iteration 84: train_loss 1.3671224117279053
Iteration 85: train_loss 1.3880176544189453
Iteration 86: train_loss 1.4331332445144653
Iteration 87: train_loss 1.419253945350647
Iteration 88: train_loss 1.4283398389816284
Iteration 89: train_loss 1.4466443061828613
Iteration 90: train_loss 1.2869569063186646
Iteration 91: train_loss 1.4513602256774902
Iteration 92: train_loss 1.4112577438354492
Iteration 93: train_loss 1.3450777530670166
Iteration 94: train_loss 1.3924033641815186
Iteration 95: train_loss 1.4920434951782227
Iteration 96: train_loss 1.4421336650848389
Iteration 97: train_loss 1.3894394636154175
Iteration 98: train_loss 1.4020121097564697
Iteration 99: train_loss 1.364957571029663
Iteration 100: train_loss 1.4408085346221924
Iteration 101: train_loss 1.4074636697769165
Iteration 102: train_loss 1.4037292003631592
Iteration 103: train_loss 1.4545674324035645
Iteration 104: train_loss 1.40902578830719
Iteration 105: train_loss 1.445525050163269
Iteration 106: train_loss 1.4061707258224487
Iteration 107: train_loss 1.4697834253311157
Iteration 108: train_loss 1.3781752586364746
Iteration 109: train_loss 1.421604037284851
Iteration 110: train_loss 1.440711259841919
Iteration 111: train_loss 1.4440696239471436
Iteration 112: train_loss 1.3912901878356934
Iteration 113: train_loss 1.390012502670288
Iteration 114: train_loss 1.4122414588928223
Iteration 115: train_loss 1.4309744834899902
Iteration 116: train_loss 1.3980696201324463
Iteration 117: train_loss 1.4132331609725952
Iteration 118: train_loss 1.4085557460784912
Iteration 119: train_loss 1.4254783391952515
Iteration 120: train_loss 1.4104160070419312
Iteration 121: train_loss 1.3346689939498901
Iteration 122: train_loss 1.4063055515289307
Iteration 123: train_loss 1.3268015384674072
Iteration 124: train_loss 1.4044984579086304
Iteration 125: train_loss 1.3983147144317627
Iteration 126: train_loss 1.4068818092346191
Iteration 127: train_loss 1.4376826286315918
Iteration 128: train_loss 1.4243593215942383
Iteration 129: train_loss 1.4051666259765625
Iteration 130: train_loss 1.3782285451889038
Iteration 131: train_loss 1.408876657485962
Iteration 132: train_loss 1.4009630680084229
Iteration 133: train_loss 1.4427937269210815
Iteration 134: train_loss 1.4157345294952393
Iteration 135: train_loss 1.4272308349609375
Iteration 136: train_loss 1.4917124509811401
Iteration 137: train_loss 1.4009581804275513
Iteration 138: train_loss 1.4122294187545776
Iteration 139: train_loss 1.399124026298523
Iteration 140: train_loss 1.4549846649169922
Iteration 141: train_loss 1.3965867757797241
Iteration 142: train_loss 1.4176480770111084
Iteration 143: train_loss 1.4370671510696411
Iteration 144: train_loss 1.5069565773010254
Iteration 145: train_loss 1.4635097980499268
Iteration 146: train_loss 1.471933126449585
Iteration 147: train_loss 1.4637064933776855
Iteration 148: train_loss 1.4756889343261719
Iteration 149: train_loss 1.4554731845855713
Iteration 150: train_loss 1.464080572128296
Iteration 151: train_loss 1.4879629611968994
Iteration 152: train_loss 1.5014564990997314
Iteration 153: train_loss 1.5068681240081787
Iteration 154: train_loss 1.4740849733352661
Iteration 155: train_loss 1.4105026721954346
Iteration 156: train_loss 1.4340999126434326
Iteration 157: train_loss 1.3731904029846191
Iteration 158: train_loss 1.4091551303863525
Iteration 159: train_loss 1.3857860565185547
Iteration 160: train_loss 1.446930170059204
Iteration 161: train_loss 1.3808794021606445
Iteration 162: train_loss 1.4720425605773926
Iteration 163: train_loss 1.4570835828781128
Iteration 164: train_loss 1.3941705226898193
Iteration 165: train_loss 1.3774925470352173
Iteration 166: train_loss 1.330865740776062
Iteration 167: train_loss 1.4100133180618286
Iteration 168: train_loss 1.4568432569503784
Iteration 169: train_loss 1.4516361951828003
Iteration 170: train_loss 1.417619228363037
Iteration 171: train_loss 1.4454517364501953
Iteration 172: train_loss 1.4227771759033203
Iteration 173: train_loss 1.3953455686569214
Iteration 174: train_loss 1.329494595527649
Iteration 175: train_loss 1.4351657629013062
Iteration 176: train_loss 1.3726751804351807
Iteration 177: train_loss 1.4025139808654785
Epoch 92: train_avg_loss 1.4065761788416717 eval_avg_acc: 0.33978567108399005 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:50:51] [32mIntermediate result: 0.33978567108399005  (Index 91)[0m
================Epoch: 93================
Iteration 1: train_loss 1.4105311632156372
Iteration 2: train_loss 1.403035044670105
Iteration 3: train_loss 1.3973320722579956
Iteration 4: train_loss 1.3843529224395752
Iteration 5: train_loss 1.3864402770996094
Iteration 6: train_loss 1.334671974182129
Iteration 7: train_loss 1.389229655265808
Iteration 8: train_loss 1.3944571018218994
Iteration 9: train_loss 1.3667263984680176
Iteration 10: train_loss 1.3713650703430176
Iteration 11: train_loss 1.3637977838516235
Iteration 12: train_loss 1.360954761505127
Iteration 13: train_loss 1.3451616764068604
Iteration 14: train_loss 1.4099880456924438
Iteration 15: train_loss 1.4161638021469116
Iteration 16: train_loss 1.3361080884933472
Iteration 17: train_loss 1.3724768161773682
Iteration 18: train_loss 1.4128823280334473
Iteration 19: train_loss 1.4398071765899658
Iteration 20: train_loss 1.4151300191879272
Iteration 21: train_loss 1.382558822631836
Iteration 22: train_loss 1.3962829113006592
Iteration 23: train_loss 1.3840709924697876
Iteration 24: train_loss 1.3831636905670166
Iteration 25: train_loss 1.3564549684524536
Iteration 26: train_loss 1.417543649673462
Iteration 27: train_loss 1.393274188041687
Iteration 28: train_loss 1.395412564277649
Iteration 29: train_loss 1.3388698101043701
Iteration 30: train_loss 1.3846510648727417
Iteration 31: train_loss 1.4021251201629639
Iteration 32: train_loss 1.4218158721923828
Iteration 33: train_loss 1.4352720975875854
Iteration 34: train_loss 1.4276002645492554
Iteration 35: train_loss 1.4211493730545044
Iteration 36: train_loss 1.3839905261993408
Iteration 37: train_loss 1.428412675857544
Iteration 38: train_loss 1.3875021934509277
Iteration 39: train_loss 1.4115800857543945
Iteration 40: train_loss 1.4287428855895996
Iteration 41: train_loss 1.454946517944336
Iteration 42: train_loss 1.3657708168029785
Iteration 43: train_loss 1.3448628187179565
Iteration 44: train_loss 1.4267269372940063
Iteration 45: train_loss 1.413049578666687
Iteration 46: train_loss 1.3724164962768555
Iteration 47: train_loss 1.3163715600967407
Iteration 48: train_loss 1.374327301979065
Iteration 49: train_loss 1.3910157680511475
Iteration 50: train_loss 1.3750771284103394
Iteration 51: train_loss 1.3915610313415527
Iteration 52: train_loss 1.4215176105499268
Iteration 53: train_loss 1.4025429487228394
Iteration 54: train_loss 1.3491623401641846
Iteration 55: train_loss 1.4071093797683716
Iteration 56: train_loss 1.3573567867279053
Iteration 57: train_loss 1.4034756422042847
Iteration 58: train_loss 1.391394019126892
Iteration 59: train_loss 1.404039740562439
Iteration 60: train_loss 1.419098973274231
Iteration 61: train_loss 1.371626377105713
Iteration 62: train_loss 1.3787765502929688
Iteration 63: train_loss 1.4095937013626099
Iteration 64: train_loss 1.3531821966171265
Iteration 65: train_loss 1.4776382446289062
Iteration 66: train_loss 1.4087488651275635
Iteration 67: train_loss 1.4571959972381592
Iteration 68: train_loss 1.4782073497772217
Iteration 69: train_loss 1.4315071105957031
Iteration 70: train_loss 1.4156898260116577
Iteration 71: train_loss 1.4389290809631348
Iteration 72: train_loss 1.4602558612823486
Iteration 73: train_loss 1.3788421154022217
Iteration 74: train_loss 1.34047269821167
Iteration 75: train_loss 1.404322624206543
Iteration 76: train_loss 1.449903964996338
Iteration 77: train_loss 1.4096136093139648
Iteration 78: train_loss 1.3599977493286133
Iteration 79: train_loss 1.379231333732605
Iteration 80: train_loss 1.3645285367965698
Iteration 81: train_loss 1.4276772737503052
Iteration 82: train_loss 1.4297263622283936
Iteration 83: train_loss 1.3942404985427856
Iteration 84: train_loss 1.411354422569275
Iteration 85: train_loss 1.4562209844589233
Iteration 86: train_loss 1.4447380304336548
Iteration 87: train_loss 1.41298508644104
Iteration 88: train_loss 1.4112213850021362
Iteration 89: train_loss 1.429072380065918
Iteration 90: train_loss 1.3432899713516235
Iteration 91: train_loss 1.370097041130066
Iteration 92: train_loss 1.3880656957626343
Iteration 93: train_loss 1.4634222984313965
Iteration 94: train_loss 1.407086968421936
Iteration 95: train_loss 1.375327229499817
Iteration 96: train_loss 1.3450053930282593
Iteration 97: train_loss 1.4171671867370605
Iteration 98: train_loss 1.4233778715133667
Iteration 99: train_loss 1.4028611183166504
Iteration 100: train_loss 1.4410429000854492
Iteration 101: train_loss 1.4368902444839478
Iteration 102: train_loss 1.3703795671463013
Iteration 103: train_loss 1.3747174739837646
Iteration 104: train_loss 1.422653317451477
Iteration 105: train_loss 1.4289718866348267
Iteration 106: train_loss 1.4042274951934814
Iteration 107: train_loss 1.3705837726593018
Iteration 108: train_loss 1.385920763015747
Iteration 109: train_loss 1.369950294494629
Iteration 110: train_loss 1.3952550888061523
Iteration 111: train_loss 1.4765185117721558
Iteration 112: train_loss 1.3799996376037598
Iteration 113: train_loss 1.3898046016693115
Iteration 114: train_loss 1.4549154043197632
Iteration 115: train_loss 1.3789714574813843
Iteration 116: train_loss 1.3981534242630005
Iteration 117: train_loss 1.4937444925308228
Iteration 118: train_loss 1.3452681303024292
Iteration 119: train_loss 1.4373061656951904
Iteration 120: train_loss 1.5138200521469116
Iteration 121: train_loss 1.4627670049667358
Iteration 122: train_loss 1.4320549964904785
Iteration 123: train_loss 1.4400486946105957
Iteration 124: train_loss 1.4080321788787842
Iteration 125: train_loss 1.4919910430908203
Iteration 126: train_loss 1.4405357837677002
Iteration 127: train_loss 1.4697892665863037
Iteration 128: train_loss 1.4138786792755127
Iteration 129: train_loss 1.4738043546676636
Iteration 130: train_loss 1.4753830432891846
Iteration 131: train_loss 1.4838632345199585
Iteration 132: train_loss 1.476773738861084
Iteration 133: train_loss 1.4507406949996948
Iteration 134: train_loss 1.4693819284439087
Iteration 135: train_loss 1.4575793743133545
Iteration 136: train_loss 1.4820725917816162
Iteration 137: train_loss 1.444018006324768
Iteration 138: train_loss 1.461909294128418
Iteration 139: train_loss 1.4393713474273682
Iteration 140: train_loss 1.4642202854156494
Iteration 141: train_loss 1.4691221714019775
Iteration 142: train_loss 1.3923627138137817
Iteration 143: train_loss 1.4265846014022827
Iteration 144: train_loss 1.472254991531372
Iteration 145: train_loss 1.415308952331543
Iteration 146: train_loss 1.4247204065322876
Iteration 147: train_loss 1.3979729413986206
Iteration 148: train_loss 1.441980242729187
Iteration 149: train_loss 1.4895025491714478
Iteration 150: train_loss 1.3903987407684326
Iteration 151: train_loss 1.468204379081726
Iteration 152: train_loss 1.3976185321807861
Iteration 153: train_loss 1.4340389966964722
Iteration 154: train_loss 1.396286964416504
Iteration 155: train_loss 1.4469324350357056
Iteration 156: train_loss 1.429429531097412
Iteration 157: train_loss 1.4541059732437134
Iteration 158: train_loss 1.4085302352905273
Iteration 159: train_loss 1.442579984664917
Iteration 160: train_loss 1.3992440700531006
Iteration 161: train_loss 1.3672585487365723
Iteration 162: train_loss 1.3703997135162354
Iteration 163: train_loss 1.349226474761963
Iteration 164: train_loss 1.3671026229858398
Iteration 165: train_loss 1.4361636638641357
Iteration 166: train_loss 1.3974812030792236
Iteration 167: train_loss 1.4504808187484741
Iteration 168: train_loss 1.435130000114441
Iteration 169: train_loss 1.490126371383667
Iteration 170: train_loss 1.5112428665161133
Iteration 171: train_loss 1.3912997245788574
Iteration 172: train_loss 1.441516637802124
Iteration 173: train_loss 1.4479575157165527
Iteration 174: train_loss 1.4930909872055054
Iteration 175: train_loss 1.4515703916549683
Iteration 176: train_loss 1.4035090208053589
Iteration 177: train_loss 1.5051372051239014
Epoch 93: train_avg_loss 1.4130355577684393 eval_avg_acc: 0.3257249253952421 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:51:32] [32mIntermediate result: 0.3257249253952421  (Index 92)[0m
================Epoch: 94================
Iteration 1: train_loss 1.3712122440338135
Iteration 2: train_loss 1.3639174699783325
Iteration 3: train_loss 1.4252912998199463
Iteration 4: train_loss 1.4156768321990967
Iteration 5: train_loss 1.4058969020843506
Iteration 6: train_loss 1.336968183517456
Iteration 7: train_loss 1.3694558143615723
Iteration 8: train_loss 1.3985835313796997
Iteration 9: train_loss 1.329368233680725
Iteration 10: train_loss 1.4075875282287598
Iteration 11: train_loss 1.40384042263031
Iteration 12: train_loss 1.3858362436294556
Iteration 13: train_loss 1.4467451572418213
Iteration 14: train_loss 1.330148696899414
Iteration 15: train_loss 1.3102374076843262
Iteration 16: train_loss 1.3574813604354858
Iteration 17: train_loss 1.421244740486145
Iteration 18: train_loss 1.3600618839263916
Iteration 19: train_loss 1.320487141609192
Iteration 20: train_loss 1.4140323400497437
Iteration 21: train_loss 1.3724457025527954
Iteration 22: train_loss 1.4049962759017944
Iteration 23: train_loss 1.2926180362701416
Iteration 24: train_loss 1.3263026475906372
Iteration 25: train_loss 1.358553171157837
Iteration 26: train_loss 1.3223206996917725
Iteration 27: train_loss 1.430994987487793
Iteration 28: train_loss 1.4216716289520264
Iteration 29: train_loss 1.377741813659668
Iteration 30: train_loss 1.3533343076705933
Iteration 31: train_loss 1.41036057472229
Iteration 32: train_loss 1.3536314964294434
Iteration 33: train_loss 1.3451873064041138
Iteration 34: train_loss 1.3489025831222534
Iteration 35: train_loss 1.3566100597381592
Iteration 36: train_loss 1.4060176610946655
Iteration 37: train_loss 1.4188640117645264
Iteration 38: train_loss 1.357003092765808
Iteration 39: train_loss 1.4328968524932861
Iteration 40: train_loss 1.4104924201965332
Iteration 41: train_loss 1.4296231269836426
Iteration 42: train_loss 1.4279218912124634
Iteration 43: train_loss 1.3834772109985352
Iteration 44: train_loss 1.4547147750854492
Iteration 45: train_loss 1.3908377885818481
Iteration 46: train_loss 1.3669193983078003
Iteration 47: train_loss 1.406407117843628
Iteration 48: train_loss 1.3707767724990845
Iteration 49: train_loss 1.3829386234283447
Iteration 50: train_loss 1.3639886379241943
Iteration 51: train_loss 1.452036738395691
Iteration 52: train_loss 1.392348051071167
Iteration 53: train_loss 1.334123969078064
Iteration 54: train_loss 1.344756841659546
Iteration 55: train_loss 1.404746413230896
Iteration 56: train_loss 1.3955813646316528
Iteration 57: train_loss 1.3544456958770752
Iteration 58: train_loss 1.3889838457107544
Iteration 59: train_loss 1.383240818977356
Iteration 60: train_loss 1.4166443347930908
Iteration 61: train_loss 1.4691925048828125
Iteration 62: train_loss 1.4327131509780884
Iteration 63: train_loss 1.4330998659133911
Iteration 64: train_loss 1.38084077835083
Iteration 65: train_loss 1.4447426795959473
Iteration 66: train_loss 1.4190528392791748
Iteration 67: train_loss 1.4042887687683105
Iteration 68: train_loss 1.396124243736267
Iteration 69: train_loss 1.4519808292388916
Iteration 70: train_loss 1.4554381370544434
Iteration 71: train_loss 1.354079246520996
Iteration 72: train_loss 1.4354279041290283
Iteration 73: train_loss 1.347989797592163
Iteration 74: train_loss 1.4478024244308472
Iteration 75: train_loss 1.4074757099151611
Iteration 76: train_loss 1.4099125862121582
Iteration 77: train_loss 1.363309621810913
Iteration 78: train_loss 1.4256690740585327
Iteration 79: train_loss 1.4257538318634033
Iteration 80: train_loss 1.3891541957855225
Iteration 81: train_loss 1.4128167629241943
Iteration 82: train_loss 1.4429800510406494
Iteration 83: train_loss 1.4907106161117554
Iteration 84: train_loss 1.4596314430236816
Iteration 85: train_loss 1.3834913969039917
Iteration 86: train_loss 1.391225814819336
Iteration 87: train_loss 1.3908209800720215
Iteration 88: train_loss 1.4187973737716675
Iteration 89: train_loss 1.4174491167068481
Iteration 90: train_loss 1.4104194641113281
Iteration 91: train_loss 1.3838542699813843
Iteration 92: train_loss 1.4263606071472168
Iteration 93: train_loss 1.3277363777160645
Iteration 94: train_loss 1.344644546508789
Iteration 95: train_loss 1.3844642639160156
Iteration 96: train_loss 1.4444806575775146
Iteration 97: train_loss 1.4780813455581665
Iteration 98: train_loss 1.4293365478515625
Iteration 99: train_loss 1.402222990989685
Iteration 100: train_loss 1.3765136003494263
Iteration 101: train_loss 1.3700789213180542
Iteration 102: train_loss 1.4118800163269043
Iteration 103: train_loss 1.4522396326065063
Iteration 104: train_loss 1.378395915031433
Iteration 105: train_loss 1.3785948753356934
Iteration 106: train_loss 1.405836582183838
Iteration 107: train_loss 1.3983429670333862
Iteration 108: train_loss 1.4020811319351196
Iteration 109: train_loss 1.3897156715393066
Iteration 110: train_loss 1.4181267023086548
Iteration 111: train_loss 1.398923397064209
Iteration 112: train_loss 1.3575217723846436
Iteration 113: train_loss 1.4251790046691895
Iteration 114: train_loss 1.3750762939453125
Iteration 115: train_loss 1.3999217748641968
Iteration 116: train_loss 1.4023841619491577
Iteration 117: train_loss 1.367671012878418
Iteration 118: train_loss 1.4001178741455078
Iteration 119: train_loss 1.3950786590576172
Iteration 120: train_loss 1.385926604270935
Iteration 121: train_loss 1.3802651166915894
Iteration 122: train_loss 1.3947426080703735
Iteration 123: train_loss 1.331313133239746
Iteration 124: train_loss 1.3492790460586548
Iteration 125: train_loss 1.386010766029358
Iteration 126: train_loss 1.4179911613464355
Iteration 127: train_loss 1.3624225854873657
Iteration 128: train_loss 1.3814573287963867
Iteration 129: train_loss 1.3226113319396973
Iteration 130: train_loss 1.4409326314926147
Iteration 131: train_loss 1.4075069427490234
Iteration 132: train_loss 1.386708378791809
Iteration 133: train_loss 1.3782968521118164
Iteration 134: train_loss 1.3657032251358032
Iteration 135: train_loss 1.4217944145202637
Iteration 136: train_loss 1.3799877166748047
Iteration 137: train_loss 1.3176143169403076
Iteration 138: train_loss 1.3425190448760986
Iteration 139: train_loss 1.3988696336746216
Iteration 140: train_loss 1.4273744821548462
Iteration 141: train_loss 1.4176143407821655
Iteration 142: train_loss 1.361753225326538
Iteration 143: train_loss 1.4105411767959595
Iteration 144: train_loss 1.3759980201721191
Iteration 145: train_loss 1.3322694301605225
Iteration 146: train_loss 1.3764643669128418
Iteration 147: train_loss 1.4477388858795166
Iteration 148: train_loss 1.4199142456054688
Iteration 149: train_loss 1.443017601966858
Iteration 150: train_loss 1.4342591762542725
Iteration 151: train_loss 1.3875818252563477
Iteration 152: train_loss 1.427363634109497
Iteration 153: train_loss 1.3653348684310913
Iteration 154: train_loss 1.4052226543426514
Iteration 155: train_loss 1.388071060180664
Iteration 156: train_loss 1.3638105392456055
Iteration 157: train_loss 1.4309815168380737
Iteration 158: train_loss 1.465955138206482
Iteration 159: train_loss 1.3644579648971558
Iteration 160: train_loss 1.4389196634292603
Iteration 161: train_loss 1.344940185546875
Iteration 162: train_loss 1.412517786026001
Iteration 163: train_loss 1.4310811758041382
Iteration 164: train_loss 1.5503371953964233
Iteration 165: train_loss 1.3881404399871826
Iteration 166: train_loss 1.4142752885818481
Iteration 167: train_loss 1.4095535278320312
Iteration 168: train_loss 1.375930905342102
Iteration 169: train_loss 1.4391751289367676
Iteration 170: train_loss 1.4089393615722656
Iteration 171: train_loss 1.4017239809036255
Iteration 172: train_loss 1.3790117502212524
Iteration 173: train_loss 1.3397727012634277
Iteration 174: train_loss 1.385744333267212
Iteration 175: train_loss 1.4032503366470337
Iteration 176: train_loss 1.4077550172805786
Iteration 177: train_loss 1.4506726264953613
Epoch 94: train_avg_loss 1.3951197929975003 eval_avg_acc: 0.34176522145843813 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:52:14] [32mIntermediate result: 0.34176522145843813  (Index 93)[0m
================Epoch: 95================
Iteration 1: train_loss 1.406744360923767
Iteration 2: train_loss 1.4133423566818237
Iteration 3: train_loss 1.3970271348953247
Iteration 4: train_loss 1.3747837543487549
Iteration 5: train_loss 1.3742934465408325
Iteration 6: train_loss 1.364151120185852
Iteration 7: train_loss 1.3468774557113647
Iteration 8: train_loss 1.3785655498504639
Iteration 9: train_loss 1.4016705751419067
Iteration 10: train_loss 1.4078447818756104
Iteration 11: train_loss 1.4071444272994995
Iteration 12: train_loss 1.398561954498291
Iteration 13: train_loss 1.336299180984497
Iteration 14: train_loss 1.3568190336227417
Iteration 15: train_loss 1.3671153783798218
Iteration 16: train_loss 1.4097216129302979
Iteration 17: train_loss 1.4260402917861938
Iteration 18: train_loss 1.3941986560821533
Iteration 19: train_loss 1.3398078680038452
Iteration 20: train_loss 1.3851091861724854
Iteration 21: train_loss 1.4102399349212646
Iteration 22: train_loss 1.394606590270996
Iteration 23: train_loss 1.3302698135375977
Iteration 24: train_loss 1.380165696144104
Iteration 25: train_loss 1.3446011543273926
Iteration 26: train_loss 1.3419188261032104
Iteration 27: train_loss 1.3993488550186157
Iteration 28: train_loss 1.360022783279419
Iteration 29: train_loss 1.4189146757125854
Iteration 30: train_loss 1.3315203189849854
Iteration 31: train_loss 1.3522449731826782
Iteration 32: train_loss 1.3504481315612793
Iteration 33: train_loss 1.4226731061935425
Iteration 34: train_loss 1.405126929283142
Iteration 35: train_loss 1.3741381168365479
Iteration 36: train_loss 1.451850414276123
Iteration 37: train_loss 1.437948226928711
Iteration 38: train_loss 1.4075281620025635
Iteration 39: train_loss 1.345625638961792
Iteration 40: train_loss 1.461916208267212
Iteration 41: train_loss 1.4068022966384888
Iteration 42: train_loss 1.3940058946609497
Iteration 43: train_loss 1.4182145595550537
Iteration 44: train_loss 1.417657732963562
Iteration 45: train_loss 1.4347947835922241
Iteration 46: train_loss 1.3835505247116089
Iteration 47: train_loss 1.445285677909851
Iteration 48: train_loss 1.403702735900879
Iteration 49: train_loss 1.3921290636062622
Iteration 50: train_loss 1.4092735052108765
Iteration 51: train_loss 1.4415545463562012
Iteration 52: train_loss 1.4413832426071167
Iteration 53: train_loss 1.4084761142730713
Iteration 54: train_loss 1.403308391571045
Iteration 55: train_loss 1.3828110694885254
Iteration 56: train_loss 1.3869625329971313
Iteration 57: train_loss 1.4479237794876099
Iteration 58: train_loss 1.4125514030456543
Iteration 59: train_loss 1.4500911235809326
Iteration 60: train_loss 1.4226490259170532
Iteration 61: train_loss 1.3944553136825562
Iteration 62: train_loss 1.4382901191711426
Iteration 63: train_loss 1.4364211559295654
Iteration 64: train_loss 1.4071062803268433
Iteration 65: train_loss 1.3255724906921387
Iteration 66: train_loss 1.4036123752593994
Iteration 67: train_loss 1.3954161405563354
Iteration 68: train_loss 1.4114683866500854
Iteration 69: train_loss 1.423753261566162
Iteration 70: train_loss 1.4459573030471802
Iteration 71: train_loss 1.3634546995162964
Iteration 72: train_loss 1.363781213760376
Iteration 73: train_loss 1.3533051013946533
Iteration 74: train_loss 1.3693710565567017
Iteration 75: train_loss 1.3766793012619019
Iteration 76: train_loss 1.3766069412231445
Iteration 77: train_loss 1.3756885528564453
Iteration 78: train_loss 1.4677878618240356
Iteration 79: train_loss 1.357439398765564
Iteration 80: train_loss 1.3781068325042725
Iteration 81: train_loss 1.3736755847930908
Iteration 82: train_loss 1.3430266380310059
Iteration 83: train_loss 1.3344573974609375
Iteration 84: train_loss 1.3852981328964233
Iteration 85: train_loss 1.40748929977417
Iteration 86: train_loss 1.4190123081207275
Iteration 87: train_loss 1.3730238676071167
Iteration 88: train_loss 1.428056240081787
Iteration 89: train_loss 1.3941760063171387
Iteration 90: train_loss 1.4007595777511597
Iteration 91: train_loss 1.4175807237625122
Iteration 92: train_loss 1.4159780740737915
Iteration 93: train_loss 1.4179786443710327
Iteration 94: train_loss 1.4052387475967407
Iteration 95: train_loss 1.4310123920440674
Iteration 96: train_loss 1.3711141347885132
Iteration 97: train_loss 1.3887947797775269
Iteration 98: train_loss 1.4125525951385498
Iteration 99: train_loss 1.3820362091064453
Iteration 100: train_loss 1.4478267431259155
Iteration 101: train_loss 1.3914068937301636
Iteration 102: train_loss 1.4454773664474487
Iteration 103: train_loss 1.4024772644042969
Iteration 104: train_loss 1.4434298276901245
Iteration 105: train_loss 1.4629592895507812
Iteration 106: train_loss 1.4483203887939453
Iteration 107: train_loss 1.40956711769104
Iteration 108: train_loss 1.423909068107605
Iteration 109: train_loss 1.3998843431472778
Iteration 110: train_loss 1.484480857849121
Iteration 111: train_loss 1.4117984771728516
Iteration 112: train_loss 1.4041274785995483
Iteration 113: train_loss 1.3363860845565796
Iteration 114: train_loss 1.41388738155365
Iteration 115: train_loss 1.5071983337402344
Iteration 116: train_loss 1.4353305101394653
Iteration 117: train_loss 1.4441839456558228
Iteration 118: train_loss 1.4619967937469482
Iteration 119: train_loss 1.4202224016189575
Iteration 120: train_loss 1.4619652032852173
Iteration 121: train_loss 1.4193567037582397
Iteration 122: train_loss 1.4494953155517578
Iteration 123: train_loss 1.4447870254516602
Iteration 124: train_loss 1.4210131168365479
Iteration 125: train_loss 1.4143760204315186
Iteration 126: train_loss 1.4097223281860352
Iteration 127: train_loss 1.4121387004852295
Iteration 128: train_loss 1.3915573358535767
Iteration 129: train_loss 1.4551845788955688
Iteration 130: train_loss 1.4343239068984985
Iteration 131: train_loss 1.3840357065200806
Iteration 132: train_loss 1.4469208717346191
Iteration 133: train_loss 1.3722645044326782
Iteration 134: train_loss 1.3876997232437134
Iteration 135: train_loss 1.4022432565689087
Iteration 136: train_loss 1.470118522644043
Iteration 137: train_loss 1.4174799919128418
Iteration 138: train_loss 1.384709119796753
Iteration 139: train_loss 1.369768738746643
Iteration 140: train_loss 1.5200809240341187
Iteration 141: train_loss 1.4638456106185913
Iteration 142: train_loss 1.4422259330749512
Iteration 143: train_loss 1.4599640369415283
Iteration 144: train_loss 1.4052972793579102
Iteration 145: train_loss 1.409331202507019
Iteration 146: train_loss 1.4036113023757935
Iteration 147: train_loss 1.4484888315200806
Iteration 148: train_loss 1.4617692232131958
Iteration 149: train_loss 1.4596643447875977
Iteration 150: train_loss 1.3744982481002808
Iteration 151: train_loss 1.44203782081604
Iteration 152: train_loss 1.3844798803329468
Iteration 153: train_loss 1.430694580078125
Iteration 154: train_loss 1.4098256826400757
Iteration 155: train_loss 1.4276251792907715
Iteration 156: train_loss 1.393319845199585
Iteration 157: train_loss 1.3369719982147217
Iteration 158: train_loss 1.411320447921753
Iteration 159: train_loss 1.3929723501205444
Iteration 160: train_loss 1.400925636291504
Iteration 161: train_loss 1.397719144821167
Iteration 162: train_loss 1.3437139987945557
Iteration 163: train_loss 1.4454759359359741
Iteration 164: train_loss 1.442660927772522
Iteration 165: train_loss 1.3974783420562744
Iteration 166: train_loss 1.359346628189087
Iteration 167: train_loss 1.4330823421478271
Iteration 168: train_loss 1.4383279085159302
Iteration 169: train_loss 1.4111818075180054
Iteration 170: train_loss 1.3809748888015747
Iteration 171: train_loss 1.4184346199035645
Iteration 172: train_loss 1.4420115947723389
Iteration 173: train_loss 1.4961198568344116
Iteration 174: train_loss 1.3836063146591187
Iteration 175: train_loss 1.3901680707931519
Iteration 176: train_loss 1.4091262817382812
Iteration 177: train_loss 1.4096667766571045
Epoch 95: train_avg_loss 1.406203202608615 eval_avg_acc: 0.34431904585442463 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:52:56] [32mIntermediate result: 0.34431904585442463  (Index 94)[0m
================Epoch: 96================
Iteration 1: train_loss 1.336935043334961
Iteration 2: train_loss 1.265537142753601
Iteration 3: train_loss 1.3565000295639038
Iteration 4: train_loss 1.3743174076080322
Iteration 5: train_loss 1.3247637748718262
Iteration 6: train_loss 1.4200221300125122
Iteration 7: train_loss 1.3567177057266235
Iteration 8: train_loss 1.4386587142944336
Iteration 9: train_loss 1.3561931848526
Iteration 10: train_loss 1.4196845293045044
Iteration 11: train_loss 1.405694842338562
Iteration 12: train_loss 1.3957635164260864
Iteration 13: train_loss 1.3420253992080688
Iteration 14: train_loss 1.4582021236419678
Iteration 15: train_loss 1.340597152709961
Iteration 16: train_loss 1.3498554229736328
Iteration 17: train_loss 1.3261008262634277
Iteration 18: train_loss 1.3418247699737549
Iteration 19: train_loss 1.3618148565292358
Iteration 20: train_loss 1.3509705066680908
Iteration 21: train_loss 1.3337515592575073
Iteration 22: train_loss 1.3681918382644653
Iteration 23: train_loss 1.3360991477966309
Iteration 24: train_loss 1.3581727743148804
Iteration 25: train_loss 1.3489431142807007
Iteration 26: train_loss 1.3223986625671387
Iteration 27: train_loss 1.3539643287658691
Iteration 28: train_loss 1.341160535812378
Iteration 29: train_loss 1.321773648262024
Iteration 30: train_loss 1.360121250152588
Iteration 31: train_loss 1.337862491607666
Iteration 32: train_loss 1.3966927528381348
Iteration 33: train_loss 1.3612043857574463
Iteration 34: train_loss 1.3377329111099243
Iteration 35: train_loss 1.3745524883270264
Iteration 36: train_loss 1.4343878030776978
Iteration 37: train_loss 1.3616143465042114
Iteration 38: train_loss 1.3945283889770508
Iteration 39: train_loss 1.3973385095596313
Iteration 40: train_loss 1.4196935892105103
Iteration 41: train_loss 1.3837803602218628
Iteration 42: train_loss 1.3184092044830322
Iteration 43: train_loss 1.3602505922317505
Iteration 44: train_loss 1.385666847229004
Iteration 45: train_loss 1.382797360420227
Iteration 46: train_loss 1.3604788780212402
Iteration 47: train_loss 1.3634629249572754
Iteration 48: train_loss 1.328436255455017
Iteration 49: train_loss 1.417364478111267
Iteration 50: train_loss 1.3288419246673584
Iteration 51: train_loss 1.398714303970337
Iteration 52: train_loss 1.3546351194381714
Iteration 53: train_loss 1.323075532913208
Iteration 54: train_loss 1.3534209728240967
Iteration 55: train_loss 1.4096479415893555
Iteration 56: train_loss 1.335877776145935
Iteration 57: train_loss 1.388231873512268
Iteration 58: train_loss 1.4079723358154297
Iteration 59: train_loss 1.3873121738433838
Iteration 60: train_loss 1.407594919204712
Iteration 61: train_loss 1.4208176136016846
Iteration 62: train_loss 1.4902077913284302
Iteration 63: train_loss 1.429513931274414
Iteration 64: train_loss 1.3392118215560913
Iteration 65: train_loss 1.3775075674057007
Iteration 66: train_loss 1.390562653541565
Iteration 67: train_loss 1.4292099475860596
Iteration 68: train_loss 1.4554293155670166
Iteration 69: train_loss 1.4229458570480347
Iteration 70: train_loss 1.4522682428359985
Iteration 71: train_loss 1.4099682569503784
Iteration 72: train_loss 1.382171869277954
Iteration 73: train_loss 1.4178944826126099
Iteration 74: train_loss 1.4089664220809937
Iteration 75: train_loss 1.3668493032455444
Iteration 76: train_loss 1.4348591566085815
Iteration 77: train_loss 1.4104552268981934
Iteration 78: train_loss 1.4172673225402832
Iteration 79: train_loss 1.3722723722457886
Iteration 80: train_loss 1.4008140563964844
Iteration 81: train_loss 1.4138507843017578
Iteration 82: train_loss 1.3733795881271362
Iteration 83: train_loss 1.4654525518417358
Iteration 84: train_loss 1.411943793296814
Iteration 85: train_loss 1.4149354696273804
Iteration 86: train_loss 1.4678696393966675
Iteration 87: train_loss 1.3925565481185913
Iteration 88: train_loss 1.4420068264007568
Iteration 89: train_loss 1.4262233972549438
Iteration 90: train_loss 1.4140005111694336
Iteration 91: train_loss 1.3795157670974731
Iteration 92: train_loss 1.435483455657959
Iteration 93: train_loss 1.3834797143936157
Iteration 94: train_loss 1.4351733922958374
Iteration 95: train_loss 1.4066017866134644
Iteration 96: train_loss 1.400037407875061
Iteration 97: train_loss 1.4778461456298828
Iteration 98: train_loss 1.4737975597381592
Iteration 99: train_loss 1.3759570121765137
Iteration 100: train_loss 1.3562185764312744
Iteration 101: train_loss 1.4054745435714722
Iteration 102: train_loss 1.4008817672729492
Iteration 103: train_loss 1.478076696395874
Iteration 104: train_loss 1.4537769556045532
Iteration 105: train_loss 1.4335263967514038
Iteration 106: train_loss 1.3253885507583618
Iteration 107: train_loss 1.4334911108016968
Iteration 108: train_loss 1.3703150749206543
Iteration 109: train_loss 1.4037036895751953
Iteration 110: train_loss 1.3991186618804932
Iteration 111: train_loss 1.3943448066711426
Iteration 112: train_loss 1.4315789937973022
Iteration 113: train_loss 1.3851262331008911
Iteration 114: train_loss 1.477394461631775
Iteration 115: train_loss 1.391518473625183
Iteration 116: train_loss 1.4773958921432495
Iteration 117: train_loss 1.3662545680999756
Iteration 118: train_loss 1.3920023441314697
Iteration 119: train_loss 1.4045913219451904
Iteration 120: train_loss 1.3957886695861816
Iteration 121: train_loss 1.426261067390442
Iteration 122: train_loss 1.3493375778198242
Iteration 123: train_loss 1.4332681894302368
Iteration 124: train_loss 1.43948233127594
Iteration 125: train_loss 1.4002811908721924
Iteration 126: train_loss 1.3608614206314087
Iteration 127: train_loss 1.401376724243164
Iteration 128: train_loss 1.3672676086425781
Iteration 129: train_loss 1.431841492652893
Iteration 130: train_loss 1.3911842107772827
Iteration 131: train_loss 1.4609134197235107
Iteration 132: train_loss 1.4376204013824463
Iteration 133: train_loss 1.377234697341919
Iteration 134: train_loss 1.3753316402435303
Iteration 135: train_loss 1.3485386371612549
Iteration 136: train_loss 1.3219397068023682
Iteration 137: train_loss 1.3371986150741577
Iteration 138: train_loss 1.387632966041565
Iteration 139: train_loss 1.443440318107605
Iteration 140: train_loss 1.395716905593872
Iteration 141: train_loss 1.3702952861785889
Iteration 142: train_loss 1.4226415157318115
Iteration 143: train_loss 1.4408248662948608
Iteration 144: train_loss 1.433390736579895
Iteration 145: train_loss 1.3965849876403809
Iteration 146: train_loss 1.4444330930709839
Iteration 147: train_loss 1.41233229637146
Iteration 148: train_loss 1.4464141130447388
Iteration 149: train_loss 1.4345171451568604
Iteration 150: train_loss 1.4085235595703125
Iteration 151: train_loss 1.4291960000991821
Iteration 152: train_loss 1.3866108655929565
Iteration 153: train_loss 1.4202842712402344
Iteration 154: train_loss 1.4130245447158813
Iteration 155: train_loss 1.4511539936065674
Iteration 156: train_loss 1.4470642805099487
Iteration 157: train_loss 1.4120192527770996
Iteration 158: train_loss 1.4248050451278687
Iteration 159: train_loss 1.4268913269042969
Iteration 160: train_loss 1.4212597608566284
Iteration 161: train_loss 1.4505864381790161
Iteration 162: train_loss 1.4452390670776367
Iteration 163: train_loss 1.464043140411377
Iteration 164: train_loss 1.4547171592712402
Iteration 165: train_loss 1.431825876235962
Iteration 166: train_loss 1.4394811391830444
Iteration 167: train_loss 1.4475699663162231
Iteration 168: train_loss 1.4107754230499268
Iteration 169: train_loss 1.3767955303192139
Iteration 170: train_loss 1.3851596117019653
Iteration 171: train_loss 1.4332948923110962
Iteration 172: train_loss 1.3934224843978882
Iteration 173: train_loss 1.4046319723129272
Iteration 174: train_loss 1.4486703872680664
Iteration 175: train_loss 1.4235774278640747
Iteration 176: train_loss 1.3827052116394043
Iteration 177: train_loss 1.380225419998169
Epoch 96: train_avg_loss 1.3970357341281439 eval_avg_acc: 0.33730241253017157 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:53:37] [32mIntermediate result: 0.33730241253017157  (Index 95)[0m
================Epoch: 97================
Iteration 1: train_loss 1.3992271423339844
Iteration 2: train_loss 1.3732092380523682
Iteration 3: train_loss 1.4211132526397705
Iteration 4: train_loss 1.3413093090057373
Iteration 5: train_loss 1.3670464754104614
Iteration 6: train_loss 1.4110311269760132
Iteration 7: train_loss 1.3720438480377197
Iteration 8: train_loss 1.3789454698562622
Iteration 9: train_loss 1.3876293897628784
Iteration 10: train_loss 1.3365421295166016
Iteration 11: train_loss 1.3709089756011963
Iteration 12: train_loss 1.3638551235198975
Iteration 13: train_loss 1.4219048023223877
Iteration 14: train_loss 1.4364460706710815
Iteration 15: train_loss 1.350441336631775
Iteration 16: train_loss 1.3672535419464111
Iteration 17: train_loss 1.3752191066741943
Iteration 18: train_loss 1.3537689447402954
Iteration 19: train_loss 1.3621115684509277
Iteration 20: train_loss 1.4441779851913452
Iteration 21: train_loss 1.3969428539276123
Iteration 22: train_loss 1.442502737045288
Iteration 23: train_loss 1.3471739292144775
Iteration 24: train_loss 1.3966114521026611
Iteration 25: train_loss 1.3737696409225464
Iteration 26: train_loss 1.3483353853225708
Iteration 27: train_loss 1.4280768632888794
Iteration 28: train_loss 1.4023103713989258
Iteration 29: train_loss 1.4187846183776855
Iteration 30: train_loss 1.4199461936950684
Iteration 31: train_loss 1.3830584287643433
Iteration 32: train_loss 1.4263464212417603
Iteration 33: train_loss 1.408722162246704
Iteration 34: train_loss 1.416925311088562
Iteration 35: train_loss 1.3594132661819458
Iteration 36: train_loss 1.3626559972763062
Iteration 37: train_loss 1.3717398643493652
Iteration 38: train_loss 1.3840690851211548
Iteration 39: train_loss 1.4999576807022095
Iteration 40: train_loss 1.4580049514770508
Iteration 41: train_loss 1.3370009660720825
Iteration 42: train_loss 1.4090086221694946
Iteration 43: train_loss 1.4467475414276123
Iteration 44: train_loss 1.3572843074798584
Iteration 45: train_loss 1.3934184312820435
Iteration 46: train_loss 1.3626744747161865
Iteration 47: train_loss 1.4263625144958496
Iteration 48: train_loss 1.3819990158081055
Iteration 49: train_loss 1.3625890016555786
Iteration 50: train_loss 1.3782325983047485
Iteration 51: train_loss 1.4124990701675415
Iteration 52: train_loss 1.4028315544128418
Iteration 53: train_loss 1.4128533601760864
Iteration 54: train_loss 1.4263423681259155
Iteration 55: train_loss 1.4055753946304321
Iteration 56: train_loss 1.408571720123291
Iteration 57: train_loss 1.385522723197937
Iteration 58: train_loss 1.404657244682312
Iteration 59: train_loss 1.4484734535217285
Iteration 60: train_loss 1.37648606300354
Iteration 61: train_loss 1.4257439374923706
Iteration 62: train_loss 1.3752130270004272
Iteration 63: train_loss 1.4529998302459717
Iteration 64: train_loss 1.395120620727539
Iteration 65: train_loss 1.4176253080368042
Iteration 66: train_loss 1.4023845195770264
Iteration 67: train_loss 1.4284437894821167
Iteration 68: train_loss 1.3888055086135864
Iteration 69: train_loss 1.3682160377502441
Iteration 70: train_loss 1.3753496408462524
Iteration 71: train_loss 1.3865667581558228
Iteration 72: train_loss 1.3932501077651978
Iteration 73: train_loss 1.3347644805908203
Iteration 74: train_loss 1.3977596759796143
Iteration 75: train_loss 1.4167213439941406
Iteration 76: train_loss 1.3685888051986694
Iteration 77: train_loss 1.3623178005218506
Iteration 78: train_loss 1.3989579677581787
Iteration 79: train_loss 1.3400189876556396
Iteration 80: train_loss 1.3668875694274902
Iteration 81: train_loss 1.438302755355835
Iteration 82: train_loss 1.4001761674880981
Iteration 83: train_loss 1.400349497795105
Iteration 84: train_loss 1.4156298637390137
Iteration 85: train_loss 1.326682448387146
Iteration 86: train_loss 1.3879104852676392
Iteration 87: train_loss 1.4287899732589722
Iteration 88: train_loss 1.4065515995025635
Iteration 89: train_loss 1.432233214378357
Iteration 90: train_loss 1.3672000169754028
Iteration 91: train_loss 1.3803752660751343
Iteration 92: train_loss 1.3819243907928467
Iteration 93: train_loss 1.3633942604064941
Iteration 94: train_loss 1.3993721008300781
Iteration 95: train_loss 1.4289358854293823
Iteration 96: train_loss 1.3840497732162476
Iteration 97: train_loss 1.4109265804290771
Iteration 98: train_loss 1.3688613176345825
Iteration 99: train_loss 1.3432981967926025
Iteration 100: train_loss 1.412853479385376
Iteration 101: train_loss 1.391017198562622
Iteration 102: train_loss 1.4292576313018799
Iteration 103: train_loss 1.362695336341858
Iteration 104: train_loss 1.3668324947357178
Iteration 105: train_loss 1.4011231660842896
Iteration 106: train_loss 1.3894035816192627
Iteration 107: train_loss 1.412614107131958
Iteration 108: train_loss 1.4448555707931519
Iteration 109: train_loss 1.4272037744522095
Iteration 110: train_loss 1.4471454620361328
Iteration 111: train_loss 1.4221404790878296
Iteration 112: train_loss 1.4171289205551147
Iteration 113: train_loss 1.423882007598877
Iteration 114: train_loss 1.4327293634414673
Iteration 115: train_loss 1.4275102615356445
Iteration 116: train_loss 1.407548189163208
Iteration 117: train_loss 1.396682620048523
Iteration 118: train_loss 1.3947904109954834
Iteration 119: train_loss 1.3937857151031494
Iteration 120: train_loss 1.419947624206543
Iteration 121: train_loss 1.3847737312316895
Iteration 122: train_loss 1.3969942331314087
Iteration 123: train_loss 1.349658489227295
Iteration 124: train_loss 1.3722320795059204
Iteration 125: train_loss 1.4085370302200317
Iteration 126: train_loss 1.3833473920822144
Iteration 127: train_loss 1.436179518699646
Iteration 128: train_loss 1.3780477046966553
Iteration 129: train_loss 1.3865272998809814
Iteration 130: train_loss 1.3837714195251465
Iteration 131: train_loss 1.4031217098236084
Iteration 132: train_loss 1.3979767560958862
Iteration 133: train_loss 1.4332467317581177
Iteration 134: train_loss 1.3830175399780273
Iteration 135: train_loss 1.359299898147583
Iteration 136: train_loss 1.4172909259796143
Iteration 137: train_loss 1.3657468557357788
Iteration 138: train_loss 1.3728982210159302
Iteration 139: train_loss 1.4173349142074585
Iteration 140: train_loss 1.4067306518554688
Iteration 141: train_loss 1.4451377391815186
Iteration 142: train_loss 1.4667472839355469
Iteration 143: train_loss 1.3731226921081543
Iteration 144: train_loss 1.3845536708831787
Iteration 145: train_loss 1.4457123279571533
Iteration 146: train_loss 1.491064429283142
Iteration 147: train_loss 1.4767042398452759
Iteration 148: train_loss 1.4774960279464722
Iteration 149: train_loss 1.3538930416107178
Iteration 150: train_loss 1.4101483821868896
Iteration 151: train_loss 1.3700909614562988
Iteration 152: train_loss 1.388776183128357
Iteration 153: train_loss 1.443669319152832
Iteration 154: train_loss 1.3959742784500122
Iteration 155: train_loss 1.4274982213974
Iteration 156: train_loss 1.3782819509506226
Iteration 157: train_loss 1.3926113843917847
Iteration 158: train_loss 1.3819328546524048
Iteration 159: train_loss 1.4185395240783691
Iteration 160: train_loss 1.3785829544067383
Iteration 161: train_loss 1.387411117553711
Iteration 162: train_loss 1.4679561853408813
Iteration 163: train_loss 1.3732231855392456
Iteration 164: train_loss 1.3755168914794922
Iteration 165: train_loss 1.3652983903884888
Iteration 166: train_loss 1.3760452270507812
Iteration 167: train_loss 1.357466220855713
Iteration 168: train_loss 1.379538655281067
Iteration 169: train_loss 1.4116132259368896
Iteration 170: train_loss 1.3818286657333374
Iteration 171: train_loss 1.3545517921447754
Iteration 172: train_loss 1.4483098983764648
Iteration 173: train_loss 1.407936453819275
Iteration 174: train_loss 1.382752776145935
Iteration 175: train_loss 1.4383199214935303
Iteration 176: train_loss 1.3781944513320923
Iteration 177: train_loss 1.4311186075210571
Epoch 97: train_avg_loss 1.3974850938818548 eval_avg_acc: 0.34588700613058293 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:54:18] [32mIntermediate result: 0.34588700613058293  (Index 96)[0m
================Epoch: 98================
Iteration 1: train_loss 1.3952696323394775
Iteration 2: train_loss 1.3569961786270142
Iteration 3: train_loss 1.334327220916748
Iteration 4: train_loss 1.3674142360687256
Iteration 5: train_loss 1.3364059925079346
Iteration 6: train_loss 1.3365401029586792
Iteration 7: train_loss 1.391632318496704
Iteration 8: train_loss 1.3697682619094849
Iteration 9: train_loss 1.3863085508346558
Iteration 10: train_loss 1.311813473701477
Iteration 11: train_loss 1.3489327430725098
Iteration 12: train_loss 1.3444812297821045
Iteration 13: train_loss 1.353717565536499
Iteration 14: train_loss 1.342981219291687
Iteration 15: train_loss 1.3551721572875977
Iteration 16: train_loss 1.3710185289382935
Iteration 17: train_loss 1.4284594058990479
Iteration 18: train_loss 1.3721330165863037
Iteration 19: train_loss 1.432032823562622
Iteration 20: train_loss 1.3285458087921143
Iteration 21: train_loss 1.4149200916290283
Iteration 22: train_loss 1.3774062395095825
Iteration 23: train_loss 1.4516067504882812
Iteration 24: train_loss 1.382267951965332
Iteration 25: train_loss 1.3789317607879639
Iteration 26: train_loss 1.3591715097427368
Iteration 27: train_loss 1.4264546632766724
Iteration 28: train_loss 1.4177228212356567
Iteration 29: train_loss 1.3942679166793823
Iteration 30: train_loss 1.3936278820037842
Iteration 31: train_loss 1.388495922088623
Iteration 32: train_loss 1.3524599075317383
Iteration 33: train_loss 1.3858082294464111
Iteration 34: train_loss 1.3898823261260986
Iteration 35: train_loss 1.3642629384994507
Iteration 36: train_loss 1.4062670469284058
Iteration 37: train_loss 1.37025785446167
Iteration 38: train_loss 1.3780286312103271
Iteration 39: train_loss 1.3843683004379272
Iteration 40: train_loss 1.3982484340667725
Iteration 41: train_loss 1.4182219505310059
Iteration 42: train_loss 1.3950985670089722
Iteration 43: train_loss 1.392544150352478
Iteration 44: train_loss 1.3943392038345337
Iteration 45: train_loss 1.345751404762268
Iteration 46: train_loss 1.3980515003204346
Iteration 47: train_loss 1.3804476261138916
Iteration 48: train_loss 1.3762481212615967
Iteration 49: train_loss 1.3043853044509888
Iteration 50: train_loss 1.365360140800476
Iteration 51: train_loss 1.4177649021148682
Iteration 52: train_loss 1.4256435632705688
Iteration 53: train_loss 1.3473116159439087
Iteration 54: train_loss 1.345325231552124
Iteration 55: train_loss 1.3485552072525024
Iteration 56: train_loss 1.3577237129211426
Iteration 57: train_loss 1.4068083763122559
Iteration 58: train_loss 1.4265813827514648
Iteration 59: train_loss 1.3910644054412842
Iteration 60: train_loss 1.3228551149368286
Iteration 61: train_loss 1.3517526388168335
Iteration 62: train_loss 1.4784175157546997
Iteration 63: train_loss 1.499620795249939
Iteration 64: train_loss 1.3807694911956787
Iteration 65: train_loss 1.2905492782592773
Iteration 66: train_loss 1.37855064868927
Iteration 67: train_loss 1.3409554958343506
Iteration 68: train_loss 1.417599081993103
Iteration 69: train_loss 1.4483734369277954
Iteration 70: train_loss 1.3602821826934814
Iteration 71: train_loss 1.3980518579483032
Iteration 72: train_loss 1.3747992515563965
Iteration 73: train_loss 1.362552285194397
Iteration 74: train_loss 1.3593659400939941
Iteration 75: train_loss 1.4266157150268555
Iteration 76: train_loss 1.404725432395935
Iteration 77: train_loss 1.3163282871246338
Iteration 78: train_loss 1.4446192979812622
Iteration 79: train_loss 1.3858458995819092
Iteration 80: train_loss 1.3718849420547485
Iteration 81: train_loss 1.3527846336364746
Iteration 82: train_loss 1.3898565769195557
Iteration 83: train_loss 1.3660062551498413
Iteration 84: train_loss 1.4108752012252808
Iteration 85: train_loss 1.383463978767395
Iteration 86: train_loss 1.3957573175430298
Iteration 87: train_loss 1.4265587329864502
Iteration 88: train_loss 1.2982889413833618
Iteration 89: train_loss 1.3628885746002197
Iteration 90: train_loss 1.389919638633728
Iteration 91: train_loss 1.3727871179580688
Iteration 92: train_loss 1.3953542709350586
Iteration 93: train_loss 1.400765061378479
Iteration 94: train_loss 1.4269952774047852
Iteration 95: train_loss 1.4066513776779175
Iteration 96: train_loss 1.3701140880584717
Iteration 97: train_loss 1.3229236602783203
Iteration 98: train_loss 1.3828867673873901
Iteration 99: train_loss 1.3335660696029663
Iteration 100: train_loss 1.3539913892745972
Iteration 101: train_loss 1.3244287967681885
Iteration 102: train_loss 1.4382565021514893
Iteration 103: train_loss 1.4519023895263672
Iteration 104: train_loss 1.3758679628372192
Iteration 105: train_loss 1.4068937301635742
Iteration 106: train_loss 1.3937264680862427
Iteration 107: train_loss 1.4682090282440186
Iteration 108: train_loss 1.3768523931503296
Iteration 109: train_loss 1.3410429954528809
Iteration 110: train_loss 1.3920258283615112
Iteration 111: train_loss 1.3878698348999023
Iteration 112: train_loss 1.4554167985916138
Iteration 113: train_loss 1.338763952255249
Iteration 114: train_loss 1.4376658201217651
Iteration 115: train_loss 1.3986104726791382
Iteration 116: train_loss 1.4149330854415894
Iteration 117: train_loss 1.4759095907211304
Iteration 118: train_loss 1.3985503911972046
Iteration 119: train_loss 1.3876657485961914
Iteration 120: train_loss 1.3661712408065796
Iteration 121: train_loss 1.3028061389923096
Iteration 122: train_loss 1.3922325372695923
Iteration 123: train_loss 1.3818588256835938
Iteration 124: train_loss 1.3774113655090332
Iteration 125: train_loss 1.4034395217895508
Iteration 126: train_loss 1.4588619470596313
Iteration 127: train_loss 1.3975207805633545
Iteration 128: train_loss 1.4264289140701294
Iteration 129: train_loss 1.40546452999115
Iteration 130: train_loss 1.434061050415039
Iteration 131: train_loss 1.4343667030334473
Iteration 132: train_loss 1.3931403160095215
Iteration 133: train_loss 1.428107500076294
Iteration 134: train_loss 1.319562554359436
Iteration 135: train_loss 1.3547536134719849
Iteration 136: train_loss 1.3513751029968262
Iteration 137: train_loss 1.3636982440948486
Iteration 138: train_loss 1.3598088026046753
Iteration 139: train_loss 1.3999298810958862
Iteration 140: train_loss 1.3648335933685303
Iteration 141: train_loss 1.3103715181350708
Iteration 142: train_loss 1.419150710105896
Iteration 143: train_loss 1.4154326915740967
Iteration 144: train_loss 1.4233452081680298
Iteration 145: train_loss 1.4313640594482422
Iteration 146: train_loss 1.4264975786209106
Iteration 147: train_loss 1.3861613273620605
Iteration 148: train_loss 1.3326411247253418
Iteration 149: train_loss 1.4083811044692993
Iteration 150: train_loss 1.3414400815963745
Iteration 151: train_loss 1.3328741788864136
Iteration 152: train_loss 1.414412021636963
Iteration 153: train_loss 1.3652328252792358
Iteration 154: train_loss 1.4283064603805542
Iteration 155: train_loss 1.3587229251861572
Iteration 156: train_loss 1.4307136535644531
Iteration 157: train_loss 1.3635077476501465
Iteration 158: train_loss 1.32537841796875
Iteration 159: train_loss 1.3558344841003418
Iteration 160: train_loss 1.431848406791687
Iteration 161: train_loss 1.3500863313674927
Iteration 162: train_loss 1.3767178058624268
Iteration 163: train_loss 1.3844306468963623
Iteration 164: train_loss 1.3796701431274414
Iteration 165: train_loss 1.3949671983718872
Iteration 166: train_loss 1.3966538906097412
Iteration 167: train_loss 1.4217453002929688
Iteration 168: train_loss 1.3418797254562378
Iteration 169: train_loss 1.380648136138916
Iteration 170: train_loss 1.3980318307876587
Iteration 171: train_loss 1.3717886209487915
Iteration 172: train_loss 1.4082248210906982
Iteration 173: train_loss 1.3316280841827393
Iteration 174: train_loss 1.362600564956665
Iteration 175: train_loss 1.3906360864639282
Iteration 176: train_loss 1.4431185722351074
Iteration 177: train_loss 1.409838080406189
Epoch 98: train_avg_loss 1.3841654850264726 eval_avg_acc: 0.3390469733876655 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:54:59] [32mIntermediate result: 0.3390469733876655  (Index 97)[0m
================Epoch: 99================
Iteration 1: train_loss 1.3518427610397339
Iteration 2: train_loss 1.3608336448669434
Iteration 3: train_loss 1.3533321619033813
Iteration 4: train_loss 1.37513267993927
Iteration 5: train_loss 1.424354910850525
Iteration 6: train_loss 1.378534197807312
Iteration 7: train_loss 1.3386341333389282
Iteration 8: train_loss 1.385085940361023
Iteration 9: train_loss 1.401102066040039
Iteration 10: train_loss 1.3341951370239258
Iteration 11: train_loss 1.3725465536117554
Iteration 12: train_loss 1.389634132385254
Iteration 13: train_loss 1.4031084775924683
Iteration 14: train_loss 1.4132511615753174
Iteration 15: train_loss 1.4428495168685913
Iteration 16: train_loss 1.4018601179122925
Iteration 17: train_loss 1.3650431632995605
Iteration 18: train_loss 1.27729070186615
Iteration 19: train_loss 1.409396767616272
Iteration 20: train_loss 1.3652604818344116
Iteration 21: train_loss 1.4481167793273926
Iteration 22: train_loss 1.4429978132247925
Iteration 23: train_loss 1.297558069229126
Iteration 24: train_loss 1.3247615098953247
Iteration 25: train_loss 1.3937761783599854
Iteration 26: train_loss 1.4061164855957031
Iteration 27: train_loss 1.3175982236862183
Iteration 28: train_loss 1.378576397895813
Iteration 29: train_loss 1.3370016813278198
Iteration 30: train_loss 1.3433411121368408
Iteration 31: train_loss 1.3092963695526123
Iteration 32: train_loss 1.2855228185653687
Iteration 33: train_loss 1.3504371643066406
Iteration 34: train_loss 1.3691887855529785
Iteration 35: train_loss 1.3082560300827026
Iteration 36: train_loss 1.2791974544525146
Iteration 37: train_loss 1.2838643789291382
Iteration 38: train_loss 1.3414736986160278
Iteration 39: train_loss 1.3516664505004883
Iteration 40: train_loss 1.3681762218475342
Iteration 41: train_loss 1.4240902662277222
Iteration 42: train_loss 1.3955905437469482
Iteration 43: train_loss 1.4053328037261963
Iteration 44: train_loss 1.4219907522201538
Iteration 45: train_loss 1.3541282415390015
Iteration 46: train_loss 1.3789408206939697
Iteration 47: train_loss 1.3592647314071655
Iteration 48: train_loss 1.3993000984191895
Iteration 49: train_loss 1.3530778884887695
Iteration 50: train_loss 1.3071379661560059
Iteration 51: train_loss 1.3427354097366333
Iteration 52: train_loss 1.3364015817642212
Iteration 53: train_loss 1.361749529838562
Iteration 54: train_loss 1.3583815097808838
Iteration 55: train_loss 1.3840594291687012
Iteration 56: train_loss 1.3670191764831543
Iteration 57: train_loss 1.4054243564605713
Iteration 58: train_loss 1.3336575031280518
Iteration 59: train_loss 1.3659385442733765
Iteration 60: train_loss 1.4227319955825806
Iteration 61: train_loss 1.455789566040039
Iteration 62: train_loss 1.364821195602417
Iteration 63: train_loss 1.3463517427444458
Iteration 64: train_loss 1.3323631286621094
Iteration 65: train_loss 1.3214677572250366
Iteration 66: train_loss 1.3947750329971313
Iteration 67: train_loss 1.3973712921142578
Iteration 68: train_loss 1.4248430728912354
Iteration 69: train_loss 1.3606681823730469
Iteration 70: train_loss 1.3889679908752441
Iteration 71: train_loss 1.339812994003296
Iteration 72: train_loss 1.3650975227355957
Iteration 73: train_loss 1.3879270553588867
Iteration 74: train_loss 1.3884280920028687
Iteration 75: train_loss 1.3578486442565918
Iteration 76: train_loss 1.3899624347686768
Iteration 77: train_loss 1.3602924346923828
Iteration 78: train_loss 1.401989221572876
Iteration 79: train_loss 1.4142491817474365
Iteration 80: train_loss 1.3539466857910156
Iteration 81: train_loss 1.390662670135498
Iteration 82: train_loss 1.3696144819259644
Iteration 83: train_loss 1.3471894264221191
Iteration 84: train_loss 1.3848161697387695
Iteration 85: train_loss 1.398552417755127
Iteration 86: train_loss 1.3871240615844727
Iteration 87: train_loss 1.3729276657104492
Iteration 88: train_loss 1.4033764600753784
Iteration 89: train_loss 1.3666101694107056
Iteration 90: train_loss 1.3887345790863037
Iteration 91: train_loss 1.4014540910720825
Iteration 92: train_loss 1.339082956314087
Iteration 93: train_loss 1.3625484704971313
Iteration 94: train_loss 1.3758400678634644
Iteration 95: train_loss 1.4024595022201538
Iteration 96: train_loss 1.4056237936019897
Iteration 97: train_loss 1.4365195035934448
Iteration 98: train_loss 1.4525700807571411
Iteration 99: train_loss 1.3727186918258667
Iteration 100: train_loss 1.4308443069458008
Iteration 101: train_loss 1.4395923614501953
Iteration 102: train_loss 1.395402431488037
Iteration 103: train_loss 1.392329454421997
Iteration 104: train_loss 1.4544154405593872
Iteration 105: train_loss 1.3987494707107544
Iteration 106: train_loss 1.413338541984558
Iteration 107: train_loss 1.380835771560669
Iteration 108: train_loss 1.410837173461914
Iteration 109: train_loss 1.393020749092102
Iteration 110: train_loss 1.3823069334030151
Iteration 111: train_loss 1.3893828392028809
Iteration 112: train_loss 1.4483904838562012
Iteration 113: train_loss 1.4517261981964111
Iteration 114: train_loss 1.3971701860427856
Iteration 115: train_loss 1.3933172225952148
Iteration 116: train_loss 1.3946514129638672
Iteration 117: train_loss 1.3855454921722412
Iteration 118: train_loss 1.4059914350509644
Iteration 119: train_loss 1.3471509218215942
Iteration 120: train_loss 1.4867366552352905
Iteration 121: train_loss 1.3840358257293701
Iteration 122: train_loss 1.3712724447250366
Iteration 123: train_loss 1.4470655918121338
Iteration 124: train_loss 1.3967278003692627
Iteration 125: train_loss 1.3710356950759888
Iteration 126: train_loss 1.3165348768234253
Iteration 127: train_loss 1.3298412561416626
Iteration 128: train_loss 1.344900369644165
Iteration 129: train_loss 1.3566726446151733
Iteration 130: train_loss 1.366074562072754
Iteration 131: train_loss 1.3640168905258179
Iteration 132: train_loss 1.4068242311477661
Iteration 133: train_loss 1.3738905191421509
Iteration 134: train_loss 1.357594609260559
Iteration 135: train_loss 1.366286039352417
Iteration 136: train_loss 1.4774097204208374
Iteration 137: train_loss 1.3255889415740967
Iteration 138: train_loss 1.3996779918670654
Iteration 139: train_loss 1.432621955871582
Iteration 140: train_loss 1.3635363578796387
Iteration 141: train_loss 1.3668315410614014
Iteration 142: train_loss 1.4469935894012451
Iteration 143: train_loss 1.3825068473815918
Iteration 144: train_loss 1.3839935064315796
Iteration 145: train_loss 1.343336582183838
Iteration 146: train_loss 1.3557507991790771
Iteration 147: train_loss 1.4417039155960083
Iteration 148: train_loss 1.4001015424728394
Iteration 149: train_loss 1.3852427005767822
Iteration 150: train_loss 1.375078558921814
Iteration 151: train_loss 1.4451755285263062
Iteration 152: train_loss 1.3735884428024292
Iteration 153: train_loss 1.3922063112258911
Iteration 154: train_loss 1.4522851705551147
Iteration 155: train_loss 1.3754327297210693
Iteration 156: train_loss 1.419689655303955
Iteration 157: train_loss 1.3493342399597168
Iteration 158: train_loss 1.3838061094284058
Iteration 159: train_loss 1.3900636434555054
Iteration 160: train_loss 1.4034779071807861
Iteration 161: train_loss 1.3215348720550537
Iteration 162: train_loss 1.4211608171463013
Iteration 163: train_loss 1.3858062028884888
Iteration 164: train_loss 1.4177122116088867
Iteration 165: train_loss 1.343410849571228
Iteration 166: train_loss 1.4335086345672607
Iteration 167: train_loss 1.4546928405761719
Iteration 168: train_loss 1.440959095954895
Iteration 169: train_loss 1.357361912727356
Iteration 170: train_loss 1.3935747146606445
Iteration 171: train_loss 1.4168775081634521
Iteration 172: train_loss 1.3366714715957642
Iteration 173: train_loss 1.375049114227295
Iteration 174: train_loss 1.3967368602752686
Iteration 175: train_loss 1.408906102180481
Iteration 176: train_loss 1.3927626609802246
Iteration 177: train_loss 1.3579174280166626
Epoch 99: train_avg_loss 1.3815093242515952 eval_avg_acc: 0.34241270948620767 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:55:40] [32mIntermediate result: 0.34241270948620767  (Index 98)[0m
================Epoch: 100================
Iteration 1: train_loss 1.4023494720458984
Iteration 2: train_loss 1.5276185274124146
Iteration 3: train_loss 1.3780068159103394
Iteration 4: train_loss 1.423936128616333
Iteration 5: train_loss 1.453680396080017
Iteration 6: train_loss 1.345113754272461
Iteration 7: train_loss 1.3758717775344849
Iteration 8: train_loss 1.4340251684188843
Iteration 9: train_loss 1.4123629331588745
Iteration 10: train_loss 1.3469284772872925
Iteration 11: train_loss 1.3891501426696777
Iteration 12: train_loss 1.3775221109390259
Iteration 13: train_loss 1.3582183122634888
Iteration 14: train_loss 1.3482604026794434
Iteration 15: train_loss 1.2768499851226807
Iteration 16: train_loss 1.339776873588562
Iteration 17: train_loss 1.3423634767532349
Iteration 18: train_loss 1.3948944807052612
Iteration 19: train_loss 1.3571791648864746
Iteration 20: train_loss 1.330742359161377
Iteration 21: train_loss 1.3728857040405273
Iteration 22: train_loss 1.3803292512893677
Iteration 23: train_loss 1.317644715309143
Iteration 24: train_loss 1.3593038320541382
Iteration 25: train_loss 1.384907603263855
Iteration 26: train_loss 1.3900684118270874
Iteration 27: train_loss 1.377126932144165
Iteration 28: train_loss 1.3564047813415527
Iteration 29: train_loss 1.448072910308838
Iteration 30: train_loss 1.3659789562225342
Iteration 31: train_loss 1.3343867063522339
Iteration 32: train_loss 1.3494313955307007
Iteration 33: train_loss 1.3539223670959473
Iteration 34: train_loss 1.364153504371643
Iteration 35: train_loss 1.3608990907669067
Iteration 36: train_loss 1.386671543121338
Iteration 37: train_loss 1.4017351865768433
Iteration 38: train_loss 1.3601495027542114
Iteration 39: train_loss 1.355515718460083
Iteration 40: train_loss 1.4174444675445557
Iteration 41: train_loss 1.4093949794769287
Iteration 42: train_loss 1.4426069259643555
Iteration 43: train_loss 1.412461280822754
Iteration 44: train_loss 1.3400120735168457
Iteration 45: train_loss 1.3762985467910767
Iteration 46: train_loss 1.3780032396316528
Iteration 47: train_loss 1.3684241771697998
Iteration 48: train_loss 1.3825562000274658
Iteration 49: train_loss 1.3909307718276978
Iteration 50: train_loss 1.353139042854309
Iteration 51: train_loss 1.4276403188705444
Iteration 52: train_loss 1.2936464548110962
Iteration 53: train_loss 1.4026159048080444
Iteration 54: train_loss 1.321475625038147
Iteration 55: train_loss 1.3169394731521606
Iteration 56: train_loss 1.3240710496902466
Iteration 57: train_loss 1.3279272317886353
Iteration 58: train_loss 1.3670886754989624
Iteration 59: train_loss 1.3536797761917114
Iteration 60: train_loss 1.364109754562378
Iteration 61: train_loss 1.3463867902755737
Iteration 62: train_loss 1.4498752355575562
Iteration 63: train_loss 1.4311909675598145
Iteration 64: train_loss 1.4115995168685913
Iteration 65: train_loss 1.3328754901885986
Iteration 66: train_loss 1.351259469985962
Iteration 67: train_loss 1.3656504154205322
Iteration 68: train_loss 1.388181447982788
Iteration 69: train_loss 1.428960919380188
Iteration 70: train_loss 1.437804102897644
Iteration 71: train_loss 1.371840476989746
Iteration 72: train_loss 1.359291911125183
Iteration 73: train_loss 1.3603016138076782
Iteration 74: train_loss 1.362586498260498
Iteration 75: train_loss 1.3128776550292969
Iteration 76: train_loss 1.3879303932189941
Iteration 77: train_loss 1.353664517402649
Iteration 78: train_loss 1.405872106552124
Iteration 79: train_loss 1.3525999784469604
Iteration 80: train_loss 1.3808395862579346
Iteration 81: train_loss 1.3277546167373657
Iteration 82: train_loss 1.3748241662979126
Iteration 83: train_loss 1.3174079656600952
Iteration 84: train_loss 1.4226353168487549
Iteration 85: train_loss 1.384348750114441
Iteration 86: train_loss 1.4065454006195068
Iteration 87: train_loss 1.4053466320037842
Iteration 88: train_loss 1.3897911310195923
Iteration 89: train_loss 1.4018571376800537
Iteration 90: train_loss 1.3433235883712769
Iteration 91: train_loss 1.3267951011657715
Iteration 92: train_loss 1.3920114040374756
Iteration 93: train_loss 1.361792802810669
Iteration 94: train_loss 1.3379229307174683
Iteration 95: train_loss 1.3626888990402222
Iteration 96: train_loss 1.3746832609176636
Iteration 97: train_loss 1.4247299432754517
Iteration 98: train_loss 1.314851999282837
Iteration 99: train_loss 1.3681844472885132
Iteration 100: train_loss 1.373815894126892
Iteration 101: train_loss 1.4499363899230957
Iteration 102: train_loss 1.3684853315353394
Iteration 103: train_loss 1.4167252779006958
Iteration 104: train_loss 1.3863098621368408
Iteration 105: train_loss 1.3673973083496094
Iteration 106: train_loss 1.4509278535842896
Iteration 107: train_loss 1.324876070022583
Iteration 108: train_loss 1.3773308992385864
Iteration 109: train_loss 1.3472857475280762
Iteration 110: train_loss 1.2977298498153687
Iteration 111: train_loss 1.3696221113204956
Iteration 112: train_loss 1.3038320541381836
Iteration 113: train_loss 1.3240967988967896
Iteration 114: train_loss 1.3087197542190552
Iteration 115: train_loss 1.4075195789337158
Iteration 116: train_loss 1.3607391119003296
Iteration 117: train_loss 1.3730303049087524
Iteration 118: train_loss 1.340773105621338
Iteration 119: train_loss 1.3703389167785645
Iteration 120: train_loss 1.3958044052124023
Iteration 121: train_loss 1.2963539361953735
Iteration 122: train_loss 1.3674441576004028
Iteration 123: train_loss 1.3926258087158203
Iteration 124: train_loss 1.3684524297714233
Iteration 125: train_loss 1.3782927989959717
Iteration 126: train_loss 1.3771190643310547
Iteration 127: train_loss 1.3639922142028809
Iteration 128: train_loss 1.3475186824798584
Iteration 129: train_loss 1.337490439414978
Iteration 130: train_loss 1.312787652015686
Iteration 131: train_loss 1.3640117645263672
Iteration 132: train_loss 1.414535641670227
Iteration 133: train_loss 1.3711360692977905
Iteration 134: train_loss 1.4255837202072144
Iteration 135: train_loss 1.437000036239624
Iteration 136: train_loss 1.4107393026351929
Iteration 137: train_loss 1.38235604763031
Iteration 138: train_loss 1.3867567777633667
Iteration 139: train_loss 1.3899364471435547
Iteration 140: train_loss 1.3797097206115723
Iteration 141: train_loss 1.3649375438690186
Iteration 142: train_loss 1.3698854446411133
Iteration 143: train_loss 1.4270756244659424
Iteration 144: train_loss 1.3725327253341675
Iteration 145: train_loss 1.3668863773345947
Iteration 146: train_loss 1.3384658098220825
Iteration 147: train_loss 1.3644627332687378
Iteration 148: train_loss 1.3791784048080444
Iteration 149: train_loss 1.4037458896636963
Iteration 150: train_loss 1.3665716648101807
Iteration 151: train_loss 1.372913122177124
Iteration 152: train_loss 1.376554012298584
Iteration 153: train_loss 1.3304768800735474
Iteration 154: train_loss 1.3519010543823242
Iteration 155: train_loss 1.36650550365448
Iteration 156: train_loss 1.3774957656860352
Iteration 157: train_loss 1.4406397342681885
Iteration 158: train_loss 1.3746899366378784
Iteration 159: train_loss 1.4422823190689087
Iteration 160: train_loss 1.4190638065338135
Iteration 161: train_loss 1.4250036478042603
Iteration 162: train_loss 1.4159295558929443
Iteration 163: train_loss 1.44985032081604
Iteration 164: train_loss 1.3495382070541382
Iteration 165: train_loss 1.401924967765808
Iteration 166: train_loss 1.398680329322815
Iteration 167: train_loss 1.4333856105804443
Iteration 168: train_loss 1.3959784507751465
Iteration 169: train_loss 1.4966020584106445
Iteration 170: train_loss 1.4847160577774048
Iteration 171: train_loss 1.4168710708618164
Iteration 172: train_loss 1.4241278171539307
Iteration 173: train_loss 1.4044239521026611
Iteration 174: train_loss 1.4177799224853516
Iteration 175: train_loss 1.3827264308929443
Iteration 176: train_loss 1.4067730903625488
Iteration 177: train_loss 1.3900396823883057
Epoch 100: train_avg_loss 1.3782697417641763 eval_avg_acc: 0.3214490516212723 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:56:20] [32mIntermediate result: 0.3214490516212723  (Index 99)[0m
================Epoch: 101================
Iteration 1: train_loss 1.3117468357086182
Iteration 2: train_loss 1.3868682384490967
Iteration 3: train_loss 1.3861503601074219
Iteration 4: train_loss 1.3501447439193726
Iteration 5: train_loss 1.4168895483016968
Iteration 6: train_loss 1.4126167297363281
Iteration 7: train_loss 1.3715789318084717
Iteration 8: train_loss 1.3387300968170166
Iteration 9: train_loss 1.3766366243362427
Iteration 10: train_loss 1.3541438579559326
Iteration 11: train_loss 1.3611860275268555
Iteration 12: train_loss 1.3689044713974
Iteration 13: train_loss 1.341139793395996
Iteration 14: train_loss 1.4187464714050293
Iteration 15: train_loss 1.3958805799484253
Iteration 16: train_loss 1.3813577890396118
Iteration 17: train_loss 1.3917800188064575
Iteration 18: train_loss 1.3721661567687988
Iteration 19: train_loss 1.2978124618530273
Iteration 20: train_loss 1.2824009656906128
Iteration 21: train_loss 1.3176445960998535
Iteration 22: train_loss 1.4384456872940063
Iteration 23: train_loss 1.3661491870880127
Iteration 24: train_loss 1.3255019187927246
Iteration 25: train_loss 1.302993893623352
Iteration 26: train_loss 1.338454008102417
Iteration 27: train_loss 1.3439431190490723
Iteration 28: train_loss 1.4103882312774658
Iteration 29: train_loss 1.3769153356552124
Iteration 30: train_loss 1.369126558303833
Iteration 31: train_loss 1.3816579580307007
Iteration 32: train_loss 1.3992462158203125
Iteration 33: train_loss 1.4282723665237427
Iteration 34: train_loss 1.3524365425109863
Iteration 35: train_loss 1.385088562965393
Iteration 36: train_loss 1.35280179977417
Iteration 37: train_loss 1.3916394710540771
Iteration 38: train_loss 1.2695014476776123
Iteration 39: train_loss 1.3330953121185303
Iteration 40: train_loss 1.370072841644287
Iteration 41: train_loss 1.354157567024231
Iteration 42: train_loss 1.3242933750152588
Iteration 43: train_loss 1.3994545936584473
Iteration 44: train_loss 1.354000210762024
Iteration 45: train_loss 1.3735958337783813
Iteration 46: train_loss 1.3542746305465698
Iteration 47: train_loss 1.3284859657287598
Iteration 48: train_loss 1.283823847770691
Iteration 49: train_loss 1.3537060022354126
Iteration 50: train_loss 1.3241034746170044
Iteration 51: train_loss 1.3290019035339355
Iteration 52: train_loss 1.365226149559021
Iteration 53: train_loss 1.3661224842071533
Iteration 54: train_loss 1.3012913465499878
Iteration 55: train_loss 1.393072247505188
Iteration 56: train_loss 1.4025095701217651
Iteration 57: train_loss 1.3260703086853027
Iteration 58: train_loss 1.385041356086731
Iteration 59: train_loss 1.3242554664611816
Iteration 60: train_loss 1.3352322578430176
Iteration 61: train_loss 1.33778715133667
Iteration 62: train_loss 1.3653225898742676
Iteration 63: train_loss 1.4092986583709717
Iteration 64: train_loss 1.3030755519866943
Iteration 65: train_loss 1.302648663520813
Iteration 66: train_loss 1.2726365327835083
Iteration 67: train_loss 1.3272380828857422
Iteration 68: train_loss 1.4197001457214355
Iteration 69: train_loss 1.3790937662124634
Iteration 70: train_loss 1.3455651998519897
Iteration 71: train_loss 1.3364754915237427
Iteration 72: train_loss 1.3675490617752075
Iteration 73: train_loss 1.354247808456421
Iteration 74: train_loss 1.3307695388793945
Iteration 75: train_loss 1.4016183614730835
Iteration 76: train_loss 1.3641352653503418
Iteration 77: train_loss 1.3247528076171875
Iteration 78: train_loss 1.42327082157135
Iteration 79: train_loss 1.4596353769302368
Iteration 80: train_loss 1.3918753862380981
Iteration 81: train_loss 1.3475288152694702
Iteration 82: train_loss 1.3544700145721436
Iteration 83: train_loss 1.3374176025390625
Iteration 84: train_loss 1.3652276992797852
Iteration 85: train_loss 1.3571817874908447
Iteration 86: train_loss 1.3698139190673828
Iteration 87: train_loss 1.28983473777771
Iteration 88: train_loss 1.4255162477493286
Iteration 89: train_loss 1.3715863227844238
Iteration 90: train_loss 1.3620004653930664
Iteration 91: train_loss 1.3786028623580933
Iteration 92: train_loss 1.390282154083252
Iteration 93: train_loss 1.3416804075241089
Iteration 94: train_loss 1.3402884006500244
Iteration 95: train_loss 1.3737069368362427
Iteration 96: train_loss 1.3208979368209839
Iteration 97: train_loss 1.3716567754745483
Iteration 98: train_loss 1.3743244409561157
Iteration 99: train_loss 1.42958664894104
Iteration 100: train_loss 1.3869186639785767
Iteration 101: train_loss 1.2868167161941528
Iteration 102: train_loss 1.3117973804473877
Iteration 103: train_loss 1.3645442724227905
Iteration 104: train_loss 1.4499666690826416
Iteration 105: train_loss 1.3782904148101807
Iteration 106: train_loss 1.4203273057937622
Iteration 107: train_loss 1.4014791250228882
Iteration 108: train_loss 1.4468843936920166
Iteration 109: train_loss 1.4822494983673096
Iteration 110: train_loss 1.4138970375061035
Iteration 111: train_loss 1.488877296447754
Iteration 112: train_loss 1.456052541732788
Iteration 113: train_loss 1.42812979221344
Iteration 114: train_loss 1.3489413261413574
Iteration 115: train_loss 1.3371989727020264
Iteration 116: train_loss 1.3917994499206543
Iteration 117: train_loss 1.4024626016616821
Iteration 118: train_loss 1.4617704153060913
Iteration 119: train_loss 1.3634248971939087
Iteration 120: train_loss 1.3563227653503418
Iteration 121: train_loss 1.3578017950057983
Iteration 122: train_loss 1.3631343841552734
Iteration 123: train_loss 1.4572473764419556
Iteration 124: train_loss 1.4099653959274292
Iteration 125: train_loss 1.401949167251587
Iteration 126: train_loss 1.3442747592926025
Iteration 127: train_loss 1.401073694229126
Iteration 128: train_loss 1.3494081497192383
Iteration 129: train_loss 1.3988690376281738
Iteration 130: train_loss 1.4290586709976196
Iteration 131: train_loss 1.3680744171142578
Iteration 132: train_loss 1.295532464981079
Iteration 133: train_loss 1.388201355934143
Iteration 134: train_loss 1.3750579357147217
Iteration 135: train_loss 1.3223944902420044
Iteration 136: train_loss 1.3721750974655151
Iteration 137: train_loss 1.434309959411621
Iteration 138: train_loss 1.3500950336456299
Iteration 139: train_loss 1.4003322124481201
Iteration 140: train_loss 1.3748462200164795
Iteration 141: train_loss 1.3413203954696655
Iteration 142: train_loss 1.4163774251937866
Iteration 143: train_loss 1.4045463800430298
Iteration 144: train_loss 1.3730276823043823
Iteration 145: train_loss 1.3480546474456787
Iteration 146: train_loss 1.3674161434173584
Iteration 147: train_loss 1.442868947982788
Iteration 148: train_loss 1.3977593183517456
Iteration 149: train_loss 1.404746174812317
Iteration 150: train_loss 1.3531391620635986
Iteration 151: train_loss 1.3583147525787354
Iteration 152: train_loss 1.427811861038208
Iteration 153: train_loss 1.4150296449661255
Iteration 154: train_loss 1.3714364767074585
Iteration 155: train_loss 1.4207539558410645
Iteration 156: train_loss 1.2522960901260376
Iteration 157: train_loss 1.4284026622772217
Iteration 158: train_loss 1.4092990159988403
Iteration 159: train_loss 1.45213782787323
Iteration 160: train_loss 1.3724215030670166
Iteration 161: train_loss 1.3735744953155518
Iteration 162: train_loss 1.4447247982025146
Iteration 163: train_loss 1.3995379209518433
Iteration 164: train_loss 1.3219789266586304
Iteration 165: train_loss 1.374043583869934
Iteration 166: train_loss 1.3640589714050293
Iteration 167: train_loss 1.4046119451522827
Iteration 168: train_loss 1.400032877922058
Iteration 169: train_loss 1.3807216882705688
Iteration 170: train_loss 1.3959041833877563
Iteration 171: train_loss 1.4343873262405396
Iteration 172: train_loss 1.3748278617858887
Iteration 173: train_loss 1.353706955909729
Iteration 174: train_loss 1.3823763132095337
Iteration 175: train_loss 1.4264737367630005
Iteration 176: train_loss 1.3286755084991455
Iteration 177: train_loss 1.3852808475494385
Epoch 101: train_avg_loss 1.3725441014025845 eval_avg_acc: 0.3390063077473345 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:57:01] [32mIntermediate result: 0.3390063077473345  (Index 100)[0m
================Epoch: 102================
Iteration 1: train_loss 1.264435887336731
Iteration 2: train_loss 1.2929952144622803
Iteration 3: train_loss 1.3310635089874268
Iteration 4: train_loss 1.3572319746017456
Iteration 5: train_loss 1.3021401166915894
Iteration 6: train_loss 1.325042724609375
Iteration 7: train_loss 1.3687570095062256
Iteration 8: train_loss 1.302809476852417
Iteration 9: train_loss 1.3260079622268677
Iteration 10: train_loss 1.3430585861206055
Iteration 11: train_loss 1.3020912408828735
Iteration 12: train_loss 1.315778374671936
Iteration 13: train_loss 1.3474807739257812
Iteration 14: train_loss 1.2908235788345337
Iteration 15: train_loss 1.323020339012146
Iteration 16: train_loss 1.3426697254180908
Iteration 17: train_loss 1.3679295778274536
Iteration 18: train_loss 1.350921630859375
Iteration 19: train_loss 1.3200037479400635
Iteration 20: train_loss 1.3499747514724731
Iteration 21: train_loss 1.3388128280639648
Iteration 22: train_loss 1.3780559301376343
Iteration 23: train_loss 1.4550429582595825
Iteration 24: train_loss 1.4123365879058838
Iteration 25: train_loss 1.4125076532363892
Iteration 26: train_loss 1.3379950523376465
Iteration 27: train_loss 1.3389478921890259
Iteration 28: train_loss 1.3637346029281616
Iteration 29: train_loss 1.3549120426177979
Iteration 30: train_loss 1.3929758071899414
Iteration 31: train_loss 1.3484904766082764
Iteration 32: train_loss 1.295866847038269
Iteration 33: train_loss 1.3954023122787476
Iteration 34: train_loss 1.330163836479187
Iteration 35: train_loss 1.39931321144104
Iteration 36: train_loss 1.3643403053283691
Iteration 37: train_loss 1.3088003396987915
Iteration 38: train_loss 1.344899296760559
Iteration 39: train_loss 1.392905354499817
Iteration 40: train_loss 1.3620591163635254
Iteration 41: train_loss 1.3533669710159302
Iteration 42: train_loss 1.3789255619049072
Iteration 43: train_loss 1.384950876235962
Iteration 44: train_loss 1.3126182556152344
Iteration 45: train_loss 1.3369325399398804
Iteration 46: train_loss 1.386521577835083
Iteration 47: train_loss 1.371404767036438
Iteration 48: train_loss 1.3562222719192505
Iteration 49: train_loss 1.3187817335128784
Iteration 50: train_loss 1.3408985137939453
Iteration 51: train_loss 1.4155762195587158
Iteration 52: train_loss 1.3831002712249756
Iteration 53: train_loss 1.3221688270568848
Iteration 54: train_loss 1.3338872194290161
Iteration 55: train_loss 1.3139891624450684
Iteration 56: train_loss 1.339247226715088
Iteration 57: train_loss 1.2908724546432495
Iteration 58: train_loss 1.3709759712219238
Iteration 59: train_loss 1.3593289852142334
Iteration 60: train_loss 1.3827977180480957
Iteration 61: train_loss 1.3982925415039062
Iteration 62: train_loss 1.3806204795837402
Iteration 63: train_loss 1.3420976400375366
Iteration 64: train_loss 1.345174789428711
Iteration 65: train_loss 1.3191064596176147
Iteration 66: train_loss 1.342819333076477
Iteration 67: train_loss 1.340100646018982
Iteration 68: train_loss 1.3446836471557617
Iteration 69: train_loss 1.4069000482559204
Iteration 70: train_loss 1.3098528385162354
Iteration 71: train_loss 1.3760181665420532
Iteration 72: train_loss 1.327315330505371
Iteration 73: train_loss 1.4122722148895264
Iteration 74: train_loss 1.3352597951889038
Iteration 75: train_loss 1.4273813962936401
Iteration 76: train_loss 1.3139859437942505
Iteration 77: train_loss 1.3890678882598877
Iteration 78: train_loss 1.3523510694503784
Iteration 79: train_loss 1.3583979606628418
Iteration 80: train_loss 1.3397231101989746
Iteration 81: train_loss 1.4316800832748413
Iteration 82: train_loss 1.389214277267456
Iteration 83: train_loss 1.3694963455200195
Iteration 84: train_loss 1.36021888256073
Iteration 85: train_loss 1.404318928718567
Iteration 86: train_loss 1.3854783773422241
Iteration 87: train_loss 1.3283458948135376
Iteration 88: train_loss 1.327522873878479
Iteration 89: train_loss 1.3628336191177368
Iteration 90: train_loss 1.324236273765564
Iteration 91: train_loss 1.3350692987442017
Iteration 92: train_loss 1.3397585153579712
Iteration 93: train_loss 1.3486372232437134
Iteration 94: train_loss 1.303023099899292
Iteration 95: train_loss 1.3672215938568115
Iteration 96: train_loss 1.3375473022460938
Iteration 97: train_loss 1.3963427543640137
Iteration 98: train_loss 1.3932024240493774
Iteration 99: train_loss 1.3434171676635742
Iteration 100: train_loss 1.4263015985488892
Iteration 101: train_loss 1.308302640914917
Iteration 102: train_loss 1.2885596752166748
Iteration 103: train_loss 1.4241447448730469
Iteration 104: train_loss 1.3829925060272217
Iteration 105: train_loss 1.3004282712936401
Iteration 106: train_loss 1.431496024131775
Iteration 107: train_loss 1.337157964706421
Iteration 108: train_loss 1.4040846824645996
Iteration 109: train_loss 1.4407129287719727
Iteration 110: train_loss 1.4038420915603638
Iteration 111: train_loss 1.4293028116226196
Iteration 112: train_loss 1.345487356185913
Iteration 113: train_loss 1.3802647590637207
Iteration 114: train_loss 1.3542155027389526
Iteration 115: train_loss 1.4896842241287231
Iteration 116: train_loss 1.3866533041000366
Iteration 117: train_loss 1.410330057144165
Iteration 118: train_loss 1.3790802955627441
Iteration 119: train_loss 1.4334986209869385
Iteration 120: train_loss 1.3236457109451294
Iteration 121: train_loss 1.3986470699310303
Iteration 122: train_loss 1.3527039289474487
Iteration 123: train_loss 1.3899437189102173
Iteration 124: train_loss 1.401689887046814
Iteration 125: train_loss 1.4583348035812378
Iteration 126: train_loss 1.349568247795105
Iteration 127: train_loss 1.4048240184783936
Iteration 128: train_loss 1.3518184423446655
Iteration 129: train_loss 1.3955848217010498
Iteration 130: train_loss 1.4235748052597046
Iteration 131: train_loss 1.3373690843582153
Iteration 132: train_loss 1.3842111825942993
Iteration 133: train_loss 1.3995062112808228
Iteration 134: train_loss 1.4600399732589722
Iteration 135: train_loss 1.4175035953521729
Iteration 136: train_loss 1.4229457378387451
Iteration 137: train_loss 1.4143989086151123
Iteration 138: train_loss 1.357608437538147
Iteration 139: train_loss 1.406415581703186
Iteration 140: train_loss 1.430873990058899
Iteration 141: train_loss 1.3046215772628784
Iteration 142: train_loss 1.4502832889556885
Iteration 143: train_loss 1.412249207496643
Iteration 144: train_loss 1.3437261581420898
Iteration 145: train_loss 1.3517264127731323
Iteration 146: train_loss 1.3560079336166382
Iteration 147: train_loss 1.3650518655776978
Iteration 148: train_loss 1.371313452720642
Iteration 149: train_loss 1.4210271835327148
Iteration 150: train_loss 1.3664734363555908
Iteration 151: train_loss 1.325773000717163
Iteration 152: train_loss 1.358142375946045
Iteration 153: train_loss 1.3480620384216309
Iteration 154: train_loss 1.3888351917266846
Iteration 155: train_loss 1.4153870344161987
Iteration 156: train_loss 1.3985671997070312
Iteration 157: train_loss 1.3693448305130005
Iteration 158: train_loss 1.3884153366088867
Iteration 159: train_loss 1.362889051437378
Iteration 160: train_loss 1.3467143774032593
Iteration 161: train_loss 1.4801703691482544
Iteration 162: train_loss 1.4019490480422974
Iteration 163: train_loss 1.3838109970092773
Iteration 164: train_loss 1.374882459640503
Iteration 165: train_loss 1.3547868728637695
Iteration 166: train_loss 1.3855434656143188
Iteration 167: train_loss 1.3938121795654297
Iteration 168: train_loss 1.4185411930084229
Iteration 169: train_loss 1.4304356575012207
Iteration 170: train_loss 1.4052395820617676
Iteration 171: train_loss 1.3655420541763306
Iteration 172: train_loss 1.3229061365127563
Iteration 173: train_loss 1.3402020931243896
Iteration 174: train_loss 1.3263548612594604
Iteration 175: train_loss 1.3819178342819214
Iteration 176: train_loss 1.3980991840362549
Iteration 177: train_loss 1.348388671875
Epoch 102: train_avg_loss 1.366713524538245 eval_avg_acc: 0.34775733202240033 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:57:42] [32mIntermediate result: 0.34775733202240033  (Index 101)[0m
================Epoch: 103================
Iteration 1: train_loss 1.3022541999816895
Iteration 2: train_loss 1.3489285707473755
Iteration 3: train_loss 1.3952784538269043
Iteration 4: train_loss 1.3697755336761475
Iteration 5: train_loss 1.3839110136032104
Iteration 6: train_loss 1.430209994316101
Iteration 7: train_loss 1.4089637994766235
Iteration 8: train_loss 1.4040515422821045
Iteration 9: train_loss 1.4239506721496582
Iteration 10: train_loss 1.3636410236358643
Iteration 11: train_loss 1.3645764589309692
Iteration 12: train_loss 1.3649184703826904
Iteration 13: train_loss 1.3748151063919067
Iteration 14: train_loss 1.31792151927948
Iteration 15: train_loss 1.304624319076538
Iteration 16: train_loss 1.3819504976272583
Iteration 17: train_loss 1.4371224641799927
Iteration 18: train_loss 1.342336654663086
Iteration 19: train_loss 1.3599718809127808
Iteration 20: train_loss 1.3684251308441162
Iteration 21: train_loss 1.3794461488723755
Iteration 22: train_loss 1.3634564876556396
Iteration 23: train_loss 1.383028268814087
Iteration 24: train_loss 1.3359533548355103
Iteration 25: train_loss 1.373165249824524
Iteration 26: train_loss 1.3794326782226562
Iteration 27: train_loss 1.3481513261795044
Iteration 28: train_loss 1.3929250240325928
Iteration 29: train_loss 1.3236162662506104
Iteration 30: train_loss 1.300935983657837
Iteration 31: train_loss 1.3210315704345703
Iteration 32: train_loss 1.3266912698745728
Iteration 33: train_loss 1.3193837404251099
Iteration 34: train_loss 1.3413681983947754
Iteration 35: train_loss 1.3423466682434082
Iteration 36: train_loss 1.328048586845398
Iteration 37: train_loss 1.3674975633621216
Iteration 38: train_loss 1.284554123878479
Iteration 39: train_loss 1.3177001476287842
Iteration 40: train_loss 1.3140780925750732
Iteration 41: train_loss 1.3671104907989502
Iteration 42: train_loss 1.336916208267212
Iteration 43: train_loss 1.3736613988876343
Iteration 44: train_loss 1.327703595161438
Iteration 45: train_loss 1.337981939315796
Iteration 46: train_loss 1.4035038948059082
Iteration 47: train_loss 1.3321106433868408
Iteration 48: train_loss 1.3209962844848633
Iteration 49: train_loss 1.397814393043518
Iteration 50: train_loss 1.2985769510269165
Iteration 51: train_loss 1.3403778076171875
Iteration 52: train_loss 1.3519699573516846
Iteration 53: train_loss 1.3870320320129395
Iteration 54: train_loss 1.3416366577148438
Iteration 55: train_loss 1.3663569688796997
Iteration 56: train_loss 1.3754127025604248
Iteration 57: train_loss 1.3265161514282227
Iteration 58: train_loss 1.3500256538391113
Iteration 59: train_loss 1.334188461303711
Iteration 60: train_loss 1.3532012701034546
Iteration 61: train_loss 1.336760401725769
Iteration 62: train_loss 1.3626306056976318
Iteration 63: train_loss 1.3605232238769531
Iteration 64: train_loss 1.396395206451416
Iteration 65: train_loss 1.3349195718765259
Iteration 66: train_loss 1.3289778232574463
Iteration 67: train_loss 1.369848608970642
Iteration 68: train_loss 1.3920443058013916
Iteration 69: train_loss 1.4120227098464966
Iteration 70: train_loss 1.425383448600769
Iteration 71: train_loss 1.3475128412246704
Iteration 72: train_loss 1.3712390661239624
Iteration 73: train_loss 1.3743960857391357
Iteration 74: train_loss 1.3066619634628296
Iteration 75: train_loss 1.398648738861084
Iteration 76: train_loss 1.3454198837280273
Iteration 77: train_loss 1.3773646354675293
Iteration 78: train_loss 1.3873612880706787
Iteration 79: train_loss 1.3987431526184082
Iteration 80: train_loss 1.306470513343811
Iteration 81: train_loss 1.4169319868087769
Iteration 82: train_loss 1.350182056427002
Iteration 83: train_loss 1.341092586517334
Iteration 84: train_loss 1.3723948001861572
Iteration 85: train_loss 1.3273844718933105
Iteration 86: train_loss 1.3749133348464966
Iteration 87: train_loss 1.3352056741714478
Iteration 88: train_loss 1.3364338874816895
Iteration 89: train_loss 1.3157658576965332
Iteration 90: train_loss 1.3610436916351318
Iteration 91: train_loss 1.314612627029419
Iteration 92: train_loss 1.3775233030319214
Iteration 93: train_loss 1.4245387315750122
Iteration 94: train_loss 1.4077931642532349
Iteration 95: train_loss 1.3433945178985596
Iteration 96: train_loss 1.3920187950134277
Iteration 97: train_loss 1.358067274093628
Iteration 98: train_loss 1.4021403789520264
Iteration 99: train_loss 1.359775185585022
Iteration 100: train_loss 1.3524384498596191
Iteration 101: train_loss 1.3952550888061523
Iteration 102: train_loss 1.3064050674438477
Iteration 103: train_loss 1.3209785223007202
Iteration 104: train_loss 1.371516466140747
Iteration 105: train_loss 1.3514357805252075
Iteration 106: train_loss 1.362898588180542
Iteration 107: train_loss 1.370909571647644
Iteration 108: train_loss 1.3156360387802124
Iteration 109: train_loss 1.3512274026870728
Iteration 110: train_loss 1.2987791299819946
Iteration 111: train_loss 1.39533531665802
Iteration 112: train_loss 1.373189926147461
Iteration 113: train_loss 1.3743823766708374
Iteration 114: train_loss 1.341613531112671
Iteration 115: train_loss 1.4389305114746094
Iteration 116: train_loss 1.408411979675293
Iteration 117: train_loss 1.3652758598327637
Iteration 118: train_loss 1.3648438453674316
Iteration 119: train_loss 1.3597184419631958
Iteration 120: train_loss 1.3672966957092285
Iteration 121: train_loss 1.3740146160125732
Iteration 122: train_loss 1.3662304878234863
Iteration 123: train_loss 1.3706004619598389
Iteration 124: train_loss 1.393375039100647
Iteration 125: train_loss 1.3734503984451294
Iteration 126: train_loss 1.3467764854431152
Iteration 127: train_loss 1.3419532775878906
Iteration 128: train_loss 1.3545135259628296
Iteration 129: train_loss 1.4746304750442505
Iteration 130: train_loss 1.376447081565857
Iteration 131: train_loss 1.3682013750076294
Iteration 132: train_loss 1.3940370082855225
Iteration 133: train_loss 1.3849354982376099
Iteration 134: train_loss 1.3967959880828857
Iteration 135: train_loss 1.3363173007965088
Iteration 136: train_loss 1.4103336334228516
Iteration 137: train_loss 1.3373241424560547
Iteration 138: train_loss 1.3474822044372559
Iteration 139: train_loss 1.3925669193267822
Iteration 140: train_loss 1.4433408975601196
Iteration 141: train_loss 1.3823102712631226
Iteration 142: train_loss 1.3333654403686523
Iteration 143: train_loss 1.444845199584961
Iteration 144: train_loss 1.3217370510101318
Iteration 145: train_loss 1.3241816759109497
Iteration 146: train_loss 1.372448444366455
Iteration 147: train_loss 1.382118582725525
Iteration 148: train_loss 1.3764562606811523
Iteration 149: train_loss 1.3220053911209106
Iteration 150: train_loss 1.389337420463562
Iteration 151: train_loss 1.3792991638183594
Iteration 152: train_loss 1.4415849447250366
Iteration 153: train_loss 1.4175828695297241
Iteration 154: train_loss 1.337360143661499
Iteration 155: train_loss 1.3865270614624023
Iteration 156: train_loss 1.3637990951538086
Iteration 157: train_loss 1.4286739826202393
Iteration 158: train_loss 1.429556131362915
Iteration 159: train_loss 1.3798937797546387
Iteration 160: train_loss 1.3733693361282349
Iteration 161: train_loss 1.4317996501922607
Iteration 162: train_loss 1.4632900953292847
Iteration 163: train_loss 1.4861551523208618
Iteration 164: train_loss 1.449389100074768
Iteration 165: train_loss 1.3972954750061035
Iteration 166: train_loss 1.3649365901947021
Iteration 167: train_loss 1.4122989177703857
Iteration 168: train_loss 1.2919429540634155
Iteration 169: train_loss 1.3813437223434448
Iteration 170: train_loss 1.4320124387741089
Iteration 171: train_loss 1.326163649559021
Iteration 172: train_loss 1.363745927810669
Iteration 173: train_loss 1.4165027141571045
Iteration 174: train_loss 1.4098032712936401
Iteration 175: train_loss 1.3743518590927124
Iteration 176: train_loss 1.373060703277588
Iteration 177: train_loss 1.3764760494232178
Epoch 103: train_avg_loss 1.367598270292336 eval_avg_acc: 0.3478874932780666 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:58:24] [32mIntermediate result: 0.3478874932780666  (Index 102)[0m
================Epoch: 104================
Iteration 1: train_loss 1.2868388891220093
Iteration 2: train_loss 1.3732168674468994
Iteration 3: train_loss 1.3159995079040527
Iteration 4: train_loss 1.365735411643982
Iteration 5: train_loss 1.3461576700210571
Iteration 6: train_loss 1.3278136253356934
Iteration 7: train_loss 1.3445192575454712
Iteration 8: train_loss 1.3835476636886597
Iteration 9: train_loss 1.3190184831619263
Iteration 10: train_loss 1.3210625648498535
Iteration 11: train_loss 1.2900465726852417
Iteration 12: train_loss 1.3408907651901245
Iteration 13: train_loss 1.3571785688400269
Iteration 14: train_loss 1.3758326768875122
Iteration 15: train_loss 1.3613669872283936
Iteration 16: train_loss 1.3028098344802856
Iteration 17: train_loss 1.3477404117584229
Iteration 18: train_loss 1.3533967733383179
Iteration 19: train_loss 1.3632034063339233
Iteration 20: train_loss 1.345641016960144
Iteration 21: train_loss 1.3296979665756226
Iteration 22: train_loss 1.3333884477615356
Iteration 23: train_loss 1.3605188131332397
Iteration 24: train_loss 1.3633815050125122
Iteration 25: train_loss 1.3631408214569092
Iteration 26: train_loss 1.3967067003250122
Iteration 27: train_loss 1.3661823272705078
Iteration 28: train_loss 1.3267935514450073
Iteration 29: train_loss 1.3072545528411865
Iteration 30: train_loss 1.3164167404174805
Iteration 31: train_loss 1.4038052558898926
Iteration 32: train_loss 1.3558807373046875
Iteration 33: train_loss 1.3725775480270386
Iteration 34: train_loss 1.392429232597351
Iteration 35: train_loss 1.3769630193710327
Iteration 36: train_loss 1.369738221168518
Iteration 37: train_loss 1.3687664270401
Iteration 38: train_loss 1.3888212442398071
Iteration 39: train_loss 1.3701390027999878
Iteration 40: train_loss 1.3460540771484375
Iteration 41: train_loss 1.378006100654602
Iteration 42: train_loss 1.362229347229004
Iteration 43: train_loss 1.4611347913742065
Iteration 44: train_loss 1.3565189838409424
Iteration 45: train_loss 1.352015495300293
Iteration 46: train_loss 1.395902395248413
Iteration 47: train_loss 1.3206945657730103
Iteration 48: train_loss 1.3909286260604858
Iteration 49: train_loss 1.3659759759902954
Iteration 50: train_loss 1.3332743644714355
Iteration 51: train_loss 1.3178898096084595
Iteration 52: train_loss 1.3353490829467773
Iteration 53: train_loss 1.350075602531433
Iteration 54: train_loss 1.3880558013916016
Iteration 55: train_loss 1.4487462043762207
Iteration 56: train_loss 1.3208543062210083
Iteration 57: train_loss 1.3451220989227295
Iteration 58: train_loss 1.3722060918807983
Iteration 59: train_loss 1.3523685932159424
Iteration 60: train_loss 1.3695160150527954
Iteration 61: train_loss 1.337167501449585
Iteration 62: train_loss 1.3763917684555054
Iteration 63: train_loss 1.3629549741744995
Iteration 64: train_loss 1.3592902421951294
Iteration 65: train_loss 1.33302903175354
Iteration 66: train_loss 1.3476080894470215
Iteration 67: train_loss 1.2756845951080322
Iteration 68: train_loss 1.340714931488037
Iteration 69: train_loss 1.3314311504364014
Iteration 70: train_loss 1.4086772203445435
Iteration 71: train_loss 1.3448352813720703
Iteration 72: train_loss 1.3694562911987305
Iteration 73: train_loss 1.3112930059432983
Iteration 74: train_loss 1.4309202432632446
Iteration 75: train_loss 1.3594555854797363
Iteration 76: train_loss 1.3503141403198242
Iteration 77: train_loss 1.3697863817214966
Iteration 78: train_loss 1.3873578310012817
Iteration 79: train_loss 1.3775514364242554
Iteration 80: train_loss 1.4425048828125
Iteration 81: train_loss 1.39676833152771
Iteration 82: train_loss 1.360676884651184
Iteration 83: train_loss 1.4085938930511475
Iteration 84: train_loss 1.3934580087661743
Iteration 85: train_loss 1.393681287765503
Iteration 86: train_loss 1.3559374809265137
Iteration 87: train_loss 1.328334927558899
Iteration 88: train_loss 1.3910272121429443
Iteration 89: train_loss 1.397728681564331
Iteration 90: train_loss 1.3364628553390503
Iteration 91: train_loss 1.3841705322265625
Iteration 92: train_loss 1.371322751045227
Iteration 93: train_loss 1.3881622552871704
Iteration 94: train_loss 1.3964695930480957
Iteration 95: train_loss 1.3658268451690674
Iteration 96: train_loss 1.3852453231811523
Iteration 97: train_loss 1.3554664850234985
Iteration 98: train_loss 1.3574044704437256
Iteration 99: train_loss 1.310788631439209
Iteration 100: train_loss 1.3039151430130005
Iteration 101: train_loss 1.3998183012008667
Iteration 102: train_loss 1.3169080018997192
Iteration 103: train_loss 1.32925283908844
Iteration 104: train_loss 1.3678611516952515
Iteration 105: train_loss 1.4077932834625244
Iteration 106: train_loss 1.3548915386199951
Iteration 107: train_loss 1.3325697183609009
Iteration 108: train_loss 1.389014720916748
Iteration 109: train_loss 1.423027515411377
Iteration 110: train_loss 1.3634828329086304
Iteration 111: train_loss 1.3917406797409058
Iteration 112: train_loss 1.398753046989441
Iteration 113: train_loss 1.3374685049057007
Iteration 114: train_loss 1.3767890930175781
Iteration 115: train_loss 1.3485748767852783
Iteration 116: train_loss 1.3936192989349365
Iteration 117: train_loss 1.3913242816925049
Iteration 118: train_loss 1.3532613515853882
Iteration 119: train_loss 1.3863545656204224
Iteration 120: train_loss 1.3359081745147705
Iteration 121: train_loss 1.339758038520813
Iteration 122: train_loss 1.4222804307937622
Iteration 123: train_loss 1.3311209678649902
Iteration 124: train_loss 1.3733922243118286
Iteration 125: train_loss 1.355560541152954
Iteration 126: train_loss 1.341180682182312
Iteration 127: train_loss 1.3879725933074951
Iteration 128: train_loss 1.3428230285644531
Iteration 129: train_loss 1.3977024555206299
Iteration 130: train_loss 1.3703093528747559
Iteration 131: train_loss 1.3283408880233765
Iteration 132: train_loss 1.3487372398376465
Iteration 133: train_loss 1.3854721784591675
Iteration 134: train_loss 1.3591923713684082
Iteration 135: train_loss 1.338015079498291
Iteration 136: train_loss 1.3452982902526855
Iteration 137: train_loss 1.3715989589691162
Iteration 138: train_loss 1.4042589664459229
Iteration 139: train_loss 1.3177589178085327
Iteration 140: train_loss 1.3110120296478271
Iteration 141: train_loss 1.3352954387664795
Iteration 142: train_loss 1.3963373899459839
Iteration 143: train_loss 1.3484437465667725
Iteration 144: train_loss 1.3924955129623413
Iteration 145: train_loss 1.3455581665039062
Iteration 146: train_loss 1.4032273292541504
Iteration 147: train_loss 1.4085017442703247
Iteration 148: train_loss 1.4435043334960938
Iteration 149: train_loss 1.3940399885177612
Iteration 150: train_loss 1.3823673725128174
Iteration 151: train_loss 1.4126266241073608
Iteration 152: train_loss 1.4118726253509521
Iteration 153: train_loss 1.3682183027267456
Iteration 154: train_loss 1.3914873600006104
Iteration 155: train_loss 1.263780951499939
Iteration 156: train_loss 1.3860151767730713
Iteration 157: train_loss 1.39584481716156
Iteration 158: train_loss 1.3850934505462646
Iteration 159: train_loss 1.438823938369751
Iteration 160: train_loss 1.3597584962844849
Iteration 161: train_loss 1.3716461658477783
Iteration 162: train_loss 1.395919680595398
Iteration 163: train_loss 1.356712818145752
Iteration 164: train_loss 1.3216391801834106
Iteration 165: train_loss 1.3689930438995361
Iteration 166: train_loss 1.4166110754013062
Iteration 167: train_loss 1.4162834882736206
Iteration 168: train_loss 1.3922572135925293
Iteration 169: train_loss 1.3962386846542358
Iteration 170: train_loss 1.422641396522522
Iteration 171: train_loss 1.340847134590149
Iteration 172: train_loss 1.3823364973068237
Iteration 173: train_loss 1.3953660726547241
Iteration 174: train_loss 1.4236127138137817
Iteration 175: train_loss 1.3189234733581543
Iteration 176: train_loss 1.4565191268920898
Iteration 177: train_loss 1.3846296072006226
Epoch 104: train_avg_loss 1.3657631227525615 eval_avg_acc: 0.3346043509976546 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:59:04] [32mIntermediate result: 0.3346043509976546  (Index 103)[0m
================Epoch: 105================
Iteration 1: train_loss 1.4081802368164062
Iteration 2: train_loss 1.3388711214065552
Iteration 3: train_loss 1.3484680652618408
Iteration 4: train_loss 1.3807357549667358
Iteration 5: train_loss 1.4504573345184326
Iteration 6: train_loss 1.4209569692611694
Iteration 7: train_loss 1.4248969554901123
Iteration 8: train_loss 1.3451443910598755
Iteration 9: train_loss 1.363014817237854
Iteration 10: train_loss 1.3765265941619873
Iteration 11: train_loss 1.3929011821746826
Iteration 12: train_loss 1.4019169807434082
Iteration 13: train_loss 1.417850375175476
Iteration 14: train_loss 1.3697152137756348
Iteration 15: train_loss 1.4150967597961426
Iteration 16: train_loss 1.3320437669754028
Iteration 17: train_loss 1.3558285236358643
Iteration 18: train_loss 1.325722098350525
Iteration 19: train_loss 1.4160292148590088
Iteration 20: train_loss 1.3562861680984497
Iteration 21: train_loss 1.3959274291992188
Iteration 22: train_loss 1.291617512702942
Iteration 23: train_loss 1.3019771575927734
Iteration 24: train_loss 1.3980003595352173
Iteration 25: train_loss 1.3335742950439453
Iteration 26: train_loss 1.3314557075500488
Iteration 27: train_loss 1.2933694124221802
Iteration 28: train_loss 1.3789050579071045
Iteration 29: train_loss 1.3283964395523071
Iteration 30: train_loss 1.3436920642852783
Iteration 31: train_loss 1.3898488283157349
Iteration 32: train_loss 1.339340090751648
Iteration 33: train_loss 1.324596643447876
Iteration 34: train_loss 1.344926118850708
Iteration 35: train_loss 1.347192645072937
Iteration 36: train_loss 1.3208554983139038
Iteration 37: train_loss 1.3660895824432373
Iteration 38: train_loss 1.2708535194396973
Iteration 39: train_loss 1.34700345993042
Iteration 40: train_loss 1.3585299253463745
Iteration 41: train_loss 1.3728723526000977
Iteration 42: train_loss 1.3187265396118164
Iteration 43: train_loss 1.3260459899902344
Iteration 44: train_loss 1.357675552368164
Iteration 45: train_loss 1.3360122442245483
Iteration 46: train_loss 1.339743733406067
Iteration 47: train_loss 1.3386350870132446
Iteration 48: train_loss 1.3724058866500854
Iteration 49: train_loss 1.3530282974243164
Iteration 50: train_loss 1.3293591737747192
Iteration 51: train_loss 1.3028186559677124
Iteration 52: train_loss 1.402021050453186
Iteration 53: train_loss 1.35581374168396
Iteration 54: train_loss 1.4106332063674927
Iteration 55: train_loss 1.354179859161377
Iteration 56: train_loss 1.3600561618804932
Iteration 57: train_loss 1.3608826398849487
Iteration 58: train_loss 1.380517601966858
Iteration 59: train_loss 1.396143913269043
Iteration 60: train_loss 1.3860706090927124
Iteration 61: train_loss 1.311484932899475
Iteration 62: train_loss 1.340950846672058
Iteration 63: train_loss 1.3597891330718994
Iteration 64: train_loss 1.3700491189956665
Iteration 65: train_loss 1.3395614624023438
Iteration 66: train_loss 1.3114063739776611
Iteration 67: train_loss 1.3673691749572754
Iteration 68: train_loss 1.3630486726760864
Iteration 69: train_loss 1.4325867891311646
Iteration 70: train_loss 1.3961875438690186
Iteration 71: train_loss 1.3055626153945923
Iteration 72: train_loss 1.308180570602417
Iteration 73: train_loss 1.3014652729034424
Iteration 74: train_loss 1.3562747240066528
Iteration 75: train_loss 1.374686360359192
Iteration 76: train_loss 1.3013797998428345
Iteration 77: train_loss 1.418392539024353
Iteration 78: train_loss 1.3318254947662354
Iteration 79: train_loss 1.350423812866211
Iteration 80: train_loss 1.378251314163208
Iteration 81: train_loss 1.3653610944747925
Iteration 82: train_loss 1.319022536277771
Iteration 83: train_loss 1.3556125164031982
Iteration 84: train_loss 1.3779276609420776
Iteration 85: train_loss 1.375071406364441
Iteration 86: train_loss 1.3424211740493774
Iteration 87: train_loss 1.3454773426055908
Iteration 88: train_loss 1.3614879846572876
Iteration 89: train_loss 1.315707802772522
Iteration 90: train_loss 1.4480100870132446
Iteration 91: train_loss 1.470191240310669
Iteration 92: train_loss 1.4040709733963013
Iteration 93: train_loss 1.4362337589263916
Iteration 94: train_loss 1.463209867477417
Iteration 95: train_loss 1.3836495876312256
Iteration 96: train_loss 1.3517848253250122
Iteration 97: train_loss 1.3453189134597778
Iteration 98: train_loss 1.3888335227966309
Iteration 99: train_loss 1.344413161277771
Iteration 100: train_loss 1.3773956298828125
Iteration 101: train_loss 1.3927078247070312
Iteration 102: train_loss 1.32633638381958
Iteration 103: train_loss 1.366106629371643
Iteration 104: train_loss 1.3883945941925049
Iteration 105: train_loss 1.3772141933441162
Iteration 106: train_loss 1.386547565460205
Iteration 107: train_loss 1.3948928117752075
Iteration 108: train_loss 1.4072692394256592
Iteration 109: train_loss 1.378444790840149
Iteration 110: train_loss 1.3151038885116577
Iteration 111: train_loss 1.3442716598510742
Iteration 112: train_loss 1.3889180421829224
Iteration 113: train_loss 1.3965436220169067
Iteration 114: train_loss 1.332505702972412
Iteration 115: train_loss 1.3599478006362915
Iteration 116: train_loss 1.3241400718688965
Iteration 117: train_loss 1.358596920967102
Iteration 118: train_loss 1.372215747833252
Iteration 119: train_loss 1.3144961595535278
Iteration 120: train_loss 1.3645961284637451
Iteration 121: train_loss 1.4080601930618286
Iteration 122: train_loss 1.3329285383224487
Iteration 123: train_loss 1.4056212902069092
Iteration 124: train_loss 1.4135189056396484
Iteration 125: train_loss 1.373229742050171
Iteration 126: train_loss 1.2995866537094116
Iteration 127: train_loss 1.372543215751648
Iteration 128: train_loss 1.3881652355194092
Iteration 129: train_loss 1.3228609561920166
Iteration 130: train_loss 1.3771414756774902
Iteration 131: train_loss 1.336575984954834
Iteration 132: train_loss 1.3549323081970215
Iteration 133: train_loss 1.3920841217041016
Iteration 134: train_loss 1.341264009475708
Iteration 135: train_loss 1.3434419631958008
Iteration 136: train_loss 1.3469263315200806
Iteration 137: train_loss 1.3420814275741577
Iteration 138: train_loss 1.3344058990478516
Iteration 139: train_loss 1.3484247922897339
Iteration 140: train_loss 1.3601175546646118
Iteration 141: train_loss 1.3875019550323486
Iteration 142: train_loss 1.3654725551605225
Iteration 143: train_loss 1.3093116283416748
Iteration 144: train_loss 1.3535794019699097
Iteration 145: train_loss 1.2914135456085205
Iteration 146: train_loss 1.3662285804748535
Iteration 147: train_loss 1.4131759405136108
Iteration 148: train_loss 1.3689887523651123
Iteration 149: train_loss 1.3338375091552734
Iteration 150: train_loss 1.394631266593933
Iteration 151: train_loss 1.3143872022628784
Iteration 152: train_loss 1.3753772974014282
Iteration 153: train_loss 1.350797176361084
Iteration 154: train_loss 1.3295656442642212
Iteration 155: train_loss 1.3563647270202637
Iteration 156: train_loss 1.382523536682129
Iteration 157: train_loss 1.3514823913574219
Iteration 158: train_loss 1.4012582302093506
Iteration 159: train_loss 1.3883267641067505
Iteration 160: train_loss 1.3414428234100342
Iteration 161: train_loss 1.3505514860153198
Iteration 162: train_loss 1.3394932746887207
Iteration 163: train_loss 1.372270107269287
Iteration 164: train_loss 1.3753750324249268
Iteration 165: train_loss 1.3675733804702759
Iteration 166: train_loss 1.375299096107483
Iteration 167: train_loss 1.4237850904464722
Iteration 168: train_loss 1.4662774801254272
Iteration 169: train_loss 1.3947330713272095
Iteration 170: train_loss 1.3579890727996826
Iteration 171: train_loss 1.367498755455017
Iteration 172: train_loss 1.3779934644699097
Iteration 173: train_loss 1.3896498680114746
Iteration 174: train_loss 1.4121603965759277
Iteration 175: train_loss 1.391568899154663
Iteration 176: train_loss 1.3643267154693604
Iteration 177: train_loss 1.2688748836517334
Epoch 105: train_avg_loss 1.3629647547242332 eval_avg_acc: 0.3473030535206228 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 02:59:47] [32mIntermediate result: 0.3473030535206228  (Index 104)[0m
================Epoch: 106================
Iteration 1: train_loss 1.3404557704925537
Iteration 2: train_loss 1.361066222190857
Iteration 3: train_loss 1.3321657180786133
Iteration 4: train_loss 1.3579171895980835
Iteration 5: train_loss 1.408029556274414
Iteration 6: train_loss 1.389669418334961
Iteration 7: train_loss 1.3501992225646973
Iteration 8: train_loss 1.374762773513794
Iteration 9: train_loss 1.349826693534851
Iteration 10: train_loss 1.4053574800491333
Iteration 11: train_loss 1.396289348602295
Iteration 12: train_loss 1.3506523370742798
Iteration 13: train_loss 1.3748451471328735
Iteration 14: train_loss 1.347764492034912
Iteration 15: train_loss 1.3267256021499634
Iteration 16: train_loss 1.3028384447097778
Iteration 17: train_loss 1.351954698562622
Iteration 18: train_loss 1.2940675020217896
Iteration 19: train_loss 1.2598448991775513
Iteration 20: train_loss 1.3284802436828613
Iteration 21: train_loss 1.320574164390564
Iteration 22: train_loss 1.2694098949432373
Iteration 23: train_loss 1.3391528129577637
Iteration 24: train_loss 1.4058775901794434
Iteration 25: train_loss 1.3447073698043823
Iteration 26: train_loss 1.3480727672576904
Iteration 27: train_loss 1.3659106492996216
Iteration 28: train_loss 1.3968192338943481
Iteration 29: train_loss 1.3062807321548462
Iteration 30: train_loss 1.294155240058899
Iteration 31: train_loss 1.3665969371795654
Iteration 32: train_loss 1.3528209924697876
Iteration 33: train_loss 1.3620946407318115
Iteration 34: train_loss 1.2974963188171387
Iteration 35: train_loss 1.3493623733520508
Iteration 36: train_loss 1.2644380331039429
Iteration 37: train_loss 1.2791811227798462
Iteration 38: train_loss 1.2917799949645996
Iteration 39: train_loss 1.2959367036819458
Iteration 40: train_loss 1.3346997499465942
Iteration 41: train_loss 1.3319600820541382
Iteration 42: train_loss 1.2947992086410522
Iteration 43: train_loss 1.3584614992141724
Iteration 44: train_loss 1.3097854852676392
Iteration 45: train_loss 1.3740482330322266
Iteration 46: train_loss 1.299130916595459
Iteration 47: train_loss 1.3597688674926758
Iteration 48: train_loss 1.2749308347702026
Iteration 49: train_loss 1.283831238746643
Iteration 50: train_loss 1.3741505146026611
Iteration 51: train_loss 1.289806842803955
Iteration 52: train_loss 1.3212358951568604
Iteration 53: train_loss 1.3506815433502197
Iteration 54: train_loss 1.3586604595184326
Iteration 55: train_loss 1.3502967357635498
Iteration 56: train_loss 1.3040205240249634
Iteration 57: train_loss 1.2868626117706299
Iteration 58: train_loss 1.2890199422836304
Iteration 59: train_loss 1.332726240158081
Iteration 60: train_loss 1.3683897256851196
Iteration 61: train_loss 1.3402916193008423
Iteration 62: train_loss 1.3082447052001953
Iteration 63: train_loss 1.360009789466858
Iteration 64: train_loss 1.3535326719284058
Iteration 65: train_loss 1.3251516819000244
Iteration 66: train_loss 1.2958223819732666
Iteration 67: train_loss 1.3264330625534058
Iteration 68: train_loss 1.2755982875823975
Iteration 69: train_loss 1.3020987510681152
Iteration 70: train_loss 1.34178626537323
Iteration 71: train_loss 1.4077072143554688
Iteration 72: train_loss 1.3504793643951416
Iteration 73: train_loss 1.3968836069107056
Iteration 74: train_loss 1.4328700304031372
Iteration 75: train_loss 1.3544526100158691
Iteration 76: train_loss 1.3752366304397583
Iteration 77: train_loss 1.332369327545166
Iteration 78: train_loss 1.3719154596328735
Iteration 79: train_loss 1.3436154127120972
Iteration 80: train_loss 1.3435695171356201
Iteration 81: train_loss 1.3235266208648682
Iteration 82: train_loss 1.3292362689971924
Iteration 83: train_loss 1.3494846820831299
Iteration 84: train_loss 1.4094276428222656
Iteration 85: train_loss 1.3899329900741577
Iteration 86: train_loss 1.4141522645950317
Iteration 87: train_loss 1.3106266260147095
Iteration 88: train_loss 1.334424376487732
Iteration 89: train_loss 1.3718762397766113
Iteration 90: train_loss 1.392971396446228
Iteration 91: train_loss 1.3832569122314453
Iteration 92: train_loss 1.3503483533859253
Iteration 93: train_loss 1.3696389198303223
Iteration 94: train_loss 1.3332751989364624
Iteration 95: train_loss 1.4040628671646118
Iteration 96: train_loss 1.3909692764282227
Iteration 97: train_loss 1.4108473062515259
Iteration 98: train_loss 1.3812779188156128
Iteration 99: train_loss 1.3778501749038696
Iteration 100: train_loss 1.3589781522750854
Iteration 101: train_loss 1.3796463012695312
Iteration 102: train_loss 1.3734169006347656
Iteration 103: train_loss 1.3362973928451538
Iteration 104: train_loss 1.3771393299102783
Iteration 105: train_loss 1.3238438367843628
Iteration 106: train_loss 1.3630515336990356
Iteration 107: train_loss 1.3612422943115234
Iteration 108: train_loss 1.3890506029129028
Iteration 109: train_loss 1.371795654296875
Iteration 110: train_loss 1.2869019508361816
Iteration 111: train_loss 1.3349409103393555
Iteration 112: train_loss 1.3204091787338257
Iteration 113: train_loss 1.4007177352905273
Iteration 114: train_loss 1.325289249420166
Iteration 115: train_loss 1.3266793489456177
Iteration 116: train_loss 1.3644508123397827
Iteration 117: train_loss 1.3819732666015625
Iteration 118: train_loss 1.3700056076049805
Iteration 119: train_loss 1.3917601108551025
Iteration 120: train_loss 1.302215814590454
Iteration 121: train_loss 1.3200643062591553
Iteration 122: train_loss 1.3696262836456299
Iteration 123: train_loss 1.352534294128418
Iteration 124: train_loss 1.4248043298721313
Iteration 125: train_loss 1.3600783348083496
Iteration 126: train_loss 1.3590166568756104
Iteration 127: train_loss 1.3271242380142212
Iteration 128: train_loss 1.3001724481582642
Iteration 129: train_loss 1.3276852369308472
Iteration 130: train_loss 1.3783525228500366
Iteration 131: train_loss 1.3709675073623657
Iteration 132: train_loss 1.3116097450256348
Iteration 133: train_loss 1.3852157592773438
Iteration 134: train_loss 1.3221515417099
Iteration 135: train_loss 1.3624745607376099
Iteration 136: train_loss 1.351640224456787
Iteration 137: train_loss 1.3401559591293335
Iteration 138: train_loss 1.3927433490753174
Iteration 139: train_loss 1.3784561157226562
Iteration 140: train_loss 1.4206318855285645
Iteration 141: train_loss 1.3537999391555786
Iteration 142: train_loss 1.4404009580612183
Iteration 143: train_loss 1.3141825199127197
Iteration 144: train_loss 1.3119407892227173
Iteration 145: train_loss 1.4249600172042847
Iteration 146: train_loss 1.3058812618255615
Iteration 147: train_loss 1.3777984380722046
Iteration 148: train_loss 1.325477123260498
Iteration 149: train_loss 1.3338546752929688
Iteration 150: train_loss 1.3320226669311523
Iteration 151: train_loss 1.433363676071167
Iteration 152: train_loss 1.3725261688232422
Iteration 153: train_loss 1.4204511642456055
Iteration 154: train_loss 1.373955249786377
Iteration 155: train_loss 1.4423224925994873
Iteration 156: train_loss 1.3495864868164062
Iteration 157: train_loss 1.347936749458313
Iteration 158: train_loss 1.3923165798187256
Iteration 159: train_loss 1.4243239164352417
Iteration 160: train_loss 1.394270658493042
Iteration 161: train_loss 1.3766100406646729
Iteration 162: train_loss 1.3596223592758179
Iteration 163: train_loss 1.2913566827774048
Iteration 164: train_loss 1.3676433563232422
Iteration 165: train_loss 1.3273628950119019
Iteration 166: train_loss 1.4055719375610352
Iteration 167: train_loss 1.3833733797073364
Iteration 168: train_loss 1.352836012840271
Iteration 169: train_loss 1.3884960412979126
Iteration 170: train_loss 1.3734098672866821
Iteration 171: train_loss 1.3479063510894775
Iteration 172: train_loss 1.2804234027862549
Iteration 173: train_loss 1.390236496925354
Iteration 174: train_loss 1.3682217597961426
Iteration 175: train_loss 1.3745914697647095
Iteration 176: train_loss 1.3486371040344238
Iteration 177: train_loss 1.370536208152771
Epoch 106: train_avg_loss 1.3516362716922652 eval_avg_acc: 0.34541824591516157 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:00:27] [32mIntermediate result: 0.34541824591516157  (Index 105)[0m
================Epoch: 107================
Iteration 1: train_loss 1.391322374343872
Iteration 2: train_loss 1.345158338546753
Iteration 3: train_loss 1.4020376205444336
Iteration 4: train_loss 1.2660844326019287
Iteration 5: train_loss 1.4062449932098389
Iteration 6: train_loss 1.3621011972427368
Iteration 7: train_loss 1.3718881607055664
Iteration 8: train_loss 1.2970857620239258
Iteration 9: train_loss 1.3016793727874756
Iteration 10: train_loss 1.311718463897705
Iteration 11: train_loss 1.2437338829040527
Iteration 12: train_loss 1.3092361688613892
Iteration 13: train_loss 1.3534245491027832
Iteration 14: train_loss 1.3180632591247559
Iteration 15: train_loss 1.33339524269104
Iteration 16: train_loss 1.2223074436187744
Iteration 17: train_loss 1.2645199298858643
Iteration 18: train_loss 1.2931352853775024
Iteration 19: train_loss 1.2872141599655151
Iteration 20: train_loss 1.2542839050292969
Iteration 21: train_loss 1.3192288875579834
Iteration 22: train_loss 1.312897801399231
Iteration 23: train_loss 1.350899338722229
Iteration 24: train_loss 1.2936707735061646
Iteration 25: train_loss 1.346557855606079
Iteration 26: train_loss 1.3375028371810913
Iteration 27: train_loss 1.333458662033081
Iteration 28: train_loss 1.3283528089523315
Iteration 29: train_loss 1.3253623247146606
Iteration 30: train_loss 1.281728982925415
Iteration 31: train_loss 1.298056960105896
Iteration 32: train_loss 1.3702659606933594
Iteration 33: train_loss 1.2889575958251953
Iteration 34: train_loss 1.360863208770752
Iteration 35: train_loss 1.2974820137023926
Iteration 36: train_loss 1.3247627019882202
Iteration 37: train_loss 1.3854637145996094
Iteration 38: train_loss 1.3248279094696045
Iteration 39: train_loss 1.278607964515686
Iteration 40: train_loss 1.3682886362075806
Iteration 41: train_loss 1.3013293743133545
Iteration 42: train_loss 1.359316349029541
Iteration 43: train_loss 1.450101613998413
Iteration 44: train_loss 1.3247449398040771
Iteration 45: train_loss 1.3418669700622559
Iteration 46: train_loss 1.2966099977493286
Iteration 47: train_loss 1.3446307182312012
Iteration 48: train_loss 1.329317569732666
Iteration 49: train_loss 1.3002026081085205
Iteration 50: train_loss 1.3153680562973022
Iteration 51: train_loss 1.3104408979415894
Iteration 52: train_loss 1.3786100149154663
Iteration 53: train_loss 1.3479324579238892
Iteration 54: train_loss 1.3626400232315063
Iteration 55: train_loss 1.3056480884552002
Iteration 56: train_loss 1.291157841682434
Iteration 57: train_loss 1.278295874595642
Iteration 58: train_loss 1.3543360233306885
Iteration 59: train_loss 1.284485101699829
Iteration 60: train_loss 1.2641445398330688
Iteration 61: train_loss 1.311671495437622
Iteration 62: train_loss 1.3950328826904297
Iteration 63: train_loss 1.379744291305542
Iteration 64: train_loss 1.3312095403671265
Iteration 65: train_loss 1.403637409210205
Iteration 66: train_loss 1.2917544841766357
Iteration 67: train_loss 1.3998607397079468
Iteration 68: train_loss 1.3226523399353027
Iteration 69: train_loss 1.269402265548706
Iteration 70: train_loss 1.3496360778808594
Iteration 71: train_loss 1.3161267042160034
Iteration 72: train_loss 1.3594038486480713
Iteration 73: train_loss 1.329505443572998
Iteration 74: train_loss 1.3275290727615356
Iteration 75: train_loss 1.3536466360092163
Iteration 76: train_loss 1.3347586393356323
Iteration 77: train_loss 1.3695958852767944
Iteration 78: train_loss 1.337949514389038
Iteration 79: train_loss 1.3266855478286743
Iteration 80: train_loss 1.4076895713806152
Iteration 81: train_loss 1.369133472442627
Iteration 82: train_loss 1.347119688987732
Iteration 83: train_loss 1.3338654041290283
Iteration 84: train_loss 1.3359943628311157
Iteration 85: train_loss 1.4214047193527222
Iteration 86: train_loss 1.3554623126983643
Iteration 87: train_loss 1.3604645729064941
Iteration 88: train_loss 1.3210467100143433
Iteration 89: train_loss 1.3575536012649536
Iteration 90: train_loss 1.3638310432434082
Iteration 91: train_loss 1.3953124284744263
Iteration 92: train_loss 1.3052260875701904
Iteration 93: train_loss 1.3727245330810547
Iteration 94: train_loss 1.3542331457138062
Iteration 95: train_loss 1.3732715845108032
Iteration 96: train_loss 1.3895951509475708
Iteration 97: train_loss 1.3842917680740356
Iteration 98: train_loss 1.3238041400909424
Iteration 99: train_loss 1.35080885887146
Iteration 100: train_loss 1.3490114212036133
Iteration 101: train_loss 1.3292380571365356
Iteration 102: train_loss 1.3415870666503906
Iteration 103: train_loss 1.332261323928833
Iteration 104: train_loss 1.3336631059646606
Iteration 105: train_loss 1.3130844831466675
Iteration 106: train_loss 1.3345094919204712
Iteration 107: train_loss 1.3503152132034302
Iteration 108: train_loss 1.294651746749878
Iteration 109: train_loss 1.3471519947052002
Iteration 110: train_loss 1.2978534698486328
Iteration 111: train_loss 1.352558970451355
Iteration 112: train_loss 1.3578448295593262
Iteration 113: train_loss 1.359298825263977
Iteration 114: train_loss 1.274720549583435
Iteration 115: train_loss 1.2979320287704468
Iteration 116: train_loss 1.3740938901901245
Iteration 117: train_loss 1.3303534984588623
Iteration 118: train_loss 1.334614634513855
Iteration 119: train_loss 1.378178596496582
Iteration 120: train_loss 1.3603768348693848
Iteration 121: train_loss 1.3557360172271729
Iteration 122: train_loss 1.3814430236816406
Iteration 123: train_loss 1.3088414669036865
Iteration 124: train_loss 1.3686180114746094
Iteration 125: train_loss 1.3679702281951904
Iteration 126: train_loss 1.3902630805969238
Iteration 127: train_loss 1.378599762916565
Iteration 128: train_loss 1.3498777151107788
Iteration 129: train_loss 1.3919401168823242
Iteration 130: train_loss 1.3588263988494873
Iteration 131: train_loss 1.3593145608901978
Iteration 132: train_loss 1.3488143682479858
Iteration 133: train_loss 1.4350980520248413
Iteration 134: train_loss 1.3625094890594482
Iteration 135: train_loss 1.3632417917251587
Iteration 136: train_loss 1.32688307762146
Iteration 137: train_loss 1.3716119527816772
Iteration 138: train_loss 1.3085572719573975
Iteration 139: train_loss 1.3830063343048096
Iteration 140: train_loss 1.2933175563812256
Iteration 141: train_loss 1.3922209739685059
Iteration 142: train_loss 1.2964563369750977
Iteration 143: train_loss 1.3662693500518799
Iteration 144: train_loss 1.336206316947937
Iteration 145: train_loss 1.2863287925720215
Iteration 146: train_loss 1.3733688592910767
Iteration 147: train_loss 1.307701587677002
Iteration 148: train_loss 1.3573253154754639
Iteration 149: train_loss 1.337841272354126
Iteration 150: train_loss 1.369115948677063
Iteration 151: train_loss 1.3668248653411865
Iteration 152: train_loss 1.3786978721618652
Iteration 153: train_loss 1.3355871438980103
Iteration 154: train_loss 1.3503353595733643
Iteration 155: train_loss 1.346161961555481
Iteration 156: train_loss 1.290001392364502
Iteration 157: train_loss 1.3538957834243774
Iteration 158: train_loss 1.331886649131775
Iteration 159: train_loss 1.3991045951843262
Iteration 160: train_loss 1.3715795278549194
Iteration 161: train_loss 1.3667129278182983
Iteration 162: train_loss 1.4010494947433472
Iteration 163: train_loss 1.3311411142349243
Iteration 164: train_loss 1.3855575323104858
Iteration 165: train_loss 1.3633625507354736
Iteration 166: train_loss 1.3719267845153809
Iteration 167: train_loss 1.4070172309875488
Iteration 168: train_loss 1.3627592325210571
Iteration 169: train_loss 1.4133937358856201
Iteration 170: train_loss 1.349668025970459
Iteration 171: train_loss 1.4033403396606445
Iteration 172: train_loss 1.3285516500473022
Iteration 173: train_loss 1.3572124242782593
Iteration 174: train_loss 1.3899190425872803
Iteration 175: train_loss 1.3844164609909058
Iteration 176: train_loss 1.370413064956665
Iteration 177: train_loss 1.322960376739502
Epoch 107: train_avg_loss 1.3425975633879839 eval_avg_acc: 0.34890814826875055 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:01:00] [32mIntermediate result: 0.34890814826875055  (Index 106)[0m
================Epoch: 108================
Iteration 1: train_loss 1.3569343090057373
Iteration 2: train_loss 1.3127385377883911
Iteration 3: train_loss 1.325801968574524
Iteration 4: train_loss 1.3112633228302002
Iteration 5: train_loss 1.3127727508544922
Iteration 6: train_loss 1.326969027519226
Iteration 7: train_loss 1.3279526233673096
Iteration 8: train_loss 1.29470956325531
Iteration 9: train_loss 1.3217394351959229
Iteration 10: train_loss 1.2687345743179321
Iteration 11: train_loss 1.318698525428772
Iteration 12: train_loss 1.3063184022903442
Iteration 13: train_loss 1.3463759422302246
Iteration 14: train_loss 1.3243402242660522
Iteration 15: train_loss 1.271720290184021
Iteration 16: train_loss 1.2986772060394287
Iteration 17: train_loss 1.3165678977966309
Iteration 18: train_loss 1.3591371774673462
Iteration 19: train_loss 1.3226720094680786
Iteration 20: train_loss 1.3175442218780518
Iteration 21: train_loss 1.3818176984786987
Iteration 22: train_loss 1.4001578092575073
Iteration 23: train_loss 1.367851972579956
Iteration 24: train_loss 1.3421237468719482
Iteration 25: train_loss 1.3183987140655518
Iteration 26: train_loss 1.2843753099441528
Iteration 27: train_loss 1.392867922782898
Iteration 28: train_loss 1.3029388189315796
Iteration 29: train_loss 1.2909398078918457
Iteration 30: train_loss 1.3679245710372925
Iteration 31: train_loss 1.371927261352539
Iteration 32: train_loss 1.3065990209579468
Iteration 33: train_loss 1.3377565145492554
Iteration 34: train_loss 1.3448094129562378
Iteration 35: train_loss 1.3463801145553589
Iteration 36: train_loss 1.3829699754714966
Iteration 37: train_loss 1.3525861501693726
Iteration 38: train_loss 1.3361918926239014
Iteration 39: train_loss 1.3655643463134766
Iteration 40: train_loss 1.3503284454345703
Iteration 41: train_loss 1.3686167001724243
Iteration 42: train_loss 1.333331823348999
Iteration 43: train_loss 1.3409351110458374
Iteration 44: train_loss 1.3153865337371826
Iteration 45: train_loss 1.3647350072860718
Iteration 46: train_loss 1.332463264465332
Iteration 47: train_loss 1.2891076803207397
Iteration 48: train_loss 1.3164258003234863
Iteration 49: train_loss 1.283470869064331
Iteration 50: train_loss 1.3377268314361572
Iteration 51: train_loss 1.3738813400268555
Iteration 52: train_loss 1.3893057107925415
Iteration 53: train_loss 1.3080346584320068
Iteration 54: train_loss 1.3587058782577515
Iteration 55: train_loss 1.3590095043182373
Iteration 56: train_loss 1.3452163934707642
Iteration 57: train_loss 1.354099154472351
Iteration 58: train_loss 1.4368447065353394
Iteration 59: train_loss 1.3599767684936523
Iteration 60: train_loss 1.3163188695907593
Iteration 61: train_loss 1.4249258041381836
Iteration 62: train_loss 1.3665759563446045
Iteration 63: train_loss 1.4219101667404175
Iteration 64: train_loss 1.4294544458389282
Iteration 65: train_loss 1.350435495376587
Iteration 66: train_loss 1.4408382177352905
Iteration 67: train_loss 1.3620177507400513
Iteration 68: train_loss 1.4303735494613647
Iteration 69: train_loss 1.3670241832733154
Iteration 70: train_loss 1.386407732963562
Iteration 71: train_loss 1.4392226934432983
Iteration 72: train_loss 1.4725459814071655
Iteration 73: train_loss 1.354560136795044
Iteration 74: train_loss 1.3676327466964722
Iteration 75: train_loss 1.3294180631637573
Iteration 76: train_loss 1.326372742652893
Iteration 77: train_loss 1.3102355003356934
Iteration 78: train_loss 1.3484783172607422
Iteration 79: train_loss 1.337829351425171
Iteration 80: train_loss 1.3473502397537231
Iteration 81: train_loss 1.3448336124420166
Iteration 82: train_loss 1.406526803970337
Iteration 83: train_loss 1.35737144947052
Iteration 84: train_loss 1.3435486555099487
Iteration 85: train_loss 1.3618299961090088
Iteration 86: train_loss 1.2995260953903198
Iteration 87: train_loss 1.342935562133789
Iteration 88: train_loss 1.3066985607147217
Iteration 89: train_loss 1.3349614143371582
Iteration 90: train_loss 1.3458795547485352
Iteration 91: train_loss 1.3666163682937622
Iteration 92: train_loss 1.3893635272979736
Iteration 93: train_loss 1.318019151687622
Iteration 94: train_loss 1.4029386043548584
Iteration 95: train_loss 1.3452221155166626
Iteration 96: train_loss 1.3562737703323364
Iteration 97: train_loss 1.355258822441101
Iteration 98: train_loss 1.32933509349823
Iteration 99: train_loss 1.3343983888626099
Iteration 100: train_loss 1.3818092346191406
Iteration 101: train_loss 1.3642356395721436
Iteration 102: train_loss 1.2914072275161743
Iteration 103: train_loss 1.343529462814331
Iteration 104: train_loss 1.3443971872329712
Iteration 105: train_loss 1.3324342966079712
Iteration 106: train_loss 1.3540198802947998
Iteration 107: train_loss 1.3453797101974487
Iteration 108: train_loss 1.35854172706604
Iteration 109: train_loss 1.268941879272461
Iteration 110: train_loss 1.3588731288909912
Iteration 111: train_loss 1.2874573469161987
Iteration 112: train_loss 1.2992186546325684
Iteration 113: train_loss 1.326365351676941
Iteration 114: train_loss 1.429397702217102
Iteration 115: train_loss 1.4173372983932495
Iteration 116: train_loss 1.3984142541885376
Iteration 117: train_loss 1.3629463911056519
Iteration 118: train_loss 1.323209285736084
Iteration 119: train_loss 1.3424046039581299
Iteration 120: train_loss 1.3895225524902344
Iteration 121: train_loss 1.3887510299682617
Iteration 122: train_loss 1.3963640928268433
Iteration 123: train_loss 1.3140696287155151
Iteration 124: train_loss 1.3812718391418457
Iteration 125: train_loss 1.3448817729949951
Iteration 126: train_loss 1.3171002864837646
Iteration 127: train_loss 1.3494696617126465
Iteration 128: train_loss 1.3274686336517334
Iteration 129: train_loss 1.371228575706482
Iteration 130: train_loss 1.383551836013794
Iteration 131: train_loss 1.2956252098083496
Iteration 132: train_loss 1.3564610481262207
Iteration 133: train_loss 1.3869549036026
Iteration 134: train_loss 1.4005590677261353
Iteration 135: train_loss 1.296327829360962
Iteration 136: train_loss 1.355374813079834
Iteration 137: train_loss 1.3706382513046265
Iteration 138: train_loss 1.351708173751831
Iteration 139: train_loss 1.3224918842315674
Iteration 140: train_loss 1.3186366558074951
Iteration 141: train_loss 1.3375753164291382
Iteration 142: train_loss 1.3275941610336304
Iteration 143: train_loss 1.3265657424926758
Iteration 144: train_loss 1.3271182775497437
Iteration 145: train_loss 1.3054951429367065
Iteration 146: train_loss 1.3179353475570679
Iteration 147: train_loss 1.3360471725463867
Iteration 148: train_loss 1.3766552209854126
Iteration 149: train_loss 1.3382267951965332
Iteration 150: train_loss 1.4045634269714355
Iteration 151: train_loss 1.3975144624710083
Iteration 152: train_loss 1.346919298171997
Iteration 153: train_loss 1.3664190769195557
Iteration 154: train_loss 1.340772032737732
Iteration 155: train_loss 1.3375353813171387
Iteration 156: train_loss 1.3855886459350586
Iteration 157: train_loss 1.4301955699920654
Iteration 158: train_loss 1.358195424079895
Iteration 159: train_loss 1.3486796617507935
Iteration 160: train_loss 1.305935025215149
Iteration 161: train_loss 1.324703574180603
Iteration 162: train_loss 1.3244247436523438
Iteration 163: train_loss 1.4228435754776
Iteration 164: train_loss 1.3565527200698853
Iteration 165: train_loss 1.383088231086731
Iteration 166: train_loss 1.4064254760742188
Iteration 167: train_loss 1.3574471473693848
Iteration 168: train_loss 1.394137978553772
Iteration 169: train_loss 1.3495341539382935
Iteration 170: train_loss 1.385049819946289
Iteration 171: train_loss 1.3819392919540405
Iteration 172: train_loss 1.3565385341644287
Iteration 173: train_loss 1.356692910194397
Iteration 174: train_loss 1.348856806755066
Iteration 175: train_loss 1.3470758199691772
Iteration 176: train_loss 1.325385332107544
Iteration 177: train_loss 1.3651237487792969
Epoch 108: train_avg_loss 1.3501415016960963 eval_avg_acc: 0.3487074703983666 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:01:37] [32mIntermediate result: 0.3487074703983666  (Index 107)[0m
================Epoch: 109================
Iteration 1: train_loss 1.3094114065170288
Iteration 2: train_loss 1.2737315893173218
Iteration 3: train_loss 1.2908496856689453
Iteration 4: train_loss 1.3347141742706299
Iteration 5: train_loss 1.3388034105300903
Iteration 6: train_loss 1.3227779865264893
Iteration 7: train_loss 1.3237131834030151
Iteration 8: train_loss 1.3687291145324707
Iteration 9: train_loss 1.3560224771499634
Iteration 10: train_loss 1.2677252292633057
Iteration 11: train_loss 1.3708922863006592
Iteration 12: train_loss 1.3319664001464844
Iteration 13: train_loss 1.326245665550232
Iteration 14: train_loss 1.3613239526748657
Iteration 15: train_loss 1.3205891847610474
Iteration 16: train_loss 1.3420560359954834
Iteration 17: train_loss 1.4145127534866333
Iteration 18: train_loss 1.3671178817749023
Iteration 19: train_loss 1.3085308074951172
Iteration 20: train_loss 1.3520867824554443
Iteration 21: train_loss 1.3408939838409424
Iteration 22: train_loss 1.319421648979187
Iteration 23: train_loss 1.2855815887451172
Iteration 24: train_loss 1.3792775869369507
Iteration 25: train_loss 1.32036554813385
Iteration 26: train_loss 1.3941795825958252
Iteration 27: train_loss 1.3487026691436768
Iteration 28: train_loss 1.3990185260772705
Iteration 29: train_loss 1.3558335304260254
Iteration 30: train_loss 1.331849455833435
Iteration 31: train_loss 1.3489701747894287
Iteration 32: train_loss 1.3717468976974487
Iteration 33: train_loss 1.3524324893951416
Iteration 34: train_loss 1.3520785570144653
Iteration 35: train_loss 1.3412063121795654
Iteration 36: train_loss 1.3082164525985718
Iteration 37: train_loss 1.3817718029022217
Iteration 38: train_loss 1.283790946006775
Iteration 39: train_loss 1.3356468677520752
Iteration 40: train_loss 1.3470808267593384
Iteration 41: train_loss 1.3495337963104248
Iteration 42: train_loss 1.331078290939331
Iteration 43: train_loss 1.3612565994262695
Iteration 44: train_loss 1.3824965953826904
Iteration 45: train_loss 1.3362401723861694
Iteration 46: train_loss 1.384480595588684
Iteration 47: train_loss 1.3000481128692627
Iteration 48: train_loss 1.318129062652588
Iteration 49: train_loss 1.3975871801376343
Iteration 50: train_loss 1.3276335000991821
Iteration 51: train_loss 1.2816286087036133
Iteration 52: train_loss 1.3511534929275513
Iteration 53: train_loss 1.2942259311676025
Iteration 54: train_loss 1.3599718809127808
Iteration 55: train_loss 1.3456616401672363
Iteration 56: train_loss 1.3795791864395142
Iteration 57: train_loss 1.360399603843689
Iteration 58: train_loss 1.3800946474075317
Iteration 59: train_loss 1.3320717811584473
Iteration 60: train_loss 1.343611240386963
Iteration 61: train_loss 1.3441474437713623
Iteration 62: train_loss 1.3183925151824951
Iteration 63: train_loss 1.3587367534637451
Iteration 64: train_loss 1.3315602540969849
Iteration 65: train_loss 1.3102580308914185
Iteration 66: train_loss 1.3630164861679077
Iteration 67: train_loss 1.3504393100738525
Iteration 68: train_loss 1.3445379734039307
Iteration 69: train_loss 1.4145807027816772
Iteration 70: train_loss 1.3407187461853027
Iteration 71: train_loss 1.3425917625427246
Iteration 72: train_loss 1.30984628200531
Iteration 73: train_loss 1.3283439874649048
Iteration 74: train_loss 1.3165583610534668
Iteration 75: train_loss 1.4177006483078003
Iteration 76: train_loss 1.399357795715332
Iteration 77: train_loss 1.3856109380722046
Iteration 78: train_loss 1.391666054725647
Iteration 79: train_loss 1.3500722646713257
Iteration 80: train_loss 1.342250943183899
Iteration 81: train_loss 1.3662344217300415
Iteration 82: train_loss 1.3508919477462769
Iteration 83: train_loss 1.3756505250930786
Iteration 84: train_loss 1.3950718641281128
Iteration 85: train_loss 1.3276406526565552
Iteration 86: train_loss 1.3532962799072266
Iteration 87: train_loss 1.3619561195373535
Iteration 88: train_loss 1.3412734270095825
Iteration 89: train_loss 1.346727728843689
Iteration 90: train_loss 1.4086377620697021
Iteration 91: train_loss 1.3339853286743164
Iteration 92: train_loss 1.3076989650726318
Iteration 93: train_loss 1.3829307556152344
Iteration 94: train_loss 1.3394970893859863
Iteration 95: train_loss 1.3962281942367554
Iteration 96: train_loss 1.296829342842102
Iteration 97: train_loss 1.3429884910583496
Iteration 98: train_loss 1.3477596044540405
Iteration 99: train_loss 1.3427139520645142
Iteration 100: train_loss 1.3277770280838013
Iteration 101: train_loss 1.3695636987686157
Iteration 102: train_loss 1.3121941089630127
Iteration 103: train_loss 1.2915118932724
Iteration 104: train_loss 1.3164801597595215
Iteration 105: train_loss 1.3837162256240845
Iteration 106: train_loss 1.3452463150024414
Iteration 107: train_loss 1.3019970655441284
Iteration 108: train_loss 1.305317759513855
Iteration 109: train_loss 1.3536834716796875
Iteration 110: train_loss 1.3241742849349976
Iteration 111: train_loss 1.3217872381210327
Iteration 112: train_loss 1.3331860303878784
Iteration 113: train_loss 1.3507757186889648
Iteration 114: train_loss 1.321211338043213
Iteration 115: train_loss 1.3183907270431519
Iteration 116: train_loss 1.2606935501098633
Iteration 117: train_loss 1.2943084239959717
Iteration 118: train_loss 1.3488802909851074
Iteration 119: train_loss 1.3448855876922607
Iteration 120: train_loss 1.3835138082504272
Iteration 121: train_loss 1.3637911081314087
Iteration 122: train_loss 1.3904308080673218
Iteration 123: train_loss 1.3607431650161743
Iteration 124: train_loss 1.3037073612213135
Iteration 125: train_loss 1.3712612390518188
Iteration 126: train_loss 1.3310348987579346
Iteration 127: train_loss 1.3626165390014648
Iteration 128: train_loss 1.347443699836731
Iteration 129: train_loss 1.3677922487258911
Iteration 130: train_loss 1.3508979082107544
Iteration 131: train_loss 1.4062772989273071
Iteration 132: train_loss 1.3538594245910645
Iteration 133: train_loss 1.3650460243225098
Iteration 134: train_loss 1.3953330516815186
Iteration 135: train_loss 1.3925079107284546
Iteration 136: train_loss 1.3109928369522095
Iteration 137: train_loss 1.4128445386886597
Iteration 138: train_loss 1.360735535621643
Iteration 139: train_loss 1.468875765800476
Iteration 140: train_loss 1.3854247331619263
Iteration 141: train_loss 1.4214497804641724
Iteration 142: train_loss 1.3752321004867554
Iteration 143: train_loss 1.3459224700927734
Iteration 144: train_loss 1.3913774490356445
Iteration 145: train_loss 1.3690787553787231
Iteration 146: train_loss 1.3793118000030518
Iteration 147: train_loss 1.4039630889892578
Iteration 148: train_loss 1.373267412185669
Iteration 149: train_loss 1.4172066450119019
Iteration 150: train_loss 1.4108468294143677
Iteration 151: train_loss 1.3919813632965088
Iteration 152: train_loss 1.4572111368179321
Iteration 153: train_loss 1.4131782054901123
Iteration 154: train_loss 1.3764883279800415
Iteration 155: train_loss 1.4353076219558716
Iteration 156: train_loss 1.4121583700180054
Iteration 157: train_loss 1.4017306566238403
Iteration 158: train_loss 1.38539719581604
Iteration 159: train_loss 1.3899646997451782
Iteration 160: train_loss 1.3929349184036255
Iteration 161: train_loss 1.3941466808319092
Iteration 162: train_loss 1.378778338432312
Iteration 163: train_loss 1.3512662649154663
Iteration 164: train_loss 1.36323881149292
Iteration 165: train_loss 1.3955955505371094
Iteration 166: train_loss 1.3763902187347412
Iteration 167: train_loss 1.3678147792816162
Iteration 168: train_loss 1.3902243375778198
Iteration 169: train_loss 1.3593989610671997
Iteration 170: train_loss 1.3477599620819092
Iteration 171: train_loss 1.3110712766647339
Iteration 172: train_loss 1.3358986377716064
Iteration 173: train_loss 1.3304104804992676
Iteration 174: train_loss 1.2466273307800293
Iteration 175: train_loss 1.2940441370010376
Iteration 176: train_loss 1.3156898021697998
Iteration 177: train_loss 1.2791398763656616
Epoch 109: train_avg_loss 1.3523591083321869 eval_avg_acc: 0.3346342078096971 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:02:17] [32mIntermediate result: 0.3346342078096971  (Index 108)[0m
================Epoch: 110================
Iteration 1: train_loss 1.303680181503296
Iteration 2: train_loss 1.3636367321014404
Iteration 3: train_loss 1.3084595203399658
Iteration 4: train_loss 1.2923154830932617
Iteration 5: train_loss 1.340919852256775
Iteration 6: train_loss 1.3504263162612915
Iteration 7: train_loss 1.3602855205535889
Iteration 8: train_loss 1.352547526359558
Iteration 9: train_loss 1.2869678735733032
Iteration 10: train_loss 1.2780213356018066
Iteration 11: train_loss 1.2866426706314087
Iteration 12: train_loss 1.2808020114898682
Iteration 13: train_loss 1.3226335048675537
Iteration 14: train_loss 1.3140722513198853
Iteration 15: train_loss 1.3634448051452637
Iteration 16: train_loss 1.3246824741363525
Iteration 17: train_loss 1.3050622940063477
Iteration 18: train_loss 1.3624045848846436
Iteration 19: train_loss 1.3319042921066284
Iteration 20: train_loss 1.269958257675171
Iteration 21: train_loss 1.2395906448364258
Iteration 22: train_loss 1.345360517501831
Iteration 23: train_loss 1.3278939723968506
Iteration 24: train_loss 1.4103916883468628
Iteration 25: train_loss 1.3027701377868652
Iteration 26: train_loss 1.270134687423706
Iteration 27: train_loss 1.3216506242752075
Iteration 28: train_loss 1.3446136713027954
Iteration 29: train_loss 1.342390775680542
Iteration 30: train_loss 1.3804599046707153
Iteration 31: train_loss 1.2876352071762085
Iteration 32: train_loss 1.2833199501037598
Iteration 33: train_loss 1.331433653831482
Iteration 34: train_loss 1.3086998462677002
Iteration 35: train_loss 1.3532501459121704
Iteration 36: train_loss 1.2659701108932495
Iteration 37: train_loss 1.302999496459961
Iteration 38: train_loss 1.3153492212295532
Iteration 39: train_loss 1.3269134759902954
Iteration 40: train_loss 1.2661188840866089
Iteration 41: train_loss 1.3413491249084473
Iteration 42: train_loss 1.3620359897613525
Iteration 43: train_loss 1.2949732542037964
Iteration 44: train_loss 1.3681910037994385
Iteration 45: train_loss 1.3421484231948853
Iteration 46: train_loss 1.3355553150177002
Iteration 47: train_loss 1.3260040283203125
Iteration 48: train_loss 1.3196765184402466
Iteration 49: train_loss 1.3219069242477417
Iteration 50: train_loss 1.3272309303283691
Iteration 51: train_loss 1.3312207460403442
Iteration 52: train_loss 1.311716079711914
Iteration 53: train_loss 1.3580436706542969
Iteration 54: train_loss 1.4024169445037842
Iteration 55: train_loss 1.3767054080963135
Iteration 56: train_loss 1.3263698816299438
Iteration 57: train_loss 1.2819347381591797
Iteration 58: train_loss 1.3454337120056152
Iteration 59: train_loss 1.3390007019042969
Iteration 60: train_loss 1.355589509010315
Iteration 61: train_loss 1.3306325674057007
Iteration 62: train_loss 1.3437403440475464
Iteration 63: train_loss 1.3521981239318848
Iteration 64: train_loss 1.3476704359054565
Iteration 65: train_loss 1.2761285305023193
Iteration 66: train_loss 1.350659966468811
Iteration 67: train_loss 1.370379090309143
Iteration 68: train_loss 1.3689614534378052
Iteration 69: train_loss 1.3804099559783936
Iteration 70: train_loss 1.3534578084945679
Iteration 71: train_loss 1.358115792274475
Iteration 72: train_loss 1.3462824821472168
Iteration 73: train_loss 1.3284637928009033
Iteration 74: train_loss 1.3665406703948975
Iteration 75: train_loss 1.3051096200942993
Iteration 76: train_loss 1.3245494365692139
Iteration 77: train_loss 1.3486640453338623
Iteration 78: train_loss 1.3066271543502808
Iteration 79: train_loss 1.366808295249939
Iteration 80: train_loss 1.363998293876648
Iteration 81: train_loss 1.3831870555877686
Iteration 82: train_loss 1.4110933542251587
Iteration 83: train_loss 1.3169721364974976
Iteration 84: train_loss 1.3344571590423584
Iteration 85: train_loss 1.3717244863510132
Iteration 86: train_loss 1.3558632135391235
Iteration 87: train_loss 1.3585411310195923
Iteration 88: train_loss 1.344423532485962
Iteration 89: train_loss 1.3870528936386108
Iteration 90: train_loss 1.383658766746521
Iteration 91: train_loss 1.351328730583191
Iteration 92: train_loss 1.3065367937088013
Iteration 93: train_loss 1.404229760169983
Iteration 94: train_loss 1.3122611045837402
Iteration 95: train_loss 1.3576745986938477
Iteration 96: train_loss 1.3957544565200806
Iteration 97: train_loss 1.3271398544311523
Iteration 98: train_loss 1.3315540552139282
Iteration 99: train_loss 1.3193199634552002
Iteration 100: train_loss 1.3848884105682373
Iteration 101: train_loss 1.3582828044891357
Iteration 102: train_loss 1.3118493556976318
Iteration 103: train_loss 1.355971336364746
Iteration 104: train_loss 1.3583519458770752
Iteration 105: train_loss 1.403317928314209
Iteration 106: train_loss 1.3919346332550049
Iteration 107: train_loss 1.3605663776397705
Iteration 108: train_loss 1.2920522689819336
Iteration 109: train_loss 1.3677130937576294
Iteration 110: train_loss 1.357589602470398
Iteration 111: train_loss 1.357987403869629
Iteration 112: train_loss 1.307888150215149
Iteration 113: train_loss 1.3309893608093262
Iteration 114: train_loss 1.3724509477615356
Iteration 115: train_loss 1.2752668857574463
Iteration 116: train_loss 1.3556609153747559
Iteration 117: train_loss 1.3033262491226196
Iteration 118: train_loss 1.3650070428848267
Iteration 119: train_loss 1.4534263610839844
Iteration 120: train_loss 1.3880422115325928
Iteration 121: train_loss 1.351576566696167
Iteration 122: train_loss 1.3663276433944702
Iteration 123: train_loss 1.354920744895935
Iteration 124: train_loss 1.3629307746887207
Iteration 125: train_loss 1.3254437446594238
Iteration 126: train_loss 1.359987735748291
Iteration 127: train_loss 1.3548717498779297
Iteration 128: train_loss 1.3908125162124634
Iteration 129: train_loss 1.3818511962890625
Iteration 130: train_loss 1.3479602336883545
Iteration 131: train_loss 1.3102413415908813
Iteration 132: train_loss 1.3478660583496094
Iteration 133: train_loss 1.3254438638687134
Iteration 134: train_loss 1.408858299255371
Iteration 135: train_loss 1.4116071462631226
Iteration 136: train_loss 1.3734296560287476
Iteration 137: train_loss 1.2744243144989014
Iteration 138: train_loss 1.3438166379928589
Iteration 139: train_loss 1.3707112073898315
Iteration 140: train_loss 1.3669663667678833
Iteration 141: train_loss 1.3116320371627808
Iteration 142: train_loss 1.357710361480713
Iteration 143: train_loss 1.3361214399337769
Iteration 144: train_loss 1.3616509437561035
Iteration 145: train_loss 1.3586015701293945
Iteration 146: train_loss 1.3102784156799316
Iteration 147: train_loss 1.3408135175704956
Iteration 148: train_loss 1.3311691284179688
Iteration 149: train_loss 1.3360676765441895
Iteration 150: train_loss 1.4474995136260986
Iteration 151: train_loss 1.363768219947815
Iteration 152: train_loss 1.3855749368667603
Iteration 153: train_loss 1.352213740348816
Iteration 154: train_loss 1.3762872219085693
Iteration 155: train_loss 1.3525309562683105
Iteration 156: train_loss 1.4110515117645264
Iteration 157: train_loss 1.3322230577468872
Iteration 158: train_loss 1.3402433395385742
Iteration 159: train_loss 1.3547346591949463
Iteration 160: train_loss 1.331626057624817
Iteration 161: train_loss 1.4160304069519043
Iteration 162: train_loss 1.3419917821884155
Iteration 163: train_loss 1.3305045366287231
Iteration 164: train_loss 1.3894315958023071
Iteration 165: train_loss 1.3631706237792969
Iteration 166: train_loss 1.3586974143981934
Iteration 167: train_loss 1.3927266597747803
Iteration 168: train_loss 1.3769452571868896
Iteration 169: train_loss 1.3795350790023804
Iteration 170: train_loss 1.3318805694580078
Iteration 171: train_loss 1.386469841003418
Iteration 172: train_loss 1.2835581302642822
Iteration 173: train_loss 1.3259291648864746
Iteration 174: train_loss 1.3498249053955078
Iteration 175: train_loss 1.3584346771240234
Iteration 176: train_loss 1.3359507322311401
Iteration 177: train_loss 1.2274045944213867
Epoch 110: train_avg_loss 1.3432677021134372 eval_avg_acc: 0.33607120320786904 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:02:56] [32mIntermediate result: 0.33607120320786904  (Index 109)[0m
================Epoch: 111================
Iteration 1: train_loss 1.352384090423584
Iteration 2: train_loss 1.2973978519439697
Iteration 3: train_loss 1.3053679466247559
Iteration 4: train_loss 1.3226299285888672
Iteration 5: train_loss 1.2801833152770996
Iteration 6: train_loss 1.2309858798980713
Iteration 7: train_loss 1.3371294736862183
Iteration 8: train_loss 1.2707536220550537
Iteration 9: train_loss 1.2375304698944092
Iteration 10: train_loss 1.294155478477478
Iteration 11: train_loss 1.282778263092041
Iteration 12: train_loss 1.2930285930633545
Iteration 13: train_loss 1.301583170890808
Iteration 14: train_loss 1.324249505996704
Iteration 15: train_loss 1.2836624383926392
Iteration 16: train_loss 1.310133934020996
Iteration 17: train_loss 1.3363596200942993
Iteration 18: train_loss 1.3056938648223877
Iteration 19: train_loss 1.3323590755462646
Iteration 20: train_loss 1.332868218421936
Iteration 21: train_loss 1.3038570880889893
Iteration 22: train_loss 1.3504191637039185
Iteration 23: train_loss 1.3168529272079468
Iteration 24: train_loss 1.3911997079849243
Iteration 25: train_loss 1.2548530101776123
Iteration 26: train_loss 1.3019593954086304
Iteration 27: train_loss 1.284326434135437
Iteration 28: train_loss 1.2842373847961426
Iteration 29: train_loss 1.3390599489212036
Iteration 30: train_loss 1.2933247089385986
Iteration 31: train_loss 1.2900097370147705
Iteration 32: train_loss 1.349399209022522
Iteration 33: train_loss 1.362379550933838
Iteration 34: train_loss 1.3096942901611328
Iteration 35: train_loss 1.3350341320037842
Iteration 36: train_loss 1.3566497564315796
Iteration 37: train_loss 1.3066604137420654
Iteration 38: train_loss 1.3458983898162842
Iteration 39: train_loss 1.279739499092102
Iteration 40: train_loss 1.3108127117156982
Iteration 41: train_loss 1.354758381843567
Iteration 42: train_loss 1.27731454372406
Iteration 43: train_loss 1.3184524774551392
Iteration 44: train_loss 1.3717713356018066
Iteration 45: train_loss 1.34237539768219
Iteration 46: train_loss 1.321190595626831
Iteration 47: train_loss 1.3454269170761108
Iteration 48: train_loss 1.3681597709655762
Iteration 49: train_loss 1.4057035446166992
Iteration 50: train_loss 1.3605867624282837
Iteration 51: train_loss 1.3286000490188599
Iteration 52: train_loss 1.2941416501998901
Iteration 53: train_loss 1.3556443452835083
Iteration 54: train_loss 1.42776620388031
Iteration 55: train_loss 1.3194756507873535
Iteration 56: train_loss 1.3716233968734741
Iteration 57: train_loss 1.3159383535385132
Iteration 58: train_loss 1.3666645288467407
Iteration 59: train_loss 1.3665045499801636
Iteration 60: train_loss 1.3725183010101318
Iteration 61: train_loss 1.2958403825759888
Iteration 62: train_loss 1.4250860214233398
Iteration 63: train_loss 1.3277393579483032
Iteration 64: train_loss 1.3010135889053345
Iteration 65: train_loss 1.2635046243667603
Iteration 66: train_loss 1.3404597043991089
Iteration 67: train_loss 1.3317854404449463
Iteration 68: train_loss 1.295050859451294
Iteration 69: train_loss 1.3212612867355347
Iteration 70: train_loss 1.3130388259887695
Iteration 71: train_loss 1.337855577468872
Iteration 72: train_loss 1.282926082611084
Iteration 73: train_loss 1.4140653610229492
Iteration 74: train_loss 1.4063022136688232
Iteration 75: train_loss 1.3989171981811523
Iteration 76: train_loss 1.3719195127487183
Iteration 77: train_loss 1.3813512325286865
Iteration 78: train_loss 1.2500606775283813
Iteration 79: train_loss 1.3588200807571411
Iteration 80: train_loss 1.3335527181625366
Iteration 81: train_loss 1.2951329946517944
Iteration 82: train_loss 1.3364269733428955
Iteration 83: train_loss 1.3336308002471924
Iteration 84: train_loss 1.399163007736206
Iteration 85: train_loss 1.3503265380859375
Iteration 86: train_loss 1.3286232948303223
Iteration 87: train_loss 1.3309133052825928
Iteration 88: train_loss 1.3565430641174316
Iteration 89: train_loss 1.3515902757644653
Iteration 90: train_loss 1.315346121788025
Iteration 91: train_loss 1.3563014268875122
Iteration 92: train_loss 1.3942517042160034
Iteration 93: train_loss 1.3165428638458252
Iteration 94: train_loss 1.275321125984192
Iteration 95: train_loss 1.361397385597229
Iteration 96: train_loss 1.3469871282577515
Iteration 97: train_loss 1.2980822324752808
Iteration 98: train_loss 1.28611159324646
Iteration 99: train_loss 1.3602315187454224
Iteration 100: train_loss 1.3456932306289673
Iteration 101: train_loss 1.2998428344726562
Iteration 102: train_loss 1.2983391284942627
Iteration 103: train_loss 1.4059511423110962
Iteration 104: train_loss 1.3598477840423584
Iteration 105: train_loss 1.3852334022521973
Iteration 106: train_loss 1.341822624206543
Iteration 107: train_loss 1.3427516222000122
Iteration 108: train_loss 1.3052606582641602
Iteration 109: train_loss 1.2970737218856812
Iteration 110: train_loss 1.3348814249038696
Iteration 111: train_loss 1.3265401124954224
Iteration 112: train_loss 1.3549379110336304
Iteration 113: train_loss 1.3248833417892456
Iteration 114: train_loss 1.3255295753479004
Iteration 115: train_loss 1.3773421049118042
Iteration 116: train_loss 1.3513857126235962
Iteration 117: train_loss 1.3683772087097168
Iteration 118: train_loss 1.347508430480957
Iteration 119: train_loss 1.3288675546646118
Iteration 120: train_loss 1.3525716066360474
Iteration 121: train_loss 1.324384093284607
Iteration 122: train_loss 1.3696033954620361
Iteration 123: train_loss 1.3729934692382812
Iteration 124: train_loss 1.3259942531585693
Iteration 125: train_loss 1.3294482231140137
Iteration 126: train_loss 1.2852778434753418
Iteration 127: train_loss 1.3436449766159058
Iteration 128: train_loss 1.3319131135940552
Iteration 129: train_loss 1.3058191537857056
Iteration 130: train_loss 1.2875983715057373
Iteration 131: train_loss 1.3886399269104004
Iteration 132: train_loss 1.3633406162261963
Iteration 133: train_loss 1.3397455215454102
Iteration 134: train_loss 1.3707013130187988
Iteration 135: train_loss 1.394287109375
Iteration 136: train_loss 1.3219894170761108
Iteration 137: train_loss 1.3961231708526611
Iteration 138: train_loss 1.3892086744308472
Iteration 139: train_loss 1.3445895910263062
Iteration 140: train_loss 1.3738124370574951
Iteration 141: train_loss 1.3609894514083862
Iteration 142: train_loss 1.4146218299865723
Iteration 143: train_loss 1.3811601400375366
Iteration 144: train_loss 1.414243459701538
Iteration 145: train_loss 1.3605390787124634
Iteration 146: train_loss 1.3035999536514282
Iteration 147: train_loss 1.3500126600265503
Iteration 148: train_loss 1.3896019458770752
Iteration 149: train_loss 1.301732063293457
Iteration 150: train_loss 1.4413503408432007
Iteration 151: train_loss 1.3910812139511108
Iteration 152: train_loss 1.310399055480957
Iteration 153: train_loss 1.2912001609802246
Iteration 154: train_loss 1.3916338682174683
Iteration 155: train_loss 1.4360089302062988
Iteration 156: train_loss 1.3242106437683105
Iteration 157: train_loss 1.3657541275024414
Iteration 158: train_loss 1.3239076137542725
Iteration 159: train_loss 1.3232210874557495
Iteration 160: train_loss 1.3312374353408813
Iteration 161: train_loss 1.3568450212478638
Iteration 162: train_loss 1.3336904048919678
Iteration 163: train_loss 1.3485162258148193
Iteration 164: train_loss 1.313909888267517
Iteration 165: train_loss 1.341796875
Iteration 166: train_loss 1.3272913694381714
Iteration 167: train_loss 1.2969993352890015
Iteration 168: train_loss 1.374284029006958
Iteration 169: train_loss 1.32662832736969
Iteration 170: train_loss 1.3326843976974487
Iteration 171: train_loss 1.3706835508346558
Iteration 172: train_loss 1.3970502614974976
Iteration 173: train_loss 1.4174573421478271
Iteration 174: train_loss 1.3586183786392212
Iteration 175: train_loss 1.3503305912017822
Iteration 176: train_loss 1.3964922428131104
Iteration 177: train_loss 1.345023274421692
Epoch 111: train_avg_loss 1.3381596352420957 eval_avg_acc: 0.34721936238280515 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:03:34] [32mIntermediate result: 0.34721936238280515  (Index 110)[0m
================Epoch: 112================
Iteration 1: train_loss 1.323807954788208
Iteration 2: train_loss 1.3058929443359375
Iteration 3: train_loss 1.3124297857284546
Iteration 4: train_loss 1.3231947422027588
Iteration 5: train_loss 1.3444210290908813
Iteration 6: train_loss 1.3134475946426392
Iteration 7: train_loss 1.3494248390197754
Iteration 8: train_loss 1.2875488996505737
Iteration 9: train_loss 1.2853673696517944
Iteration 10: train_loss 1.3020401000976562
Iteration 11: train_loss 1.3297096490859985
Iteration 12: train_loss 1.3017046451568604
Iteration 13: train_loss 1.3346436023712158
Iteration 14: train_loss 1.316435694694519
Iteration 15: train_loss 1.318679928779602
Iteration 16: train_loss 1.319236159324646
Iteration 17: train_loss 1.2470805644989014
Iteration 18: train_loss 1.299773097038269
Iteration 19: train_loss 1.2872930765151978
Iteration 20: train_loss 1.3243266344070435
Iteration 21: train_loss 1.282057762145996
Iteration 22: train_loss 1.365932583808899
Iteration 23: train_loss 1.300377368927002
Iteration 24: train_loss 1.3551827669143677
Iteration 25: train_loss 1.3167544603347778
Iteration 26: train_loss 1.3055095672607422
Iteration 27: train_loss 1.3026291131973267
Iteration 28: train_loss 1.3542882204055786
Iteration 29: train_loss 1.3064076900482178
Iteration 30: train_loss 1.3328691720962524
Iteration 31: train_loss 1.3155463933944702
Iteration 32: train_loss 1.27586829662323
Iteration 33: train_loss 1.376426339149475
Iteration 34: train_loss 1.3417093753814697
Iteration 35: train_loss 1.3201546669006348
Iteration 36: train_loss 1.3282320499420166
Iteration 37: train_loss 1.3512812852859497
Iteration 38: train_loss 1.3335087299346924
Iteration 39: train_loss 1.3731180429458618
Iteration 40: train_loss 1.3658276796340942
Iteration 41: train_loss 1.3378033638000488
Iteration 42: train_loss 1.3623555898666382
Iteration 43: train_loss 1.3749045133590698
Iteration 44: train_loss 1.2710720300674438
Iteration 45: train_loss 1.4229456186294556
Iteration 46: train_loss 1.3080005645751953
Iteration 47: train_loss 1.3154337406158447
Iteration 48: train_loss 1.3034006357192993
Iteration 49: train_loss 1.2989144325256348
Iteration 50: train_loss 1.3620575666427612
Iteration 51: train_loss 1.2824821472167969
Iteration 52: train_loss 1.2738529443740845
Iteration 53: train_loss 1.304240345954895
Iteration 54: train_loss 1.275030255317688
Iteration 55: train_loss 1.3418629169464111
Iteration 56: train_loss 1.3019665479660034
Iteration 57: train_loss 1.3293812274932861
Iteration 58: train_loss 1.3487175703048706
Iteration 59: train_loss 1.2752869129180908
Iteration 60: train_loss 1.318955421447754
Iteration 61: train_loss 1.3202954530715942
Iteration 62: train_loss 1.351561188697815
Iteration 63: train_loss 1.3862706422805786
Iteration 64: train_loss 1.2901484966278076
Iteration 65: train_loss 1.3582038879394531
Iteration 66: train_loss 1.3136886358261108
Iteration 67: train_loss 1.2965489625930786
Iteration 68: train_loss 1.328013300895691
Iteration 69: train_loss 1.3484597206115723
Iteration 70: train_loss 1.2780539989471436
Iteration 71: train_loss 1.3498196601867676
Iteration 72: train_loss 1.3324795961380005
Iteration 73: train_loss 1.295064091682434
Iteration 74: train_loss 1.3580255508422852
Iteration 75: train_loss 1.2990398406982422
Iteration 76: train_loss 1.3562254905700684
Iteration 77: train_loss 1.342482328414917
Iteration 78: train_loss 1.3938289880752563
Iteration 79: train_loss 1.3207541704177856
Iteration 80: train_loss 1.2975566387176514
Iteration 81: train_loss 1.3268264532089233
Iteration 82: train_loss 1.4037262201309204
Iteration 83: train_loss 1.401076316833496
Iteration 84: train_loss 1.3162351846694946
Iteration 85: train_loss 1.3645819425582886
Iteration 86: train_loss 1.3236265182495117
Iteration 87: train_loss 1.3728169202804565
Iteration 88: train_loss 1.3279386758804321
Iteration 89: train_loss 1.3970637321472168
Iteration 90: train_loss 1.389655351638794
Iteration 91: train_loss 1.3614989519119263
Iteration 92: train_loss 1.3174803256988525
Iteration 93: train_loss 1.273703694343567
Iteration 94: train_loss 1.3514318466186523
Iteration 95: train_loss 1.3423762321472168
Iteration 96: train_loss 1.3805392980575562
Iteration 97: train_loss 1.3309733867645264
Iteration 98: train_loss 1.3815317153930664
Iteration 99: train_loss 1.3683274984359741
Iteration 100: train_loss 1.3992666006088257
Iteration 101: train_loss 1.332566738128662
Iteration 102: train_loss 1.3684523105621338
Iteration 103: train_loss 1.329872965812683
Iteration 104: train_loss 1.3759396076202393
Iteration 105: train_loss 1.3645728826522827
Iteration 106: train_loss 1.3303450345993042
Iteration 107: train_loss 1.3897724151611328
Iteration 108: train_loss 1.2943782806396484
Iteration 109: train_loss 1.3790054321289062
Iteration 110: train_loss 1.273016095161438
Iteration 111: train_loss 1.350644588470459
Iteration 112: train_loss 1.3221403360366821
Iteration 113: train_loss 1.3341716527938843
Iteration 114: train_loss 1.3467580080032349
Iteration 115: train_loss 1.341572880744934
Iteration 116: train_loss 1.3330694437026978
Iteration 117: train_loss 1.3059874773025513
Iteration 118: train_loss 1.3469752073287964
Iteration 119: train_loss 1.3822627067565918
Iteration 120: train_loss 1.3045780658721924
Iteration 121: train_loss 1.34200918674469
Iteration 122: train_loss 1.4224910736083984
Iteration 123: train_loss 1.3566513061523438
Iteration 124: train_loss 1.3326911926269531
Iteration 125: train_loss 1.3755854368209839
Iteration 126: train_loss 1.3302515745162964
Iteration 127: train_loss 1.3602763414382935
Iteration 128: train_loss 1.3587278127670288
Iteration 129: train_loss 1.3680506944656372
Iteration 130: train_loss 1.315621018409729
Iteration 131: train_loss 1.3285006284713745
Iteration 132: train_loss 1.3354220390319824
Iteration 133: train_loss 1.2863500118255615
Iteration 134: train_loss 1.3737385272979736
Iteration 135: train_loss 1.34339439868927
Iteration 136: train_loss 1.3273404836654663
Iteration 137: train_loss 1.3600276708602905
Iteration 138: train_loss 1.3924378156661987
Iteration 139: train_loss 1.3091000318527222
Iteration 140: train_loss 1.3370181322097778
Iteration 141: train_loss 1.3449841737747192
Iteration 142: train_loss 1.3589295148849487
Iteration 143: train_loss 1.4070005416870117
Iteration 144: train_loss 1.2885016202926636
Iteration 145: train_loss 1.299326777458191
Iteration 146: train_loss 1.3556702136993408
Iteration 147: train_loss 1.3393034934997559
Iteration 148: train_loss 1.2746925354003906
Iteration 149: train_loss 1.3087347745895386
Iteration 150: train_loss 1.326807975769043
Iteration 151: train_loss 1.3381505012512207
Iteration 152: train_loss 1.2805016040802002
Iteration 153: train_loss 1.3298828601837158
Iteration 154: train_loss 1.3395065069198608
Iteration 155: train_loss 1.36522376537323
Iteration 156: train_loss 1.3197402954101562
Iteration 157: train_loss 1.3605787754058838
Iteration 158: train_loss 1.3041651248931885
Iteration 159: train_loss 1.334587812423706
Iteration 160: train_loss 1.3122106790542603
Iteration 161: train_loss 1.3262490034103394
Iteration 162: train_loss 1.3553074598312378
Iteration 163: train_loss 1.3402037620544434
Iteration 164: train_loss 1.2929006814956665
Iteration 165: train_loss 1.3048204183578491
Iteration 166: train_loss 1.300702691078186
Iteration 167: train_loss 1.3215383291244507
Iteration 168: train_loss 1.3459175825119019
Iteration 169: train_loss 1.3160032033920288
Iteration 170: train_loss 1.3400951623916626
Iteration 171: train_loss 1.3198572397232056
Iteration 172: train_loss 1.4147955179214478
Iteration 173: train_loss 1.3218567371368408
Iteration 174: train_loss 1.3390246629714966
Iteration 175: train_loss 1.3603161573410034
Iteration 176: train_loss 1.4568634033203125
Iteration 177: train_loss 1.4390674829483032
Epoch 112: train_avg_loss 1.3346428716250058 eval_avg_acc: 0.3466811035166755 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:04:13] [32mIntermediate result: 0.3466811035166755  (Index 111)[0m
================Epoch: 113================
Iteration 1: train_loss 1.2956095933914185
Iteration 2: train_loss 1.3120299577713013
Iteration 3: train_loss 1.3622965812683105
Iteration 4: train_loss 1.3064194917678833
Iteration 5: train_loss 1.3167763948440552
Iteration 6: train_loss 1.267121434211731
Iteration 7: train_loss 1.358466625213623
Iteration 8: train_loss 1.2954922914505005
Iteration 9: train_loss 1.3046469688415527
Iteration 10: train_loss 1.2837700843811035
Iteration 11: train_loss 1.3949931859970093
Iteration 12: train_loss 1.338613510131836
Iteration 13: train_loss 1.2603824138641357
Iteration 14: train_loss 1.3565648794174194
Iteration 15: train_loss 1.317705750465393
Iteration 16: train_loss 1.2478222846984863
Iteration 17: train_loss 1.2941539287567139
Iteration 18: train_loss 1.2977904081344604
Iteration 19: train_loss 1.2884751558303833
Iteration 20: train_loss 1.3287192583084106
Iteration 21: train_loss 1.3156284093856812
Iteration 22: train_loss 1.2425086498260498
Iteration 23: train_loss 1.3273913860321045
Iteration 24: train_loss 1.3264729976654053
Iteration 25: train_loss 1.2748644351959229
Iteration 26: train_loss 1.3747884035110474
Iteration 27: train_loss 1.3337461948394775
Iteration 28: train_loss 1.320933222770691
Iteration 29: train_loss 1.310848593711853
Iteration 30: train_loss 1.3122140169143677
Iteration 31: train_loss 1.2862366437911987
Iteration 32: train_loss 1.3644139766693115
Iteration 33: train_loss 1.2972335815429688
Iteration 34: train_loss 1.3241568803787231
Iteration 35: train_loss 1.31636381149292
Iteration 36: train_loss 1.2538026571273804
Iteration 37: train_loss 1.2623199224472046
Iteration 38: train_loss 1.2926523685455322
Iteration 39: train_loss 1.250823974609375
Iteration 40: train_loss 1.276418924331665
Iteration 41: train_loss 1.3219876289367676
Iteration 42: train_loss 1.3364601135253906
Iteration 43: train_loss 1.3125905990600586
Iteration 44: train_loss 1.2786608934402466
Iteration 45: train_loss 1.3473150730133057
Iteration 46: train_loss 1.2200267314910889
Iteration 47: train_loss 1.2478675842285156
Iteration 48: train_loss 1.2960286140441895
Iteration 49: train_loss 1.3224531412124634
Iteration 50: train_loss 1.3414530754089355
Iteration 51: train_loss 1.3251839876174927
Iteration 52: train_loss 1.2588368654251099
Iteration 53: train_loss 1.3015633821487427
Iteration 54: train_loss 1.3139803409576416
Iteration 55: train_loss 1.2402889728546143
Iteration 56: train_loss 1.354671835899353
Iteration 57: train_loss 1.3511126041412354
Iteration 58: train_loss 1.4125086069107056
Iteration 59: train_loss 1.3292897939682007
Iteration 60: train_loss 1.2989084720611572
Iteration 61: train_loss 1.3529599905014038
Iteration 62: train_loss 1.3457322120666504
Iteration 63: train_loss 1.3946533203125
Iteration 64: train_loss 1.3459656238555908
Iteration 65: train_loss 1.343002438545227
Iteration 66: train_loss 1.3276962041854858
Iteration 67: train_loss 1.3063874244689941
Iteration 68: train_loss 1.3788743019104004
Iteration 69: train_loss 1.380569577217102
Iteration 70: train_loss 1.3365105390548706
Iteration 71: train_loss 1.3489965200424194
Iteration 72: train_loss 1.3527469635009766
Iteration 73: train_loss 1.3880382776260376
Iteration 74: train_loss 1.3091189861297607
Iteration 75: train_loss 1.3287748098373413
Iteration 76: train_loss 1.352439284324646
Iteration 77: train_loss 1.3211616277694702
Iteration 78: train_loss 1.3109930753707886
Iteration 79: train_loss 1.326556921005249
Iteration 80: train_loss 1.3766722679138184
Iteration 81: train_loss 1.311588168144226
Iteration 82: train_loss 1.3414875268936157
Iteration 83: train_loss 1.304174780845642
Iteration 84: train_loss 1.290472149848938
Iteration 85: train_loss 1.3073372840881348
Iteration 86: train_loss 1.3196653127670288
Iteration 87: train_loss 1.3014453649520874
Iteration 88: train_loss 1.3473525047302246
Iteration 89: train_loss 1.2958122491836548
Iteration 90: train_loss 1.4038469791412354
Iteration 91: train_loss 1.3410543203353882
Iteration 92: train_loss 1.2896207571029663
Iteration 93: train_loss 1.3063050508499146
Iteration 94: train_loss 1.3934009075164795
Iteration 95: train_loss 1.3010469675064087
Iteration 96: train_loss 1.302538275718689
Iteration 97: train_loss 1.2747594118118286
Iteration 98: train_loss 1.2782058715820312
Iteration 99: train_loss 1.375462532043457
Iteration 100: train_loss 1.2894656658172607
Iteration 101: train_loss 1.2739295959472656
Iteration 102: train_loss 1.322460412979126
Iteration 103: train_loss 1.3461626768112183
Iteration 104: train_loss 1.3025697469711304
Iteration 105: train_loss 1.3220057487487793
Iteration 106: train_loss 1.311957836151123
Iteration 107: train_loss 1.3269253969192505
Iteration 108: train_loss 1.274192214012146
Iteration 109: train_loss 1.371960163116455
Iteration 110: train_loss 1.3917499780654907
Iteration 111: train_loss 1.3835817575454712
Iteration 112: train_loss 1.3199617862701416
Iteration 113: train_loss 1.340846061706543
Iteration 114: train_loss 1.326600432395935
Iteration 115: train_loss 1.3810577392578125
Iteration 116: train_loss 1.3159456253051758
Iteration 117: train_loss 1.3405379056930542
Iteration 118: train_loss 1.326135516166687
Iteration 119: train_loss 1.364931344985962
Iteration 120: train_loss 1.338843584060669
Iteration 121: train_loss 1.353163242340088
Iteration 122: train_loss 1.270450472831726
Iteration 123: train_loss 1.3301403522491455
Iteration 124: train_loss 1.3083057403564453
Iteration 125: train_loss 1.300438642501831
Iteration 126: train_loss 1.3233444690704346
Iteration 127: train_loss 1.2626601457595825
Iteration 128: train_loss 1.3492783308029175
Iteration 129: train_loss 1.3045083284378052
Iteration 130: train_loss 1.3650668859481812
Iteration 131: train_loss 1.2827668190002441
Iteration 132: train_loss 1.3601467609405518
Iteration 133: train_loss 1.3624638319015503
Iteration 134: train_loss 1.2778488397598267
Iteration 135: train_loss 1.313664197921753
Iteration 136: train_loss 1.381574273109436
Iteration 137: train_loss 1.3405818939208984
Iteration 138: train_loss 1.325692892074585
Iteration 139: train_loss 1.335429072380066
Iteration 140: train_loss 1.3263523578643799
Iteration 141: train_loss 1.346723198890686
Iteration 142: train_loss 1.314584493637085
Iteration 143: train_loss 1.3383753299713135
Iteration 144: train_loss 1.375550627708435
Iteration 145: train_loss 1.3750466108322144
Iteration 146: train_loss 1.3609633445739746
Iteration 147: train_loss 1.2640453577041626
Iteration 148: train_loss 1.364160418510437
Iteration 149: train_loss 1.303531289100647
Iteration 150: train_loss 1.32066810131073
Iteration 151: train_loss 1.3414857387542725
Iteration 152: train_loss 1.3206229209899902
Iteration 153: train_loss 1.354401707649231
Iteration 154: train_loss 1.2897670269012451
Iteration 155: train_loss 1.3468595743179321
Iteration 156: train_loss 1.3224776983261108
Iteration 157: train_loss 1.3586734533309937
Iteration 158: train_loss 1.2990375757217407
Iteration 159: train_loss 1.3540419340133667
Iteration 160: train_loss 1.3099033832550049
Iteration 161: train_loss 1.3842076063156128
Iteration 162: train_loss 1.4030519723892212
Iteration 163: train_loss 1.4071286916732788
Iteration 164: train_loss 1.3654321432113647
Iteration 165: train_loss 1.3722351789474487
Iteration 166: train_loss 1.3488348722457886
Iteration 167: train_loss 1.3938579559326172
Iteration 168: train_loss 1.350746750831604
Iteration 169: train_loss 1.3827956914901733
Iteration 170: train_loss 1.3400869369506836
Iteration 171: train_loss 1.2867594957351685
Iteration 172: train_loss 1.2544326782226562
Iteration 173: train_loss 1.2760162353515625
Iteration 174: train_loss 1.362626075744629
Iteration 175: train_loss 1.3107619285583496
Iteration 176: train_loss 1.360985279083252
Iteration 177: train_loss 1.389501929283142
Epoch 113: train_avg_loss 1.3254935835714394 eval_avg_acc: 0.3391365156178198 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:04:52] [32mIntermediate result: 0.3391365156178198  (Index 112)[0m
================Epoch: 114================
Iteration 1: train_loss 1.3278121948242188
Iteration 2: train_loss 1.337153434753418
Iteration 3: train_loss 1.4013057947158813
Iteration 4: train_loss 1.328222632408142
Iteration 5: train_loss 1.350854516029358
Iteration 6: train_loss 1.2567719221115112
Iteration 7: train_loss 1.3494069576263428
Iteration 8: train_loss 1.3493130207061768
Iteration 9: train_loss 1.3038347959518433
Iteration 10: train_loss 1.3355296850204468
Iteration 11: train_loss 1.2759612798690796
Iteration 12: train_loss 1.3151482343673706
Iteration 13: train_loss 1.299471378326416
Iteration 14: train_loss 1.2578192949295044
Iteration 15: train_loss 1.3038259744644165
Iteration 16: train_loss 1.2835594415664673
Iteration 17: train_loss 1.3069026470184326
Iteration 18: train_loss 1.3253623247146606
Iteration 19: train_loss 1.3487874269485474
Iteration 20: train_loss 1.3516398668289185
Iteration 21: train_loss 1.224973201751709
Iteration 22: train_loss 1.323115587234497
Iteration 23: train_loss 1.3560140132904053
Iteration 24: train_loss 1.2499778270721436
Iteration 25: train_loss 1.314059853553772
Iteration 26: train_loss 1.3499959707260132
Iteration 27: train_loss 1.2836438417434692
Iteration 28: train_loss 1.3179227113723755
Iteration 29: train_loss 1.364831805229187
Iteration 30: train_loss 1.2610543966293335
Iteration 31: train_loss 1.3509396314620972
Iteration 32: train_loss 1.3868297338485718
Iteration 33: train_loss 1.3566768169403076
Iteration 34: train_loss 1.3459484577178955
Iteration 35: train_loss 1.2800443172454834
Iteration 36: train_loss 1.3034749031066895
Iteration 37: train_loss 1.3223260641098022
Iteration 38: train_loss 1.3016245365142822
Iteration 39: train_loss 1.3059455156326294
Iteration 40: train_loss 1.3278967142105103
Iteration 41: train_loss 1.3064485788345337
Iteration 42: train_loss 1.3609225749969482
Iteration 43: train_loss 1.2934805154800415
Iteration 44: train_loss 1.2797764539718628
Iteration 45: train_loss 1.3226004838943481
Iteration 46: train_loss 1.3348240852355957
Iteration 47: train_loss 1.3160053491592407
Iteration 48: train_loss 1.337677001953125
Iteration 49: train_loss 1.3567306995391846
Iteration 50: train_loss 1.2868893146514893
Iteration 51: train_loss 1.332269310951233
Iteration 52: train_loss 1.3453282117843628
Iteration 53: train_loss 1.3006335496902466
Iteration 54: train_loss 1.2884278297424316
Iteration 55: train_loss 1.3095381259918213
Iteration 56: train_loss 1.311554193496704
Iteration 57: train_loss 1.3133121728897095
Iteration 58: train_loss 1.4171392917633057
Iteration 59: train_loss 1.3336585760116577
Iteration 60: train_loss 1.3205773830413818
Iteration 61: train_loss 1.3018690347671509
Iteration 62: train_loss 1.3085377216339111
Iteration 63: train_loss 1.3832074403762817
Iteration 64: train_loss 1.3373385667800903
Iteration 65: train_loss 1.3327370882034302
Iteration 66: train_loss 1.3349026441574097
Iteration 67: train_loss 1.3433196544647217
Iteration 68: train_loss 1.3479020595550537
Iteration 69: train_loss 1.3329660892486572
Iteration 70: train_loss 1.3266024589538574
Iteration 71: train_loss 1.3039741516113281
Iteration 72: train_loss 1.3380773067474365
Iteration 73: train_loss 1.30536949634552
Iteration 74: train_loss 1.34946608543396
Iteration 75: train_loss 1.3000304698944092
Iteration 76: train_loss 1.31924307346344
Iteration 77: train_loss 1.263852834701538
Iteration 78: train_loss 1.3393969535827637
Iteration 79: train_loss 1.2858989238739014
Iteration 80: train_loss 1.2983729839324951
Iteration 81: train_loss 1.3023109436035156
Iteration 82: train_loss 1.3603951930999756
Iteration 83: train_loss 1.3349175453186035
Iteration 84: train_loss 1.2952138185501099
Iteration 85: train_loss 1.2877265214920044
Iteration 86: train_loss 1.2867789268493652
Iteration 87: train_loss 1.3095886707305908
Iteration 88: train_loss 1.2835928201675415
Iteration 89: train_loss 1.349554181098938
Iteration 90: train_loss 1.3554385900497437
Iteration 91: train_loss 1.3299201726913452
Iteration 92: train_loss 1.336212158203125
Iteration 93: train_loss 1.2769616842269897
Iteration 94: train_loss 1.3465815782546997
Iteration 95: train_loss 1.289590835571289
Iteration 96: train_loss 1.2756539583206177
Iteration 97: train_loss 1.3810243606567383
Iteration 98: train_loss 1.3469388484954834
Iteration 99: train_loss 1.2958242893218994
Iteration 100: train_loss 1.2673898935317993
Iteration 101: train_loss 1.2977368831634521
Iteration 102: train_loss 1.3138564825057983
Iteration 103: train_loss 1.3589978218078613
Iteration 104: train_loss 1.272639513015747
Iteration 105: train_loss 1.265873670578003
Iteration 106: train_loss 1.2448524236679077
Iteration 107: train_loss 1.3383351564407349
Iteration 108: train_loss 1.2742871046066284
Iteration 109: train_loss 1.3740992546081543
Iteration 110: train_loss 1.3805615901947021
Iteration 111: train_loss 1.340328335762024
Iteration 112: train_loss 1.3188589811325073
Iteration 113: train_loss 1.3610938787460327
Iteration 114: train_loss 1.3403712511062622
Iteration 115: train_loss 1.2892003059387207
Iteration 116: train_loss 1.249686598777771
Iteration 117: train_loss 1.336889624595642
Iteration 118: train_loss 1.3255178928375244
Iteration 119: train_loss 1.3506550788879395
Iteration 120: train_loss 1.251570701599121
Iteration 121: train_loss 1.3464986085891724
Iteration 122: train_loss 1.3436155319213867
Iteration 123: train_loss 1.3086953163146973
Iteration 124: train_loss 1.3050322532653809
Iteration 125: train_loss 1.285156488418579
Iteration 126: train_loss 1.3769285678863525
Iteration 127: train_loss 1.378624439239502
Iteration 128: train_loss 1.3912713527679443
Iteration 129: train_loss 1.3459497690200806
Iteration 130: train_loss 1.3756746053695679
Iteration 131: train_loss 1.3472297191619873
Iteration 132: train_loss 1.3782365322113037
Iteration 133: train_loss 1.319513201713562
Iteration 134: train_loss 1.394517183303833
Iteration 135: train_loss 1.282021164894104
Iteration 136: train_loss 1.3723194599151611
Iteration 137: train_loss 1.345731496810913
Iteration 138: train_loss 1.323414921760559
Iteration 139: train_loss 1.3265935182571411
Iteration 140: train_loss 1.3276054859161377
Iteration 141: train_loss 1.3463430404663086
Iteration 142: train_loss 1.2798916101455688
Iteration 143: train_loss 1.3223055601119995
Iteration 144: train_loss 1.298432469367981
Iteration 145: train_loss 1.324169635772705
Iteration 146: train_loss 1.3462870121002197
Iteration 147: train_loss 1.3161720037460327
Iteration 148: train_loss 1.3492982387542725
Iteration 149: train_loss 1.3203823566436768
Iteration 150: train_loss 1.2833248376846313
Iteration 151: train_loss 1.3665858507156372
Iteration 152: train_loss 1.3853142261505127
Iteration 153: train_loss 1.2916160821914673
Iteration 154: train_loss 1.313429832458496
Iteration 155: train_loss 1.402494192123413
Iteration 156: train_loss 1.3398727178573608
Iteration 157: train_loss 1.370093822479248
Iteration 158: train_loss 1.401302456855774
Iteration 159: train_loss 1.3997787237167358
Iteration 160: train_loss 1.4199696779251099
Iteration 161: train_loss 1.3605848550796509
Iteration 162: train_loss 1.4006774425506592
Iteration 163: train_loss 1.298386573791504
Iteration 164: train_loss 1.328223466873169
Iteration 165: train_loss 1.3308606147766113
Iteration 166: train_loss 1.3495789766311646
Iteration 167: train_loss 1.318557858467102
Iteration 168: train_loss 1.3580180406570435
Iteration 169: train_loss 1.3157713413238525
Iteration 170: train_loss 1.3745051622390747
Iteration 171: train_loss 1.3423131704330444
Iteration 172: train_loss 1.3542330265045166
Iteration 173: train_loss 1.3642356395721436
Iteration 174: train_loss 1.3259897232055664
Iteration 175: train_loss 1.2952966690063477
Iteration 176: train_loss 1.3183096647262573
Iteration 177: train_loss 1.3879978656768799
Epoch 114: train_avg_loss 1.3267180737802537 eval_avg_acc: 0.34636360404126 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:05:31] [32mIntermediate result: 0.34636360404126  (Index 113)[0m
================Epoch: 115================
Iteration 1: train_loss 1.2988488674163818
Iteration 2: train_loss 1.3099898099899292
Iteration 3: train_loss 1.3465701341629028
Iteration 4: train_loss 1.2969045639038086
Iteration 5: train_loss 1.2539236545562744
Iteration 6: train_loss 1.3123779296875
Iteration 7: train_loss 1.272754430770874
Iteration 8: train_loss 1.2771834135055542
Iteration 9: train_loss 1.305830717086792
Iteration 10: train_loss 1.349822998046875
Iteration 11: train_loss 1.3255436420440674
Iteration 12: train_loss 1.30217444896698
Iteration 13: train_loss 1.28883957862854
Iteration 14: train_loss 1.2704507112503052
Iteration 15: train_loss 1.300330400466919
Iteration 16: train_loss 1.2367948293685913
Iteration 17: train_loss 1.2962946891784668
Iteration 18: train_loss 1.3336927890777588
Iteration 19: train_loss 1.338637113571167
Iteration 20: train_loss 1.3005436658859253
Iteration 21: train_loss 1.2888871431350708
Iteration 22: train_loss 1.3348584175109863
Iteration 23: train_loss 1.2836663722991943
Iteration 24: train_loss 1.3406622409820557
Iteration 25: train_loss 1.3042782545089722
Iteration 26: train_loss 1.383547306060791
Iteration 27: train_loss 1.3395782709121704
Iteration 28: train_loss 1.3114086389541626
Iteration 29: train_loss 1.3421480655670166
Iteration 30: train_loss 1.3023165464401245
Iteration 31: train_loss 1.2621456384658813
Iteration 32: train_loss 1.3954877853393555
Iteration 33: train_loss 1.3204997777938843
Iteration 34: train_loss 1.3365010023117065
Iteration 35: train_loss 1.343337893486023
Iteration 36: train_loss 1.3058964014053345
Iteration 37: train_loss 1.3399864435195923
Iteration 38: train_loss 1.278881311416626
Iteration 39: train_loss 1.2869457006454468
Iteration 40: train_loss 1.288353443145752
Iteration 41: train_loss 1.320067286491394
Iteration 42: train_loss 1.3308764696121216
Iteration 43: train_loss 1.29694402217865
Iteration 44: train_loss 1.2971540689468384
Iteration 45: train_loss 1.295040488243103
Iteration 46: train_loss 1.2960513830184937
Iteration 47: train_loss 1.3210691213607788
Iteration 48: train_loss 1.2954940795898438
Iteration 49: train_loss 1.326420545578003
Iteration 50: train_loss 1.323673963546753
Iteration 51: train_loss 1.300645112991333
Iteration 52: train_loss 1.2779268026351929
Iteration 53: train_loss 1.3097285032272339
Iteration 54: train_loss 1.2746222019195557
Iteration 55: train_loss 1.3360627889633179
Iteration 56: train_loss 1.3301684856414795
Iteration 57: train_loss 1.3634880781173706
Iteration 58: train_loss 1.3347398042678833
Iteration 59: train_loss 1.335355520248413
Iteration 60: train_loss 1.3279122114181519
Iteration 61: train_loss 1.3015655279159546
Iteration 62: train_loss 1.3585797548294067
Iteration 63: train_loss 1.3550976514816284
Iteration 64: train_loss 1.3654561042785645
Iteration 65: train_loss 1.4084054231643677
Iteration 66: train_loss 1.3524991273880005
Iteration 67: train_loss 1.3618546724319458
Iteration 68: train_loss 1.3450839519500732
Iteration 69: train_loss 1.3254404067993164
Iteration 70: train_loss 1.2291510105133057
Iteration 71: train_loss 1.3668605089187622
Iteration 72: train_loss 1.3611267805099487
Iteration 73: train_loss 1.320083498954773
Iteration 74: train_loss 1.3244388103485107
Iteration 75: train_loss 1.2843798398971558
Iteration 76: train_loss 1.3500361442565918
Iteration 77: train_loss 1.2861566543579102
Iteration 78: train_loss 1.36995530128479
Iteration 79: train_loss 1.306378722190857
Iteration 80: train_loss 1.2831578254699707
Iteration 81: train_loss 1.278378963470459
Iteration 82: train_loss 1.3746910095214844
Iteration 83: train_loss 1.335440754890442
Iteration 84: train_loss 1.3403009176254272
Iteration 85: train_loss 1.2530051469802856
Iteration 86: train_loss 1.2933605909347534
Iteration 87: train_loss 1.2959504127502441
Iteration 88: train_loss 1.2880436182022095
Iteration 89: train_loss 1.27155339717865
Iteration 90: train_loss 1.3399767875671387
Iteration 91: train_loss 1.2761695384979248
Iteration 92: train_loss 1.2996948957443237
Iteration 93: train_loss 1.321432113647461
Iteration 94: train_loss 1.3010910749435425
Iteration 95: train_loss 1.2664059400558472
Iteration 96: train_loss 1.3332438468933105
Iteration 97: train_loss 1.3409134149551392
Iteration 98: train_loss 1.3406060934066772
Iteration 99: train_loss 1.3141626119613647
Iteration 100: train_loss 1.344731330871582
Iteration 101: train_loss 1.299127459526062
Iteration 102: train_loss 1.346519112586975
Iteration 103: train_loss 1.279488444328308
Iteration 104: train_loss 1.3486435413360596
Iteration 105: train_loss 1.3552742004394531
Iteration 106: train_loss 1.3388969898223877
Iteration 107: train_loss 1.3395147323608398
Iteration 108: train_loss 1.3148236274719238
Iteration 109: train_loss 1.3127332925796509
Iteration 110: train_loss 1.3110941648483276
Iteration 111: train_loss 1.3710570335388184
Iteration 112: train_loss 1.356298565864563
Iteration 113: train_loss 1.356693148612976
Iteration 114: train_loss 1.3417190313339233
Iteration 115: train_loss 1.326040267944336
Iteration 116: train_loss 1.3394783735275269
Iteration 117: train_loss 1.3254743814468384
Iteration 118: train_loss 1.295979380607605
Iteration 119: train_loss 1.2954570055007935
Iteration 120: train_loss 1.345361590385437
Iteration 121: train_loss 1.3320285081863403
Iteration 122: train_loss 1.331279993057251
Iteration 123: train_loss 1.287196397781372
Iteration 124: train_loss 1.3733476400375366
Iteration 125: train_loss 1.3028130531311035
Iteration 126: train_loss 1.3736870288848877
Iteration 127: train_loss 1.381885290145874
Iteration 128: train_loss 1.390694260597229
Iteration 129: train_loss 1.3087503910064697
Iteration 130: train_loss 1.3418363332748413
Iteration 131: train_loss 1.3260748386383057
Iteration 132: train_loss 1.3385374546051025
Iteration 133: train_loss 1.3279110193252563
Iteration 134: train_loss 1.2893190383911133
Iteration 135: train_loss 1.340944766998291
Iteration 136: train_loss 1.313914179801941
Iteration 137: train_loss 1.3112033605575562
Iteration 138: train_loss 1.2844339609146118
Iteration 139: train_loss 1.3565806150436401
Iteration 140: train_loss 1.2906156778335571
Iteration 141: train_loss 1.3468871116638184
Iteration 142: train_loss 1.2910305261611938
Iteration 143: train_loss 1.3600184917449951
Iteration 144: train_loss 1.3345226049423218
Iteration 145: train_loss 1.4159932136535645
Iteration 146: train_loss 1.3371202945709229
Iteration 147: train_loss 1.2784572839736938
Iteration 148: train_loss 1.323434591293335
Iteration 149: train_loss 1.32932448387146
Iteration 150: train_loss 1.4068411588668823
Iteration 151: train_loss 1.341314435005188
Iteration 152: train_loss 1.3094050884246826
Iteration 153: train_loss 1.278289794921875
Iteration 154: train_loss 1.3713505268096924
Iteration 155: train_loss 1.361200213432312
Iteration 156: train_loss 1.304208517074585
Iteration 157: train_loss 1.3404035568237305
Iteration 158: train_loss 1.3312911987304688
Iteration 159: train_loss 1.2621694803237915
Iteration 160: train_loss 1.320346474647522
Iteration 161: train_loss 1.2946233749389648
Iteration 162: train_loss 1.3694591522216797
Iteration 163: train_loss 1.409684419631958
Iteration 164: train_loss 1.3636057376861572
Iteration 165: train_loss 1.3419541120529175
Iteration 166: train_loss 1.3428902626037598
Iteration 167: train_loss 1.3783804178237915
Iteration 168: train_loss 1.337891697883606
Iteration 169: train_loss 1.3677170276641846
Iteration 170: train_loss 1.336301326751709
Iteration 171: train_loss 1.3322631120681763
Iteration 172: train_loss 1.3181759119033813
Iteration 173: train_loss 1.3767842054367065
Iteration 174: train_loss 1.317534327507019
Iteration 175: train_loss 1.2905021905899048
Iteration 176: train_loss 1.2970372438430786
Iteration 177: train_loss 1.277787208557129
Epoch 115: train_avg_loss 1.3229611586716215 eval_avg_acc: 0.3471512897897478 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:06:09] [32mIntermediate result: 0.3471512897897478  (Index 114)[0m
================Epoch: 116================
Iteration 1: train_loss 1.3116167783737183
Iteration 2: train_loss 1.28954017162323
Iteration 3: train_loss 1.309403419494629
Iteration 4: train_loss 1.3157614469528198
Iteration 5: train_loss 1.2692286968231201
Iteration 6: train_loss 1.3182761669158936
Iteration 7: train_loss 1.2948359251022339
Iteration 8: train_loss 1.3210753202438354
Iteration 9: train_loss 1.287719964981079
Iteration 10: train_loss 1.3438396453857422
Iteration 11: train_loss 1.2768486738204956
Iteration 12: train_loss 1.2887637615203857
Iteration 13: train_loss 1.313897728919983
Iteration 14: train_loss 1.3377456665039062
Iteration 15: train_loss 1.2953238487243652
Iteration 16: train_loss 1.2679381370544434
Iteration 17: train_loss 1.2801709175109863
Iteration 18: train_loss 1.288199543952942
Iteration 19: train_loss 1.2948722839355469
Iteration 20: train_loss 1.3038707971572876
Iteration 21: train_loss 1.2746425867080688
Iteration 22: train_loss 1.341639518737793
Iteration 23: train_loss 1.2691327333450317
Iteration 24: train_loss 1.2530491352081299
Iteration 25: train_loss 1.3030846118927002
Iteration 26: train_loss 1.2878905534744263
Iteration 27: train_loss 1.2762891054153442
Iteration 28: train_loss 1.316102385520935
Iteration 29: train_loss 1.267061471939087
Iteration 30: train_loss 1.279628038406372
Iteration 31: train_loss 1.3174995183944702
Iteration 32: train_loss 1.287900447845459
Iteration 33: train_loss 1.2847199440002441
Iteration 34: train_loss 1.268879771232605
Iteration 35: train_loss 1.2782468795776367
Iteration 36: train_loss 1.2404911518096924
Iteration 37: train_loss 1.305044174194336
Iteration 38: train_loss 1.3726694583892822
Iteration 39: train_loss 1.266467571258545
Iteration 40: train_loss 1.2861523628234863
Iteration 41: train_loss 1.2630542516708374
Iteration 42: train_loss 1.2823104858398438
Iteration 43: train_loss 1.333448052406311
Iteration 44: train_loss 1.2850497961044312
Iteration 45: train_loss 1.3101046085357666
Iteration 46: train_loss 1.3060193061828613
Iteration 47: train_loss 1.3352057933807373
Iteration 48: train_loss 1.3185824155807495
Iteration 49: train_loss 1.2864108085632324
Iteration 50: train_loss 1.345463514328003
Iteration 51: train_loss 1.3055551052093506
Iteration 52: train_loss 1.3240505456924438
Iteration 53: train_loss 1.2912355661392212
Iteration 54: train_loss 1.234313726425171
Iteration 55: train_loss 1.3196494579315186
Iteration 56: train_loss 1.258155345916748
Iteration 57: train_loss 1.2189841270446777
Iteration 58: train_loss 1.2574584484100342
Iteration 59: train_loss 1.28280508518219
Iteration 60: train_loss 1.3034439086914062
Iteration 61: train_loss 1.2914342880249023
Iteration 62: train_loss 1.2639216184616089
Iteration 63: train_loss 1.2369964122772217
Iteration 64: train_loss 1.268890142440796
Iteration 65: train_loss 1.3066377639770508
Iteration 66: train_loss 1.2331663370132446
Iteration 67: train_loss 1.2837538719177246
Iteration 68: train_loss 1.287512183189392
Iteration 69: train_loss 1.2907270193099976
Iteration 70: train_loss 1.2893770933151245
Iteration 71: train_loss 1.269558072090149
Iteration 72: train_loss 1.32547926902771
Iteration 73: train_loss 1.3236857652664185
Iteration 74: train_loss 1.3180434703826904
Iteration 75: train_loss 1.320288896560669
Iteration 76: train_loss 1.3622848987579346
Iteration 77: train_loss 1.300730586051941
Iteration 78: train_loss 1.361199140548706
Iteration 79: train_loss 1.288234829902649
Iteration 80: train_loss 1.343587875366211
Iteration 81: train_loss 1.28532075881958
Iteration 82: train_loss 1.3429882526397705
Iteration 83: train_loss 1.3059102296829224
Iteration 84: train_loss 1.3283343315124512
Iteration 85: train_loss 1.3871543407440186
Iteration 86: train_loss 1.2664507627487183
Iteration 87: train_loss 1.307594656944275
Iteration 88: train_loss 1.3170406818389893
Iteration 89: train_loss 1.3277335166931152
Iteration 90: train_loss 1.3568689823150635
Iteration 91: train_loss 1.320939302444458
Iteration 92: train_loss 1.326392412185669
Iteration 93: train_loss 1.3556760549545288
Iteration 94: train_loss 1.270548939704895
Iteration 95: train_loss 1.3263417482376099
Iteration 96: train_loss 1.2913768291473389
Iteration 97: train_loss 1.376607894897461
Iteration 98: train_loss 1.3046021461486816
Iteration 99: train_loss 1.3029671907424927
Iteration 100: train_loss 1.3443745374679565
Iteration 101: train_loss 1.3050110340118408
Iteration 102: train_loss 1.3008320331573486
Iteration 103: train_loss 1.3330683708190918
Iteration 104: train_loss 1.3376777172088623
Iteration 105: train_loss 1.3469775915145874
Iteration 106: train_loss 1.3207037448883057
Iteration 107: train_loss 1.2819758653640747
Iteration 108: train_loss 1.251124382019043
Iteration 109: train_loss 1.3666677474975586
Iteration 110: train_loss 1.3076753616333008
Iteration 111: train_loss 1.306614637374878
Iteration 112: train_loss 1.3487977981567383
Iteration 113: train_loss 1.3242884874343872
Iteration 114: train_loss 1.3424043655395508
Iteration 115: train_loss 1.3294076919555664
Iteration 116: train_loss 1.3187024593353271
Iteration 117: train_loss 1.3519006967544556
Iteration 118: train_loss 1.3723469972610474
Iteration 119: train_loss 1.32375967502594
Iteration 120: train_loss 1.290717363357544
Iteration 121: train_loss 1.2932679653167725
Iteration 122: train_loss 1.2994365692138672
Iteration 123: train_loss 1.3104090690612793
Iteration 124: train_loss 1.2609655857086182
Iteration 125: train_loss 1.2869117259979248
Iteration 126: train_loss 1.3198981285095215
Iteration 127: train_loss 1.3783254623413086
Iteration 128: train_loss 1.2415132522583008
Iteration 129: train_loss 1.2679407596588135
Iteration 130: train_loss 1.3200687170028687
Iteration 131: train_loss 1.3190898895263672
Iteration 132: train_loss 1.322503924369812
Iteration 133: train_loss 1.3228100538253784
Iteration 134: train_loss 1.3734431266784668
Iteration 135: train_loss 1.302681803703308
Iteration 136: train_loss 1.3618987798690796
Iteration 137: train_loss 1.2445423603057861
Iteration 138: train_loss 1.2928615808486938
Iteration 139: train_loss 1.3295745849609375
Iteration 140: train_loss 1.2663931846618652
Iteration 141: train_loss 1.3249118328094482
Iteration 142: train_loss 1.252820372581482
Iteration 143: train_loss 1.2427921295166016
Iteration 144: train_loss 1.363206386566162
Iteration 145: train_loss 1.2898284196853638
Iteration 146: train_loss 1.3394373655319214
Iteration 147: train_loss 1.2819995880126953
Iteration 148: train_loss 1.3097745180130005
Iteration 149: train_loss 1.3067222833633423
Iteration 150: train_loss 1.2935954332351685
Iteration 151: train_loss 1.2934445142745972
Iteration 152: train_loss 1.2886677980422974
Iteration 153: train_loss 1.2817308902740479
Iteration 154: train_loss 1.2791905403137207
Iteration 155: train_loss 1.3011409044265747
Iteration 156: train_loss 1.3210656642913818
Iteration 157: train_loss 1.3383045196533203
Iteration 158: train_loss 1.3047850131988525
Iteration 159: train_loss 1.2761120796203613
Iteration 160: train_loss 1.3121192455291748
Iteration 161: train_loss 1.3090300559997559
Iteration 162: train_loss 1.3193057775497437
Iteration 163: train_loss 1.3817914724349976
Iteration 164: train_loss 1.3893839120864868
Iteration 165: train_loss 1.3511310815811157
Iteration 166: train_loss 1.2881405353546143
Iteration 167: train_loss 1.3364038467407227
Iteration 168: train_loss 1.2984751462936401
Iteration 169: train_loss 1.3249436616897583
Iteration 170: train_loss 1.330275535583496
Iteration 171: train_loss 1.3370423316955566
Iteration 172: train_loss 1.3001400232315063
Iteration 173: train_loss 1.3692256212234497
Iteration 174: train_loss 1.362802505493164
Iteration 175: train_loss 1.3418816328048706
Iteration 176: train_loss 1.343145728111267
Iteration 177: train_loss 1.2866593599319458
Epoch 116: train_avg_loss 1.3068032318589378 eval_avg_acc: 0.343274147911332 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:06:48] [32mIntermediate result: 0.343274147911332  (Index 115)[0m
================Epoch: 117================
Iteration 1: train_loss 1.3281396627426147
Iteration 2: train_loss 1.382769227027893
Iteration 3: train_loss 1.2956181764602661
Iteration 4: train_loss 1.3091042041778564
Iteration 5: train_loss 1.3060314655303955
Iteration 6: train_loss 1.35493803024292
Iteration 7: train_loss 1.3111363649368286
Iteration 8: train_loss 1.331618070602417
Iteration 9: train_loss 1.338724970817566
Iteration 10: train_loss 1.3044146299362183
Iteration 11: train_loss 1.343207597732544
Iteration 12: train_loss 1.2874953746795654
Iteration 13: train_loss 1.332040786743164
Iteration 14: train_loss 1.3065117597579956
Iteration 15: train_loss 1.3966352939605713
Iteration 16: train_loss 1.3409457206726074
Iteration 17: train_loss 1.276384949684143
Iteration 18: train_loss 1.2780042886734009
Iteration 19: train_loss 1.2572377920150757
Iteration 20: train_loss 1.2944929599761963
Iteration 21: train_loss 1.2716093063354492
Iteration 22: train_loss 1.3342729806900024
Iteration 23: train_loss 1.3408323526382446
Iteration 24: train_loss 1.3469690084457397
Iteration 25: train_loss 1.3114049434661865
Iteration 26: train_loss 1.3259093761444092
Iteration 27: train_loss 1.3221817016601562
Iteration 28: train_loss 1.2916662693023682
Iteration 29: train_loss 1.2813677787780762
Iteration 30: train_loss 1.3406339883804321
Iteration 31: train_loss 1.207612156867981
Iteration 32: train_loss 1.2843941450119019
Iteration 33: train_loss 1.2364858388900757
Iteration 34: train_loss 1.2790170907974243
Iteration 35: train_loss 1.3028781414031982
Iteration 36: train_loss 1.3504770994186401
Iteration 37: train_loss 1.2648369073867798
Iteration 38: train_loss 1.289395809173584
Iteration 39: train_loss 1.3464304208755493
Iteration 40: train_loss 1.3188437223434448
Iteration 41: train_loss 1.240608811378479
Iteration 42: train_loss 1.2695144414901733
Iteration 43: train_loss 1.3068093061447144
Iteration 44: train_loss 1.3104665279388428
Iteration 45: train_loss 1.2628072500228882
Iteration 46: train_loss 1.3204188346862793
Iteration 47: train_loss 1.2888362407684326
Iteration 48: train_loss 1.3212352991104126
Iteration 49: train_loss 1.2593950033187866
Iteration 50: train_loss 1.2748064994812012
Iteration 51: train_loss 1.2602825164794922
Iteration 52: train_loss 1.2447870969772339
Iteration 53: train_loss 1.2838844060897827
Iteration 54: train_loss 1.2821791172027588
Iteration 55: train_loss 1.2859249114990234
Iteration 56: train_loss 1.3280971050262451
Iteration 57: train_loss 1.3070363998413086
Iteration 58: train_loss 1.3317099809646606
Iteration 59: train_loss 1.3088873624801636
Iteration 60: train_loss 1.2651863098144531
Iteration 61: train_loss 1.3542518615722656
Iteration 62: train_loss 1.3194266557693481
Iteration 63: train_loss 1.2891818284988403
Iteration 64: train_loss 1.293608546257019
Iteration 65: train_loss 1.3330366611480713
Iteration 66: train_loss 1.3215582370758057
Iteration 67: train_loss 1.325160264968872
Iteration 68: train_loss 1.3014907836914062
Iteration 69: train_loss 1.2616937160491943
Iteration 70: train_loss 1.3011903762817383
Iteration 71: train_loss 1.335760474205017
Iteration 72: train_loss 1.2987061738967896
Iteration 73: train_loss 1.2820112705230713
Iteration 74: train_loss 1.2924221754074097
Iteration 75: train_loss 1.317305564880371
Iteration 76: train_loss 1.3786996603012085
Iteration 77: train_loss 1.2889163494110107
Iteration 78: train_loss 1.29425847530365
Iteration 79: train_loss 1.3116353750228882
Iteration 80: train_loss 1.2644935846328735
Iteration 81: train_loss 1.3310675621032715
Iteration 82: train_loss 1.3557573556900024
Iteration 83: train_loss 1.325091004371643
Iteration 84: train_loss 1.3559492826461792
Iteration 85: train_loss 1.3103601932525635
Iteration 86: train_loss 1.2873114347457886
Iteration 87: train_loss 1.2866483926773071
Iteration 88: train_loss 1.2798081636428833
Iteration 89: train_loss 1.2889161109924316
Iteration 90: train_loss 1.330275058746338
Iteration 91: train_loss 1.2675827741622925
Iteration 92: train_loss 1.295904517173767
Iteration 93: train_loss 1.3098074197769165
Iteration 94: train_loss 1.2751110792160034
Iteration 95: train_loss 1.3211424350738525
Iteration 96: train_loss 1.357074499130249
Iteration 97: train_loss 1.2977800369262695
Iteration 98: train_loss 1.3012422323226929
Iteration 99: train_loss 1.3119525909423828
Iteration 100: train_loss 1.338732361793518
Iteration 101: train_loss 1.333871841430664
Iteration 102: train_loss 1.3525426387786865
Iteration 103: train_loss 1.3080933094024658
Iteration 104: train_loss 1.2334585189819336
Iteration 105: train_loss 1.321504831314087
Iteration 106: train_loss 1.315295934677124
Iteration 107: train_loss 1.3755178451538086
Iteration 108: train_loss 1.2572646141052246
Iteration 109: train_loss 1.258096694946289
Iteration 110: train_loss 1.3045991659164429
Iteration 111: train_loss 1.3111494779586792
Iteration 112: train_loss 1.2481869459152222
Iteration 113: train_loss 1.289494514465332
Iteration 114: train_loss 1.3207297325134277
Iteration 115: train_loss 1.2761801481246948
Iteration 116: train_loss 1.283621907234192
Iteration 117: train_loss 1.2641130685806274
Iteration 118: train_loss 1.2635759115219116
Iteration 119: train_loss 1.2477328777313232
Iteration 120: train_loss 1.2833497524261475
Iteration 121: train_loss 1.2323973178863525
Iteration 122: train_loss 1.3804210424423218
Iteration 123: train_loss 1.277366280555725
Iteration 124: train_loss 1.2949131727218628
Iteration 125: train_loss 1.3126932382583618
Iteration 126: train_loss 1.2802189588546753
Iteration 127: train_loss 1.3119930028915405
Iteration 128: train_loss 1.3046671152114868
Iteration 129: train_loss 1.3308265209197998
Iteration 130: train_loss 1.2775145769119263
Iteration 131: train_loss 1.2755937576293945
Iteration 132: train_loss 1.3016865253448486
Iteration 133: train_loss 1.3652068376541138
Iteration 134: train_loss 1.30347740650177
Iteration 135: train_loss 1.2991222143173218
Iteration 136: train_loss 1.298241376876831
Iteration 137: train_loss 1.3667514324188232
Iteration 138: train_loss 1.2967990636825562
Iteration 139: train_loss 1.3207998275756836
Iteration 140: train_loss 1.3304932117462158
Iteration 141: train_loss 1.3291096687316895
Iteration 142: train_loss 1.3478918075561523
Iteration 143: train_loss 1.3408892154693604
Iteration 144: train_loss 1.3216880559921265
Iteration 145: train_loss 1.3461582660675049
Iteration 146: train_loss 1.3224881887435913
Iteration 147: train_loss 1.3003543615341187
Iteration 148: train_loss 1.3579007387161255
Iteration 149: train_loss 1.315024495124817
Iteration 150: train_loss 1.330756664276123
Iteration 151: train_loss 1.28572678565979
Iteration 152: train_loss 1.2712141275405884
Iteration 153: train_loss 1.272262692451477
Iteration 154: train_loss 1.409731149673462
Iteration 155: train_loss 1.3524278402328491
Iteration 156: train_loss 1.4071900844573975
Iteration 157: train_loss 1.312103509902954
Iteration 158: train_loss 1.2927615642547607
Iteration 159: train_loss 1.3229860067367554
Iteration 160: train_loss 1.3275984525680542
Iteration 161: train_loss 1.2752684354782104
Iteration 162: train_loss 1.313812494277954
Iteration 163: train_loss 1.3844704627990723
Iteration 164: train_loss 1.286965250968933
Iteration 165: train_loss 1.3329932689666748
Iteration 166: train_loss 1.3305665254592896
Iteration 167: train_loss 1.2220735549926758
Iteration 168: train_loss 1.373375654220581
Iteration 169: train_loss 1.3681721687316895
Iteration 170: train_loss 1.423995018005371
Iteration 171: train_loss 1.353068470954895
Iteration 172: train_loss 1.3509801626205444
Iteration 173: train_loss 1.3256267309188843
Iteration 174: train_loss 1.287894368171692
Iteration 175: train_loss 1.3123373985290527
Iteration 176: train_loss 1.2646933794021606
Iteration 177: train_loss 1.3557302951812744
Epoch 117: train_avg_loss 1.3090718432334856 eval_avg_acc: 0.3425027529868418 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:07:26] [32mIntermediate result: 0.3425027529868418  (Index 116)[0m
================Epoch: 118================
Iteration 1: train_loss 1.254830002784729
Iteration 2: train_loss 1.3772143125534058
Iteration 3: train_loss 1.326468586921692
Iteration 4: train_loss 1.3014312982559204
Iteration 5: train_loss 1.4032583236694336
Iteration 6: train_loss 1.3031643629074097
Iteration 7: train_loss 1.3386085033416748
Iteration 8: train_loss 1.2615529298782349
Iteration 9: train_loss 1.3305583000183105
Iteration 10: train_loss 1.3104413747787476
Iteration 11: train_loss 1.3342161178588867
Iteration 12: train_loss 1.276906967163086
Iteration 13: train_loss 1.3079488277435303
Iteration 14: train_loss 1.319930076599121
Iteration 15: train_loss 1.3439054489135742
Iteration 16: train_loss 1.2775315046310425
Iteration 17: train_loss 1.3447381258010864
Iteration 18: train_loss 1.3105050325393677
Iteration 19: train_loss 1.2617814540863037
Iteration 20: train_loss 1.2710837125778198
Iteration 21: train_loss 1.2956044673919678
Iteration 22: train_loss 1.2686820030212402
Iteration 23: train_loss 1.1999472379684448
Iteration 24: train_loss 1.2253435850143433
Iteration 25: train_loss 1.240893006324768
Iteration 26: train_loss 1.313717007637024
Iteration 27: train_loss 1.3108704090118408
Iteration 28: train_loss 1.2597622871398926
Iteration 29: train_loss 1.303606629371643
Iteration 30: train_loss 1.326407790184021
Iteration 31: train_loss 1.2902899980545044
Iteration 32: train_loss 1.3249722719192505
Iteration 33: train_loss 1.2886309623718262
Iteration 34: train_loss 1.31885826587677
Iteration 35: train_loss 1.316152572631836
Iteration 36: train_loss 1.2099689245224
Iteration 37: train_loss 1.3200050592422485
Iteration 38: train_loss 1.287604570388794
Iteration 39: train_loss 1.2922700643539429
Iteration 40: train_loss 1.3198999166488647
Iteration 41: train_loss 1.3776673078536987
Iteration 42: train_loss 1.2738456726074219
Iteration 43: train_loss 1.307552695274353
Iteration 44: train_loss 1.2871559858322144
Iteration 45: train_loss 1.2838627099990845
Iteration 46: train_loss 1.3117320537567139
Iteration 47: train_loss 1.3059072494506836
Iteration 48: train_loss 1.326457142829895
Iteration 49: train_loss 1.3044381141662598
Iteration 50: train_loss 1.291717767715454
Iteration 51: train_loss 1.2539242506027222
Iteration 52: train_loss 1.2967987060546875
Iteration 53: train_loss 1.2241438627243042
Iteration 54: train_loss 1.2929861545562744
Iteration 55: train_loss 1.2666795253753662
Iteration 56: train_loss 1.3141368627548218
Iteration 57: train_loss 1.2576584815979004
Iteration 58: train_loss 1.2542928457260132
Iteration 59: train_loss 1.3683433532714844
Iteration 60: train_loss 1.3847792148590088
Iteration 61: train_loss 1.3208261728286743
Iteration 62: train_loss 1.3231192827224731
Iteration 63: train_loss 1.3394343852996826
Iteration 64: train_loss 1.4123398065567017
Iteration 65: train_loss 1.3304673433303833
Iteration 66: train_loss 1.3458627462387085
Iteration 67: train_loss 1.3619611263275146
Iteration 68: train_loss 1.3417192697525024
Iteration 69: train_loss 1.318287968635559
Iteration 70: train_loss 1.3380895853042603
Iteration 71: train_loss 1.3243547677993774
Iteration 72: train_loss 1.3021578788757324
Iteration 73: train_loss 1.328503966331482
Iteration 74: train_loss 1.2502994537353516
Iteration 75: train_loss 1.272233009338379
Iteration 76: train_loss 1.2826263904571533
Iteration 77: train_loss 1.3239542245864868
Iteration 78: train_loss 1.2748334407806396
Iteration 79: train_loss 1.3262726068496704
Iteration 80: train_loss 1.3276185989379883
Iteration 81: train_loss 1.2498246431350708
Iteration 82: train_loss 1.2403407096862793
Iteration 83: train_loss 1.3403255939483643
Iteration 84: train_loss 1.3897948265075684
Iteration 85: train_loss 1.2906081676483154
Iteration 86: train_loss 1.320986032485962
Iteration 87: train_loss 1.280220627784729
Iteration 88: train_loss 1.318456768989563
Iteration 89: train_loss 1.2702566385269165
Iteration 90: train_loss 1.3315002918243408
Iteration 91: train_loss 1.3256539106369019
Iteration 92: train_loss 1.303192377090454
Iteration 93: train_loss 1.3187401294708252
Iteration 94: train_loss 1.3165260553359985
Iteration 95: train_loss 1.3176604509353638
Iteration 96: train_loss 1.2681467533111572
Iteration 97: train_loss 1.2517846822738647
Iteration 98: train_loss 1.2733350992202759
Iteration 99: train_loss 1.3337829113006592
Iteration 100: train_loss 1.3028972148895264
Iteration 101: train_loss 1.309162974357605
Iteration 102: train_loss 1.351198434829712
Iteration 103: train_loss 1.3465065956115723
Iteration 104: train_loss 1.3179898262023926
Iteration 105: train_loss 1.3397990465164185
Iteration 106: train_loss 1.295813798904419
Iteration 107: train_loss 1.286667823791504
Iteration 108: train_loss 1.3623446226119995
Iteration 109: train_loss 1.3119679689407349
Iteration 110: train_loss 1.3339143991470337
Iteration 111: train_loss 1.3531229496002197
Iteration 112: train_loss 1.3258484601974487
Iteration 113: train_loss 1.3204700946807861
Iteration 114: train_loss 1.2699379920959473
Iteration 115: train_loss 1.2924585342407227
Iteration 116: train_loss 1.346827745437622
Iteration 117: train_loss 1.367940902709961
Iteration 118: train_loss 1.3356205224990845
Iteration 119: train_loss 1.304384708404541
Iteration 120: train_loss 1.2340692281723022
Iteration 121: train_loss 1.3219619989395142
Iteration 122: train_loss 1.2839027643203735
Iteration 123: train_loss 1.287001371383667
Iteration 124: train_loss 1.3025434017181396
Iteration 125: train_loss 1.2666178941726685
Iteration 126: train_loss 1.2681406736373901
Iteration 127: train_loss 1.267596960067749
Iteration 128: train_loss 1.3300397396087646
Iteration 129: train_loss 1.3138598203659058
Iteration 130: train_loss 1.3759499788284302
Iteration 131: train_loss 1.2372941970825195
Iteration 132: train_loss 1.327465295791626
Iteration 133: train_loss 1.2946972846984863
Iteration 134: train_loss 1.4027491807937622
Iteration 135: train_loss 1.3339660167694092
Iteration 136: train_loss 1.347991943359375
Iteration 137: train_loss 1.3159533739089966
Iteration 138: train_loss 1.3612288236618042
Iteration 139: train_loss 1.3486378192901611
Iteration 140: train_loss 1.3537719249725342
Iteration 141: train_loss 1.350250244140625
Iteration 142: train_loss 1.3484289646148682
Iteration 143: train_loss 1.3289247751235962
Iteration 144: train_loss 1.3505661487579346
Iteration 145: train_loss 1.4013837575912476
Iteration 146: train_loss 1.3374478816986084
Iteration 147: train_loss 1.2786579132080078
Iteration 148: train_loss 1.3143492937088013
Iteration 149: train_loss 1.354634165763855
Iteration 150: train_loss 1.300801396369934
Iteration 151: train_loss 1.4181900024414062
Iteration 152: train_loss 1.395966649055481
Iteration 153: train_loss 1.3285093307495117
Iteration 154: train_loss 1.3298639059066772
Iteration 155: train_loss 1.2689777612686157
Iteration 156: train_loss 1.3300079107284546
Iteration 157: train_loss 1.3190028667449951
Iteration 158: train_loss 1.3550535440444946
Iteration 159: train_loss 1.316795825958252
Iteration 160: train_loss 1.3119345903396606
Iteration 161: train_loss 1.2518603801727295
Iteration 162: train_loss 1.2898061275482178
Iteration 163: train_loss 1.3123260736465454
Iteration 164: train_loss 1.299790620803833
Iteration 165: train_loss 1.285807728767395
Iteration 166: train_loss 1.309243083000183
Iteration 167: train_loss 1.2587089538574219
Iteration 168: train_loss 1.3190783262252808
Iteration 169: train_loss 1.3611088991165161
Iteration 170: train_loss 1.3094497919082642
Iteration 171: train_loss 1.3768442869186401
Iteration 172: train_loss 1.3827309608459473
Iteration 173: train_loss 1.3232817649841309
Iteration 174: train_loss 1.317583680152893
Iteration 175: train_loss 1.2859629392623901
Iteration 176: train_loss 1.3903264999389648
Iteration 177: train_loss 1.2663370370864868
Epoch 118: train_avg_loss 1.3122601657263977 eval_avg_acc: 0.34360561371462234 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:08:05] [32mIntermediate result: 0.34360561371462234  (Index 117)[0m
================Epoch: 119================
Iteration 1: train_loss 1.252983808517456
Iteration 2: train_loss 1.3299998044967651
Iteration 3: train_loss 1.3089637756347656
Iteration 4: train_loss 1.286624789237976
Iteration 5: train_loss 1.2815295457839966
Iteration 6: train_loss 1.328410267829895
Iteration 7: train_loss 1.286242127418518
Iteration 8: train_loss 1.3468067646026611
Iteration 9: train_loss 1.2804542779922485
Iteration 10: train_loss 1.300705075263977
Iteration 11: train_loss 1.2487798929214478
Iteration 12: train_loss 1.2760008573532104
Iteration 13: train_loss 1.3000729084014893
Iteration 14: train_loss 1.2745698690414429
Iteration 15: train_loss 1.2501987218856812
Iteration 16: train_loss 1.3101903200149536
Iteration 17: train_loss 1.2933270931243896
Iteration 18: train_loss 1.290082573890686
Iteration 19: train_loss 1.242033839225769
Iteration 20: train_loss 1.2357019186019897
Iteration 21: train_loss 1.2505959272384644
Iteration 22: train_loss 1.2588154077529907
Iteration 23: train_loss 1.3234683275222778
Iteration 24: train_loss 1.2600361108779907
Iteration 25: train_loss 1.257840871810913
Iteration 26: train_loss 1.277134656906128
Iteration 27: train_loss 1.2722892761230469
Iteration 28: train_loss 1.2269400358200073
Iteration 29: train_loss 1.2725579738616943
Iteration 30: train_loss 1.2480088472366333
Iteration 31: train_loss 1.2905055284500122
Iteration 32: train_loss 1.3099515438079834
Iteration 33: train_loss 1.268868088722229
Iteration 34: train_loss 1.2518755197525024
Iteration 35: train_loss 1.287231206893921
Iteration 36: train_loss 1.3202217817306519
Iteration 37: train_loss 1.2600939273834229
Iteration 38: train_loss 1.2669785022735596
Iteration 39: train_loss 1.2686433792114258
Iteration 40: train_loss 1.2460541725158691
Iteration 41: train_loss 1.2513097524642944
Iteration 42: train_loss 1.2890528440475464
Iteration 43: train_loss 1.3550654649734497
Iteration 44: train_loss 1.3188798427581787
Iteration 45: train_loss 1.2508586645126343
Iteration 46: train_loss 1.261088252067566
Iteration 47: train_loss 1.3204642534255981
Iteration 48: train_loss 1.2481410503387451
Iteration 49: train_loss 1.232418179512024
Iteration 50: train_loss 1.2788584232330322
Iteration 51: train_loss 1.255332112312317
Iteration 52: train_loss 1.2684743404388428
Iteration 53: train_loss 1.3085638284683228
Iteration 54: train_loss 1.2282483577728271
Iteration 55: train_loss 1.2844992876052856
Iteration 56: train_loss 1.2676174640655518
Iteration 57: train_loss 1.3328137397766113
Iteration 58: train_loss 1.3188124895095825
Iteration 59: train_loss 1.2737009525299072
Iteration 60: train_loss 1.295450210571289
Iteration 61: train_loss 1.2996618747711182
Iteration 62: train_loss 1.3298397064208984
Iteration 63: train_loss 1.3534618616104126
Iteration 64: train_loss 1.2790942192077637
Iteration 65: train_loss 1.2973815202713013
Iteration 66: train_loss 1.269851803779602
Iteration 67: train_loss 1.3101192712783813
Iteration 68: train_loss 1.3713128566741943
Iteration 69: train_loss 1.2872657775878906
Iteration 70: train_loss 1.3024539947509766
Iteration 71: train_loss 1.256182312965393
Iteration 72: train_loss 1.322813868522644
Iteration 73: train_loss 1.2594139575958252
Iteration 74: train_loss 1.2755695581436157
Iteration 75: train_loss 1.214104413986206
Iteration 76: train_loss 1.30218505859375
Iteration 77: train_loss 1.217057704925537
Iteration 78: train_loss 1.3114768266677856
Iteration 79: train_loss 1.2545682191848755
Iteration 80: train_loss 1.2625212669372559
Iteration 81: train_loss 1.2492908239364624
Iteration 82: train_loss 1.2724162340164185
Iteration 83: train_loss 1.2587366104125977
Iteration 84: train_loss 1.316126823425293
Iteration 85: train_loss 1.2944375276565552
Iteration 86: train_loss 1.261972188949585
Iteration 87: train_loss 1.3361181020736694
Iteration 88: train_loss 1.3093714714050293
Iteration 89: train_loss 1.2738007307052612
Iteration 90: train_loss 1.3067219257354736
Iteration 91: train_loss 1.2625826597213745
Iteration 92: train_loss 1.3030142784118652
Iteration 93: train_loss 1.2701257467269897
Iteration 94: train_loss 1.256395697593689
Iteration 95: train_loss 1.269845724105835
Iteration 96: train_loss 1.2497549057006836
Iteration 97: train_loss 1.314662218093872
Iteration 98: train_loss 1.3152364492416382
Iteration 99: train_loss 1.347085952758789
Iteration 100: train_loss 1.2775636911392212
Iteration 101: train_loss 1.342200517654419
Iteration 102: train_loss 1.291944146156311
Iteration 103: train_loss 1.3047053813934326
Iteration 104: train_loss 1.3250700235366821
Iteration 105: train_loss 1.263428807258606
Iteration 106: train_loss 1.2861526012420654
Iteration 107: train_loss 1.2925785779953003
Iteration 108: train_loss 1.3328646421432495
Iteration 109: train_loss 1.358652949333191
Iteration 110: train_loss 1.3215928077697754
Iteration 111: train_loss 1.3285521268844604
Iteration 112: train_loss 1.3355244398117065
Iteration 113: train_loss 1.3425778150558472
Iteration 114: train_loss 1.388214349746704
Iteration 115: train_loss 1.3892210721969604
Iteration 116: train_loss 1.292341709136963
Iteration 117: train_loss 1.389642357826233
Iteration 118: train_loss 1.314976453781128
Iteration 119: train_loss 1.311076045036316
Iteration 120: train_loss 1.3209913969039917
Iteration 121: train_loss 1.3518891334533691
Iteration 122: train_loss 1.3636555671691895
Iteration 123: train_loss 1.383151888847351
Iteration 124: train_loss 1.3385649919509888
Iteration 125: train_loss 1.3123681545257568
Iteration 126: train_loss 1.3351984024047852
Iteration 127: train_loss 1.3190761804580688
Iteration 128: train_loss 1.274703860282898
Iteration 129: train_loss 1.3506325483322144
Iteration 130: train_loss 1.262880802154541
Iteration 131: train_loss 1.3522205352783203
Iteration 132: train_loss 1.364025592803955
Iteration 133: train_loss 1.3315167427062988
Iteration 134: train_loss 1.2883210182189941
Iteration 135: train_loss 1.323936104774475
Iteration 136: train_loss 1.3170894384384155
Iteration 137: train_loss 1.377364993095398
Iteration 138: train_loss 1.2941303253173828
Iteration 139: train_loss 1.3654509782791138
Iteration 140: train_loss 1.3556945323944092
Iteration 141: train_loss 1.326201319694519
Iteration 142: train_loss 1.3049055337905884
Iteration 143: train_loss 1.3613420724868774
Iteration 144: train_loss 1.2634799480438232
Iteration 145: train_loss 1.2522445917129517
Iteration 146: train_loss 1.294755458831787
Iteration 147: train_loss 1.303787112236023
Iteration 148: train_loss 1.358549952507019
Iteration 149: train_loss 1.2955690622329712
Iteration 150: train_loss 1.2671986818313599
Iteration 151: train_loss 1.3371448516845703
Iteration 152: train_loss 1.3306912183761597
Iteration 153: train_loss 1.3258427381515503
Iteration 154: train_loss 1.279528021812439
Iteration 155: train_loss 1.258095622062683
Iteration 156: train_loss 1.2713264226913452
Iteration 157: train_loss 1.3223448991775513
Iteration 158: train_loss 1.36515212059021
Iteration 159: train_loss 1.3183910846710205
Iteration 160: train_loss 1.315379023551941
Iteration 161: train_loss 1.296166181564331
Iteration 162: train_loss 1.316918134689331
Iteration 163: train_loss 1.3189976215362549
Iteration 164: train_loss 1.2615076303482056
Iteration 165: train_loss 1.2700532674789429
Iteration 166: train_loss 1.3033311367034912
Iteration 167: train_loss 1.2920383214950562
Iteration 168: train_loss 1.2610629796981812
Iteration 169: train_loss 1.3043676614761353
Iteration 170: train_loss 1.2781293392181396
Iteration 171: train_loss 1.318328857421875
Iteration 172: train_loss 1.3181060552597046
Iteration 173: train_loss 1.35658860206604
Iteration 174: train_loss 1.311432957649231
Iteration 175: train_loss 1.282619833946228
Iteration 176: train_loss 1.3682068586349487
Iteration 177: train_loss 1.2272624969482422
Epoch 119: train_avg_loss 1.2979336855775219 eval_avg_acc: 0.3452831676550431 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:08:44] [32mIntermediate result: 0.3452831676550431  (Index 118)[0m
================Epoch: 120================
Iteration 1: train_loss 1.2968134880065918
Iteration 2: train_loss 1.2879754304885864
Iteration 3: train_loss 1.2542178630828857
Iteration 4: train_loss 1.3112064599990845
Iteration 5: train_loss 1.290205478668213
Iteration 6: train_loss 1.3174567222595215
Iteration 7: train_loss 1.3079575300216675
Iteration 8: train_loss 1.3525362014770508
Iteration 9: train_loss 1.3215231895446777
Iteration 10: train_loss 1.3171844482421875
Iteration 11: train_loss 1.3370589017868042
Iteration 12: train_loss 1.3179936408996582
Iteration 13: train_loss 1.276534080505371
Iteration 14: train_loss 1.340551733970642
Iteration 15: train_loss 1.3010506629943848
Iteration 16: train_loss 1.3256014585494995
Iteration 17: train_loss 1.2956100702285767
Iteration 18: train_loss 1.286929965019226
Iteration 19: train_loss 1.2815784215927124
Iteration 20: train_loss 1.2334524393081665
Iteration 21: train_loss 1.3184229135513306
Iteration 22: train_loss 1.2254209518432617
Iteration 23: train_loss 1.2945834398269653
Iteration 24: train_loss 1.29970121383667
Iteration 25: train_loss 1.2816284894943237
Iteration 26: train_loss 1.3432456254959106
Iteration 27: train_loss 1.2819080352783203
Iteration 28: train_loss 1.3047891855239868
Iteration 29: train_loss 1.332573413848877
Iteration 30: train_loss 1.2910250425338745
Iteration 31: train_loss 1.356122374534607
Iteration 32: train_loss 1.2975462675094604
Iteration 33: train_loss 1.2910778522491455
Iteration 34: train_loss 1.2696470022201538
Iteration 35: train_loss 1.3171921968460083
Iteration 36: train_loss 1.3237104415893555
Iteration 37: train_loss 1.2889788150787354
Iteration 38: train_loss 1.2624623775482178
Iteration 39: train_loss 1.3266329765319824
Iteration 40: train_loss 1.2939369678497314
Iteration 41: train_loss 1.3383690118789673
Iteration 42: train_loss 1.3055505752563477
Iteration 43: train_loss 1.3237897157669067
Iteration 44: train_loss 1.2970484495162964
Iteration 45: train_loss 1.2880510091781616
Iteration 46: train_loss 1.2814940214157104
Iteration 47: train_loss 1.3614176511764526
Iteration 48: train_loss 1.355064868927002
Iteration 49: train_loss 1.2848312854766846
Iteration 50: train_loss 1.282257318496704
Iteration 51: train_loss 1.3268167972564697
Iteration 52: train_loss 1.2837709188461304
Iteration 53: train_loss 1.3111681938171387
Iteration 54: train_loss 1.2932356595993042
Iteration 55: train_loss 1.3480324745178223
Iteration 56: train_loss 1.305090308189392
Iteration 57: train_loss 1.2772852182388306
Iteration 58: train_loss 1.3155872821807861
Iteration 59: train_loss 1.3064017295837402
Iteration 60: train_loss 1.3098727464675903
Iteration 61: train_loss 1.298388123512268
Iteration 62: train_loss 1.332335114479065
Iteration 63: train_loss 1.2958446741104126
Iteration 64: train_loss 1.301600694656372
Iteration 65: train_loss 1.283859133720398
Iteration 66: train_loss 1.268406867980957
Iteration 67: train_loss 1.3004040718078613
Iteration 68: train_loss 1.2550967931747437
Iteration 69: train_loss 1.282970666885376
Iteration 70: train_loss 1.2557207345962524
Iteration 71: train_loss 1.2935487031936646
Iteration 72: train_loss 1.2704267501831055
Iteration 73: train_loss 1.2882000207901
Iteration 74: train_loss 1.3027949333190918
Iteration 75: train_loss 1.2738460302352905
Iteration 76: train_loss 1.3467719554901123
Iteration 77: train_loss 1.2946370840072632
Iteration 78: train_loss 1.29759681224823
Iteration 79: train_loss 1.2131463289260864
Iteration 80: train_loss 1.2982192039489746
Iteration 81: train_loss 1.3249578475952148
Iteration 82: train_loss 1.341410756111145
Iteration 83: train_loss 1.2982792854309082
Iteration 84: train_loss 1.2713446617126465
Iteration 85: train_loss 1.2658864259719849
Iteration 86: train_loss 1.2743675708770752
Iteration 87: train_loss 1.2409998178482056
Iteration 88: train_loss 1.278618335723877
Iteration 89: train_loss 1.2491202354431152
Iteration 90: train_loss 1.3082027435302734
Iteration 91: train_loss 1.2482645511627197
Iteration 92: train_loss 1.2888665199279785
Iteration 93: train_loss 1.2779461145401
Iteration 94: train_loss 1.3190193176269531
Iteration 95: train_loss 1.2762876749038696
Iteration 96: train_loss 1.3044123649597168
Iteration 97: train_loss 1.322016954421997
Iteration 98: train_loss 1.2745260000228882
Iteration 99: train_loss 1.3466691970825195
Iteration 100: train_loss 1.32822847366333
Iteration 101: train_loss 1.2636007070541382
Iteration 102: train_loss 1.341076374053955
Iteration 103: train_loss 1.3337053060531616
Iteration 104: train_loss 1.3327826261520386
Iteration 105: train_loss 1.307870864868164
Iteration 106: train_loss 1.303244948387146
Iteration 107: train_loss 1.3536456823349
Iteration 108: train_loss 1.2883837223052979
Iteration 109: train_loss 1.2901054620742798
Iteration 110: train_loss 1.3672302961349487
Iteration 111: train_loss 1.3843488693237305
Iteration 112: train_loss 1.3478673696517944
Iteration 113: train_loss 1.3246982097625732
Iteration 114: train_loss 1.3150794506072998
Iteration 115: train_loss 1.3922559022903442
Iteration 116: train_loss 1.3178364038467407
Iteration 117: train_loss 1.370958685874939
Iteration 118: train_loss 1.2597633600234985
Iteration 119: train_loss 1.3185408115386963
Iteration 120: train_loss 1.372198224067688
Iteration 121: train_loss 1.2234869003295898
Iteration 122: train_loss 1.3381757736206055
Iteration 123: train_loss 1.3038573265075684
Iteration 124: train_loss 1.25849187374115
Iteration 125: train_loss 1.2976480722427368
Iteration 126: train_loss 1.3116868734359741
Iteration 127: train_loss 1.3135895729064941
Iteration 128: train_loss 1.2900714874267578
Iteration 129: train_loss 1.2404890060424805
Iteration 130: train_loss 1.3022849559783936
Iteration 131: train_loss 1.306965708732605
Iteration 132: train_loss 1.2564899921417236
Iteration 133: train_loss 1.2798659801483154
Iteration 134: train_loss 1.2875986099243164
Iteration 135: train_loss 1.256027340888977
Iteration 136: train_loss 1.278836727142334
Iteration 137: train_loss 1.257218360900879
Iteration 138: train_loss 1.3304284811019897
Iteration 139: train_loss 1.3365719318389893
Iteration 140: train_loss 1.276281714439392
Iteration 141: train_loss 1.3476059436798096
Iteration 142: train_loss 1.4214069843292236
Iteration 143: train_loss 1.3534069061279297
Iteration 144: train_loss 1.2416651248931885
Iteration 145: train_loss 1.2827067375183105
Iteration 146: train_loss 1.3315467834472656
Iteration 147: train_loss 1.3335096836090088
Iteration 148: train_loss 1.3026201725006104
Iteration 149: train_loss 1.3414641618728638
Iteration 150: train_loss 1.2882603406906128
Iteration 151: train_loss 1.2869765758514404
Iteration 152: train_loss 1.3077378273010254
Iteration 153: train_loss 1.3045215606689453
Iteration 154: train_loss 1.348193645477295
Iteration 155: train_loss 1.3262927532196045
Iteration 156: train_loss 1.3040246963500977
Iteration 157: train_loss 1.3223739862442017
Iteration 158: train_loss 1.301177740097046
Iteration 159: train_loss 1.2731785774230957
Iteration 160: train_loss 1.2970004081726074
Iteration 161: train_loss 1.3215261697769165
Iteration 162: train_loss 1.2300273180007935
Iteration 163: train_loss 1.2974094152450562
Iteration 164: train_loss 1.3243446350097656
Iteration 165: train_loss 1.3122544288635254
Iteration 166: train_loss 1.3226172924041748
Iteration 167: train_loss 1.3206123113632202
Iteration 168: train_loss 1.3052988052368164
Iteration 169: train_loss 1.3158371448516846
Iteration 170: train_loss 1.2647143602371216
Iteration 171: train_loss 1.255043625831604
Iteration 172: train_loss 1.319685459136963
Iteration 173: train_loss 1.3166147470474243
Iteration 174: train_loss 1.271310806274414
Iteration 175: train_loss 1.3795474767684937
Iteration 176: train_loss 1.3206981420516968
Iteration 177: train_loss 1.3611763715744019
Epoch 120: train_avg_loss 1.3035484047259314 eval_avg_acc: 0.34535891270248886 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:09:23] [32mIntermediate result: 0.34535891270248886  (Index 119)[0m
================Epoch: 121================
Iteration 1: train_loss 1.3516387939453125
Iteration 2: train_loss 1.2959288358688354
Iteration 3: train_loss 1.3201229572296143
Iteration 4: train_loss 1.3379229307174683
Iteration 5: train_loss 1.3841992616653442
Iteration 6: train_loss 1.3670514822006226
Iteration 7: train_loss 1.322722315788269
Iteration 8: train_loss 1.3438705205917358
Iteration 9: train_loss 1.4101253747940063
Iteration 10: train_loss 1.3137606382369995
Iteration 11: train_loss 1.3112266063690186
Iteration 12: train_loss 1.3075400590896606
Iteration 13: train_loss 1.3678805828094482
Iteration 14: train_loss 1.3331940174102783
Iteration 15: train_loss 1.338492512702942
Iteration 16: train_loss 1.3755223751068115
Iteration 17: train_loss 1.2512754201889038
Iteration 18: train_loss 1.2861251831054688
Iteration 19: train_loss 1.2952901124954224
Iteration 20: train_loss 1.3089184761047363
Iteration 21: train_loss 1.322881817817688
Iteration 22: train_loss 1.3541467189788818
Iteration 23: train_loss 1.289158821105957
Iteration 24: train_loss 1.2650976181030273
Iteration 25: train_loss 1.306363821029663
Iteration 26: train_loss 1.386974811553955
Iteration 27: train_loss 1.2777036428451538
Iteration 28: train_loss 1.2895303964614868
Iteration 29: train_loss 1.3404309749603271
Iteration 30: train_loss 1.3280245065689087
Iteration 31: train_loss 1.3337434530258179
Iteration 32: train_loss 1.2767629623413086
Iteration 33: train_loss 1.2973686456680298
Iteration 34: train_loss 1.2992005348205566
Iteration 35: train_loss 1.3040412664413452
Iteration 36: train_loss 1.2294597625732422
Iteration 37: train_loss 1.2966703176498413
Iteration 38: train_loss 1.2551876306533813
Iteration 39: train_loss 1.253326177597046
Iteration 40: train_loss 1.2634233236312866
Iteration 41: train_loss 1.3376258611679077
Iteration 42: train_loss 1.2786052227020264
Iteration 43: train_loss 1.3624516725540161
Iteration 44: train_loss 1.3316911458969116
Iteration 45: train_loss 1.3257049322128296
Iteration 46: train_loss 1.279176115989685
Iteration 47: train_loss 1.316353678703308
Iteration 48: train_loss 1.259172797203064
Iteration 49: train_loss 1.285222053527832
Iteration 50: train_loss 1.3247945308685303
Iteration 51: train_loss 1.2733014822006226
Iteration 52: train_loss 1.3294851779937744
Iteration 53: train_loss 1.3377554416656494
Iteration 54: train_loss 1.2531265020370483
Iteration 55: train_loss 1.3121930360794067
Iteration 56: train_loss 1.3030071258544922
Iteration 57: train_loss 1.2862622737884521
Iteration 58: train_loss 1.3412082195281982
Iteration 59: train_loss 1.2985711097717285
Iteration 60: train_loss 1.2833709716796875
Iteration 61: train_loss 1.3300977945327759
Iteration 62: train_loss 1.3399287462234497
Iteration 63: train_loss 1.2497345209121704
Iteration 64: train_loss 1.2706609964370728
Iteration 65: train_loss 1.3444526195526123
Iteration 66: train_loss 1.310868501663208
Iteration 67: train_loss 1.3400529623031616
Iteration 68: train_loss 1.2643386125564575
Iteration 69: train_loss 1.289068341255188
Iteration 70: train_loss 1.2479588985443115
Iteration 71: train_loss 1.2609221935272217
Iteration 72: train_loss 1.271341323852539
Iteration 73: train_loss 1.303499460220337
Iteration 74: train_loss 1.2519835233688354
Iteration 75: train_loss 1.4052863121032715
Iteration 76: train_loss 1.319709062576294
Iteration 77: train_loss 1.2894930839538574
Iteration 78: train_loss 1.3068256378173828
Iteration 79: train_loss 1.2941888570785522
Iteration 80: train_loss 1.3351815938949585
Iteration 81: train_loss 1.2671101093292236
Iteration 82: train_loss 1.284429907798767
Iteration 83: train_loss 1.3266431093215942
Iteration 84: train_loss 1.3274836540222168
Iteration 85: train_loss 1.2595939636230469
Iteration 86: train_loss 1.295168399810791
Iteration 87: train_loss 1.2847485542297363
Iteration 88: train_loss 1.3147828578948975
Iteration 89: train_loss 1.3378692865371704
Iteration 90: train_loss 1.3398569822311401
Iteration 91: train_loss 1.3468730449676514
Iteration 92: train_loss 1.3000739812850952
Iteration 93: train_loss 1.3200604915618896
Iteration 94: train_loss 1.2976598739624023
Iteration 95: train_loss 1.3677752017974854
Iteration 96: train_loss 1.362567663192749
Iteration 97: train_loss 1.3155027627944946
Iteration 98: train_loss 1.2962168455123901
Iteration 99: train_loss 1.3372405767440796
Iteration 100: train_loss 1.3135327100753784
Iteration 101: train_loss 1.3177071809768677
Iteration 102: train_loss 1.3319071531295776
Iteration 103: train_loss 1.1926991939544678
Iteration 104: train_loss 1.3013525009155273
Iteration 105: train_loss 1.3312945365905762
Iteration 106: train_loss 1.273537278175354
Iteration 107: train_loss 1.2624207735061646
Iteration 108: train_loss 1.299318552017212
Iteration 109: train_loss 1.305842399597168
Iteration 110: train_loss 1.3038640022277832
Iteration 111: train_loss 1.3269950151443481
Iteration 112: train_loss 1.2964838743209839
Iteration 113: train_loss 1.260711431503296
Iteration 114: train_loss 1.2505810260772705
Iteration 115: train_loss 1.3221673965454102
Iteration 116: train_loss 1.2743663787841797
Iteration 117: train_loss 1.3398650884628296
Iteration 118: train_loss 1.31132972240448
Iteration 119: train_loss 1.313532829284668
Iteration 120: train_loss 1.3746320009231567
Iteration 121: train_loss 1.2768676280975342
Iteration 122: train_loss 1.2690919637680054
Iteration 123: train_loss 1.2905235290527344
Iteration 124: train_loss 1.3592746257781982
Iteration 125: train_loss 1.3042194843292236
Iteration 126: train_loss 1.3379021883010864
Iteration 127: train_loss 1.305546522140503
Iteration 128: train_loss 1.3522741794586182
Iteration 129: train_loss 1.2610801458358765
Iteration 130: train_loss 1.3410930633544922
Iteration 131: train_loss 1.2806452512741089
Iteration 132: train_loss 1.3414114713668823
Iteration 133: train_loss 1.3180525302886963
Iteration 134: train_loss 1.3325881958007812
Iteration 135: train_loss 1.1988670825958252
Iteration 136: train_loss 1.2524126768112183
Iteration 137: train_loss 1.3425731658935547
Iteration 138: train_loss 1.3337538242340088
Iteration 139: train_loss 1.2690887451171875
Iteration 140: train_loss 1.3173640966415405
Iteration 141: train_loss 1.3169587850570679
Iteration 142: train_loss 1.3378762006759644
Iteration 143: train_loss 1.2215393781661987
Iteration 144: train_loss 1.2915116548538208
Iteration 145: train_loss 1.2935887575149536
Iteration 146: train_loss 1.3164259195327759
Iteration 147: train_loss 1.3440169095993042
Iteration 148: train_loss 1.3100284337997437
Iteration 149: train_loss 1.2920560836791992
Iteration 150: train_loss 1.3031864166259766
Iteration 151: train_loss 1.2425024509429932
Iteration 152: train_loss 1.253870964050293
Iteration 153: train_loss 1.3023923635482788
Iteration 154: train_loss 1.3359756469726562
Iteration 155: train_loss 1.330362319946289
Iteration 156: train_loss 1.354179859161377
Iteration 157: train_loss 1.3825405836105347
Iteration 158: train_loss 1.3641456365585327
Iteration 159: train_loss 1.3055329322814941
Iteration 160: train_loss 1.3148362636566162
Iteration 161: train_loss 1.3162730932235718
Iteration 162: train_loss 1.3136736154556274
Iteration 163: train_loss 1.3076980113983154
Iteration 164: train_loss 1.289408802986145
Iteration 165: train_loss 1.2611318826675415
Iteration 166: train_loss 1.353954792022705
Iteration 167: train_loss 1.3864386081695557
Iteration 168: train_loss 1.3026975393295288
Iteration 169: train_loss 1.2823110818862915
Iteration 170: train_loss 1.3348830938339233
Iteration 171: train_loss 1.3392754793167114
Iteration 172: train_loss 1.306536078453064
Iteration 173: train_loss 1.2961454391479492
Iteration 174: train_loss 1.33431875705719
Iteration 175: train_loss 1.4432264566421509
Iteration 176: train_loss 1.278721809387207
Iteration 177: train_loss 1.2928582429885864
Epoch 121: train_avg_loss 1.3093812829357083 eval_avg_acc: 0.332338508514062 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:10:00] [32mIntermediate result: 0.332338508514062  (Index 120)[0m
================Epoch: 122================
Iteration 1: train_loss 1.266660213470459
Iteration 2: train_loss 1.280874490737915
Iteration 3: train_loss 1.2370456457138062
Iteration 4: train_loss 1.2670789957046509
Iteration 5: train_loss 1.261173963546753
Iteration 6: train_loss 1.3269332647323608
Iteration 7: train_loss 1.3049613237380981
Iteration 8: train_loss 1.2602910995483398
Iteration 9: train_loss 1.286957025527954
Iteration 10: train_loss 1.2610198259353638
Iteration 11: train_loss 1.2759544849395752
Iteration 12: train_loss 1.3092306852340698
Iteration 13: train_loss 1.2665202617645264
Iteration 14: train_loss 1.220333456993103
Iteration 15: train_loss 1.3252800703048706
Iteration 16: train_loss 1.2398039102554321
Iteration 17: train_loss 1.1921305656433105
Iteration 18: train_loss 1.272344946861267
Iteration 19: train_loss 1.237753987312317
Iteration 20: train_loss 1.292979121208191
Iteration 21: train_loss 1.2849444150924683
Iteration 22: train_loss 1.3001962900161743
Iteration 23: train_loss 1.2580825090408325
Iteration 24: train_loss 1.264100193977356
Iteration 25: train_loss 1.3152906894683838
Iteration 26: train_loss 1.3199751377105713
Iteration 27: train_loss 1.2996219396591187
Iteration 28: train_loss 1.2507493495941162
Iteration 29: train_loss 1.2783938646316528
Iteration 30: train_loss 1.266256332397461
Iteration 31: train_loss 1.2534785270690918
Iteration 32: train_loss 1.3065874576568604
Iteration 33: train_loss 1.2565044164657593
Iteration 34: train_loss 1.2942371368408203
Iteration 35: train_loss 1.2789926528930664
Iteration 36: train_loss 1.2118412256240845
Iteration 37: train_loss 1.3045928478240967
Iteration 38: train_loss 1.2844144105911255
Iteration 39: train_loss 1.2675687074661255
Iteration 40: train_loss 1.2711416482925415
Iteration 41: train_loss 1.2307628393173218
Iteration 42: train_loss 1.290220856666565
Iteration 43: train_loss 1.2353943586349487
Iteration 44: train_loss 1.2592624425888062
Iteration 45: train_loss 1.3494150638580322
Iteration 46: train_loss 1.3139621019363403
Iteration 47: train_loss 1.3111616373062134
Iteration 48: train_loss 1.3108237981796265
Iteration 49: train_loss 1.304985523223877
Iteration 50: train_loss 1.273878812789917
Iteration 51: train_loss 1.2631354331970215
Iteration 52: train_loss 1.2645001411437988
Iteration 53: train_loss 1.2562901973724365
Iteration 54: train_loss 1.278159499168396
Iteration 55: train_loss 1.2681912183761597
Iteration 56: train_loss 1.3304859399795532
Iteration 57: train_loss 1.2843966484069824
Iteration 58: train_loss 1.322631597518921
Iteration 59: train_loss 1.265638828277588
Iteration 60: train_loss 1.2263550758361816
Iteration 61: train_loss 1.2717254161834717
Iteration 62: train_loss 1.2187488079071045
Iteration 63: train_loss 1.3278000354766846
Iteration 64: train_loss 1.2305227518081665
Iteration 65: train_loss 1.2524993419647217
Iteration 66: train_loss 1.283190131187439
Iteration 67: train_loss 1.3153178691864014
Iteration 68: train_loss 1.2681502103805542
Iteration 69: train_loss 1.2623049020767212
Iteration 70: train_loss 1.296409249305725
Iteration 71: train_loss 1.3051782846450806
Iteration 72: train_loss 1.318814992904663
Iteration 73: train_loss 1.2188048362731934
Iteration 74: train_loss 1.2247600555419922
Iteration 75: train_loss 1.3153897523880005
Iteration 76: train_loss 1.3118557929992676
Iteration 77: train_loss 1.2485090494155884
Iteration 78: train_loss 1.2033108472824097
Iteration 79: train_loss 1.3151252269744873
Iteration 80: train_loss 1.2513505220413208
Iteration 81: train_loss 1.2734836339950562
Iteration 82: train_loss 1.2865984439849854
Iteration 83: train_loss 1.2875473499298096
Iteration 84: train_loss 1.3115330934524536
Iteration 85: train_loss 1.218077301979065
Iteration 86: train_loss 1.2551381587982178
Iteration 87: train_loss 1.2524234056472778
Iteration 88: train_loss 1.306294322013855
Iteration 89: train_loss 1.239526391029358
Iteration 90: train_loss 1.2690099477767944
Iteration 91: train_loss 1.2907809019088745
Iteration 92: train_loss 1.2828388214111328
Iteration 93: train_loss 1.2603003978729248
Iteration 94: train_loss 1.29753577709198
Iteration 95: train_loss 1.326796293258667
Iteration 96: train_loss 1.3279823064804077
Iteration 97: train_loss 1.2611454725265503
Iteration 98: train_loss 1.3348886966705322
Iteration 99: train_loss 1.297346830368042
Iteration 100: train_loss 1.2667731046676636
Iteration 101: train_loss 1.2988275289535522
Iteration 102: train_loss 1.2306207418441772
Iteration 103: train_loss 1.2411890029907227
Iteration 104: train_loss 1.2880736589431763
Iteration 105: train_loss 1.2932231426239014
Iteration 106: train_loss 1.3286622762680054
Iteration 107: train_loss 1.2528761625289917
Iteration 108: train_loss 1.3267143964767456
Iteration 109: train_loss 1.3264853954315186
Iteration 110: train_loss 1.3875465393066406
Iteration 111: train_loss 1.271420955657959
Iteration 112: train_loss 1.266108512878418
Iteration 113: train_loss 1.2837427854537964
Iteration 114: train_loss 1.3185900449752808
Iteration 115: train_loss 1.3130996227264404
Iteration 116: train_loss 1.3683913946151733
Iteration 117: train_loss 1.315994143486023
Iteration 118: train_loss 1.3213558197021484
Iteration 119: train_loss 1.2923049926757812
Iteration 120: train_loss 1.3285961151123047
Iteration 121: train_loss 1.2863342761993408
Iteration 122: train_loss 1.2655375003814697
Iteration 123: train_loss 1.327751636505127
Iteration 124: train_loss 1.3041653633117676
Iteration 125: train_loss 1.3090811967849731
Iteration 126: train_loss 1.3054218292236328
Iteration 127: train_loss 1.2561140060424805
Iteration 128: train_loss 1.308978796005249
Iteration 129: train_loss 1.269545316696167
Iteration 130: train_loss 1.2510781288146973
Iteration 131: train_loss 1.3231642246246338
Iteration 132: train_loss 1.3593826293945312
Iteration 133: train_loss 1.3439151048660278
Iteration 134: train_loss 1.2858309745788574
Iteration 135: train_loss 1.328629732131958
Iteration 136: train_loss 1.3099998235702515
Iteration 137: train_loss 1.2363367080688477
Iteration 138: train_loss 1.3185908794403076
Iteration 139: train_loss 1.305825114250183
Iteration 140: train_loss 1.2368338108062744
Iteration 141: train_loss 1.314374327659607
Iteration 142: train_loss 1.3424252271652222
Iteration 143: train_loss 1.2744886875152588
Iteration 144: train_loss 1.2828415632247925
Iteration 145: train_loss 1.226929783821106
Iteration 146: train_loss 1.292944312095642
Iteration 147: train_loss 1.2547837495803833
Iteration 148: train_loss 1.2441493272781372
Iteration 149: train_loss 1.3024251461029053
Iteration 150: train_loss 1.3112776279449463
Iteration 151: train_loss 1.2538164854049683
Iteration 152: train_loss 1.2707518339157104
Iteration 153: train_loss 1.2792160511016846
Iteration 154: train_loss 1.2767293453216553
Iteration 155: train_loss 1.2778462171554565
Iteration 156: train_loss 1.283570647239685
Iteration 157: train_loss 1.3075604438781738
Iteration 158: train_loss 1.3230066299438477
Iteration 159: train_loss 1.3254852294921875
Iteration 160: train_loss 1.310010552406311
Iteration 161: train_loss 1.2837772369384766
Iteration 162: train_loss 1.293446660041809
Iteration 163: train_loss 1.3161791563034058
Iteration 164: train_loss 1.2402913570404053
Iteration 165: train_loss 1.2817491292953491
Iteration 166: train_loss 1.251600980758667
Iteration 167: train_loss 1.3266162872314453
Iteration 168: train_loss 1.3384044170379639
Iteration 169: train_loss 1.3330564498901367
Iteration 170: train_loss 1.2985785007476807
Iteration 171: train_loss 1.3153425455093384
Iteration 172: train_loss 1.2858328819274902
Iteration 173: train_loss 1.3503717184066772
Iteration 174: train_loss 1.266458511352539
Iteration 175: train_loss 1.3313783407211304
Iteration 176: train_loss 1.3285974264144897
Iteration 177: train_loss 1.291359543800354
Epoch 122: train_avg_loss 1.2856031211756043 eval_avg_acc: 0.34364637346993615 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:10:39] [32mIntermediate result: 0.34364637346993615  (Index 121)[0m
================Epoch: 123================
Iteration 1: train_loss 1.3420699834823608
Iteration 2: train_loss 1.3347047567367554
Iteration 3: train_loss 1.2897809743881226
Iteration 4: train_loss 1.262933373451233
Iteration 5: train_loss 1.3383488655090332
Iteration 6: train_loss 1.3325059413909912
Iteration 7: train_loss 1.267863154411316
Iteration 8: train_loss 1.2655905485153198
Iteration 9: train_loss 1.3083633184432983
Iteration 10: train_loss 1.3687397241592407
Iteration 11: train_loss 1.285323143005371
Iteration 12: train_loss 1.3014426231384277
Iteration 13: train_loss 1.248924970626831
Iteration 14: train_loss 1.3096799850463867
Iteration 15: train_loss 1.249893307685852
Iteration 16: train_loss 1.2511732578277588
Iteration 17: train_loss 1.303814172744751
Iteration 18: train_loss 1.212162733078003
Iteration 19: train_loss 1.274389386177063
Iteration 20: train_loss 1.300675868988037
Iteration 21: train_loss 1.340811014175415
Iteration 22: train_loss 1.240293025970459
Iteration 23: train_loss 1.343151569366455
Iteration 24: train_loss 1.2615740299224854
Iteration 25: train_loss 1.3452733755111694
Iteration 26: train_loss 1.2515463829040527
Iteration 27: train_loss 1.1821314096450806
Iteration 28: train_loss 1.2664430141448975
Iteration 29: train_loss 1.2862085103988647
Iteration 30: train_loss 1.2729451656341553
Iteration 31: train_loss 1.2950838804244995
Iteration 32: train_loss 1.2623677253723145
Iteration 33: train_loss 1.2775505781173706
Iteration 34: train_loss 1.2603154182434082
Iteration 35: train_loss 1.268325686454773
Iteration 36: train_loss 1.242586612701416
Iteration 37: train_loss 1.2805216312408447
Iteration 38: train_loss 1.2435716390609741
Iteration 39: train_loss 1.2385897636413574
Iteration 40: train_loss 1.2733105421066284
Iteration 41: train_loss 1.2990232706069946
Iteration 42: train_loss 1.2846910953521729
Iteration 43: train_loss 1.293124794960022
Iteration 44: train_loss 1.2376965284347534
Iteration 45: train_loss 1.297433853149414
Iteration 46: train_loss 1.2683757543563843
Iteration 47: train_loss 1.3177679777145386
Iteration 48: train_loss 1.265825867652893
Iteration 49: train_loss 1.3270840644836426
Iteration 50: train_loss 1.2310069799423218
Iteration 51: train_loss 1.2207581996917725
Iteration 52: train_loss 1.2454828023910522
Iteration 53: train_loss 1.2504832744598389
Iteration 54: train_loss 1.265388011932373
Iteration 55: train_loss 1.270043134689331
Iteration 56: train_loss 1.3212463855743408
Iteration 57: train_loss 1.257753610610962
Iteration 58: train_loss 1.2935222387313843
Iteration 59: train_loss 1.262428641319275
Iteration 60: train_loss 1.292433738708496
Iteration 61: train_loss 1.2197695970535278
Iteration 62: train_loss 1.254341721534729
Iteration 63: train_loss 1.1674375534057617
Iteration 64: train_loss 1.2689167261123657
Iteration 65: train_loss 1.2263209819793701
Iteration 66: train_loss 1.2076690196990967
Iteration 67: train_loss 1.2894189357757568
Iteration 68: train_loss 1.2027239799499512
Iteration 69: train_loss 1.237246036529541
Iteration 70: train_loss 1.2649775743484497
Iteration 71: train_loss 1.3277673721313477
Iteration 72: train_loss 1.261837363243103
Iteration 73: train_loss 1.2598248720169067
Iteration 74: train_loss 1.2854201793670654
Iteration 75: train_loss 1.2614073753356934
Iteration 76: train_loss 1.319658875465393
Iteration 77: train_loss 1.2957342863082886
Iteration 78: train_loss 1.3060402870178223
Iteration 79: train_loss 1.3257596492767334
Iteration 80: train_loss 1.2582314014434814
Iteration 81: train_loss 1.280882477760315
Iteration 82: train_loss 1.3182493448257446
Iteration 83: train_loss 1.278609275817871
Iteration 84: train_loss 1.2579693794250488
Iteration 85: train_loss 1.2787796258926392
Iteration 86: train_loss 1.2683416604995728
Iteration 87: train_loss 1.3327420949935913
Iteration 88: train_loss 1.2655885219573975
Iteration 89: train_loss 1.2932336330413818
Iteration 90: train_loss 1.2771178483963013
Iteration 91: train_loss 1.255767583847046
Iteration 92: train_loss 1.2796680927276611
Iteration 93: train_loss 1.284056305885315
Iteration 94: train_loss 1.201695442199707
Iteration 95: train_loss 1.3190969228744507
Iteration 96: train_loss 1.2965691089630127
Iteration 97: train_loss 1.321465015411377
Iteration 98: train_loss 1.2989506721496582
Iteration 99: train_loss 1.338403344154358
Iteration 100: train_loss 1.3066519498825073
Iteration 101: train_loss 1.3043129444122314
Iteration 102: train_loss 1.279012680053711
Iteration 103: train_loss 1.2970378398895264
Iteration 104: train_loss 1.3382707834243774
Iteration 105: train_loss 1.2951451539993286
Iteration 106: train_loss 1.287729024887085
Iteration 107: train_loss 1.3196301460266113
Iteration 108: train_loss 1.2767069339752197
Iteration 109: train_loss 1.3077114820480347
Iteration 110: train_loss 1.3125885725021362
Iteration 111: train_loss 1.3648942708969116
Iteration 112: train_loss 1.2455312013626099
Iteration 113: train_loss 1.3000203371047974
Iteration 114: train_loss 1.307987928390503
Iteration 115: train_loss 1.301847219467163
Iteration 116: train_loss 1.341627597808838
Iteration 117: train_loss 1.2477142810821533
Iteration 118: train_loss 1.323753833770752
Iteration 119: train_loss 1.3720922470092773
Iteration 120: train_loss 1.3095085620880127
Iteration 121: train_loss 1.3732578754425049
Iteration 122: train_loss 1.3282700777053833
Iteration 123: train_loss 1.3968802690505981
Iteration 124: train_loss 1.3097189664840698
Iteration 125: train_loss 1.286194920539856
Iteration 126: train_loss 1.2943034172058105
Iteration 127: train_loss 1.2997043132781982
Iteration 128: train_loss 1.2210952043533325
Iteration 129: train_loss 1.283258318901062
Iteration 130: train_loss 1.3183363676071167
Iteration 131: train_loss 1.2778565883636475
Iteration 132: train_loss 1.278328537940979
Iteration 133: train_loss 1.3081715106964111
Iteration 134: train_loss 1.26134192943573
Iteration 135: train_loss 1.2687480449676514
Iteration 136: train_loss 1.264494776725769
Iteration 137: train_loss 1.3617312908172607
Iteration 138: train_loss 1.3200496435165405
Iteration 139: train_loss 1.327849268913269
Iteration 140: train_loss 1.2922190427780151
Iteration 141: train_loss 1.3121129274368286
Iteration 142: train_loss 1.2910925149917603
Iteration 143: train_loss 1.329372525215149
Iteration 144: train_loss 1.362170934677124
Iteration 145: train_loss 1.3621474504470825
Iteration 146: train_loss 1.3361310958862305
Iteration 147: train_loss 1.297262191772461
Iteration 148: train_loss 1.2752952575683594
Iteration 149: train_loss 1.3096891641616821
Iteration 150: train_loss 1.3507442474365234
Iteration 151: train_loss 1.325695276260376
Iteration 152: train_loss 1.2600147724151611
Iteration 153: train_loss 1.3341221809387207
Iteration 154: train_loss 1.2898255586624146
Iteration 155: train_loss 1.3202087879180908
Iteration 156: train_loss 1.2487256526947021
Iteration 157: train_loss 1.346086859703064
Iteration 158: train_loss 1.3357170820236206
Iteration 159: train_loss 1.309739351272583
Iteration 160: train_loss 1.2494126558303833
Iteration 161: train_loss 1.3206634521484375
Iteration 162: train_loss 1.2479290962219238
Iteration 163: train_loss 1.288145899772644
Iteration 164: train_loss 1.282263994216919
Iteration 165: train_loss 1.2697827816009521
Iteration 166: train_loss 1.250328540802002
Iteration 167: train_loss 1.2885305881500244
Iteration 168: train_loss 1.350767731666565
Iteration 169: train_loss 1.2935608625411987
Iteration 170: train_loss 1.3324124813079834
Iteration 171: train_loss 1.324399471282959
Iteration 172: train_loss 1.3050649166107178
Iteration 173: train_loss 1.3202451467514038
Iteration 174: train_loss 1.2527409791946411
Iteration 175: train_loss 1.3288577795028687
Iteration 176: train_loss 1.2789560556411743
Iteration 177: train_loss 1.3636857271194458
Epoch 123: train_avg_loss 1.2899758687800607 eval_avg_acc: 0.33282769864373957 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:11:18] [32mIntermediate result: 0.33282769864373957  (Index 122)[0m
================Epoch: 124================
Iteration 1: train_loss 1.247216820716858
Iteration 2: train_loss 1.2683937549591064
Iteration 3: train_loss 1.3093458414077759
Iteration 4: train_loss 1.1997828483581543
Iteration 5: train_loss 1.2560030221939087
Iteration 6: train_loss 1.2501540184020996
Iteration 7: train_loss 1.2819061279296875
Iteration 8: train_loss 1.2809522151947021
Iteration 9: train_loss 1.2118403911590576
Iteration 10: train_loss 1.2787866592407227
Iteration 11: train_loss 1.2398626804351807
Iteration 12: train_loss 1.290541648864746
Iteration 13: train_loss 1.2708135843276978
Iteration 14: train_loss 1.2706656455993652
Iteration 15: train_loss 1.2965949773788452
Iteration 16: train_loss 1.250165581703186
Iteration 17: train_loss 1.2318694591522217
Iteration 18: train_loss 1.2356635332107544
Iteration 19: train_loss 1.3062208890914917
Iteration 20: train_loss 1.2288024425506592
Iteration 21: train_loss 1.2525995969772339
Iteration 22: train_loss 1.2468836307525635
Iteration 23: train_loss 1.3289912939071655
Iteration 24: train_loss 1.2135486602783203
Iteration 25: train_loss 1.2230870723724365
Iteration 26: train_loss 1.1871485710144043
Iteration 27: train_loss 1.260084867477417
Iteration 28: train_loss 1.267019271850586
Iteration 29: train_loss 1.2824311256408691
Iteration 30: train_loss 1.2742522954940796
Iteration 31: train_loss 1.3084689378738403
Iteration 32: train_loss 1.2774592638015747
Iteration 33: train_loss 1.2731330394744873
Iteration 34: train_loss 1.3083751201629639
Iteration 35: train_loss 1.2552865743637085
Iteration 36: train_loss 1.282489538192749
Iteration 37: train_loss 1.218106985092163
Iteration 38: train_loss 1.3068053722381592
Iteration 39: train_loss 1.264950156211853
Iteration 40: train_loss 1.3282431364059448
Iteration 41: train_loss 1.307729721069336
Iteration 42: train_loss 1.2824350595474243
Iteration 43: train_loss 1.3184895515441895
Iteration 44: train_loss 1.2442620992660522
Iteration 45: train_loss 1.3194959163665771
Iteration 46: train_loss 1.3178927898406982
Iteration 47: train_loss 1.2576003074645996
Iteration 48: train_loss 1.2643240690231323
Iteration 49: train_loss 1.3267749547958374
Iteration 50: train_loss 1.2850754261016846
Iteration 51: train_loss 1.2791932821273804
Iteration 52: train_loss 1.3135217428207397
Iteration 53: train_loss 1.351135015487671
Iteration 54: train_loss 1.2849197387695312
Iteration 55: train_loss 1.3132452964782715
Iteration 56: train_loss 1.2978243827819824
Iteration 57: train_loss 1.3397419452667236
Iteration 58: train_loss 1.3073623180389404
Iteration 59: train_loss 1.271423101425171
Iteration 60: train_loss 1.3514533042907715
Iteration 61: train_loss 1.3747049570083618
Iteration 62: train_loss 1.3425185680389404
Iteration 63: train_loss 1.333237886428833
Iteration 64: train_loss 1.3227776288986206
Iteration 65: train_loss 1.33536958694458
Iteration 66: train_loss 1.2147226333618164
Iteration 67: train_loss 1.3472908735275269
Iteration 68: train_loss 1.2991234064102173
Iteration 69: train_loss 1.3275136947631836
Iteration 70: train_loss 1.3286128044128418
Iteration 71: train_loss 1.2847967147827148
Iteration 72: train_loss 1.2889106273651123
Iteration 73: train_loss 1.3038427829742432
Iteration 74: train_loss 1.3011581897735596
Iteration 75: train_loss 1.2831181287765503
Iteration 76: train_loss 1.2128639221191406
Iteration 77: train_loss 1.2148188352584839
Iteration 78: train_loss 1.2644383907318115
Iteration 79: train_loss 1.2686902284622192
Iteration 80: train_loss 1.2500871419906616
Iteration 81: train_loss 1.2450082302093506
Iteration 82: train_loss 1.2962907552719116
Iteration 83: train_loss 1.2329065799713135
Iteration 84: train_loss 1.2799497842788696
Iteration 85: train_loss 1.2770076990127563
Iteration 86: train_loss 1.3033483028411865
Iteration 87: train_loss 1.2898805141448975
Iteration 88: train_loss 1.3073809146881104
Iteration 89: train_loss 1.354177474975586
Iteration 90: train_loss 1.2894285917282104
Iteration 91: train_loss 1.3084615468978882
Iteration 92: train_loss 1.2517770528793335
Iteration 93: train_loss 1.2820006608963013
Iteration 94: train_loss 1.3074073791503906
Iteration 95: train_loss 1.3359718322753906
Iteration 96: train_loss 1.3553658723831177
Iteration 97: train_loss 1.3068751096725464
Iteration 98: train_loss 1.322591781616211
Iteration 99: train_loss 1.3360854387283325
Iteration 100: train_loss 1.3031619787216187
Iteration 101: train_loss 1.2574580907821655
Iteration 102: train_loss 1.2762513160705566
Iteration 103: train_loss 1.3789526224136353
Iteration 104: train_loss 1.28009033203125
Iteration 105: train_loss 1.2855082750320435
Iteration 106: train_loss 1.2596436738967896
Iteration 107: train_loss 1.3268083333969116
Iteration 108: train_loss 1.2717316150665283
Iteration 109: train_loss 1.2619198560714722
Iteration 110: train_loss 1.287497639656067
Iteration 111: train_loss 1.2350940704345703
Iteration 112: train_loss 1.3397899866104126
Iteration 113: train_loss 1.2722399234771729
Iteration 114: train_loss 1.298071026802063
Iteration 115: train_loss 1.3278651237487793
Iteration 116: train_loss 1.2609270811080933
Iteration 117: train_loss 1.3098183870315552
Iteration 118: train_loss 1.2746599912643433
Iteration 119: train_loss 1.3190079927444458
Iteration 120: train_loss 1.3329334259033203
Iteration 121: train_loss 1.297189474105835
Iteration 122: train_loss 1.2743688821792603
Iteration 123: train_loss 1.292117953300476
Iteration 124: train_loss 1.3134686946868896
Iteration 125: train_loss 1.2849392890930176
Iteration 126: train_loss 1.2825770378112793
Iteration 127: train_loss 1.283126950263977
Iteration 128: train_loss 1.2890008687973022
Iteration 129: train_loss 1.321489691734314
Iteration 130: train_loss 1.2584515810012817
Iteration 131: train_loss 1.3374465703964233
Iteration 132: train_loss 1.2412469387054443
Iteration 133: train_loss 1.3446766138076782
Iteration 134: train_loss 1.3001303672790527
Iteration 135: train_loss 1.2788186073303223
Iteration 136: train_loss 1.3135114908218384
Iteration 137: train_loss 1.2983521223068237
Iteration 138: train_loss 1.2765527963638306
Iteration 139: train_loss 1.3730676174163818
Iteration 140: train_loss 1.3091378211975098
Iteration 141: train_loss 1.3244774341583252
Iteration 142: train_loss 1.2990472316741943
Iteration 143: train_loss 1.3608964681625366
Iteration 144: train_loss 1.3069612979888916
Iteration 145: train_loss 1.3665568828582764
Iteration 146: train_loss 1.386315941810608
Iteration 147: train_loss 1.36260187625885
Iteration 148: train_loss 1.3387365341186523
Iteration 149: train_loss 1.4087861776351929
Iteration 150: train_loss 1.331874132156372
Iteration 151: train_loss 1.3318748474121094
Iteration 152: train_loss 1.3244502544403076
Iteration 153: train_loss 1.3078556060791016
Iteration 154: train_loss 1.377245545387268
Iteration 155: train_loss 1.336747169494629
Iteration 156: train_loss 1.3474106788635254
Iteration 157: train_loss 1.3142493963241577
Iteration 158: train_loss 1.3803582191467285
Iteration 159: train_loss 1.3528746366500854
Iteration 160: train_loss 1.3099682331085205
Iteration 161: train_loss 1.3843308687210083
Iteration 162: train_loss 1.3171528577804565
Iteration 163: train_loss 1.3489104509353638
Iteration 164: train_loss 1.2447537183761597
Iteration 165: train_loss 1.3475537300109863
Iteration 166: train_loss 1.316567063331604
Iteration 167: train_loss 1.2889184951782227
Iteration 168: train_loss 1.2744252681732178
Iteration 169: train_loss 1.2682818174362183
Iteration 170: train_loss 1.2820065021514893
Iteration 171: train_loss 1.306522011756897
Iteration 172: train_loss 1.2684577703475952
Iteration 173: train_loss 1.2992634773254395
Iteration 174: train_loss 1.2846622467041016
Iteration 175: train_loss 1.3560041189193726
Iteration 176: train_loss 1.3534945249557495
Iteration 177: train_loss 1.2980172634124756
Epoch 124: train_avg_loss 1.2961416500436385 eval_avg_acc: 0.3454153851099675 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:11:56] [32mIntermediate result: 0.3454153851099675  (Index 123)[0m
================Epoch: 125================
Iteration 1: train_loss 1.3046396970748901
Iteration 2: train_loss 1.256731390953064
Iteration 3: train_loss 1.2673301696777344
Iteration 4: train_loss 1.2766128778457642
Iteration 5: train_loss 1.25246000289917
Iteration 6: train_loss 1.2320950031280518
Iteration 7: train_loss 1.261314034461975
Iteration 8: train_loss 1.2882832288742065
Iteration 9: train_loss 1.2752161026000977
Iteration 10: train_loss 1.2572319507598877
Iteration 11: train_loss 1.2891675233840942
Iteration 12: train_loss 1.2212167978286743
Iteration 13: train_loss 1.2647713422775269
Iteration 14: train_loss 1.2670210599899292
Iteration 15: train_loss 1.259855031967163
Iteration 16: train_loss 1.2724840641021729
Iteration 17: train_loss 1.310779094696045
Iteration 18: train_loss 1.2500725984573364
Iteration 19: train_loss 1.2266486883163452
Iteration 20: train_loss 1.2749059200286865
Iteration 21: train_loss 1.267727017402649
Iteration 22: train_loss 1.260497808456421
Iteration 23: train_loss 1.3020480871200562
Iteration 24: train_loss 1.2531343698501587
Iteration 25: train_loss 1.2557207345962524
Iteration 26: train_loss 1.2671771049499512
Iteration 27: train_loss 1.3005578517913818
Iteration 28: train_loss 1.209744930267334
Iteration 29: train_loss 1.2737913131713867
Iteration 30: train_loss 1.2731642723083496
Iteration 31: train_loss 1.262679934501648
Iteration 32: train_loss 1.2854434251785278
Iteration 33: train_loss 1.2684251070022583
Iteration 34: train_loss 1.2584744691848755
Iteration 35: train_loss 1.2738007307052612
Iteration 36: train_loss 1.2568057775497437
Iteration 37: train_loss 1.2633845806121826
Iteration 38: train_loss 1.225094199180603
Iteration 39: train_loss 1.27104914188385
Iteration 40: train_loss 1.2925465106964111
Iteration 41: train_loss 1.2835261821746826
Iteration 42: train_loss 1.2556525468826294
Iteration 43: train_loss 1.1694605350494385
Iteration 44: train_loss 1.296200156211853
Iteration 45: train_loss 1.324520230293274
Iteration 46: train_loss 1.2607760429382324
Iteration 47: train_loss 1.2799710035324097
Iteration 48: train_loss 1.2566709518432617
Iteration 49: train_loss 1.2744295597076416
Iteration 50: train_loss 1.2671008110046387
Iteration 51: train_loss 1.2559690475463867
Iteration 52: train_loss 1.2574208974838257
Iteration 53: train_loss 1.273348331451416
Iteration 54: train_loss 1.3191015720367432
Iteration 55: train_loss 1.2815868854522705
Iteration 56: train_loss 1.3378797769546509
Iteration 57: train_loss 1.3408308029174805
Iteration 58: train_loss 1.3136533498764038
Iteration 59: train_loss 1.306291937828064
Iteration 60: train_loss 1.2506897449493408
Iteration 61: train_loss 1.2831437587738037
Iteration 62: train_loss 1.317847490310669
Iteration 63: train_loss 1.2600950002670288
Iteration 64: train_loss 1.302140474319458
Iteration 65: train_loss 1.336073398590088
Iteration 66: train_loss 1.2786239385604858
Iteration 67: train_loss 1.2605116367340088
Iteration 68: train_loss 1.2529287338256836
Iteration 69: train_loss 1.3070814609527588
Iteration 70: train_loss 1.3292723894119263
Iteration 71: train_loss 1.1931440830230713
Iteration 72: train_loss 1.3511563539505005
Iteration 73: train_loss 1.2669304609298706
Iteration 74: train_loss 1.3139429092407227
Iteration 75: train_loss 1.3282665014266968
Iteration 76: train_loss 1.284803032875061
Iteration 77: train_loss 1.318526029586792
Iteration 78: train_loss 1.2630990743637085
Iteration 79: train_loss 1.2618674039840698
Iteration 80: train_loss 1.2439042329788208
Iteration 81: train_loss 1.265573501586914
Iteration 82: train_loss 1.2324661016464233
Iteration 83: train_loss 1.323424220085144
Iteration 84: train_loss 1.2727850675582886
Iteration 85: train_loss 1.247974157333374
Iteration 86: train_loss 1.2763996124267578
Iteration 87: train_loss 1.3536838293075562
Iteration 88: train_loss 1.2862299680709839
Iteration 89: train_loss 1.2803043127059937
Iteration 90: train_loss 1.254847526550293
Iteration 91: train_loss 1.3326404094696045
Iteration 92: train_loss 1.2686457633972168
Iteration 93: train_loss 1.3345357179641724
Iteration 94: train_loss 1.3297197818756104
Iteration 95: train_loss 1.3211580514907837
Iteration 96: train_loss 1.301925539970398
Iteration 97: train_loss 1.2573093175888062
Iteration 98: train_loss 1.2870497703552246
Iteration 99: train_loss 1.293880820274353
Iteration 100: train_loss 1.2767150402069092
Iteration 101: train_loss 1.3029781579971313
Iteration 102: train_loss 1.2818809747695923
Iteration 103: train_loss 1.268412709236145
Iteration 104: train_loss 1.295885682106018
Iteration 105: train_loss 1.275484323501587
Iteration 106: train_loss 1.2591758966445923
Iteration 107: train_loss 1.2693438529968262
Iteration 108: train_loss 1.2364953756332397
Iteration 109: train_loss 1.3269342184066772
Iteration 110: train_loss 1.3058981895446777
Iteration 111: train_loss 1.2892361879348755
Iteration 112: train_loss 1.3324196338653564
Iteration 113: train_loss 1.3050274848937988
Iteration 114: train_loss 1.2468163967132568
Iteration 115: train_loss 1.3383864164352417
Iteration 116: train_loss 1.273347020149231
Iteration 117: train_loss 1.3054295778274536
Iteration 118: train_loss 1.3017939329147339
Iteration 119: train_loss 1.2757673263549805
Iteration 120: train_loss 1.2913192510604858
Iteration 121: train_loss 1.2848254442214966
Iteration 122: train_loss 1.2515357732772827
Iteration 123: train_loss 1.2450934648513794
Iteration 124: train_loss 1.2869768142700195
Iteration 125: train_loss 1.3063380718231201
Iteration 126: train_loss 1.3253194093704224
Iteration 127: train_loss 1.2258036136627197
Iteration 128: train_loss 1.3114827871322632
Iteration 129: train_loss 1.2512552738189697
Iteration 130: train_loss 1.258098840713501
Iteration 131: train_loss 1.260154128074646
Iteration 132: train_loss 1.2272744178771973
Iteration 133: train_loss 1.2397979497909546
Iteration 134: train_loss 1.3076249361038208
Iteration 135: train_loss 1.2760462760925293
Iteration 136: train_loss 1.2696704864501953
Iteration 137: train_loss 1.3282543420791626
Iteration 138: train_loss 1.328670859336853
Iteration 139: train_loss 1.2668734788894653
Iteration 140: train_loss 1.3094477653503418
Iteration 141: train_loss 1.3171948194503784
Iteration 142: train_loss 1.39925217628479
Iteration 143: train_loss 1.2847496271133423
Iteration 144: train_loss 1.3201135396957397
Iteration 145: train_loss 1.3269788026809692
Iteration 146: train_loss 1.2507251501083374
Iteration 147: train_loss 1.3200902938842773
Iteration 148: train_loss 1.2597002983093262
Iteration 149: train_loss 1.2365468740463257
Iteration 150: train_loss 1.2835410833358765
Iteration 151: train_loss 1.321154236793518
Iteration 152: train_loss 1.287091851234436
Iteration 153: train_loss 1.2843010425567627
Iteration 154: train_loss 1.2764995098114014
Iteration 155: train_loss 1.269879698753357
Iteration 156: train_loss 1.2859047651290894
Iteration 157: train_loss 1.319352626800537
Iteration 158: train_loss 1.2677634954452515
Iteration 159: train_loss 1.2570453882217407
Iteration 160: train_loss 1.269836664199829
Iteration 161: train_loss 1.294018268585205
Iteration 162: train_loss 1.2739834785461426
Iteration 163: train_loss 1.26835298538208
Iteration 164: train_loss 1.281457543373108
Iteration 165: train_loss 1.2823618650436401
Iteration 166: train_loss 1.2912300825119019
Iteration 167: train_loss 1.330897569656372
Iteration 168: train_loss 1.2832562923431396
Iteration 169: train_loss 1.2250754833221436
Iteration 170: train_loss 1.2782464027404785
Iteration 171: train_loss 1.3294719457626343
Iteration 172: train_loss 1.2881673574447632
Iteration 173: train_loss 1.2923052310943604
Iteration 174: train_loss 1.2944459915161133
Iteration 175: train_loss 1.3549001216888428
Iteration 176: train_loss 1.2878857851028442
Iteration 177: train_loss 1.2939118146896362
Epoch 125: train_avg_loss 1.2820117406252414 eval_avg_acc: 0.34635791378479763 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:12:34] [32mIntermediate result: 0.34635791378479763  (Index 124)[0m
================Epoch: 126================
Iteration 1: train_loss 1.2258785963058472
Iteration 2: train_loss 1.2505745887756348
Iteration 3: train_loss 1.2740538120269775
Iteration 4: train_loss 1.2566148042678833
Iteration 5: train_loss 1.2637102603912354
Iteration 6: train_loss 1.2465002536773682
Iteration 7: train_loss 1.3194535970687866
Iteration 8: train_loss 1.2307144403457642
Iteration 9: train_loss 1.2782801389694214
Iteration 10: train_loss 1.1868462562561035
Iteration 11: train_loss 1.2117564678192139
Iteration 12: train_loss 1.2517504692077637
Iteration 13: train_loss 1.280722737312317
Iteration 14: train_loss 1.2819124460220337
Iteration 15: train_loss 1.2842888832092285
Iteration 16: train_loss 1.2882269620895386
Iteration 17: train_loss 1.3013159036636353
Iteration 18: train_loss 1.2722229957580566
Iteration 19: train_loss 1.2527271509170532
Iteration 20: train_loss 1.3104064464569092
Iteration 21: train_loss 1.209755539894104
Iteration 22: train_loss 1.208600640296936
Iteration 23: train_loss 1.3478492498397827
Iteration 24: train_loss 1.2477799654006958
Iteration 25: train_loss 1.238122582435608
Iteration 26: train_loss 1.2647271156311035
Iteration 27: train_loss 1.2125811576843262
Iteration 28: train_loss 1.2524328231811523
Iteration 29: train_loss 1.202282190322876
Iteration 30: train_loss 1.2154715061187744
Iteration 31: train_loss 1.1850125789642334
Iteration 32: train_loss 1.2590713500976562
Iteration 33: train_loss 1.2714767456054688
Iteration 34: train_loss 1.2387148141860962
Iteration 35: train_loss 1.2759497165679932
Iteration 36: train_loss 1.2402939796447754
Iteration 37: train_loss 1.3050154447555542
Iteration 38: train_loss 1.283233404159546
Iteration 39: train_loss 1.2289254665374756
Iteration 40: train_loss 1.2641814947128296
Iteration 41: train_loss 1.2431622743606567
Iteration 42: train_loss 1.33008873462677
Iteration 43: train_loss 1.2537813186645508
Iteration 44: train_loss 1.2389874458312988
Iteration 45: train_loss 1.227994680404663
Iteration 46: train_loss 1.249685287475586
Iteration 47: train_loss 1.2943023443222046
Iteration 48: train_loss 1.2323981523513794
Iteration 49: train_loss 1.2644686698913574
Iteration 50: train_loss 1.2269208431243896
Iteration 51: train_loss 1.2518491744995117
Iteration 52: train_loss 1.2695612907409668
Iteration 53: train_loss 1.306040644645691
Iteration 54: train_loss 1.2362998723983765
Iteration 55: train_loss 1.3103336095809937
Iteration 56: train_loss 1.2276935577392578
Iteration 57: train_loss 1.3016711473464966
Iteration 58: train_loss 1.2950353622436523
Iteration 59: train_loss 1.314117193222046
Iteration 60: train_loss 1.2199623584747314
Iteration 61: train_loss 1.245835781097412
Iteration 62: train_loss 1.2940924167633057
Iteration 63: train_loss 1.238342523574829
Iteration 64: train_loss 1.293238878250122
Iteration 65: train_loss 1.3101580142974854
Iteration 66: train_loss 1.2194335460662842
Iteration 67: train_loss 1.237839698791504
Iteration 68: train_loss 1.23166823387146
Iteration 69: train_loss 1.3129448890686035
Iteration 70: train_loss 1.3185827732086182
Iteration 71: train_loss 1.2626585960388184
Iteration 72: train_loss 1.2757236957550049
Iteration 73: train_loss 1.2981244325637817
Iteration 74: train_loss 1.3130794763565063
Iteration 75: train_loss 1.4323607683181763
Iteration 76: train_loss 1.381539225578308
Iteration 77: train_loss 1.2387973070144653
Iteration 78: train_loss 1.3409807682037354
Iteration 79: train_loss 1.3251169919967651
Iteration 80: train_loss 1.2604763507843018
Iteration 81: train_loss 1.3351435661315918
Iteration 82: train_loss 1.279190182685852
Iteration 83: train_loss 1.3185153007507324
Iteration 84: train_loss 1.3304436206817627
Iteration 85: train_loss 1.2721076011657715
Iteration 86: train_loss 1.2861915826797485
Iteration 87: train_loss 1.2599862813949585
Iteration 88: train_loss 1.299856185913086
Iteration 89: train_loss 1.3246406316757202
Iteration 90: train_loss 1.2630541324615479
Iteration 91: train_loss 1.3317886590957642
Iteration 92: train_loss 1.2631945610046387
Iteration 93: train_loss 1.3322302103042603
Iteration 94: train_loss 1.3258333206176758
Iteration 95: train_loss 1.252350926399231
Iteration 96: train_loss 1.269956350326538
Iteration 97: train_loss 1.2173372507095337
Iteration 98: train_loss 1.3218234777450562
Iteration 99: train_loss 1.3178631067276
Iteration 100: train_loss 1.3141505718231201
Iteration 101: train_loss 1.2773562669754028
Iteration 102: train_loss 1.2671152353286743
Iteration 103: train_loss 1.287277102470398
Iteration 104: train_loss 1.301574945449829
Iteration 105: train_loss 1.2493571043014526
Iteration 106: train_loss 1.2263765335083008
Iteration 107: train_loss 1.2501413822174072
Iteration 108: train_loss 1.2802382707595825
Iteration 109: train_loss 1.3351826667785645
Iteration 110: train_loss 1.2967376708984375
Iteration 111: train_loss 1.2537935972213745
Iteration 112: train_loss 1.2731541395187378
Iteration 113: train_loss 1.3032779693603516
Iteration 114: train_loss 1.2989157438278198
Iteration 115: train_loss 1.3682726621627808
Iteration 116: train_loss 1.3111225366592407
Iteration 117: train_loss 1.2718133926391602
Iteration 118: train_loss 1.2470935583114624
Iteration 119: train_loss 1.2962689399719238
Iteration 120: train_loss 1.2969480752944946
Iteration 121: train_loss 1.3569488525390625
Iteration 122: train_loss 1.3040785789489746
Iteration 123: train_loss 1.2629989385604858
Iteration 124: train_loss 1.2455207109451294
Iteration 125: train_loss 1.250455617904663
Iteration 126: train_loss 1.286568284034729
Iteration 127: train_loss 1.2704578638076782
Iteration 128: train_loss 1.2508344650268555
Iteration 129: train_loss 1.3007700443267822
Iteration 130: train_loss 1.2714464664459229
Iteration 131: train_loss 1.2062007188796997
Iteration 132: train_loss 1.2478535175323486
Iteration 133: train_loss 1.2705329656600952
Iteration 134: train_loss 1.2701175212860107
Iteration 135: train_loss 1.2985543012619019
Iteration 136: train_loss 1.1728167533874512
Iteration 137: train_loss 1.2984931468963623
Iteration 138: train_loss 1.258784294128418
Iteration 139: train_loss 1.2696164846420288
Iteration 140: train_loss 1.3216667175292969
Iteration 141: train_loss 1.2215840816497803
Iteration 142: train_loss 1.2821698188781738
Iteration 143: train_loss 1.2932652235031128
Iteration 144: train_loss 1.269473671913147
Iteration 145: train_loss 1.299214243888855
Iteration 146: train_loss 1.280164122581482
Iteration 147: train_loss 1.2956370115280151
Iteration 148: train_loss 1.2877756357192993
Iteration 149: train_loss 1.293555498123169
Iteration 150: train_loss 1.2444262504577637
Iteration 151: train_loss 1.336279273033142
Iteration 152: train_loss 1.291157603263855
Iteration 153: train_loss 1.2344777584075928
Iteration 154: train_loss 1.2695337533950806
Iteration 155: train_loss 1.276152491569519
Iteration 156: train_loss 1.2453325986862183
Iteration 157: train_loss 1.2484198808670044
Iteration 158: train_loss 1.3088202476501465
Iteration 159: train_loss 1.190523386001587
Iteration 160: train_loss 1.2872650623321533
Iteration 161: train_loss 1.2617114782333374
Iteration 162: train_loss 1.2627599239349365
Iteration 163: train_loss 1.2941526174545288
Iteration 164: train_loss 1.3207175731658936
Iteration 165: train_loss 1.2889195680618286
Iteration 166: train_loss 1.2928006649017334
Iteration 167: train_loss 1.3392589092254639
Iteration 168: train_loss 1.248275637626648
Iteration 169: train_loss 1.2772717475891113
Iteration 170: train_loss 1.256253957748413
Iteration 171: train_loss 1.2409261465072632
Iteration 172: train_loss 1.2768679857254028
Iteration 173: train_loss 1.3816462755203247
Iteration 174: train_loss 1.2501640319824219
Iteration 175: train_loss 1.303849458694458
Iteration 176: train_loss 1.2677184343338013
Iteration 177: train_loss 1.2044999599456787
Epoch 126: train_avg_loss 1.2745208861464161 eval_avg_acc: 0.34186865808026506 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:13:13] [32mIntermediate result: 0.34186865808026506  (Index 125)[0m
================Epoch: 127================
Iteration 1: train_loss 1.3209954500198364
Iteration 2: train_loss 1.2423062324523926
Iteration 3: train_loss 1.205329179763794
Iteration 4: train_loss 1.3127764463424683
Iteration 5: train_loss 1.3707166910171509
Iteration 6: train_loss 1.3025569915771484
Iteration 7: train_loss 1.2799286842346191
Iteration 8: train_loss 1.2950384616851807
Iteration 9: train_loss 1.3997857570648193
Iteration 10: train_loss 1.3275889158248901
Iteration 11: train_loss 1.2958990335464478
Iteration 12: train_loss 1.3055849075317383
Iteration 13: train_loss 1.262954831123352
Iteration 14: train_loss 1.2787553071975708
Iteration 15: train_loss 1.2953288555145264
Iteration 16: train_loss 1.2800228595733643
Iteration 17: train_loss 1.2681490182876587
Iteration 18: train_loss 1.2024083137512207
Iteration 19: train_loss 1.3045692443847656
Iteration 20: train_loss 1.2547744512557983
Iteration 21: train_loss 1.2278624773025513
Iteration 22: train_loss 1.3123220205307007
Iteration 23: train_loss 1.2555744647979736
Iteration 24: train_loss 1.1888573169708252
Iteration 25: train_loss 1.2248486280441284
Iteration 26: train_loss 1.21402108669281
Iteration 27: train_loss 1.2588814496994019
Iteration 28: train_loss 1.239274501800537
Iteration 29: train_loss 1.3068690299987793
Iteration 30: train_loss 1.291751503944397
Iteration 31: train_loss 1.2827906608581543
Iteration 32: train_loss 1.31267511844635
Iteration 33: train_loss 1.2653791904449463
Iteration 34: train_loss 1.2155770063400269
Iteration 35: train_loss 1.2694600820541382
Iteration 36: train_loss 1.269033432006836
Iteration 37: train_loss 1.2617442607879639
Iteration 38: train_loss 1.2674589157104492
Iteration 39: train_loss 1.3083585500717163
Iteration 40: train_loss 1.2996771335601807
Iteration 41: train_loss 1.2532414197921753
Iteration 42: train_loss 1.2445347309112549
Iteration 43: train_loss 1.2369498014450073
Iteration 44: train_loss 1.2759591341018677
Iteration 45: train_loss 1.242646336555481
Iteration 46: train_loss 1.273137092590332
Iteration 47: train_loss 1.3028963804244995
Iteration 48: train_loss 1.2957487106323242
Iteration 49: train_loss 1.2833951711654663
Iteration 50: train_loss 1.2543575763702393
Iteration 51: train_loss 1.2572134733200073
Iteration 52: train_loss 1.3201673030853271
Iteration 53: train_loss 1.27711021900177
Iteration 54: train_loss 1.3104506731033325
Iteration 55: train_loss 1.2698124647140503
Iteration 56: train_loss 1.2770434617996216
Iteration 57: train_loss 1.234572410583496
Iteration 58: train_loss 1.2812411785125732
Iteration 59: train_loss 1.2481738328933716
Iteration 60: train_loss 1.295574426651001
Iteration 61: train_loss 1.2186216115951538
Iteration 62: train_loss 1.293558955192566
Iteration 63: train_loss 1.3086071014404297
Iteration 64: train_loss 1.3279078006744385
Iteration 65: train_loss 1.3315002918243408
Iteration 66: train_loss 1.298344612121582
Iteration 67: train_loss 1.3836077451705933
Iteration 68: train_loss 1.298421025276184
Iteration 69: train_loss 1.268561601638794
Iteration 70: train_loss 1.2692879438400269
Iteration 71: train_loss 1.3290809392929077
Iteration 72: train_loss 1.3015031814575195
Iteration 73: train_loss 1.2982943058013916
Iteration 74: train_loss 1.3055839538574219
Iteration 75: train_loss 1.2092238664627075
Iteration 76: train_loss 1.316598653793335
Iteration 77: train_loss 1.2968871593475342
Iteration 78: train_loss 1.3315104246139526
Iteration 79: train_loss 1.3116717338562012
Iteration 80: train_loss 1.3246995210647583
Iteration 81: train_loss 1.2471843957901
Iteration 82: train_loss 1.3010919094085693
Iteration 83: train_loss 1.339363694190979
Iteration 84: train_loss 1.2749395370483398
Iteration 85: train_loss 1.2963755130767822
Iteration 86: train_loss 1.335679054260254
Iteration 87: train_loss 1.265104055404663
Iteration 88: train_loss 1.2573641538619995
Iteration 89: train_loss 1.269576072692871
Iteration 90: train_loss 1.2820091247558594
Iteration 91: train_loss 1.2169848680496216
Iteration 92: train_loss 1.2886041402816772
Iteration 93: train_loss 1.3324462175369263
Iteration 94: train_loss 1.2751801013946533
Iteration 95: train_loss 1.2900224924087524
Iteration 96: train_loss 1.3233764171600342
Iteration 97: train_loss 1.2887383699417114
Iteration 98: train_loss 1.2523096799850464
Iteration 99: train_loss 1.3125253915786743
Iteration 100: train_loss 1.2357701063156128
Iteration 101: train_loss 1.2494559288024902
Iteration 102: train_loss 1.3127162456512451
Iteration 103: train_loss 1.2952567338943481
Iteration 104: train_loss 1.3443437814712524
Iteration 105: train_loss 1.2967346906661987
Iteration 106: train_loss 1.2741295099258423
Iteration 107: train_loss 1.3145484924316406
Iteration 108: train_loss 1.2928270101547241
Iteration 109: train_loss 1.3332933187484741
Iteration 110: train_loss 1.3299570083618164
Iteration 111: train_loss 1.3559608459472656
Iteration 112: train_loss 1.2834571599960327
Iteration 113: train_loss 1.3366860151290894
Iteration 114: train_loss 1.297098159790039
Iteration 115: train_loss 1.2478712797164917
Iteration 116: train_loss 1.2889238595962524
Iteration 117: train_loss 1.3104678392410278
Iteration 118: train_loss 1.2872140407562256
Iteration 119: train_loss 1.3010914325714111
Iteration 120: train_loss 1.2909091711044312
Iteration 121: train_loss 1.2460768222808838
Iteration 122: train_loss 1.2829474210739136
Iteration 123: train_loss 1.2833064794540405
Iteration 124: train_loss 1.276926875114441
Iteration 125: train_loss 1.2981013059616089
Iteration 126: train_loss 1.2375530004501343
Iteration 127: train_loss 1.2771341800689697
Iteration 128: train_loss 1.3212159872055054
Iteration 129: train_loss 1.2704607248306274
Iteration 130: train_loss 1.2754298448562622
Iteration 131: train_loss 1.2978049516677856
Iteration 132: train_loss 1.2984029054641724
Iteration 133: train_loss 1.2919121980667114
Iteration 134: train_loss 1.2319074869155884
Iteration 135: train_loss 1.2643946409225464
Iteration 136: train_loss 1.2500466108322144
Iteration 137: train_loss 1.2669408321380615
Iteration 138: train_loss 1.3351374864578247
Iteration 139: train_loss 1.2573304176330566
Iteration 140: train_loss 1.266065239906311
Iteration 141: train_loss 1.3060472011566162
Iteration 142: train_loss 1.3488214015960693
Iteration 143: train_loss 1.312716007232666
Iteration 144: train_loss 1.309251308441162
Iteration 145: train_loss 1.2638343572616577
Iteration 146: train_loss 1.2888760566711426
Iteration 147: train_loss 1.2734549045562744
Iteration 148: train_loss 1.2913074493408203
Iteration 149: train_loss 1.3090084791183472
Iteration 150: train_loss 1.2515233755111694
Iteration 151: train_loss 1.2592817544937134
Iteration 152: train_loss 1.3099607229232788
Iteration 153: train_loss 1.3000880479812622
Iteration 154: train_loss 1.26482093334198
Iteration 155: train_loss 1.2528578042984009
Iteration 156: train_loss 1.3274345397949219
Iteration 157: train_loss 1.2631064653396606
Iteration 158: train_loss 1.2430938482284546
Iteration 159: train_loss 1.3068009614944458
Iteration 160: train_loss 1.3150657415390015
Iteration 161: train_loss 1.2718526124954224
Iteration 162: train_loss 1.2776196002960205
Iteration 163: train_loss 1.284624457359314
Iteration 164: train_loss 1.3322969675064087
Iteration 165: train_loss 1.3021715879440308
Iteration 166: train_loss 1.3001867532730103
Iteration 167: train_loss 1.3164533376693726
Iteration 168: train_loss 1.266366958618164
Iteration 169: train_loss 1.2885398864746094
Iteration 170: train_loss 1.2827318906784058
Iteration 171: train_loss 1.2797791957855225
Iteration 172: train_loss 1.2368594408035278
Iteration 173: train_loss 1.235840082168579
Iteration 174: train_loss 1.2430695295333862
Iteration 175: train_loss 1.2724394798278809
Iteration 176: train_loss 1.2812576293945312
Iteration 177: train_loss 1.250425100326538
Epoch 127: train_avg_loss 1.2842493434410311 eval_avg_acc: 0.34560607106669344 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:13:52] [32mIntermediate result: 0.34560607106669344  (Index 126)[0m
================Epoch: 128================
Iteration 1: train_loss 1.2236524820327759
Iteration 2: train_loss 1.230476975440979
Iteration 3: train_loss 1.2830917835235596
Iteration 4: train_loss 1.3034536838531494
Iteration 5: train_loss 1.2464256286621094
Iteration 6: train_loss 1.317938208580017
Iteration 7: train_loss 1.319637656211853
Iteration 8: train_loss 1.2318999767303467
Iteration 9: train_loss 1.272309422492981
Iteration 10: train_loss 1.287562608718872
Iteration 11: train_loss 1.3135766983032227
Iteration 12: train_loss 1.2641690969467163
Iteration 13: train_loss 1.2717721462249756
Iteration 14: train_loss 1.2827714681625366
Iteration 15: train_loss 1.3086934089660645
Iteration 16: train_loss 1.2894632816314697
Iteration 17: train_loss 1.3032180070877075
Iteration 18: train_loss 1.2408099174499512
Iteration 19: train_loss 1.232662320137024
Iteration 20: train_loss 1.2392038106918335
Iteration 21: train_loss 1.2918195724487305
Iteration 22: train_loss 1.302525520324707
Iteration 23: train_loss 1.2081584930419922
Iteration 24: train_loss 1.2684752941131592
Iteration 25: train_loss 1.2502832412719727
Iteration 26: train_loss 1.3061240911483765
Iteration 27: train_loss 1.2968541383743286
Iteration 28: train_loss 1.2638839483261108
Iteration 29: train_loss 1.2428748607635498
Iteration 30: train_loss 1.2967915534973145
Iteration 31: train_loss 1.2777124643325806
Iteration 32: train_loss 1.262305498123169
Iteration 33: train_loss 1.2745072841644287
Iteration 34: train_loss 1.2623461484909058
Iteration 35: train_loss 1.3070825338363647
Iteration 36: train_loss 1.2099326848983765
Iteration 37: train_loss 1.3385452032089233
Iteration 38: train_loss 1.2697272300720215
Iteration 39: train_loss 1.2289735078811646
Iteration 40: train_loss 1.2657861709594727
Iteration 41: train_loss 1.2971524000167847
Iteration 42: train_loss 1.2959922552108765
Iteration 43: train_loss 1.2712244987487793
Iteration 44: train_loss 1.3040261268615723
Iteration 45: train_loss 1.312361478805542
Iteration 46: train_loss 1.2481263875961304
Iteration 47: train_loss 1.3433719873428345
Iteration 48: train_loss 1.2711544036865234
Iteration 49: train_loss 1.3400425910949707
Iteration 50: train_loss 1.2522379159927368
Iteration 51: train_loss 1.2627826929092407
Iteration 52: train_loss 1.2844988107681274
Iteration 53: train_loss 1.2767374515533447
Iteration 54: train_loss 1.2668941020965576
Iteration 55: train_loss 1.3093712329864502
Iteration 56: train_loss 1.2790106534957886
Iteration 57: train_loss 1.3018518686294556
Iteration 58: train_loss 1.2473676204681396
Iteration 59: train_loss 1.27021062374115
Iteration 60: train_loss 1.2346642017364502
Iteration 61: train_loss 1.2985397577285767
Iteration 62: train_loss 1.2846596240997314
Iteration 63: train_loss 1.2599831819534302
Iteration 64: train_loss 1.2407617568969727
Iteration 65: train_loss 1.2642557621002197
Iteration 66: train_loss 1.3133045434951782
Iteration 67: train_loss 1.2205884456634521
Iteration 68: train_loss 1.277647614479065
Iteration 69: train_loss 1.2684574127197266
Iteration 70: train_loss 1.335067629814148
Iteration 71: train_loss 1.302598237991333
Iteration 72: train_loss 1.268193006515503
Iteration 73: train_loss 1.2583180665969849
Iteration 74: train_loss 1.2971230745315552
Iteration 75: train_loss 1.2454184293746948
Iteration 76: train_loss 1.2659046649932861
Iteration 77: train_loss 1.3151532411575317
Iteration 78: train_loss 1.3323451280593872
Iteration 79: train_loss 1.3190152645111084
Iteration 80: train_loss 1.2832310199737549
Iteration 81: train_loss 1.312713623046875
Iteration 82: train_loss 1.2645663022994995
Iteration 83: train_loss 1.3513240814208984
Iteration 84: train_loss 1.3595303297042847
Iteration 85: train_loss 1.2744446992874146
Iteration 86: train_loss 1.2378356456756592
Iteration 87: train_loss 1.3257904052734375
Iteration 88: train_loss 1.3056056499481201
Iteration 89: train_loss 1.2673975229263306
Iteration 90: train_loss 1.2627270221710205
Iteration 91: train_loss 1.2594621181488037
Iteration 92: train_loss 1.2747819423675537
Iteration 93: train_loss 1.2846217155456543
Iteration 94: train_loss 1.2733534574508667
Iteration 95: train_loss 1.2337945699691772
Iteration 96: train_loss 1.299254298210144
Iteration 97: train_loss 1.263739824295044
Iteration 98: train_loss 1.2518839836120605
Iteration 99: train_loss 1.3262877464294434
Iteration 100: train_loss 1.1915229558944702
Iteration 101: train_loss 1.2889050245285034
Iteration 102: train_loss 1.3016071319580078
Iteration 103: train_loss 1.2170119285583496
Iteration 104: train_loss 1.194854736328125
Iteration 105: train_loss 1.290073037147522
Iteration 106: train_loss 1.2412582635879517
Iteration 107: train_loss 1.2748618125915527
Iteration 108: train_loss 1.2010620832443237
Iteration 109: train_loss 1.2191848754882812
Iteration 110: train_loss 1.1688793897628784
Iteration 111: train_loss 1.2449469566345215
Iteration 112: train_loss 1.2165873050689697
Iteration 113: train_loss 1.2516154050827026
Iteration 114: train_loss 1.2753379344940186
Iteration 115: train_loss 1.249488115310669
Iteration 116: train_loss 1.239282488822937
Iteration 117: train_loss 1.3797584772109985
Iteration 118: train_loss 1.2721062898635864
Iteration 119: train_loss 1.335565447807312
Iteration 120: train_loss 1.268871784210205
Iteration 121: train_loss 1.2452592849731445
Iteration 122: train_loss 1.269501805305481
Iteration 123: train_loss 1.3227157592773438
Iteration 124: train_loss 1.3041255474090576
Iteration 125: train_loss 1.318355679512024
Iteration 126: train_loss 1.2830878496170044
Iteration 127: train_loss 1.276079773902893
Iteration 128: train_loss 1.2680766582489014
Iteration 129: train_loss 1.2646939754486084
Iteration 130: train_loss 1.2853285074234009
Iteration 131: train_loss 1.2944670915603638
Iteration 132: train_loss 1.2894599437713623
Iteration 133: train_loss 1.3253979682922363
Iteration 134: train_loss 1.2489795684814453
Iteration 135: train_loss 1.2980209589004517
Iteration 136: train_loss 1.2456386089324951
Iteration 137: train_loss 1.2434817552566528
Iteration 138: train_loss 1.322350263595581
Iteration 139: train_loss 1.2552233934402466
Iteration 140: train_loss 1.2874244451522827
Iteration 141: train_loss 1.2692179679870605
Iteration 142: train_loss 1.2517998218536377
Iteration 143: train_loss 1.2689380645751953
Iteration 144: train_loss 1.2409918308258057
Iteration 145: train_loss 1.277056097984314
Iteration 146: train_loss 1.2950910329818726
Iteration 147: train_loss 1.332841157913208
Iteration 148: train_loss 1.3073370456695557
Iteration 149: train_loss 1.3147300481796265
Iteration 150: train_loss 1.2656887769699097
Iteration 151: train_loss 1.2548902034759521
Iteration 152: train_loss 1.2956063747406006
Iteration 153: train_loss 1.3019520044326782
Iteration 154: train_loss 1.3058195114135742
Iteration 155: train_loss 1.2987571954727173
Iteration 156: train_loss 1.3426451683044434
Iteration 157: train_loss 1.317468285560608
Iteration 158: train_loss 1.2915072441101074
Iteration 159: train_loss 1.2891592979431152
Iteration 160: train_loss 1.2950977087020874
Iteration 161: train_loss 1.3064956665039062
Iteration 162: train_loss 1.2243181467056274
Iteration 163: train_loss 1.2175742387771606
Iteration 164: train_loss 1.214363932609558
Iteration 165: train_loss 1.2511098384857178
Iteration 166: train_loss 1.287143588066101
Iteration 167: train_loss 1.2638344764709473
Iteration 168: train_loss 1.2892248630523682
Iteration 169: train_loss 1.2539706230163574
Iteration 170: train_loss 1.33039391040802
Iteration 171: train_loss 1.2931101322174072
Iteration 172: train_loss 1.2450259923934937
Iteration 173: train_loss 1.2150381803512573
Iteration 174: train_loss 1.23514986038208
Iteration 175: train_loss 1.2319319248199463
Iteration 176: train_loss 1.2321420907974243
Iteration 177: train_loss 1.331528902053833
Epoch 128: train_avg_loss 1.2759641786079623 eval_avg_acc: 0.34081243784456994 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:14:31] [32mIntermediate result: 0.34081243784456994  (Index 127)[0m
================Epoch: 129================
Iteration 1: train_loss 1.3044404983520508
Iteration 2: train_loss 1.242564082145691
Iteration 3: train_loss 1.274402141571045
Iteration 4: train_loss 1.2587854862213135
Iteration 5: train_loss 1.2208001613616943
Iteration 6: train_loss 1.241647481918335
Iteration 7: train_loss 1.289573073387146
Iteration 8: train_loss 1.2413952350616455
Iteration 9: train_loss 1.2579901218414307
Iteration 10: train_loss 1.259252667427063
Iteration 11: train_loss 1.2596954107284546
Iteration 12: train_loss 1.2932966947555542
Iteration 13: train_loss 1.2461572885513306
Iteration 14: train_loss 1.2289621829986572
Iteration 15: train_loss 1.2826343774795532
Iteration 16: train_loss 1.2551078796386719
Iteration 17: train_loss 1.270389199256897
Iteration 18: train_loss 1.2971155643463135
Iteration 19: train_loss 1.2578046321868896
Iteration 20: train_loss 1.2628182172775269
Iteration 21: train_loss 1.3236221075057983
Iteration 22: train_loss 1.224946141242981
Iteration 23: train_loss 1.2638609409332275
Iteration 24: train_loss 1.2287278175354004
Iteration 25: train_loss 1.206860899925232
Iteration 26: train_loss 1.2429661750793457
Iteration 27: train_loss 1.25850248336792
Iteration 28: train_loss 1.213153600692749
Iteration 29: train_loss 1.2836419343948364
Iteration 30: train_loss 1.2026835680007935
Iteration 31: train_loss 1.3050755262374878
Iteration 32: train_loss 1.2366158962249756
Iteration 33: train_loss 1.308451771736145
Iteration 34: train_loss 1.1760741472244263
Iteration 35: train_loss 1.2840524911880493
Iteration 36: train_loss 1.2332273721694946
Iteration 37: train_loss 1.181835651397705
Iteration 38: train_loss 1.2287715673446655
Iteration 39: train_loss 1.2571250200271606
Iteration 40: train_loss 1.2990940809249878
Iteration 41: train_loss 1.2386723756790161
Iteration 42: train_loss 1.3016128540039062
Iteration 43: train_loss 1.2985538244247437
Iteration 44: train_loss 1.2702349424362183
Iteration 45: train_loss 1.161990761756897
Iteration 46: train_loss 1.2587815523147583
Iteration 47: train_loss 1.2061264514923096
Iteration 48: train_loss 1.2352750301361084
Iteration 49: train_loss 1.2476283311843872
Iteration 50: train_loss 1.2402701377868652
Iteration 51: train_loss 1.2673652172088623
Iteration 52: train_loss 1.2165098190307617
Iteration 53: train_loss 1.2225675582885742
Iteration 54: train_loss 1.260046362876892
Iteration 55: train_loss 1.2192201614379883
Iteration 56: train_loss 1.2757377624511719
Iteration 57: train_loss 1.2603211402893066
Iteration 58: train_loss 1.1983319520950317
Iteration 59: train_loss 1.230509877204895
Iteration 60: train_loss 1.2249385118484497
Iteration 61: train_loss 1.2077438831329346
Iteration 62: train_loss 1.2140144109725952
Iteration 63: train_loss 1.203998327255249
Iteration 64: train_loss 1.240679144859314
Iteration 65: train_loss 1.2431180477142334
Iteration 66: train_loss 1.2837854623794556
Iteration 67: train_loss 1.171991229057312
Iteration 68: train_loss 1.2798676490783691
Iteration 69: train_loss 1.1963635683059692
Iteration 70: train_loss 1.2322745323181152
Iteration 71: train_loss 1.2947258949279785
Iteration 72: train_loss 1.3292418718338013
Iteration 73: train_loss 1.2484163045883179
Iteration 74: train_loss 1.2037416696548462
Iteration 75: train_loss 1.267573595046997
Iteration 76: train_loss 1.206093668937683
Iteration 77: train_loss 1.2659913301467896
Iteration 78: train_loss 1.3199611902236938
Iteration 79: train_loss 1.282486081123352
Iteration 80: train_loss 1.3038102388381958
Iteration 81: train_loss 1.2563810348510742
Iteration 82: train_loss 1.2189058065414429
Iteration 83: train_loss 1.3074042797088623
Iteration 84: train_loss 1.305189609527588
Iteration 85: train_loss 1.3132041692733765
Iteration 86: train_loss 1.219938039779663
Iteration 87: train_loss 1.3212202787399292
Iteration 88: train_loss 1.3008846044540405
Iteration 89: train_loss 1.2826951742172241
Iteration 90: train_loss 1.2893099784851074
Iteration 91: train_loss 1.288456678390503
Iteration 92: train_loss 1.236697793006897
Iteration 93: train_loss 1.2868598699569702
Iteration 94: train_loss 1.2430963516235352
Iteration 95: train_loss 1.266527533531189
Iteration 96: train_loss 1.291747808456421
Iteration 97: train_loss 1.2750197649002075
Iteration 98: train_loss 1.2555564641952515
Iteration 99: train_loss 1.3317973613739014
Iteration 100: train_loss 1.272433876991272
Iteration 101: train_loss 1.218602180480957
Iteration 102: train_loss 1.283389925956726
Iteration 103: train_loss 1.3250097036361694
Iteration 104: train_loss 1.329345464706421
Iteration 105: train_loss 1.3006923198699951
Iteration 106: train_loss 1.3378363847732544
Iteration 107: train_loss 1.2207473516464233
Iteration 108: train_loss 1.2240413427352905
Iteration 109: train_loss 1.343863606452942
Iteration 110: train_loss 1.227713704109192
Iteration 111: train_loss 1.2429933547973633
Iteration 112: train_loss 1.2158445119857788
Iteration 113: train_loss 1.2702819108963013
Iteration 114: train_loss 1.2826122045516968
Iteration 115: train_loss 1.3437867164611816
Iteration 116: train_loss 1.319757103919983
Iteration 117: train_loss 1.328417181968689
Iteration 118: train_loss 1.2674102783203125
Iteration 119: train_loss 1.255494236946106
Iteration 120: train_loss 1.2955570220947266
Iteration 121: train_loss 1.2912648916244507
Iteration 122: train_loss 1.3136467933654785
Iteration 123: train_loss 1.2535090446472168
Iteration 124: train_loss 1.2764455080032349
Iteration 125: train_loss 1.2502024173736572
Iteration 126: train_loss 1.2644624710083008
Iteration 127: train_loss 1.2136892080307007
Iteration 128: train_loss 1.2779582738876343
Iteration 129: train_loss 1.2789288759231567
Iteration 130: train_loss 1.3448151350021362
Iteration 131: train_loss 1.3221722841262817
Iteration 132: train_loss 1.2455041408538818
Iteration 133: train_loss 1.2670233249664307
Iteration 134: train_loss 1.2877451181411743
Iteration 135: train_loss 1.276922583580017
Iteration 136: train_loss 1.2308964729309082
Iteration 137: train_loss 1.2877509593963623
Iteration 138: train_loss 1.2879586219787598
Iteration 139: train_loss 1.2707033157348633
Iteration 140: train_loss 1.2767980098724365
Iteration 141: train_loss 1.2760274410247803
Iteration 142: train_loss 1.3310837745666504
Iteration 143: train_loss 1.315708041191101
Iteration 144: train_loss 1.3242793083190918
Iteration 145: train_loss 1.2719658613204956
Iteration 146: train_loss 1.2697418928146362
Iteration 147: train_loss 1.312157154083252
Iteration 148: train_loss 1.2486793994903564
Iteration 149: train_loss 1.2708587646484375
Iteration 150: train_loss 1.2776259183883667
Iteration 151: train_loss 1.2944804430007935
Iteration 152: train_loss 1.2968252897262573
Iteration 153: train_loss 1.2158076763153076
Iteration 154: train_loss 1.2610355615615845
Iteration 155: train_loss 1.2973122596740723
Iteration 156: train_loss 1.2686399221420288
Iteration 157: train_loss 1.3006019592285156
Iteration 158: train_loss 1.3206084966659546
Iteration 159: train_loss 1.2580595016479492
Iteration 160: train_loss 1.2279064655303955
Iteration 161: train_loss 1.2527505159378052
Iteration 162: train_loss 1.318886399269104
Iteration 163: train_loss 1.2766987085342407
Iteration 164: train_loss 1.3229669332504272
Iteration 165: train_loss 1.2730590105056763
Iteration 166: train_loss 1.2837401628494263
Iteration 167: train_loss 1.2814561128616333
Iteration 168: train_loss 1.3047395944595337
Iteration 169: train_loss 1.2779743671417236
Iteration 170: train_loss 1.2491790056228638
Iteration 171: train_loss 1.361660361289978
Iteration 172: train_loss 1.3060367107391357
Iteration 173: train_loss 1.3253058195114136
Iteration 174: train_loss 1.3133628368377686
Iteration 175: train_loss 1.265641689300537
Iteration 176: train_loss 1.2537987232208252
Iteration 177: train_loss 1.3057022094726562
Epoch 129: train_avg_loss 1.2675829324345131 eval_avg_acc: 0.3475362026895931 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:15:09] [32mIntermediate result: 0.3475362026895931  (Index 128)[0m
================Epoch: 130================
Iteration 1: train_loss 1.2026472091674805
Iteration 2: train_loss 1.2208251953125
Iteration 3: train_loss 1.225276231765747
Iteration 4: train_loss 1.2237738370895386
Iteration 5: train_loss 1.2009756565093994
Iteration 6: train_loss 1.22781503200531
Iteration 7: train_loss 1.253472924232483
Iteration 8: train_loss 1.2158676385879517
Iteration 9: train_loss 1.2102903127670288
Iteration 10: train_loss 1.224225401878357
Iteration 11: train_loss 1.278511881828308
Iteration 12: train_loss 1.2614718675613403
Iteration 13: train_loss 1.2561655044555664
Iteration 14: train_loss 1.269200086593628
Iteration 15: train_loss 1.2557811737060547
Iteration 16: train_loss 1.225709319114685
Iteration 17: train_loss 1.274681568145752
Iteration 18: train_loss 1.2606645822525024
Iteration 19: train_loss 1.2586402893066406
Iteration 20: train_loss 1.251539945602417
Iteration 21: train_loss 1.2514959573745728
Iteration 22: train_loss 1.276041865348816
Iteration 23: train_loss 1.2432185411453247
Iteration 24: train_loss 1.2519304752349854
Iteration 25: train_loss 1.2996811866760254
Iteration 26: train_loss 1.2926658391952515
Iteration 27: train_loss 1.2326018810272217
Iteration 28: train_loss 1.2444486618041992
Iteration 29: train_loss 1.3322579860687256
Iteration 30: train_loss 1.332598090171814
Iteration 31: train_loss 1.2062501907348633
Iteration 32: train_loss 1.2369346618652344
Iteration 33: train_loss 1.2811129093170166
Iteration 34: train_loss 1.2429172992706299
Iteration 35: train_loss 1.2719494104385376
Iteration 36: train_loss 1.2276511192321777
Iteration 37: train_loss 1.245915174484253
Iteration 38: train_loss 1.2163283824920654
Iteration 39: train_loss 1.3111345767974854
Iteration 40: train_loss 1.2462146282196045
Iteration 41: train_loss 1.1890302896499634
Iteration 42: train_loss 1.2419300079345703
Iteration 43: train_loss 1.2432059049606323
Iteration 44: train_loss 1.285559892654419
Iteration 45: train_loss 1.2253209352493286
Iteration 46: train_loss 1.3036423921585083
Iteration 47: train_loss 1.207595944404602
Iteration 48: train_loss 1.27378511428833
Iteration 49: train_loss 1.2329119443893433
Iteration 50: train_loss 1.2555553913116455
Iteration 51: train_loss 1.3252578973770142
Iteration 52: train_loss 1.343459129333496
Iteration 53: train_loss 1.267722249031067
Iteration 54: train_loss 1.285314679145813
Iteration 55: train_loss 1.2820401191711426
Iteration 56: train_loss 1.2623592615127563
Iteration 57: train_loss 1.2538772821426392
Iteration 58: train_loss 1.2126678228378296
Iteration 59: train_loss 1.2771903276443481
Iteration 60: train_loss 1.2742079496383667
Iteration 61: train_loss 1.2655621767044067
Iteration 62: train_loss 1.2686532735824585
Iteration 63: train_loss 1.236879587173462
Iteration 64: train_loss 1.2853381633758545
Iteration 65: train_loss 1.2339093685150146
Iteration 66: train_loss 1.2365361452102661
Iteration 67: train_loss 1.1682687997817993
Iteration 68: train_loss 1.2229359149932861
Iteration 69: train_loss 1.2072241306304932
Iteration 70: train_loss 1.2392820119857788
Iteration 71: train_loss 1.2522586584091187
Iteration 72: train_loss 1.2349469661712646
Iteration 73: train_loss 1.2137843370437622
Iteration 74: train_loss 1.2459065914154053
Iteration 75: train_loss 1.2617560625076294
Iteration 76: train_loss 1.1915946006774902
Iteration 77: train_loss 1.2699402570724487
Iteration 78: train_loss 1.2757526636123657
Iteration 79: train_loss 1.2063976526260376
Iteration 80: train_loss 1.2268940210342407
Iteration 81: train_loss 1.268924593925476
Iteration 82: train_loss 1.2787270545959473
Iteration 83: train_loss 1.1951621770858765
Iteration 84: train_loss 1.2437915802001953
Iteration 85: train_loss 1.279723048210144
Iteration 86: train_loss 1.311171054840088
Iteration 87: train_loss 1.238262414932251
Iteration 88: train_loss 1.252162218093872
Iteration 89: train_loss 1.2541382312774658
Iteration 90: train_loss 1.2857232093811035
Iteration 91: train_loss 1.1994377374649048
Iteration 92: train_loss 1.2595152854919434
Iteration 93: train_loss 1.250475287437439
Iteration 94: train_loss 1.2451268434524536
Iteration 95: train_loss 1.2745022773742676
Iteration 96: train_loss 1.2466135025024414
Iteration 97: train_loss 1.3364262580871582
Iteration 98: train_loss 1.2696360349655151
Iteration 99: train_loss 1.2175917625427246
Iteration 100: train_loss 1.3053834438323975
Iteration 101: train_loss 1.3178257942199707
Iteration 102: train_loss 1.182495355606079
Iteration 103: train_loss 1.2700868844985962
Iteration 104: train_loss 1.238332748413086
Iteration 105: train_loss 1.3297460079193115
Iteration 106: train_loss 1.2003470659255981
Iteration 107: train_loss 1.239557147026062
Iteration 108: train_loss 1.2613449096679688
Iteration 109: train_loss 1.2718522548675537
Iteration 110: train_loss 1.2565938234329224
Iteration 111: train_loss 1.2784173488616943
Iteration 112: train_loss 1.2914676666259766
Iteration 113: train_loss 1.3475925922393799
Iteration 114: train_loss 1.2750160694122314
Iteration 115: train_loss 1.3260873556137085
Iteration 116: train_loss 1.3084779977798462
Iteration 117: train_loss 1.3000719547271729
Iteration 118: train_loss 1.3053332567214966
Iteration 119: train_loss 1.3596867322921753
Iteration 120: train_loss 1.3127002716064453
Iteration 121: train_loss 1.3365229368209839
Iteration 122: train_loss 1.3398091793060303
Iteration 123: train_loss 1.3470075130462646
Iteration 124: train_loss 1.3269462585449219
Iteration 125: train_loss 1.278982400894165
Iteration 126: train_loss 1.2522814273834229
Iteration 127: train_loss 1.3143278360366821
Iteration 128: train_loss 1.22636878490448
Iteration 129: train_loss 1.2080751657485962
Iteration 130: train_loss 1.2819666862487793
Iteration 131: train_loss 1.2526172399520874
Iteration 132: train_loss 1.2488417625427246
Iteration 133: train_loss 1.235793113708496
Iteration 134: train_loss 1.297025203704834
Iteration 135: train_loss 1.3242809772491455
Iteration 136: train_loss 1.264245629310608
Iteration 137: train_loss 1.2834887504577637
Iteration 138: train_loss 1.205155372619629
Iteration 139: train_loss 1.2912949323654175
Iteration 140: train_loss 1.2949585914611816
Iteration 141: train_loss 1.2641048431396484
Iteration 142: train_loss 1.2458806037902832
Iteration 143: train_loss 1.3354558944702148
Iteration 144: train_loss 1.2724331617355347
Iteration 145: train_loss 1.2671312093734741
Iteration 146: train_loss 1.2391082048416138
Iteration 147: train_loss 1.2369544506072998
Iteration 148: train_loss 1.25456964969635
Iteration 149: train_loss 1.3155792951583862
Iteration 150: train_loss 1.2641897201538086
Iteration 151: train_loss 1.2758684158325195
Iteration 152: train_loss 1.2656104564666748
Iteration 153: train_loss 1.333261251449585
Iteration 154: train_loss 1.2650700807571411
Iteration 155: train_loss 1.3150640726089478
Iteration 156: train_loss 1.2675293684005737
Iteration 157: train_loss 1.379706859588623
Iteration 158: train_loss 1.3144782781600952
Iteration 159: train_loss 1.372275710105896
Iteration 160: train_loss 1.3061809539794922
Iteration 161: train_loss 1.263535499572754
Iteration 162: train_loss 1.2639260292053223
Iteration 163: train_loss 1.333438754081726
Iteration 164: train_loss 1.3127799034118652
Iteration 165: train_loss 1.3245785236358643
Iteration 166: train_loss 1.2704590559005737
Iteration 167: train_loss 1.2845839262008667
Iteration 168: train_loss 1.2780308723449707
Iteration 169: train_loss 1.2924875020980835
Iteration 170: train_loss 1.2791942358016968
Iteration 171: train_loss 1.225335955619812
Iteration 172: train_loss 1.275184988975525
Iteration 173: train_loss 1.3124631643295288
Iteration 174: train_loss 1.274817705154419
Iteration 175: train_loss 1.2892122268676758
Iteration 176: train_loss 1.3218531608581543
Iteration 177: train_loss 1.3436325788497925
Epoch 130: train_avg_loss 1.2669990055978635 eval_avg_acc: 0.3499704276014923 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:15:47] [32mIntermediate result: 0.3499704276014923  (Index 129)[0m
================Epoch: 131================
Iteration 1: train_loss 1.222819209098816
Iteration 2: train_loss 1.2079378366470337
Iteration 3: train_loss 1.2063485383987427
Iteration 4: train_loss 1.2245744466781616
Iteration 5: train_loss 1.2167437076568604
Iteration 6: train_loss 1.204664945602417
Iteration 7: train_loss 1.1996369361877441
Iteration 8: train_loss 1.2071417570114136
Iteration 9: train_loss 1.2467788457870483
Iteration 10: train_loss 1.2438428401947021
Iteration 11: train_loss 1.229859471321106
Iteration 12: train_loss 1.256840467453003
Iteration 13: train_loss 1.2701901197433472
Iteration 14: train_loss 1.279907464981079
Iteration 15: train_loss 1.2227697372436523
Iteration 16: train_loss 1.2727901935577393
Iteration 17: train_loss 1.2702898979187012
Iteration 18: train_loss 1.2533795833587646
Iteration 19: train_loss 1.2493878602981567
Iteration 20: train_loss 1.2066493034362793
Iteration 21: train_loss 1.2374616861343384
Iteration 22: train_loss 1.2290329933166504
Iteration 23: train_loss 1.2960516214370728
Iteration 24: train_loss 1.2736225128173828
Iteration 25: train_loss 1.1950304508209229
Iteration 26: train_loss 1.2604820728302002
Iteration 27: train_loss 1.21210515499115
Iteration 28: train_loss 1.2263983488082886
Iteration 29: train_loss 1.2269729375839233
Iteration 30: train_loss 1.2158936262130737
Iteration 31: train_loss 1.285850167274475
Iteration 32: train_loss 1.2363296747207642
Iteration 33: train_loss 1.2390600442886353
Iteration 34: train_loss 1.249003291130066
Iteration 35: train_loss 1.2076853513717651
Iteration 36: train_loss 1.2280986309051514
Iteration 37: train_loss 1.2093877792358398
Iteration 38: train_loss 1.2278188467025757
Iteration 39: train_loss 1.1726994514465332
Iteration 40: train_loss 1.288200855255127
Iteration 41: train_loss 1.3163632154464722
Iteration 42: train_loss 1.3203233480453491
Iteration 43: train_loss 1.2517207860946655
Iteration 44: train_loss 1.2727481126785278
Iteration 45: train_loss 1.2914183139801025
Iteration 46: train_loss 1.198316216468811
Iteration 47: train_loss 1.2378370761871338
Iteration 48: train_loss 1.3269906044006348
Iteration 49: train_loss 1.291501522064209
Iteration 50: train_loss 1.2560150623321533
Iteration 51: train_loss 1.3174874782562256
Iteration 52: train_loss 1.2715516090393066
Iteration 53: train_loss 1.28500497341156
Iteration 54: train_loss 1.277988314628601
Iteration 55: train_loss 1.305456280708313
Iteration 56: train_loss 1.226655125617981
Iteration 57: train_loss 1.2213044166564941
Iteration 58: train_loss 1.2409495115280151
Iteration 59: train_loss 1.2586044073104858
Iteration 60: train_loss 1.2451189756393433
Iteration 61: train_loss 1.280941128730774
Iteration 62: train_loss 1.2669429779052734
Iteration 63: train_loss 1.2312175035476685
Iteration 64: train_loss 1.235972285270691
Iteration 65: train_loss 1.2256275415420532
Iteration 66: train_loss 1.2536202669143677
Iteration 67: train_loss 1.2977149486541748
Iteration 68: train_loss 1.3018662929534912
Iteration 69: train_loss 1.3221558332443237
Iteration 70: train_loss 1.2408335208892822
Iteration 71: train_loss 1.3032914400100708
Iteration 72: train_loss 1.2663047313690186
Iteration 73: train_loss 1.2064898014068604
Iteration 74: train_loss 1.2919883728027344
Iteration 75: train_loss 1.2272835969924927
Iteration 76: train_loss 1.237096905708313
Iteration 77: train_loss 1.2176318168640137
Iteration 78: train_loss 1.2720502614974976
Iteration 79: train_loss 1.2395755052566528
Iteration 80: train_loss 1.2587206363677979
Iteration 81: train_loss 1.2788851261138916
Iteration 82: train_loss 1.3069608211517334
Iteration 83: train_loss 1.2780413627624512
Iteration 84: train_loss 1.2597606182098389
Iteration 85: train_loss 1.2104861736297607
Iteration 86: train_loss 1.268012285232544
Iteration 87: train_loss 1.207976222038269
Iteration 88: train_loss 1.282047986984253
Iteration 89: train_loss 1.2748180627822876
Iteration 90: train_loss 1.286346197128296
Iteration 91: train_loss 1.2704286575317383
Iteration 92: train_loss 1.2624895572662354
Iteration 93: train_loss 1.2946717739105225
Iteration 94: train_loss 1.2563631534576416
Iteration 95: train_loss 1.2976057529449463
Iteration 96: train_loss 1.3264933824539185
Iteration 97: train_loss 1.362031102180481
Iteration 98: train_loss 1.2389254570007324
Iteration 99: train_loss 1.2387908697128296
Iteration 100: train_loss 1.2418630123138428
Iteration 101: train_loss 1.2393338680267334
Iteration 102: train_loss 1.2737542390823364
Iteration 103: train_loss 1.2942804098129272
Iteration 104: train_loss 1.3405978679656982
Iteration 105: train_loss 1.364156723022461
Iteration 106: train_loss 1.2869185209274292
Iteration 107: train_loss 1.3231706619262695
Iteration 108: train_loss 1.3020927906036377
Iteration 109: train_loss 1.3270024061203003
Iteration 110: train_loss 1.3703322410583496
Iteration 111: train_loss 1.3457030057907104
Iteration 112: train_loss 1.348489761352539
Iteration 113: train_loss 1.268445372581482
Iteration 114: train_loss 1.3417797088623047
Iteration 115: train_loss 1.2520411014556885
Iteration 116: train_loss 1.336092472076416
Iteration 117: train_loss 1.2954598665237427
Iteration 118: train_loss 1.3081310987472534
Iteration 119: train_loss 1.2661046981811523
Iteration 120: train_loss 1.2267104387283325
Iteration 121: train_loss 1.3450533151626587
Iteration 122: train_loss 1.3123764991760254
Iteration 123: train_loss 1.3379859924316406
Iteration 124: train_loss 1.277632474899292
Iteration 125: train_loss 1.3017770051956177
Iteration 126: train_loss 1.270089030265808
Iteration 127: train_loss 1.323339581489563
Iteration 128: train_loss 1.2785866260528564
Iteration 129: train_loss 1.270156741142273
Iteration 130: train_loss 1.3146369457244873
Iteration 131: train_loss 1.2834222316741943
Iteration 132: train_loss 1.2684030532836914
Iteration 133: train_loss 1.2789897918701172
Iteration 134: train_loss 1.2758725881576538
Iteration 135: train_loss 1.303366780281067
Iteration 136: train_loss 1.3062407970428467
Iteration 137: train_loss 1.3171441555023193
Iteration 138: train_loss 1.2251293659210205
Iteration 139: train_loss 1.2469693422317505
Iteration 140: train_loss 1.2828121185302734
Iteration 141: train_loss 1.2960572242736816
Iteration 142: train_loss 1.268600583076477
Iteration 143: train_loss 1.3261255025863647
Iteration 144: train_loss 1.2530920505523682
Iteration 145: train_loss 1.2705326080322266
Iteration 146: train_loss 1.3245630264282227
Iteration 147: train_loss 1.320496916770935
Iteration 148: train_loss 1.330875277519226
Iteration 149: train_loss 1.340280294418335
Iteration 150: train_loss 1.297659158706665
Iteration 151: train_loss 1.27862548828125
Iteration 152: train_loss 1.2544149160385132
Iteration 153: train_loss 1.2725452184677124
Iteration 154: train_loss 1.3069194555282593
Iteration 155: train_loss 1.2987852096557617
Iteration 156: train_loss 1.298764944076538
Iteration 157: train_loss 1.250789761543274
Iteration 158: train_loss 1.2614761590957642
Iteration 159: train_loss 1.296074628829956
Iteration 160: train_loss 1.2569328546524048
Iteration 161: train_loss 1.256494402885437
Iteration 162: train_loss 1.3250349760055542
Iteration 163: train_loss 1.2699168920516968
Iteration 164: train_loss 1.2755428552627563
Iteration 165: train_loss 1.266890048980713
Iteration 166: train_loss 1.3002872467041016
Iteration 167: train_loss 1.3226619958877563
Iteration 168: train_loss 1.3117787837982178
Iteration 169: train_loss 1.3104746341705322
Iteration 170: train_loss 1.3313524723052979
Iteration 171: train_loss 1.2872923612594604
Iteration 172: train_loss 1.2556711435317993
Iteration 173: train_loss 1.305584192276001
Iteration 174: train_loss 1.3102508783340454
Iteration 175: train_loss 1.290531039237976
Iteration 176: train_loss 1.2771772146224976
Iteration 177: train_loss 1.2868249416351318
Epoch 131: train_avg_loss 1.272098169488422 eval_avg_acc: 0.34068078610271596 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:16:26] [32mIntermediate result: 0.34068078610271596  (Index 130)[0m
================Epoch: 132================
Iteration 1: train_loss 1.2531806230545044
Iteration 2: train_loss 1.3089238405227661
Iteration 3: train_loss 1.2363338470458984
Iteration 4: train_loss 1.300851583480835
Iteration 5: train_loss 1.294808030128479
Iteration 6: train_loss 1.2481014728546143
Iteration 7: train_loss 1.2469987869262695
Iteration 8: train_loss 1.3101191520690918
Iteration 9: train_loss 1.2980287075042725
Iteration 10: train_loss 1.3250914812088013
Iteration 11: train_loss 1.306647777557373
Iteration 12: train_loss 1.2758402824401855
Iteration 13: train_loss 1.2609009742736816
Iteration 14: train_loss 1.2663040161132812
Iteration 15: train_loss 1.2458293437957764
Iteration 16: train_loss 1.2532132863998413
Iteration 17: train_loss 1.2352527379989624
Iteration 18: train_loss 1.2894713878631592
Iteration 19: train_loss 1.2622870206832886
Iteration 20: train_loss 1.2312300205230713
Iteration 21: train_loss 1.2385398149490356
Iteration 22: train_loss 1.2196768522262573
Iteration 23: train_loss 1.2573721408843994
Iteration 24: train_loss 1.28312087059021
Iteration 25: train_loss 1.235276460647583
Iteration 26: train_loss 1.2253528833389282
Iteration 27: train_loss 1.2400182485580444
Iteration 28: train_loss 1.2206063270568848
Iteration 29: train_loss 1.2537338733673096
Iteration 30: train_loss 1.210614562034607
Iteration 31: train_loss 1.2164450883865356
Iteration 32: train_loss 1.2460861206054688
Iteration 33: train_loss 1.2830984592437744
Iteration 34: train_loss 1.2304861545562744
Iteration 35: train_loss 1.2686108350753784
Iteration 36: train_loss 1.304796814918518
Iteration 37: train_loss 1.2611122131347656
Iteration 38: train_loss 1.2489378452301025
Iteration 39: train_loss 1.2490431070327759
Iteration 40: train_loss 1.3082168102264404
Iteration 41: train_loss 1.3251816034317017
Iteration 42: train_loss 1.2927931547164917
Iteration 43: train_loss 1.2750741243362427
Iteration 44: train_loss 1.2519952058792114
Iteration 45: train_loss 1.266340970993042
Iteration 46: train_loss 1.2840725183486938
Iteration 47: train_loss 1.2498564720153809
Iteration 48: train_loss 1.2887059450149536
Iteration 49: train_loss 1.2793773412704468
Iteration 50: train_loss 1.233568549156189
Iteration 51: train_loss 1.2371681928634644
Iteration 52: train_loss 1.2633651494979858
Iteration 53: train_loss 1.1477423906326294
Iteration 54: train_loss 1.2362751960754395
Iteration 55: train_loss 1.217394471168518
Iteration 56: train_loss 1.2160834074020386
Iteration 57: train_loss 1.236907958984375
Iteration 58: train_loss 1.2334800958633423
Iteration 59: train_loss 1.2532336711883545
Iteration 60: train_loss 1.2574642896652222
Iteration 61: train_loss 1.1942448616027832
Iteration 62: train_loss 1.2143067121505737
Iteration 63: train_loss 1.1985647678375244
Iteration 64: train_loss 1.2186037302017212
Iteration 65: train_loss 1.270013451576233
Iteration 66: train_loss 1.2935656309127808
Iteration 67: train_loss 1.256519079208374
Iteration 68: train_loss 1.2817143201828003
Iteration 69: train_loss 1.285873532295227
Iteration 70: train_loss 1.259779453277588
Iteration 71: train_loss 1.261370062828064
Iteration 72: train_loss 1.3038198947906494
Iteration 73: train_loss 1.2403514385223389
Iteration 74: train_loss 1.2539429664611816
Iteration 75: train_loss 1.3340154886245728
Iteration 76: train_loss 1.2430893182754517
Iteration 77: train_loss 1.2681525945663452
Iteration 78: train_loss 1.2773548364639282
Iteration 79: train_loss 1.2604115009307861
Iteration 80: train_loss 1.274925947189331
Iteration 81: train_loss 1.2976748943328857
Iteration 82: train_loss 1.2097108364105225
Iteration 83: train_loss 1.2780910730361938
Iteration 84: train_loss 1.2755050659179688
Iteration 85: train_loss 1.2933858633041382
Iteration 86: train_loss 1.3261017799377441
Iteration 87: train_loss 1.2696794271469116
Iteration 88: train_loss 1.2572636604309082
Iteration 89: train_loss 1.2986536026000977
Iteration 90: train_loss 1.282906174659729
Iteration 91: train_loss 1.2746696472167969
Iteration 92: train_loss 1.259931206703186
Iteration 93: train_loss 1.3037264347076416
Iteration 94: train_loss 1.2826160192489624
Iteration 95: train_loss 1.325393557548523
Iteration 96: train_loss 1.2331324815750122
Iteration 97: train_loss 1.262108325958252
Iteration 98: train_loss 1.336820363998413
Iteration 99: train_loss 1.269114375114441
Iteration 100: train_loss 1.352738618850708
Iteration 101: train_loss 1.2902097702026367
Iteration 102: train_loss 1.2261457443237305
Iteration 103: train_loss 1.2777785062789917
Iteration 104: train_loss 1.1616300344467163
Iteration 105: train_loss 1.3145993947982788
Iteration 106: train_loss 1.2413135766983032
Iteration 107: train_loss 1.2775331735610962
Iteration 108: train_loss 1.2435675859451294
Iteration 109: train_loss 1.328959345817566
Iteration 110: train_loss 1.2633839845657349
Iteration 111: train_loss 1.2419459819793701
Iteration 112: train_loss 1.2601534128189087
Iteration 113: train_loss 1.2951507568359375
Iteration 114: train_loss 1.3371785879135132
Iteration 115: train_loss 1.2456663846969604
Iteration 116: train_loss 1.2821805477142334
Iteration 117: train_loss 1.247641682624817
Iteration 118: train_loss 1.3214536905288696
Iteration 119: train_loss 1.2676762342453003
Iteration 120: train_loss 1.2784208059310913
Iteration 121: train_loss 1.2997410297393799
Iteration 122: train_loss 1.2796399593353271
Iteration 123: train_loss 1.3624550104141235
Iteration 124: train_loss 1.2690318822860718
Iteration 125: train_loss 1.2171356678009033
Iteration 126: train_loss 1.2299307584762573
Iteration 127: train_loss 1.294857382774353
Iteration 128: train_loss 1.3054273128509521
Iteration 129: train_loss 1.305814266204834
Iteration 130: train_loss 1.2600536346435547
Iteration 131: train_loss 1.2795276641845703
Iteration 132: train_loss 1.2208036184310913
Iteration 133: train_loss 1.2774080038070679
Iteration 134: train_loss 1.2759438753128052
Iteration 135: train_loss 1.2954180240631104
Iteration 136: train_loss 1.2325679063796997
Iteration 137: train_loss 1.263015866279602
Iteration 138: train_loss 1.2728767395019531
Iteration 139: train_loss 1.2390263080596924
Iteration 140: train_loss 1.252291202545166
Iteration 141: train_loss 1.2910820245742798
Iteration 142: train_loss 1.2533257007598877
Iteration 143: train_loss 1.2484934329986572
Iteration 144: train_loss 1.2596553564071655
Iteration 145: train_loss 1.3388690948486328
Iteration 146: train_loss 1.232537031173706
Iteration 147: train_loss 1.2507591247558594
Iteration 148: train_loss 1.3062108755111694
Iteration 149: train_loss 1.291763186454773
Iteration 150: train_loss 1.3394068479537964
Iteration 151: train_loss 1.2374941110610962
Iteration 152: train_loss 1.2008247375488281
Iteration 153: train_loss 1.3485792875289917
Iteration 154: train_loss 1.2648100852966309
Iteration 155: train_loss 1.3433222770690918
Iteration 156: train_loss 1.2553223371505737
Iteration 157: train_loss 1.2995535135269165
Iteration 158: train_loss 1.289707064628601
Iteration 159: train_loss 1.2620458602905273
Iteration 160: train_loss 1.2907302379608154
Iteration 161: train_loss 1.3458119630813599
Iteration 162: train_loss 1.2845653295516968
Iteration 163: train_loss 1.2380521297454834
Iteration 164: train_loss 1.3413163423538208
Iteration 165: train_loss 1.3348286151885986
Iteration 166: train_loss 1.3409655094146729
Iteration 167: train_loss 1.3074150085449219
Iteration 168: train_loss 1.3274903297424316
Iteration 169: train_loss 1.2968591451644897
Iteration 170: train_loss 1.2988053560256958
Iteration 171: train_loss 1.258802890777588
Iteration 172: train_loss 1.24339759349823
Iteration 173: train_loss 1.2542041540145874
Iteration 174: train_loss 1.3214213848114014
Iteration 175: train_loss 1.2488126754760742
Iteration 176: train_loss 1.3133691549301147
Iteration 177: train_loss 1.314376950263977
Epoch 132: train_avg_loss 1.2705481672017587 eval_avg_acc: 0.3499190265972926 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:17:05] [32mIntermediate result: 0.3499190265972926  (Index 131)[0m
================Epoch: 133================
Iteration 1: train_loss 1.2260791063308716
Iteration 2: train_loss 1.2079558372497559
Iteration 3: train_loss 1.24892258644104
Iteration 4: train_loss 1.2588609457015991
Iteration 5: train_loss 1.2626014947891235
Iteration 6: train_loss 1.2379826307296753
Iteration 7: train_loss 1.2907191514968872
Iteration 8: train_loss 1.283425211906433
Iteration 9: train_loss 1.246817708015442
Iteration 10: train_loss 1.2233080863952637
Iteration 11: train_loss 1.2100987434387207
Iteration 12: train_loss 1.2048999071121216
Iteration 13: train_loss 1.184478998184204
Iteration 14: train_loss 1.265589714050293
Iteration 15: train_loss 1.2205893993377686
Iteration 16: train_loss 1.2259281873703003
Iteration 17: train_loss 1.235208511352539
Iteration 18: train_loss 1.1475549936294556
Iteration 19: train_loss 1.291571021080017
Iteration 20: train_loss 1.226963996887207
Iteration 21: train_loss 1.2314106225967407
Iteration 22: train_loss 1.2694257497787476
Iteration 23: train_loss 1.267741322517395
Iteration 24: train_loss 1.1983249187469482
Iteration 25: train_loss 1.1834142208099365
Iteration 26: train_loss 1.2113666534423828
Iteration 27: train_loss 1.2551417350769043
Iteration 28: train_loss 1.2373137474060059
Iteration 29: train_loss 1.2706143856048584
Iteration 30: train_loss 1.1991491317749023
Iteration 31: train_loss 1.237780213356018
Iteration 32: train_loss 1.263415813446045
Iteration 33: train_loss 1.2445865869522095
Iteration 34: train_loss 1.1739368438720703
Iteration 35: train_loss 1.2760900259017944
Iteration 36: train_loss 1.2006300687789917
Iteration 37: train_loss 1.2217564582824707
Iteration 38: train_loss 1.277882695198059
Iteration 39: train_loss 1.2067718505859375
Iteration 40: train_loss 1.257157325744629
Iteration 41: train_loss 1.2106412649154663
Iteration 42: train_loss 1.2338297367095947
Iteration 43: train_loss 1.2696263790130615
Iteration 44: train_loss 1.2489458322525024
Iteration 45: train_loss 1.2137787342071533
Iteration 46: train_loss 1.247719168663025
Iteration 47: train_loss 1.236011266708374
Iteration 48: train_loss 1.2368372678756714
Iteration 49: train_loss 1.2689955234527588
Iteration 50: train_loss 1.2403720617294312
Iteration 51: train_loss 1.2542214393615723
Iteration 52: train_loss 1.2524616718292236
Iteration 53: train_loss 1.2347161769866943
Iteration 54: train_loss 1.2441028356552124
Iteration 55: train_loss 1.2092875242233276
Iteration 56: train_loss 1.241371989250183
Iteration 57: train_loss 1.2650146484375
Iteration 58: train_loss 1.260381817817688
Iteration 59: train_loss 1.271128535270691
Iteration 60: train_loss 1.2465025186538696
Iteration 61: train_loss 1.2966103553771973
Iteration 62: train_loss 1.3098264932632446
Iteration 63: train_loss 1.2335655689239502
Iteration 64: train_loss 1.2400665283203125
Iteration 65: train_loss 1.2597484588623047
Iteration 66: train_loss 1.2075504064559937
Iteration 67: train_loss 1.270254373550415
Iteration 68: train_loss 1.2692155838012695
Iteration 69: train_loss 1.2248139381408691
Iteration 70: train_loss 1.278848648071289
Iteration 71: train_loss 1.3114079236984253
Iteration 72: train_loss 1.248515248298645
Iteration 73: train_loss 1.2635458707809448
Iteration 74: train_loss 1.186203122138977
Iteration 75: train_loss 1.2888261079788208
Iteration 76: train_loss 1.2864975929260254
Iteration 77: train_loss 1.2569900751113892
Iteration 78: train_loss 1.3336392641067505
Iteration 79: train_loss 1.3091226816177368
Iteration 80: train_loss 1.3010152578353882
Iteration 81: train_loss 1.2539334297180176
Iteration 82: train_loss 1.3135517835617065
Iteration 83: train_loss 1.2345831394195557
Iteration 84: train_loss 1.2748960256576538
Iteration 85: train_loss 1.2635180950164795
Iteration 86: train_loss 1.2388111352920532
Iteration 87: train_loss 1.287185549736023
Iteration 88: train_loss 1.2619236707687378
Iteration 89: train_loss 1.2509446144104004
Iteration 90: train_loss 1.3238568305969238
Iteration 91: train_loss 1.2560311555862427
Iteration 92: train_loss 1.2466459274291992
Iteration 93: train_loss 1.2860186100006104
Iteration 94: train_loss 1.2624707221984863
Iteration 95: train_loss 1.2701407670974731
Iteration 96: train_loss 1.3213390111923218
Iteration 97: train_loss 1.259927749633789
Iteration 98: train_loss 1.2589575052261353
Iteration 99: train_loss 1.2519419193267822
Iteration 100: train_loss 1.3006985187530518
Iteration 101: train_loss 1.3348060846328735
Iteration 102: train_loss 1.266209363937378
Iteration 103: train_loss 1.3092496395111084
Iteration 104: train_loss 1.288878083229065
Iteration 105: train_loss 1.3155996799468994
Iteration 106: train_loss 1.2602109909057617
Iteration 107: train_loss 1.3067750930786133
Iteration 108: train_loss 1.3171244859695435
Iteration 109: train_loss 1.3028090000152588
Iteration 110: train_loss 1.2863938808441162
Iteration 111: train_loss 1.3121181726455688
Iteration 112: train_loss 1.257897138595581
Iteration 113: train_loss 1.302676796913147
Iteration 114: train_loss 1.2903693914413452
Iteration 115: train_loss 1.299774408340454
Iteration 116: train_loss 1.3590353727340698
Iteration 117: train_loss 1.2860162258148193
Iteration 118: train_loss 1.2712082862854004
Iteration 119: train_loss 1.3218841552734375
Iteration 120: train_loss 1.3286157846450806
Iteration 121: train_loss 1.2614229917526245
Iteration 122: train_loss 1.3590632677078247
Iteration 123: train_loss 1.2805930376052856
Iteration 124: train_loss 1.3259034156799316
Iteration 125: train_loss 1.2924937009811401
Iteration 126: train_loss 1.24564790725708
Iteration 127: train_loss 1.2362942695617676
Iteration 128: train_loss 1.2763394117355347
Iteration 129: train_loss 1.2447479963302612
Iteration 130: train_loss 1.1980314254760742
Iteration 131: train_loss 1.2432475090026855
Iteration 132: train_loss 1.261927843093872
Iteration 133: train_loss 1.2476378679275513
Iteration 134: train_loss 1.305761456489563
Iteration 135: train_loss 1.3065344095230103
Iteration 136: train_loss 1.2371703386306763
Iteration 137: train_loss 1.2903484106063843
Iteration 138: train_loss 1.2763497829437256
Iteration 139: train_loss 1.2570346593856812
Iteration 140: train_loss 1.248331069946289
Iteration 141: train_loss 1.2730501890182495
Iteration 142: train_loss 1.216909646987915
Iteration 143: train_loss 1.282282829284668
Iteration 144: train_loss 1.2160050868988037
Iteration 145: train_loss 1.259295105934143
Iteration 146: train_loss 1.2333738803863525
Iteration 147: train_loss 1.2016034126281738
Iteration 148: train_loss 1.2166128158569336
Iteration 149: train_loss 1.205176591873169
Iteration 150: train_loss 1.2244561910629272
Iteration 151: train_loss 1.2557584047317505
Iteration 152: train_loss 1.2593892812728882
Iteration 153: train_loss 1.2274515628814697
Iteration 154: train_loss 1.2332098484039307
Iteration 155: train_loss 1.313522458076477
Iteration 156: train_loss 1.2044724225997925
Iteration 157: train_loss 1.2362284660339355
Iteration 158: train_loss 1.2487305402755737
Iteration 159: train_loss 1.2535085678100586
Iteration 160: train_loss 1.271442174911499
Iteration 161: train_loss 1.2656638622283936
Iteration 162: train_loss 1.2770614624023438
Iteration 163: train_loss 1.2292367219924927
Iteration 164: train_loss 1.2956613302230835
Iteration 165: train_loss 1.2970486879348755
Iteration 166: train_loss 1.2643723487854004
Iteration 167: train_loss 1.2613333463668823
Iteration 168: train_loss 1.2339329719543457
Iteration 169: train_loss 1.2874765396118164
Iteration 170: train_loss 1.22188401222229
Iteration 171: train_loss 1.224671483039856
Iteration 172: train_loss 1.265331745147705
Iteration 173: train_loss 1.2837873697280884
Iteration 174: train_loss 1.2150949239730835
Iteration 175: train_loss 1.2300456762313843
Iteration 176: train_loss 1.2764558792114258
Iteration 177: train_loss 1.2560781240463257
Epoch 133: train_avg_loss 1.2581536803541884 eval_avg_acc: 0.34966420896989786 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:17:43] [32mIntermediate result: 0.34966420896989786  (Index 132)[0m
================Epoch: 134================
Iteration 1: train_loss 1.204907774925232
Iteration 2: train_loss 1.2352559566497803
Iteration 3: train_loss 1.2428638935089111
Iteration 4: train_loss 1.2609087228775024
Iteration 5: train_loss 1.2204419374465942
Iteration 6: train_loss 1.2625552415847778
Iteration 7: train_loss 1.2252739667892456
Iteration 8: train_loss 1.2228007316589355
Iteration 9: train_loss 1.2587897777557373
Iteration 10: train_loss 1.2707237005233765
Iteration 11: train_loss 1.2921885251998901
Iteration 12: train_loss 1.2481476068496704
Iteration 13: train_loss 1.3185590505599976
Iteration 14: train_loss 1.221165418624878
Iteration 15: train_loss 1.207208514213562
Iteration 16: train_loss 1.2281759977340698
Iteration 17: train_loss 1.2235393524169922
Iteration 18: train_loss 1.2607958316802979
Iteration 19: train_loss 1.2505844831466675
Iteration 20: train_loss 1.2685855627059937
Iteration 21: train_loss 1.2763946056365967
Iteration 22: train_loss 1.2296288013458252
Iteration 23: train_loss 1.2084754705429077
Iteration 24: train_loss 1.2623891830444336
Iteration 25: train_loss 1.241955280303955
Iteration 26: train_loss 1.2611243724822998
Iteration 27: train_loss 1.268688678741455
Iteration 28: train_loss 1.2552340030670166
Iteration 29: train_loss 1.2837661504745483
Iteration 30: train_loss 1.3089275360107422
Iteration 31: train_loss 1.2976152896881104
Iteration 32: train_loss 1.2714403867721558
Iteration 33: train_loss 1.2564858198165894
Iteration 34: train_loss 1.2669481039047241
Iteration 35: train_loss 1.2736903429031372
Iteration 36: train_loss 1.2859567403793335
Iteration 37: train_loss 1.2210534811019897
Iteration 38: train_loss 1.2664453983306885
Iteration 39: train_loss 1.2311177253723145
Iteration 40: train_loss 1.2543586492538452
Iteration 41: train_loss 1.206505298614502
Iteration 42: train_loss 1.1997320652008057
Iteration 43: train_loss 1.2680870294570923
Iteration 44: train_loss 1.1983994245529175
Iteration 45: train_loss 1.2665376663208008
Iteration 46: train_loss 1.2217410802841187
Iteration 47: train_loss 1.214959740638733
Iteration 48: train_loss 1.2615835666656494
Iteration 49: train_loss 1.1738383769989014
Iteration 50: train_loss 1.2521930932998657
Iteration 51: train_loss 1.1857221126556396
Iteration 52: train_loss 1.308318018913269
Iteration 53: train_loss 1.2263507843017578
Iteration 54: train_loss 1.2542024850845337
Iteration 55: train_loss 1.269195795059204
Iteration 56: train_loss 1.2557722330093384
Iteration 57: train_loss 1.1690019369125366
Iteration 58: train_loss 1.256093978881836
Iteration 59: train_loss 1.2464878559112549
Iteration 60: train_loss 1.2612308263778687
Iteration 61: train_loss 1.245290756225586
Iteration 62: train_loss 1.2145733833312988
Iteration 63: train_loss 1.2800021171569824
Iteration 64: train_loss 1.2985188961029053
Iteration 65: train_loss 1.2307206392288208
Iteration 66: train_loss 1.2877776622772217
Iteration 67: train_loss 1.2899647951126099
Iteration 68: train_loss 1.195360779762268
Iteration 69: train_loss 1.2232259511947632
Iteration 70: train_loss 1.2262557744979858
Iteration 71: train_loss 1.3162610530853271
Iteration 72: train_loss 1.279530644416809
Iteration 73: train_loss 1.2183233499526978
Iteration 74: train_loss 1.2506892681121826
Iteration 75: train_loss 1.2691349983215332
Iteration 76: train_loss 1.2730952501296997
Iteration 77: train_loss 1.2618881464004517
Iteration 78: train_loss 1.2613955736160278
Iteration 79: train_loss 1.2316229343414307
Iteration 80: train_loss 1.2498363256454468
Iteration 81: train_loss 1.2627813816070557
Iteration 82: train_loss 1.3093847036361694
Iteration 83: train_loss 1.27222740650177
Iteration 84: train_loss 1.2830297946929932
Iteration 85: train_loss 1.253333568572998
Iteration 86: train_loss 1.2588552236557007
Iteration 87: train_loss 1.2023838758468628
Iteration 88: train_loss 1.2552103996276855
Iteration 89: train_loss 1.2969119548797607
Iteration 90: train_loss 1.2110025882720947
Iteration 91: train_loss 1.2740319967269897
Iteration 92: train_loss 1.2407395839691162
Iteration 93: train_loss 1.2579046487808228
Iteration 94: train_loss 1.2469948530197144
Iteration 95: train_loss 1.1714317798614502
Iteration 96: train_loss 1.2135519981384277
Iteration 97: train_loss 1.188438057899475
Iteration 98: train_loss 1.2600276470184326
Iteration 99: train_loss 1.2817673683166504
Iteration 100: train_loss 1.219216227531433
Iteration 101: train_loss 1.1770668029785156
Iteration 102: train_loss 1.2191296815872192
Iteration 103: train_loss 1.238763451576233
Iteration 104: train_loss 1.250523328781128
Iteration 105: train_loss 1.2416276931762695
Iteration 106: train_loss 1.247883915901184
Iteration 107: train_loss 1.2330243587493896
Iteration 108: train_loss 1.2780652046203613
Iteration 109: train_loss 1.262997031211853
Iteration 110: train_loss 1.3031245470046997
Iteration 111: train_loss 1.2259382009506226
Iteration 112: train_loss 1.2565349340438843
Iteration 113: train_loss 1.2599021196365356
Iteration 114: train_loss 1.2710691690444946
Iteration 115: train_loss 1.260511040687561
Iteration 116: train_loss 1.3056316375732422
Iteration 117: train_loss 1.2561362981796265
Iteration 118: train_loss 1.171958088874817
Iteration 119: train_loss 1.285443663597107
Iteration 120: train_loss 1.2292180061340332
Iteration 121: train_loss 1.2544246912002563
Iteration 122: train_loss 1.2391172647476196
Iteration 123: train_loss 1.2467031478881836
Iteration 124: train_loss 1.2606476545333862
Iteration 125: train_loss 1.240646481513977
Iteration 126: train_loss 1.3119901418685913
Iteration 127: train_loss 1.226576328277588
Iteration 128: train_loss 1.221046805381775
Iteration 129: train_loss 1.2460312843322754
Iteration 130: train_loss 1.1645803451538086
Iteration 131: train_loss 1.2340786457061768
Iteration 132: train_loss 1.2070143222808838
Iteration 133: train_loss 1.2507600784301758
Iteration 134: train_loss 1.221718192100525
Iteration 135: train_loss 1.2459017038345337
Iteration 136: train_loss 1.2960225343704224
Iteration 137: train_loss 1.2937915325164795
Iteration 138: train_loss 1.2532036304473877
Iteration 139: train_loss 1.2865368127822876
Iteration 140: train_loss 1.2361335754394531
Iteration 141: train_loss 1.2564045190811157
Iteration 142: train_loss 1.256563663482666
Iteration 143: train_loss 1.2923444509506226
Iteration 144: train_loss 1.2593449354171753
Iteration 145: train_loss 1.2300702333450317
Iteration 146: train_loss 1.2751787900924683
Iteration 147: train_loss 1.2625004053115845
Iteration 148: train_loss 1.2356270551681519
Iteration 149: train_loss 1.2295087575912476
Iteration 150: train_loss 1.2629808187484741
Iteration 151: train_loss 1.3182529211044312
Iteration 152: train_loss 1.2745674848556519
Iteration 153: train_loss 1.246286392211914
Iteration 154: train_loss 1.264379858970642
Iteration 155: train_loss 1.2245161533355713
Iteration 156: train_loss 1.2842711210250854
Iteration 157: train_loss 1.2254304885864258
Iteration 158: train_loss 1.2379165887832642
Iteration 159: train_loss 1.2442374229431152
Iteration 160: train_loss 1.2762342691421509
Iteration 161: train_loss 1.1980310678482056
Iteration 162: train_loss 1.2446717023849487
Iteration 163: train_loss 1.2526782751083374
Iteration 164: train_loss 1.3204896450042725
Iteration 165: train_loss 1.2455347776412964
Iteration 166: train_loss 1.2563726902008057
Iteration 167: train_loss 1.2732930183410645
Iteration 168: train_loss 1.3029347658157349
Iteration 169: train_loss 1.216342806816101
Iteration 170: train_loss 1.2102099657058716
Iteration 171: train_loss 1.2181305885314941
Iteration 172: train_loss 1.2549443244934082
Iteration 173: train_loss 1.2256932258605957
Iteration 174: train_loss 1.24541175365448
Iteration 175: train_loss 1.2484662532806396
Iteration 176: train_loss 1.2658369541168213
Iteration 177: train_loss 1.258187174797058
Epoch 134: train_avg_loss 1.2497691212400879 eval_avg_acc: 0.35036490500320794 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:18:24] [32mIntermediate result: 0.35036490500320794  (Index 133)[0m
================Epoch: 135================
Iteration 1: train_loss 1.2243854999542236
Iteration 2: train_loss 1.2016724348068237
Iteration 3: train_loss 1.2271205186843872
Iteration 4: train_loss 1.2210086584091187
Iteration 5: train_loss 1.2558863162994385
Iteration 6: train_loss 1.2379573583602905
Iteration 7: train_loss 1.2474764585494995
Iteration 8: train_loss 1.1999567747116089
Iteration 9: train_loss 1.293006181716919
Iteration 10: train_loss 1.2022664546966553
Iteration 11: train_loss 1.2910770177841187
Iteration 12: train_loss 1.2337336540222168
Iteration 13: train_loss 1.2326381206512451
Iteration 14: train_loss 1.2321438789367676
Iteration 15: train_loss 1.2498352527618408
Iteration 16: train_loss 1.209736943244934
Iteration 17: train_loss 1.313714861869812
Iteration 18: train_loss 1.1891963481903076
Iteration 19: train_loss 1.270668864250183
Iteration 20: train_loss 1.2742903232574463
Iteration 21: train_loss 1.194697380065918
Iteration 22: train_loss 1.2423518896102905
Iteration 23: train_loss 1.207068920135498
Iteration 24: train_loss 1.2351748943328857
Iteration 25: train_loss 1.2133471965789795
Iteration 26: train_loss 1.2241499423980713
Iteration 27: train_loss 1.27053964138031
Iteration 28: train_loss 1.25604248046875
Iteration 29: train_loss 1.2546213865280151
Iteration 30: train_loss 1.3063417673110962
Iteration 31: train_loss 1.2763097286224365
Iteration 32: train_loss 1.2821519374847412
Iteration 33: train_loss 1.2914481163024902
Iteration 34: train_loss 1.2309696674346924
Iteration 35: train_loss 1.2916843891143799
Iteration 36: train_loss 1.2428631782531738
Iteration 37: train_loss 1.239397406578064
Iteration 38: train_loss 1.2084728479385376
Iteration 39: train_loss 1.2800620794296265
Iteration 40: train_loss 1.2635319232940674
Iteration 41: train_loss 1.2586214542388916
Iteration 42: train_loss 1.1329975128173828
Iteration 43: train_loss 1.2317240238189697
Iteration 44: train_loss 1.2339377403259277
Iteration 45: train_loss 1.261207938194275
Iteration 46: train_loss 1.2068244218826294
Iteration 47: train_loss 1.27513587474823
Iteration 48: train_loss 1.2709975242614746
Iteration 49: train_loss 1.2270543575286865
Iteration 50: train_loss 1.214347243309021
Iteration 51: train_loss 1.23935866355896
Iteration 52: train_loss 1.2741303443908691
Iteration 53: train_loss 1.193172812461853
Iteration 54: train_loss 1.1869598627090454
Iteration 55: train_loss 1.2222352027893066
Iteration 56: train_loss 1.2347631454467773
Iteration 57: train_loss 1.222338318824768
Iteration 58: train_loss 1.2368167638778687
Iteration 59: train_loss 1.2696648836135864
Iteration 60: train_loss 1.2542195320129395
Iteration 61: train_loss 1.2716755867004395
Iteration 62: train_loss 1.270517110824585
Iteration 63: train_loss 1.268854022026062
Iteration 64: train_loss 1.2457237243652344
Iteration 65: train_loss 1.236910343170166
Iteration 66: train_loss 1.241380214691162
Iteration 67: train_loss 1.2309812307357788
Iteration 68: train_loss 1.1771392822265625
Iteration 69: train_loss 1.2824314832687378
Iteration 70: train_loss 1.2515103816986084
Iteration 71: train_loss 1.301529884338379
Iteration 72: train_loss 1.2470489740371704
Iteration 73: train_loss 1.2471768856048584
Iteration 74: train_loss 1.2904764413833618
Iteration 75: train_loss 1.266109585762024
Iteration 76: train_loss 1.2381731271743774
Iteration 77: train_loss 1.1984690427780151
Iteration 78: train_loss 1.2819944620132446
Iteration 79: train_loss 1.1954913139343262
Iteration 80: train_loss 1.2842341661453247
Iteration 81: train_loss 1.338458776473999
Iteration 82: train_loss 1.261129379272461
Iteration 83: train_loss 1.2632813453674316
Iteration 84: train_loss 1.2582958936691284
Iteration 85: train_loss 1.2733724117279053
Iteration 86: train_loss 1.2339133024215698
Iteration 87: train_loss 1.2549561262130737
Iteration 88: train_loss 1.2165312767028809
Iteration 89: train_loss 1.2538189888000488
Iteration 90: train_loss 1.282362937927246
Iteration 91: train_loss 1.2391114234924316
Iteration 92: train_loss 1.2805200815200806
Iteration 93: train_loss 1.2298614978790283
Iteration 94: train_loss 1.2501274347305298
Iteration 95: train_loss 1.2812551259994507
Iteration 96: train_loss 1.2426743507385254
Iteration 97: train_loss 1.2450411319732666
Iteration 98: train_loss 1.289088249206543
Iteration 99: train_loss 1.272009015083313
Iteration 100: train_loss 1.2534842491149902
Iteration 101: train_loss 1.278208613395691
Iteration 102: train_loss 1.2085506916046143
Iteration 103: train_loss 1.2652223110198975
Iteration 104: train_loss 1.242753028869629
Iteration 105: train_loss 1.2689214944839478
Iteration 106: train_loss 1.2581912279129028
Iteration 107: train_loss 1.2592381238937378
Iteration 108: train_loss 1.2724578380584717
Iteration 109: train_loss 1.2517338991165161
Iteration 110: train_loss 1.2785989046096802
Iteration 111: train_loss 1.2743637561798096
Iteration 112: train_loss 1.252482533454895
Iteration 113: train_loss 1.184674620628357
Iteration 114: train_loss 1.2428102493286133
Iteration 115: train_loss 1.3084012269973755
Iteration 116: train_loss 1.2784394025802612
Iteration 117: train_loss 1.2601555585861206
Iteration 118: train_loss 1.2519137859344482
Iteration 119: train_loss 1.2555102109909058
Iteration 120: train_loss 1.222744345664978
Iteration 121: train_loss 1.2645796537399292
Iteration 122: train_loss 1.2243685722351074
Iteration 123: train_loss 1.2368884086608887
Iteration 124: train_loss 1.2080347537994385
Iteration 125: train_loss 1.2347452640533447
Iteration 126: train_loss 1.2396925687789917
Iteration 127: train_loss 1.2449491024017334
Iteration 128: train_loss 1.2212082147598267
Iteration 129: train_loss 1.2210921049118042
Iteration 130: train_loss 1.2558082342147827
Iteration 131: train_loss 1.3247500658035278
Iteration 132: train_loss 1.3094381093978882
Iteration 133: train_loss 1.258409857749939
Iteration 134: train_loss 1.211907982826233
Iteration 135: train_loss 1.204206943511963
Iteration 136: train_loss 1.2381151914596558
Iteration 137: train_loss 1.2503039836883545
Iteration 138: train_loss 1.2788084745407104
Iteration 139: train_loss 1.2812525033950806
Iteration 140: train_loss 1.1329280138015747
Iteration 141: train_loss 1.2113066911697388
Iteration 142: train_loss 1.2446964979171753
Iteration 143: train_loss 1.2573339939117432
Iteration 144: train_loss 1.258673906326294
Iteration 145: train_loss 1.2670255899429321
Iteration 146: train_loss 1.2802997827529907
Iteration 147: train_loss 1.2613167762756348
Iteration 148: train_loss 1.3104832172393799
Iteration 149: train_loss 1.2367467880249023
Iteration 150: train_loss 1.1756987571716309
Iteration 151: train_loss 1.2117998600006104
Iteration 152: train_loss 1.2660553455352783
Iteration 153: train_loss 1.2293533086776733
Iteration 154: train_loss 1.2924212217330933
Iteration 155: train_loss 1.2455432415008545
Iteration 156: train_loss 1.3134019374847412
Iteration 157: train_loss 1.2162292003631592
Iteration 158: train_loss 1.2712050676345825
Iteration 159: train_loss 1.2818491458892822
Iteration 160: train_loss 1.2789080142974854
Iteration 161: train_loss 1.2989184856414795
Iteration 162: train_loss 1.2322046756744385
Iteration 163: train_loss 1.267867088317871
Iteration 164: train_loss 1.2630776166915894
Iteration 165: train_loss 1.3339159488677979
Iteration 166: train_loss 1.289697527885437
Iteration 167: train_loss 1.2744876146316528
Iteration 168: train_loss 1.294392466545105
Iteration 169: train_loss 1.2103793621063232
Iteration 170: train_loss 1.2362241744995117
Iteration 171: train_loss 1.2377028465270996
Iteration 172: train_loss 1.2360678911209106
Iteration 173: train_loss 1.2266241312026978
Iteration 174: train_loss 1.2494564056396484
Iteration 175: train_loss 1.250510573387146
Iteration 176: train_loss 1.3029849529266357
Iteration 177: train_loss 1.2102692127227783
Epoch 135: train_avg_loss 1.249687094472896 eval_avg_acc: 0.3450986294571506 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:19:05] [32mIntermediate result: 0.3450986294571506  (Index 134)[0m
================Epoch: 136================
Iteration 1: train_loss 1.2823277711868286
Iteration 2: train_loss 1.3103705644607544
Iteration 3: train_loss 1.2594351768493652
Iteration 4: train_loss 1.2170093059539795
Iteration 5: train_loss 1.2719151973724365
Iteration 6: train_loss 1.2843356132507324
Iteration 7: train_loss 1.2825400829315186
Iteration 8: train_loss 1.2479171752929688
Iteration 9: train_loss 1.259653091430664
Iteration 10: train_loss 1.2484806776046753
Iteration 11: train_loss 1.215462565422058
Iteration 12: train_loss 1.2620575428009033
Iteration 13: train_loss 1.2027292251586914
Iteration 14: train_loss 1.176956057548523
Iteration 15: train_loss 1.232410192489624
Iteration 16: train_loss 1.252020001411438
Iteration 17: train_loss 1.218947172164917
Iteration 18: train_loss 1.1883409023284912
Iteration 19: train_loss 1.2314270734786987
Iteration 20: train_loss 1.2188637256622314
Iteration 21: train_loss 1.2261234521865845
Iteration 22: train_loss 1.2663016319274902
Iteration 23: train_loss 1.2378320693969727
Iteration 24: train_loss 1.2141705751419067
Iteration 25: train_loss 1.2836534976959229
Iteration 26: train_loss 1.213426947593689
Iteration 27: train_loss 1.2724188566207886
Iteration 28: train_loss 1.2686834335327148
Iteration 29: train_loss 1.266147255897522
Iteration 30: train_loss 1.2792422771453857
Iteration 31: train_loss 1.30125093460083
Iteration 32: train_loss 1.2914612293243408
Iteration 33: train_loss 1.2952665090560913
Iteration 34: train_loss 1.251535177230835
Iteration 35: train_loss 1.256453514099121
Iteration 36: train_loss 1.3018208742141724
Iteration 37: train_loss 1.2871841192245483
Iteration 38: train_loss 1.2709280252456665
Iteration 39: train_loss 1.2194652557373047
Iteration 40: train_loss 1.2392393350601196
Iteration 41: train_loss 1.2604970932006836
Iteration 42: train_loss 1.2826749086380005
Iteration 43: train_loss 1.207432508468628
Iteration 44: train_loss 1.2788153886795044
Iteration 45: train_loss 1.249077320098877
Iteration 46: train_loss 1.2658109664916992
Iteration 47: train_loss 1.2833222150802612
Iteration 48: train_loss 1.217315673828125
Iteration 49: train_loss 1.2180956602096558
Iteration 50: train_loss 1.2449781894683838
Iteration 51: train_loss 1.1898976564407349
Iteration 52: train_loss 1.2169557809829712
Iteration 53: train_loss 1.2514647245407104
Iteration 54: train_loss 1.2482411861419678
Iteration 55: train_loss 1.2270772457122803
Iteration 56: train_loss 1.2533929347991943
Iteration 57: train_loss 1.2347867488861084
Iteration 58: train_loss 1.2481274604797363
Iteration 59: train_loss 1.2547284364700317
Iteration 60: train_loss 1.2509053945541382
Iteration 61: train_loss 1.1872979402542114
Iteration 62: train_loss 1.2769469022750854
Iteration 63: train_loss 1.246030330657959
Iteration 64: train_loss 1.2945528030395508
Iteration 65: train_loss 1.2162538766860962
Iteration 66: train_loss 1.2102394104003906
Iteration 67: train_loss 1.228947639465332
Iteration 68: train_loss 1.3039759397506714
Iteration 69: train_loss 1.2588478326797485
Iteration 70: train_loss 1.2757421731948853
Iteration 71: train_loss 1.25420343875885
Iteration 72: train_loss 1.2277244329452515
Iteration 73: train_loss 1.2659058570861816
Iteration 74: train_loss 1.2537668943405151
Iteration 75: train_loss 1.270648717880249
Iteration 76: train_loss 1.331891417503357
Iteration 77: train_loss 1.2735830545425415
Iteration 78: train_loss 1.2685089111328125
Iteration 79: train_loss 1.2857425212860107
Iteration 80: train_loss 1.3315672874450684
Iteration 81: train_loss 1.3141556978225708
Iteration 82: train_loss 1.3069123029708862
Iteration 83: train_loss 1.2758781909942627
Iteration 84: train_loss 1.2880303859710693
Iteration 85: train_loss 1.3051114082336426
Iteration 86: train_loss 1.3210258483886719
Iteration 87: train_loss 1.366757869720459
Iteration 88: train_loss 1.231199860572815
Iteration 89: train_loss 1.2675926685333252
Iteration 90: train_loss 1.313447117805481
Iteration 91: train_loss 1.2745977640151978
Iteration 92: train_loss 1.2310348749160767
Iteration 93: train_loss 1.260340690612793
Iteration 94: train_loss 1.250400185585022
Iteration 95: train_loss 1.265355110168457
Iteration 96: train_loss 1.2722967863082886
Iteration 97: train_loss 1.2614569664001465
Iteration 98: train_loss 1.2775719165802002
Iteration 99: train_loss 1.2741986513137817
Iteration 100: train_loss 1.2368428707122803
Iteration 101: train_loss 1.2182036638259888
Iteration 102: train_loss 1.2477947473526
Iteration 103: train_loss 1.2832595109939575
Iteration 104: train_loss 1.2804362773895264
Iteration 105: train_loss 1.297982096672058
Iteration 106: train_loss 1.2754517793655396
Iteration 107: train_loss 1.2610507011413574
Iteration 108: train_loss 1.302431344985962
Iteration 109: train_loss 1.2338144779205322
Iteration 110: train_loss 1.2335675954818726
Iteration 111: train_loss 1.2452067136764526
Iteration 112: train_loss 1.2155182361602783
Iteration 113: train_loss 1.2476081848144531
Iteration 114: train_loss 1.2609012126922607
Iteration 115: train_loss 1.3145370483398438
Iteration 116: train_loss 1.327091097831726
Iteration 117: train_loss 1.29209303855896
Iteration 118: train_loss 1.2594220638275146
Iteration 119: train_loss 1.2435543537139893
Iteration 120: train_loss 1.2736365795135498
Iteration 121: train_loss 1.318581461906433
Iteration 122: train_loss 1.294777750968933
Iteration 123: train_loss 1.3235610723495483
Iteration 124: train_loss 1.3147978782653809
Iteration 125: train_loss 1.2716647386550903
Iteration 126: train_loss 1.2432993650436401
Iteration 127: train_loss 1.220474123954773
Iteration 128: train_loss 1.2899436950683594
Iteration 129: train_loss 1.2489454746246338
Iteration 130: train_loss 1.2592377662658691
Iteration 131: train_loss 1.2700588703155518
Iteration 132: train_loss 1.254685640335083
Iteration 133: train_loss 1.2882355451583862
Iteration 134: train_loss 1.221667766571045
Iteration 135: train_loss 1.3776013851165771
Iteration 136: train_loss 1.2983028888702393
Iteration 137: train_loss 1.3324769735336304
Iteration 138: train_loss 1.2923166751861572
Iteration 139: train_loss 1.276682734489441
Iteration 140: train_loss 1.2814253568649292
Iteration 141: train_loss 1.3258349895477295
Iteration 142: train_loss 1.264918327331543
Iteration 143: train_loss 1.2347890138626099
Iteration 144: train_loss 1.2832533121109009
Iteration 145: train_loss 1.2841123342514038
Iteration 146: train_loss 1.1802304983139038
Iteration 147: train_loss 1.203240156173706
Iteration 148: train_loss 1.2214107513427734
Iteration 149: train_loss 1.2045354843139648
Iteration 150: train_loss 1.2534518241882324
Iteration 151: train_loss 1.2521296739578247
Iteration 152: train_loss 1.2504342794418335
Iteration 153: train_loss 1.3013789653778076
Iteration 154: train_loss 1.2110767364501953
Iteration 155: train_loss 1.266442894935608
Iteration 156: train_loss 1.2309093475341797
Iteration 157: train_loss 1.2325568199157715
Iteration 158: train_loss 1.250983476638794
Iteration 159: train_loss 1.1994317770004272
Iteration 160: train_loss 1.2099924087524414
Iteration 161: train_loss 1.2941380739212036
Iteration 162: train_loss 1.2731307744979858
Iteration 163: train_loss 1.2759549617767334
Iteration 164: train_loss 1.3068888187408447
Iteration 165: train_loss 1.2852872610092163
Iteration 166: train_loss 1.328628659248352
Iteration 167: train_loss 1.2994111776351929
Iteration 168: train_loss 1.363662838935852
Iteration 169: train_loss 1.2694480419158936
Iteration 170: train_loss 1.287582516670227
Iteration 171: train_loss 1.2798235416412354
Iteration 172: train_loss 1.2724311351776123
Iteration 173: train_loss 1.2862180471420288
Iteration 174: train_loss 1.2994141578674316
Iteration 175: train_loss 1.2821818590164185
Iteration 176: train_loss 1.310282588005066
Iteration 177: train_loss 1.1825391054153442
Epoch 136: train_avg_loss 1.263256613817592 eval_avg_acc: 0.34127739157877124 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:19:44] [32mIntermediate result: 0.34127739157877124  (Index 135)[0m
================Epoch: 137================
Iteration 1: train_loss 1.2300281524658203
Iteration 2: train_loss 1.228865623474121
Iteration 3: train_loss 1.243017315864563
Iteration 4: train_loss 1.206191897392273
Iteration 5: train_loss 1.2576578855514526
Iteration 6: train_loss 1.2379515171051025
Iteration 7: train_loss 1.2410223484039307
Iteration 8: train_loss 1.2580419778823853
Iteration 9: train_loss 1.2728191614151
Iteration 10: train_loss 1.2475316524505615
Iteration 11: train_loss 1.2818565368652344
Iteration 12: train_loss 1.249968409538269
Iteration 13: train_loss 1.32273530960083
Iteration 14: train_loss 1.2897182703018188
Iteration 15: train_loss 1.2269072532653809
Iteration 16: train_loss 1.256947636604309
Iteration 17: train_loss 1.3306782245635986
Iteration 18: train_loss 1.2793023586273193
Iteration 19: train_loss 1.2925864458084106
Iteration 20: train_loss 1.2909728288650513
Iteration 21: train_loss 1.283496618270874
Iteration 22: train_loss 1.2984927892684937
Iteration 23: train_loss 1.2933411598205566
Iteration 24: train_loss 1.2729482650756836
Iteration 25: train_loss 1.2969112396240234
Iteration 26: train_loss 1.3140333890914917
Iteration 27: train_loss 1.2246497869491577
Iteration 28: train_loss 1.2815616130828857
Iteration 29: train_loss 1.3334383964538574
Iteration 30: train_loss 1.3358163833618164
Iteration 31: train_loss 1.2939561605453491
Iteration 32: train_loss 1.3061834573745728
Iteration 33: train_loss 1.1983357667922974
Iteration 34: train_loss 1.2309443950653076
Iteration 35: train_loss 1.2267513275146484
Iteration 36: train_loss 1.210188865661621
Iteration 37: train_loss 1.2143595218658447
Iteration 38: train_loss 1.249179720878601
Iteration 39: train_loss 1.238990306854248
Iteration 40: train_loss 1.2482796907424927
Iteration 41: train_loss 1.1954700946807861
Iteration 42: train_loss 1.2906994819641113
Iteration 43: train_loss 1.2344948053359985
Iteration 44: train_loss 1.2439095973968506
Iteration 45: train_loss 1.2435455322265625
Iteration 46: train_loss 1.2373697757720947
Iteration 47: train_loss 1.2859739065170288
Iteration 48: train_loss 1.179201602935791
Iteration 49: train_loss 1.2379696369171143
Iteration 50: train_loss 1.264830231666565
Iteration 51: train_loss 1.2491265535354614
Iteration 52: train_loss 1.236687421798706
Iteration 53: train_loss 1.2562832832336426
Iteration 54: train_loss 1.273705244064331
Iteration 55: train_loss 1.3280823230743408
Iteration 56: train_loss 1.256561040878296
Iteration 57: train_loss 1.229224443435669
Iteration 58: train_loss 1.3484046459197998
Iteration 59: train_loss 1.2269110679626465
Iteration 60: train_loss 1.2099254131317139
Iteration 61: train_loss 1.2264776229858398
Iteration 62: train_loss 1.2133738994598389
Iteration 63: train_loss 1.2821835279464722
Iteration 64: train_loss 1.219038486480713
Iteration 65: train_loss 1.2535632848739624
Iteration 66: train_loss 1.2594019174575806
Iteration 67: train_loss 1.2213701009750366
Iteration 68: train_loss 1.2359168529510498
Iteration 69: train_loss 1.2741261720657349
Iteration 70: train_loss 1.2569403648376465
Iteration 71: train_loss 1.2233879566192627
Iteration 72: train_loss 1.273335337638855
Iteration 73: train_loss 1.2332640886306763
Iteration 74: train_loss 1.2670682668685913
Iteration 75: train_loss 1.2830625772476196
Iteration 76: train_loss 1.2721067667007446
Iteration 77: train_loss 1.214327335357666
Iteration 78: train_loss 1.302306056022644
Iteration 79: train_loss 1.167768955230713
Iteration 80: train_loss 1.2939757108688354
Iteration 81: train_loss 1.2511533498764038
Iteration 82: train_loss 1.2175464630126953
Iteration 83: train_loss 1.2452882528305054
Iteration 84: train_loss 1.2648390531539917
Iteration 85: train_loss 1.2338449954986572
Iteration 86: train_loss 1.2944910526275635
Iteration 87: train_loss 1.211891770362854
Iteration 88: train_loss 1.2870063781738281
Iteration 89: train_loss 1.2539036273956299
Iteration 90: train_loss 1.200857400894165
Iteration 91: train_loss 1.2480621337890625
Iteration 92: train_loss 1.277256965637207
Iteration 93: train_loss 1.290256142616272
Iteration 94: train_loss 1.2477960586547852
Iteration 95: train_loss 1.2379947900772095
Iteration 96: train_loss 1.2717630863189697
Iteration 97: train_loss 1.2569838762283325
Iteration 98: train_loss 1.2809922695159912
Iteration 99: train_loss 1.1593724489212036
Iteration 100: train_loss 1.268441081047058
Iteration 101: train_loss 1.286296010017395
Iteration 102: train_loss 1.2151235342025757
Iteration 103: train_loss 1.285521388053894
Iteration 104: train_loss 1.2511742115020752
Iteration 105: train_loss 1.3014053106307983
Iteration 106: train_loss 1.2508678436279297
Iteration 107: train_loss 1.2610769271850586
Iteration 108: train_loss 1.2088114023208618
Iteration 109: train_loss 1.3103268146514893
Iteration 110: train_loss 1.2918070554733276
Iteration 111: train_loss 1.2760781049728394
Iteration 112: train_loss 1.3120229244232178
Iteration 113: train_loss 1.2770390510559082
Iteration 114: train_loss 1.263875961303711
Iteration 115: train_loss 1.2729305028915405
Iteration 116: train_loss 1.3382848501205444
Iteration 117: train_loss 1.2850089073181152
Iteration 118: train_loss 1.2416455745697021
Iteration 119: train_loss 1.2537976503372192
Iteration 120: train_loss 1.208295226097107
Iteration 121: train_loss 1.2725722789764404
Iteration 122: train_loss 1.2968335151672363
Iteration 123: train_loss 1.220909595489502
Iteration 124: train_loss 1.220550537109375
Iteration 125: train_loss 1.2215126752853394
Iteration 126: train_loss 1.2237176895141602
Iteration 127: train_loss 1.2118393182754517
Iteration 128: train_loss 1.2461833953857422
Iteration 129: train_loss 1.2227944135665894
Iteration 130: train_loss 1.2292078733444214
Iteration 131: train_loss 1.2592231035232544
Iteration 132: train_loss 1.2409873008728027
Iteration 133: train_loss 1.2423533201217651
Iteration 134: train_loss 1.198325514793396
Iteration 135: train_loss 1.2845090627670288
Iteration 136: train_loss 1.2421033382415771
Iteration 137: train_loss 1.3067207336425781
Iteration 138: train_loss 1.2477290630340576
Iteration 139: train_loss 1.2447409629821777
Iteration 140: train_loss 1.196964144706726
Iteration 141: train_loss 1.249495506286621
Iteration 142: train_loss 1.2182981967926025
Iteration 143: train_loss 1.2232104539871216
Iteration 144: train_loss 1.2311005592346191
Iteration 145: train_loss 1.2206528186798096
Iteration 146: train_loss 1.264955997467041
Iteration 147: train_loss 1.2096917629241943
Iteration 148: train_loss 1.2408576011657715
Iteration 149: train_loss 1.2055407762527466
Iteration 150: train_loss 1.227720022201538
Iteration 151: train_loss 1.2870537042617798
Iteration 152: train_loss 1.2498655319213867
Iteration 153: train_loss 1.289478063583374
Iteration 154: train_loss 1.2067664861679077
Iteration 155: train_loss 1.220924735069275
Iteration 156: train_loss 1.200496792793274
Iteration 157: train_loss 1.209303617477417
Iteration 158: train_loss 1.2735856771469116
Iteration 159: train_loss 1.241720199584961
Iteration 160: train_loss 1.2521398067474365
Iteration 161: train_loss 1.2491859197616577
Iteration 162: train_loss 1.2362064123153687
Iteration 163: train_loss 1.2481894493103027
Iteration 164: train_loss 1.2540408372879028
Iteration 165: train_loss 1.2591660022735596
Iteration 166: train_loss 1.264623761177063
Iteration 167: train_loss 1.2356492280960083
Iteration 168: train_loss 1.270298957824707
Iteration 169: train_loss 1.1979191303253174
Iteration 170: train_loss 1.2380726337432861
Iteration 171: train_loss 1.2544242143630981
Iteration 172: train_loss 1.2671799659729004
Iteration 173: train_loss 1.2477238178253174
Iteration 174: train_loss 1.2953563928604126
Iteration 175: train_loss 1.2674720287322998
Iteration 176: train_loss 1.2424668073654175
Iteration 177: train_loss 1.2736471891403198
Epoch 137: train_avg_loss 1.2533526575497989 eval_avg_acc: 0.34505827183545745 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:20:25] [32mIntermediate result: 0.34505827183545745  (Index 136)[0m
================Epoch: 138================
Iteration 1: train_loss 1.219138741493225
Iteration 2: train_loss 1.2198970317840576
Iteration 3: train_loss 1.2089513540267944
Iteration 4: train_loss 1.2642838954925537
Iteration 5: train_loss 1.2482565641403198
Iteration 6: train_loss 1.1959996223449707
Iteration 7: train_loss 1.230809211730957
Iteration 8: train_loss 1.2354505062103271
Iteration 9: train_loss 1.2083402872085571
Iteration 10: train_loss 1.1365677118301392
Iteration 11: train_loss 1.2302637100219727
Iteration 12: train_loss 1.2302554845809937
Iteration 13: train_loss 1.1889281272888184
Iteration 14: train_loss 1.2134320735931396
Iteration 15: train_loss 1.21029531955719
Iteration 16: train_loss 1.235558032989502
Iteration 17: train_loss 1.2603280544281006
Iteration 18: train_loss 1.2606853246688843
Iteration 19: train_loss 1.215657114982605
Iteration 20: train_loss 1.2789920568466187
Iteration 21: train_loss 1.22136390209198
Iteration 22: train_loss 1.2007925510406494
Iteration 23: train_loss 1.2348405122756958
Iteration 24: train_loss 1.2857630252838135
Iteration 25: train_loss 1.282981514930725
Iteration 26: train_loss 1.2453999519348145
Iteration 27: train_loss 1.2352045774459839
Iteration 28: train_loss 1.222425937652588
Iteration 29: train_loss 1.271907091140747
Iteration 30: train_loss 1.2626489400863647
Iteration 31: train_loss 1.2254799604415894
Iteration 32: train_loss 1.2767459154129028
Iteration 33: train_loss 1.2352374792099
Iteration 34: train_loss 1.2362297773361206
Iteration 35: train_loss 1.2584960460662842
Iteration 36: train_loss 1.2454391717910767
Iteration 37: train_loss 1.1901332139968872
Iteration 38: train_loss 1.1785682439804077
Iteration 39: train_loss 1.2992665767669678
Iteration 40: train_loss 1.2562452554702759
Iteration 41: train_loss 1.252983808517456
Iteration 42: train_loss 1.2182538509368896
Iteration 43: train_loss 1.2837244272232056
Iteration 44: train_loss 1.225724458694458
Iteration 45: train_loss 1.2443536520004272
Iteration 46: train_loss 1.2361984252929688
Iteration 47: train_loss 1.215524673461914
Iteration 48: train_loss 1.2194916009902954
Iteration 49: train_loss 1.2663471698760986
Iteration 50: train_loss 1.205507755279541
Iteration 51: train_loss 1.2177231311798096
Iteration 52: train_loss 1.2513673305511475
Iteration 53: train_loss 1.237375020980835
Iteration 54: train_loss 1.2577077150344849
Iteration 55: train_loss 1.2357990741729736
Iteration 56: train_loss 1.1733723878860474
Iteration 57: train_loss 1.2406718730926514
Iteration 58: train_loss 1.2682864665985107
Iteration 59: train_loss 1.2776787281036377
Iteration 60: train_loss 1.224602222442627
Iteration 61: train_loss 1.2644610404968262
Iteration 62: train_loss 1.2625027894973755
Iteration 63: train_loss 1.2114624977111816
Iteration 64: train_loss 1.2766739130020142
Iteration 65: train_loss 1.2579933404922485
Iteration 66: train_loss 1.242379069328308
Iteration 67: train_loss 1.2303106784820557
Iteration 68: train_loss 1.2219927310943604
Iteration 69: train_loss 1.1854207515716553
Iteration 70: train_loss 1.2405893802642822
Iteration 71: train_loss 1.3222776651382446
Iteration 72: train_loss 1.2541272640228271
Iteration 73: train_loss 1.2551274299621582
Iteration 74: train_loss 1.2803254127502441
Iteration 75: train_loss 1.2926740646362305
Iteration 76: train_loss 1.2560527324676514
Iteration 77: train_loss 1.223581075668335
Iteration 78: train_loss 1.3061103820800781
Iteration 79: train_loss 1.244606614112854
Iteration 80: train_loss 1.288640022277832
Iteration 81: train_loss 1.2557711601257324
Iteration 82: train_loss 1.2175918817520142
Iteration 83: train_loss 1.2481179237365723
Iteration 84: train_loss 1.2271308898925781
Iteration 85: train_loss 1.2484426498413086
Iteration 86: train_loss 1.233457088470459
Iteration 87: train_loss 1.2417423725128174
Iteration 88: train_loss 1.2805265188217163
Iteration 89: train_loss 1.2466462850570679
Iteration 90: train_loss 1.2137131690979004
Iteration 91: train_loss 1.2524663209915161
Iteration 92: train_loss 1.2167197465896606
Iteration 93: train_loss 1.2501931190490723
Iteration 94: train_loss 1.2541605234146118
Iteration 95: train_loss 1.235255479812622
Iteration 96: train_loss 1.2756879329681396
Iteration 97: train_loss 1.2044428586959839
Iteration 98: train_loss 1.2842434644699097
Iteration 99: train_loss 1.292459487915039
Iteration 100: train_loss 1.249289870262146
Iteration 101: train_loss 1.2915958166122437
Iteration 102: train_loss 1.2712392807006836
Iteration 103: train_loss 1.2546875476837158
Iteration 104: train_loss 1.2991480827331543
Iteration 105: train_loss 1.2816483974456787
Iteration 106: train_loss 1.2255734205245972
Iteration 107: train_loss 1.2164496183395386
Iteration 108: train_loss 1.282884120941162
Iteration 109: train_loss 1.3404890298843384
Iteration 110: train_loss 1.2387816905975342
Iteration 111: train_loss 1.2416270971298218
Iteration 112: train_loss 1.2739275693893433
Iteration 113: train_loss 1.2331088781356812
Iteration 114: train_loss 1.2472026348114014
Iteration 115: train_loss 1.2368059158325195
Iteration 116: train_loss 1.2415097951889038
Iteration 117: train_loss 1.2566801309585571
Iteration 118: train_loss 1.2810722589492798
Iteration 119: train_loss 1.232913613319397
Iteration 120: train_loss 1.290426254272461
Iteration 121: train_loss 1.2802799940109253
Iteration 122: train_loss 1.290775179862976
Iteration 123: train_loss 1.265920639038086
Iteration 124: train_loss 1.197628140449524
Iteration 125: train_loss 1.1771165132522583
Iteration 126: train_loss 1.266715407371521
Iteration 127: train_loss 1.232418179512024
Iteration 128: train_loss 1.2389562129974365
Iteration 129: train_loss 1.2461804151535034
Iteration 130: train_loss 1.2171624898910522
Iteration 131: train_loss 1.3063923120498657
Iteration 132: train_loss 1.2223149538040161
Iteration 133: train_loss 1.1968953609466553
Iteration 134: train_loss 1.231108546257019
Iteration 135: train_loss 1.3372070789337158
Iteration 136: train_loss 1.2703014612197876
Iteration 137: train_loss 1.2082304954528809
Iteration 138: train_loss 1.274975061416626
Iteration 139: train_loss 1.2557687759399414
Iteration 140: train_loss 1.24976646900177
Iteration 141: train_loss 1.3064401149749756
Iteration 142: train_loss 1.2577260732650757
Iteration 143: train_loss 1.1848610639572144
Iteration 144: train_loss 1.2545067071914673
Iteration 145: train_loss 1.2356010675430298
Iteration 146: train_loss 1.2258985042572021
Iteration 147: train_loss 1.298423171043396
Iteration 148: train_loss 1.2663568258285522
Iteration 149: train_loss 1.2413763999938965
Iteration 150: train_loss 1.2993226051330566
Iteration 151: train_loss 1.2947639226913452
Iteration 152: train_loss 1.2753384113311768
Iteration 153: train_loss 1.2557120323181152
Iteration 154: train_loss 1.276515007019043
Iteration 155: train_loss 1.2721003293991089
Iteration 156: train_loss 1.2877284288406372
Iteration 157: train_loss 1.2300318479537964
Iteration 158: train_loss 1.2889955043792725
Iteration 159: train_loss 1.2482044696807861
Iteration 160: train_loss 1.279131531715393
Iteration 161: train_loss 1.3173993825912476
Iteration 162: train_loss 1.2872859239578247
Iteration 163: train_loss 1.324523687362671
Iteration 164: train_loss 1.3332105875015259
Iteration 165: train_loss 1.2991801500320435
Iteration 166: train_loss 1.302115797996521
Iteration 167: train_loss 1.2817898988723755
Iteration 168: train_loss 1.2989107370376587
Iteration 169: train_loss 1.2666754722595215
Iteration 170: train_loss 1.2533838748931885
Iteration 171: train_loss 1.2879855632781982
Iteration 172: train_loss 1.24245285987854
Iteration 173: train_loss 1.3201491832733154
Iteration 174: train_loss 1.2691473960876465
Iteration 175: train_loss 1.297087550163269
Iteration 176: train_loss 1.2363890409469604
Iteration 177: train_loss 1.3291757106781006
Epoch 138: train_avg_loss 1.251893236812225 eval_avg_acc: 0.3470423382665301 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:21:06] [32mIntermediate result: 0.3470423382665301  (Index 137)[0m
================Epoch: 139================
Iteration 1: train_loss 1.2287379503250122
Iteration 2: train_loss 1.2113083600997925
Iteration 3: train_loss 1.1689804792404175
Iteration 4: train_loss 1.2291232347488403
Iteration 5: train_loss 1.2159422636032104
Iteration 6: train_loss 1.2665841579437256
Iteration 7: train_loss 1.247029185295105
Iteration 8: train_loss 1.1728163957595825
Iteration 9: train_loss 1.215688943862915
Iteration 10: train_loss 1.2463314533233643
Iteration 11: train_loss 1.177741527557373
Iteration 12: train_loss 1.1751259565353394
Iteration 13: train_loss 1.2508785724639893
Iteration 14: train_loss 1.2261970043182373
Iteration 15: train_loss 1.2392174005508423
Iteration 16: train_loss 1.183834433555603
Iteration 17: train_loss 1.1843476295471191
Iteration 18: train_loss 1.2665122747421265
Iteration 19: train_loss 1.2422575950622559
Iteration 20: train_loss 1.2143909931182861
Iteration 21: train_loss 1.201019048690796
Iteration 22: train_loss 1.1574950218200684
Iteration 23: train_loss 1.285589575767517
Iteration 24: train_loss 1.2969987392425537
Iteration 25: train_loss 1.2391432523727417
Iteration 26: train_loss 1.2317097187042236
Iteration 27: train_loss 1.2139519453048706
Iteration 28: train_loss 1.229919672012329
Iteration 29: train_loss 1.279653549194336
Iteration 30: train_loss 1.2346818447113037
Iteration 31: train_loss 1.2222927808761597
Iteration 32: train_loss 1.25753915309906
Iteration 33: train_loss 1.2516225576400757
Iteration 34: train_loss 1.3003990650177002
Iteration 35: train_loss 1.3182735443115234
Iteration 36: train_loss 1.2735779285430908
Iteration 37: train_loss 1.3057829141616821
Iteration 38: train_loss 1.2793103456497192
Iteration 39: train_loss 1.2285590171813965
Iteration 40: train_loss 1.2197669744491577
Iteration 41: train_loss 1.2575550079345703
Iteration 42: train_loss 1.2256454229354858
Iteration 43: train_loss 1.2867469787597656
Iteration 44: train_loss 1.2309699058532715
Iteration 45: train_loss 1.2591078281402588
Iteration 46: train_loss 1.2625463008880615
Iteration 47: train_loss 1.2294305562973022
Iteration 48: train_loss 1.2618260383605957
Iteration 49: train_loss 1.255449652671814
Iteration 50: train_loss 1.212324857711792
Iteration 51: train_loss 1.2094744443893433
Iteration 52: train_loss 1.2449846267700195
Iteration 53: train_loss 1.2674012184143066
Iteration 54: train_loss 1.293616771697998
Iteration 55: train_loss 1.2784875631332397
Iteration 56: train_loss 1.3021881580352783
Iteration 57: train_loss 1.3624334335327148
Iteration 58: train_loss 1.2147103548049927
Iteration 59: train_loss 1.2967524528503418
Iteration 60: train_loss 1.2482386827468872
Iteration 61: train_loss 1.2586829662322998
Iteration 62: train_loss 1.1632235050201416
Iteration 63: train_loss 1.2411407232284546
Iteration 64: train_loss 1.3070122003555298
Iteration 65: train_loss 1.2139065265655518
Iteration 66: train_loss 1.2478349208831787
Iteration 67: train_loss 1.2532085180282593
Iteration 68: train_loss 1.3036023378372192
Iteration 69: train_loss 1.2637922763824463
Iteration 70: train_loss 1.2582576274871826
Iteration 71: train_loss 1.278401494026184
Iteration 72: train_loss 1.246380090713501
Iteration 73: train_loss 1.2382872104644775
Iteration 74: train_loss 1.231856107711792
Iteration 75: train_loss 1.3255720138549805
Iteration 76: train_loss 1.2591297626495361
Iteration 77: train_loss 1.2561371326446533
Iteration 78: train_loss 1.2381925582885742
Iteration 79: train_loss 1.239033579826355
Iteration 80: train_loss 1.2389336824417114
Iteration 81: train_loss 1.3278425931930542
Iteration 82: train_loss 1.2037049531936646
Iteration 83: train_loss 1.2749775648117065
Iteration 84: train_loss 1.2284557819366455
Iteration 85: train_loss 1.2149304151535034
Iteration 86: train_loss 1.2432738542556763
Iteration 87: train_loss 1.2461801767349243
Iteration 88: train_loss 1.1650304794311523
Iteration 89: train_loss 1.235101580619812
Iteration 90: train_loss 1.289570927619934
Iteration 91: train_loss 1.2543483972549438
Iteration 92: train_loss 1.220584511756897
Iteration 93: train_loss 1.2840601205825806
Iteration 94: train_loss 1.2954989671707153
Iteration 95: train_loss 1.2331818342208862
Iteration 96: train_loss 1.2402403354644775
Iteration 97: train_loss 1.1885563135147095
Iteration 98: train_loss 1.27138352394104
Iteration 99: train_loss 1.1856435537338257
Iteration 100: train_loss 1.2274444103240967
Iteration 101: train_loss 1.2439061403274536
Iteration 102: train_loss 1.2594122886657715
Iteration 103: train_loss 1.2351160049438477
Iteration 104: train_loss 1.2345786094665527
Iteration 105: train_loss 1.1952062845230103
Iteration 106: train_loss 1.2260701656341553
Iteration 107: train_loss 1.1743974685668945
Iteration 108: train_loss 1.2356157302856445
Iteration 109: train_loss 1.2471815347671509
Iteration 110: train_loss 1.2925549745559692
Iteration 111: train_loss 1.223366618156433
Iteration 112: train_loss 1.1606332063674927
Iteration 113: train_loss 1.2173025608062744
Iteration 114: train_loss 1.2104758024215698
Iteration 115: train_loss 1.2086821794509888
Iteration 116: train_loss 1.2589722871780396
Iteration 117: train_loss 1.2065001726150513
Iteration 118: train_loss 1.2312943935394287
Iteration 119: train_loss 1.2345902919769287
Iteration 120: train_loss 1.200515866279602
Iteration 121: train_loss 1.206213355064392
Iteration 122: train_loss 1.2061989307403564
Iteration 123: train_loss 1.237488031387329
Iteration 124: train_loss 1.1997857093811035
Iteration 125: train_loss 1.229629635810852
Iteration 126: train_loss 1.2093231678009033
Iteration 127: train_loss 1.2328364849090576
Iteration 128: train_loss 1.1721302270889282
Iteration 129: train_loss 1.2393972873687744
Iteration 130: train_loss 1.236221432685852
Iteration 131: train_loss 1.3207619190216064
Iteration 132: train_loss 1.2473015785217285
Iteration 133: train_loss 1.2310457229614258
Iteration 134: train_loss 1.2506591081619263
Iteration 135: train_loss 1.2173954248428345
Iteration 136: train_loss 1.2899760007858276
Iteration 137: train_loss 1.2839707136154175
Iteration 138: train_loss 1.2205278873443604
Iteration 139: train_loss 1.2182180881500244
Iteration 140: train_loss 1.2270725965499878
Iteration 141: train_loss 1.291528344154358
Iteration 142: train_loss 1.2024269104003906
Iteration 143: train_loss 1.2201359272003174
Iteration 144: train_loss 1.3320120573043823
Iteration 145: train_loss 1.259997010231018
Iteration 146: train_loss 1.2204807996749878
Iteration 147: train_loss 1.2644463777542114
Iteration 148: train_loss 1.247177004814148
Iteration 149: train_loss 1.1975983381271362
Iteration 150: train_loss 1.2832884788513184
Iteration 151: train_loss 1.1992098093032837
Iteration 152: train_loss 1.3232030868530273
Iteration 153: train_loss 1.2626010179519653
Iteration 154: train_loss 1.3470793962478638
Iteration 155: train_loss 1.2748091220855713
Iteration 156: train_loss 1.3374050855636597
Iteration 157: train_loss 1.331510305404663
Iteration 158: train_loss 1.256898045539856
Iteration 159: train_loss 1.2697962522506714
Iteration 160: train_loss 1.2677277326583862
Iteration 161: train_loss 1.326181173324585
Iteration 162: train_loss 1.3277924060821533
Iteration 163: train_loss 1.2019360065460205
Iteration 164: train_loss 1.2447010278701782
Iteration 165: train_loss 1.2597790956497192
Iteration 166: train_loss 1.2651863098144531
Iteration 167: train_loss 1.2387961149215698
Iteration 168: train_loss 1.2351793050765991
Iteration 169: train_loss 1.3069013357162476
Iteration 170: train_loss 1.1740069389343262
Iteration 171: train_loss 1.2971642017364502
Iteration 172: train_loss 1.2943576574325562
Iteration 173: train_loss 1.2159054279327393
Iteration 174: train_loss 1.2514723539352417
Iteration 175: train_loss 1.2387973070144653
Iteration 176: train_loss 1.2119799852371216
Iteration 177: train_loss 1.3044863939285278
Epoch 139: train_avg_loss 1.2454197642493383 eval_avg_acc: 0.33934926445344615 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:21:44] [32mIntermediate result: 0.33934926445344615  (Index 138)[0m
================Epoch: 140================
Iteration 1: train_loss 1.2745990753173828
Iteration 2: train_loss 1.2068582773208618
Iteration 3: train_loss 1.2431557178497314
Iteration 4: train_loss 1.2550488710403442
Iteration 5: train_loss 1.164508581161499
Iteration 6: train_loss 1.2309119701385498
Iteration 7: train_loss 1.2254048585891724
Iteration 8: train_loss 1.20569908618927
Iteration 9: train_loss 1.2437912225723267
Iteration 10: train_loss 1.2253994941711426
Iteration 11: train_loss 1.2607872486114502
Iteration 12: train_loss 1.2177095413208008
Iteration 13: train_loss 1.2610036134719849
Iteration 14: train_loss 1.2403531074523926
Iteration 15: train_loss 1.228703498840332
Iteration 16: train_loss 1.232241153717041
Iteration 17: train_loss 1.273650884628296
Iteration 18: train_loss 1.2425048351287842
Iteration 19: train_loss 1.218649983406067
Iteration 20: train_loss 1.2324591875076294
Iteration 21: train_loss 1.2858830690383911
Iteration 22: train_loss 1.232651948928833
Iteration 23: train_loss 1.2208558320999146
Iteration 24: train_loss 1.2785965204238892
Iteration 25: train_loss 1.2397700548171997
Iteration 26: train_loss 1.2402286529541016
Iteration 27: train_loss 1.24043607711792
Iteration 28: train_loss 1.259093999862671
Iteration 29: train_loss 1.2219055891036987
Iteration 30: train_loss 1.298701524734497
Iteration 31: train_loss 1.2527629137039185
Iteration 32: train_loss 1.1900813579559326
Iteration 33: train_loss 1.1726963520050049
Iteration 34: train_loss 1.2447739839553833
Iteration 35: train_loss 1.2269837856292725
Iteration 36: train_loss 1.1657699346542358
Iteration 37: train_loss 1.1799391508102417
Iteration 38: train_loss 1.230902075767517
Iteration 39: train_loss 1.1982194185256958
Iteration 40: train_loss 1.2450919151306152
Iteration 41: train_loss 1.20094895362854
Iteration 42: train_loss 1.2009376287460327
Iteration 43: train_loss 1.191744327545166
Iteration 44: train_loss 1.2303352355957031
Iteration 45: train_loss 1.1904723644256592
Iteration 46: train_loss 1.205956220626831
Iteration 47: train_loss 1.1756075620651245
Iteration 48: train_loss 1.2205110788345337
Iteration 49: train_loss 1.2106313705444336
Iteration 50: train_loss 1.166360855102539
Iteration 51: train_loss 1.2469488382339478
Iteration 52: train_loss 1.1795985698699951
Iteration 53: train_loss 1.2019057273864746
Iteration 54: train_loss 1.1914736032485962
Iteration 55: train_loss 1.205728530883789
Iteration 56: train_loss 1.1861803531646729
Iteration 57: train_loss 1.208780288696289
Iteration 58: train_loss 1.2486376762390137
Iteration 59: train_loss 1.238180160522461
Iteration 60: train_loss 1.2562661170959473
Iteration 61: train_loss 1.190873622894287
Iteration 62: train_loss 1.2638890743255615
Iteration 63: train_loss 1.2664556503295898
Iteration 64: train_loss 1.235425591468811
Iteration 65: train_loss 1.2344322204589844
Iteration 66: train_loss 1.2189768552780151
Iteration 67: train_loss 1.2909059524536133
Iteration 68: train_loss 1.2451602220535278
Iteration 69: train_loss 1.2049839496612549
Iteration 70: train_loss 1.2207920551300049
Iteration 71: train_loss 1.2109142541885376
Iteration 72: train_loss 1.2346584796905518
Iteration 73: train_loss 1.2135932445526123
Iteration 74: train_loss 1.2749162912368774
Iteration 75: train_loss 1.2967519760131836
Iteration 76: train_loss 1.2300974130630493
Iteration 77: train_loss 1.191415548324585
Iteration 78: train_loss 1.1669347286224365
Iteration 79: train_loss 1.209210991859436
Iteration 80: train_loss 1.2048834562301636
Iteration 81: train_loss 1.1833332777023315
Iteration 82: train_loss 1.2457925081253052
Iteration 83: train_loss 1.1415200233459473
Iteration 84: train_loss 1.1893843412399292
Iteration 85: train_loss 1.2515206336975098
Iteration 86: train_loss 1.2550411224365234
Iteration 87: train_loss 1.2145780324935913
Iteration 88: train_loss 1.2329484224319458
Iteration 89: train_loss 1.2512478828430176
Iteration 90: train_loss 1.1847457885742188
Iteration 91: train_loss 1.2108838558197021
Iteration 92: train_loss 1.2600879669189453
Iteration 93: train_loss 1.2020002603530884
Iteration 94: train_loss 1.2529915571212769
Iteration 95: train_loss 1.2311145067214966
Iteration 96: train_loss 1.2600470781326294
Iteration 97: train_loss 1.266463041305542
Iteration 98: train_loss 1.2037575244903564
Iteration 99: train_loss 1.219569444656372
Iteration 100: train_loss 1.251684308052063
Iteration 101: train_loss 1.1844435930252075
Iteration 102: train_loss 1.2067080736160278
Iteration 103: train_loss 1.2007911205291748
Iteration 104: train_loss 1.2184978723526
Iteration 105: train_loss 1.2434399127960205
Iteration 106: train_loss 1.2545195817947388
Iteration 107: train_loss 1.2550652027130127
Iteration 108: train_loss 1.1777793169021606
Iteration 109: train_loss 1.2075469493865967
Iteration 110: train_loss 1.2110837697982788
Iteration 111: train_loss 1.2318543195724487
Iteration 112: train_loss 1.226986289024353
Iteration 113: train_loss 1.2753819227218628
Iteration 114: train_loss 1.2227457761764526
Iteration 115: train_loss 1.2183700799942017
Iteration 116: train_loss 1.1475001573562622
Iteration 117: train_loss 1.1883431673049927
Iteration 118: train_loss 1.2080353498458862
Iteration 119: train_loss 1.1645872592926025
Iteration 120: train_loss 1.1770460605621338
Iteration 121: train_loss 1.2300294637680054
Iteration 122: train_loss 1.2120695114135742
Iteration 123: train_loss 1.2031406164169312
Iteration 124: train_loss 1.2205297946929932
Iteration 125: train_loss 1.2276555299758911
Iteration 126: train_loss 1.241430640220642
Iteration 127: train_loss 1.2612636089324951
Iteration 128: train_loss 1.2303173542022705
Iteration 129: train_loss 1.1782687902450562
Iteration 130: train_loss 1.2378066778182983
Iteration 131: train_loss 1.2368217706680298
Iteration 132: train_loss 1.2084957361221313
Iteration 133: train_loss 1.2683393955230713
Iteration 134: train_loss 1.2165738344192505
Iteration 135: train_loss 1.2130357027053833
Iteration 136: train_loss 1.26575767993927
Iteration 137: train_loss 1.2817379236221313
Iteration 138: train_loss 1.2628467082977295
Iteration 139: train_loss 1.2853703498840332
Iteration 140: train_loss 1.2289884090423584
Iteration 141: train_loss 1.2123987674713135
Iteration 142: train_loss 1.2825859785079956
Iteration 143: train_loss 1.21249258518219
Iteration 144: train_loss 1.2476130723953247
Iteration 145: train_loss 1.2462774515151978
Iteration 146: train_loss 1.238898754119873
Iteration 147: train_loss 1.2390128374099731
Iteration 148: train_loss 1.267757773399353
Iteration 149: train_loss 1.2467358112335205
Iteration 150: train_loss 1.2341649532318115
Iteration 151: train_loss 1.2116029262542725
Iteration 152: train_loss 1.1980535984039307
Iteration 153: train_loss 1.29548180103302
Iteration 154: train_loss 1.3102389574050903
Iteration 155: train_loss 1.301987648010254
Iteration 156: train_loss 1.312760829925537
Iteration 157: train_loss 1.3069554567337036
Iteration 158: train_loss 1.200188159942627
Iteration 159: train_loss 1.2803140878677368
Iteration 160: train_loss 1.2960290908813477
Iteration 161: train_loss 1.2279362678527832
Iteration 162: train_loss 1.2699403762817383
Iteration 163: train_loss 1.339171290397644
Iteration 164: train_loss 1.2552926540374756
Iteration 165: train_loss 1.2445803880691528
Iteration 166: train_loss 1.2897169589996338
Iteration 167: train_loss 1.2521731853485107
Iteration 168: train_loss 1.2651253938674927
Iteration 169: train_loss 1.2568721771240234
Iteration 170: train_loss 1.2749959230422974
Iteration 171: train_loss 1.2599549293518066
Iteration 172: train_loss 1.3256824016571045
Iteration 173: train_loss 1.217263102531433
Iteration 174: train_loss 1.235602617263794
Iteration 175: train_loss 1.287458062171936
Iteration 176: train_loss 1.2557705640792847
Iteration 177: train_loss 1.2042427062988281
Epoch 140: train_avg_loss 1.2322853547705095 eval_avg_acc: 0.34205330236610065 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:22:23] [32mIntermediate result: 0.34205330236610065  (Index 139)[0m
================Epoch: 141================
Iteration 1: train_loss 1.2269278764724731
Iteration 2: train_loss 1.2812350988388062
Iteration 3: train_loss 1.22014319896698
Iteration 4: train_loss 1.2486581802368164
Iteration 5: train_loss 1.176688551902771
Iteration 6: train_loss 1.1776607036590576
Iteration 7: train_loss 1.2590219974517822
Iteration 8: train_loss 1.2521510124206543
Iteration 9: train_loss 1.2308064699172974
Iteration 10: train_loss 1.2542498111724854
Iteration 11: train_loss 1.3239225149154663
Iteration 12: train_loss 1.219375729560852
Iteration 13: train_loss 1.241188406944275
Iteration 14: train_loss 1.232380747795105
Iteration 15: train_loss 1.2808746099472046
Iteration 16: train_loss 1.283833622932434
Iteration 17: train_loss 1.2312825918197632
Iteration 18: train_loss 1.2513798475265503
Iteration 19: train_loss 1.2699753046035767
Iteration 20: train_loss 1.2642464637756348
Iteration 21: train_loss 1.2359528541564941
Iteration 22: train_loss 1.3202606439590454
Iteration 23: train_loss 1.2590060234069824
Iteration 24: train_loss 1.2876194715499878
Iteration 25: train_loss 1.2966407537460327
Iteration 26: train_loss 1.2878977060317993
Iteration 27: train_loss 1.2888787984848022
Iteration 28: train_loss 1.2554453611373901
Iteration 29: train_loss 1.212432622909546
Iteration 30: train_loss 1.2771848440170288
Iteration 31: train_loss 1.2383277416229248
Iteration 32: train_loss 1.2354035377502441
Iteration 33: train_loss 1.224104642868042
Iteration 34: train_loss 1.2050082683563232
Iteration 35: train_loss 1.277229905128479
Iteration 36: train_loss 1.269552230834961
Iteration 37: train_loss 1.2193032503128052
Iteration 38: train_loss 1.2303136587142944
Iteration 39: train_loss 1.232092261314392
Iteration 40: train_loss 1.2819137573242188
Iteration 41: train_loss 1.2173150777816772
Iteration 42: train_loss 1.1664789915084839
Iteration 43: train_loss 1.2189103364944458
Iteration 44: train_loss 1.1838312149047852
Iteration 45: train_loss 1.1442008018493652
Iteration 46: train_loss 1.2015180587768555
Iteration 47: train_loss 1.251805305480957
Iteration 48: train_loss 1.1994959115982056
Iteration 49: train_loss 1.2360624074935913
Iteration 50: train_loss 1.236688494682312
Iteration 51: train_loss 1.165792465209961
Iteration 52: train_loss 1.2191472053527832
Iteration 53: train_loss 1.234153389930725
Iteration 54: train_loss 1.2443360090255737
Iteration 55: train_loss 1.2634637355804443
Iteration 56: train_loss 1.223276972770691
Iteration 57: train_loss 1.2229365110397339
Iteration 58: train_loss 1.2349318265914917
Iteration 59: train_loss 1.221118688583374
Iteration 60: train_loss 1.224149227142334
Iteration 61: train_loss 1.1938468217849731
Iteration 62: train_loss 1.2266405820846558
Iteration 63: train_loss 1.20979642868042
Iteration 64: train_loss 1.3092890977859497
Iteration 65: train_loss 1.2110939025878906
Iteration 66: train_loss 1.2108213901519775
Iteration 67: train_loss 1.2283672094345093
Iteration 68: train_loss 1.3025403022766113
Iteration 69: train_loss 1.2269914150238037
Iteration 70: train_loss 1.2678444385528564
Iteration 71: train_loss 1.2206450700759888
Iteration 72: train_loss 1.203299641609192
Iteration 73: train_loss 1.221053957939148
Iteration 74: train_loss 1.2013875246047974
Iteration 75: train_loss 1.178584337234497
Iteration 76: train_loss 1.292800784111023
Iteration 77: train_loss 1.1744029521942139
Iteration 78: train_loss 1.2538901567459106
Iteration 79: train_loss 1.2186212539672852
Iteration 80: train_loss 1.239646077156067
Iteration 81: train_loss 1.2137045860290527
Iteration 82: train_loss 1.2126332521438599
Iteration 83: train_loss 1.2206268310546875
Iteration 84: train_loss 1.2396122217178345
Iteration 85: train_loss 1.2379944324493408
Iteration 86: train_loss 1.3043584823608398
Iteration 87: train_loss 1.2525873184204102
Iteration 88: train_loss 1.2388572692871094
Iteration 89: train_loss 1.1826283931732178
Iteration 90: train_loss 1.2018561363220215
Iteration 91: train_loss 1.1813398599624634
Iteration 92: train_loss 1.2804219722747803
Iteration 93: train_loss 1.177005648612976
Iteration 94: train_loss 1.2242916822433472
Iteration 95: train_loss 1.1766248941421509
Iteration 96: train_loss 1.189515471458435
Iteration 97: train_loss 1.2675704956054688
Iteration 98: train_loss 1.2511191368103027
Iteration 99: train_loss 1.2422131299972534
Iteration 100: train_loss 1.2122721672058105
Iteration 101: train_loss 1.269070029258728
Iteration 102: train_loss 1.2848855257034302
Iteration 103: train_loss 1.1930302381515503
Iteration 104: train_loss 1.26392662525177
Iteration 105: train_loss 1.2473458051681519
Iteration 106: train_loss 1.2477974891662598
Iteration 107: train_loss 1.219338297843933
Iteration 108: train_loss 1.2393866777420044
Iteration 109: train_loss 1.2940293550491333
Iteration 110: train_loss 1.2657585144042969
Iteration 111: train_loss 1.206406831741333
Iteration 112: train_loss 1.2313637733459473
Iteration 113: train_loss 1.2300360202789307
Iteration 114: train_loss 1.2808589935302734
Iteration 115: train_loss 1.2249424457550049
Iteration 116: train_loss 1.2421581745147705
Iteration 117: train_loss 1.2599550485610962
Iteration 118: train_loss 1.3007498979568481
Iteration 119: train_loss 1.236753225326538
Iteration 120: train_loss 1.2566664218902588
Iteration 121: train_loss 1.2456096410751343
Iteration 122: train_loss 1.2536617517471313
Iteration 123: train_loss 1.2779275178909302
Iteration 124: train_loss 1.2450674772262573
Iteration 125: train_loss 1.2951836585998535
Iteration 126: train_loss 1.2127728462219238
Iteration 127: train_loss 1.2718462944030762
Iteration 128: train_loss 1.2618675231933594
Iteration 129: train_loss 1.2932524681091309
Iteration 130: train_loss 1.2659070491790771
Iteration 131: train_loss 1.2348346710205078
Iteration 132: train_loss 1.2241290807724
Iteration 133: train_loss 1.2645522356033325
Iteration 134: train_loss 1.187684178352356
Iteration 135: train_loss 1.2825931310653687
Iteration 136: train_loss 1.2384790182113647
Iteration 137: train_loss 1.3315472602844238
Iteration 138: train_loss 1.2719945907592773
Iteration 139: train_loss 1.2165194749832153
Iteration 140: train_loss 1.2855876684188843
Iteration 141: train_loss 1.2467249631881714
Iteration 142: train_loss 1.3184731006622314
Iteration 143: train_loss 1.2772711515426636
Iteration 144: train_loss 1.2600115537643433
Iteration 145: train_loss 1.21735680103302
Iteration 146: train_loss 1.306685447692871
Iteration 147: train_loss 1.2680318355560303
Iteration 148: train_loss 1.3281527757644653
Iteration 149: train_loss 1.318211555480957
Iteration 150: train_loss 1.2879718542099
Iteration 151: train_loss 1.2648528814315796
Iteration 152: train_loss 1.347931981086731
Iteration 153: train_loss 1.331617832183838
Iteration 154: train_loss 1.27091646194458
Iteration 155: train_loss 1.2618789672851562
Iteration 156: train_loss 1.222273349761963
Iteration 157: train_loss 1.2868598699569702
Iteration 158: train_loss 1.259972095489502
Iteration 159: train_loss 1.2343018054962158
Iteration 160: train_loss 1.2575924396514893
Iteration 161: train_loss 1.2964006662368774
Iteration 162: train_loss 1.226768136024475
Iteration 163: train_loss 1.2851248979568481
Iteration 164: train_loss 1.2941521406173706
Iteration 165: train_loss 1.2492176294326782
Iteration 166: train_loss 1.2227742671966553
Iteration 167: train_loss 1.2972813844680786
Iteration 168: train_loss 1.1989977359771729
Iteration 169: train_loss 1.2747859954833984
Iteration 170: train_loss 1.2107670307159424
Iteration 171: train_loss 1.2143220901489258
Iteration 172: train_loss 1.2879118919372559
Iteration 173: train_loss 1.2667597532272339
Iteration 174: train_loss 1.178361415863037
Iteration 175: train_loss 1.2286456823349
Iteration 176: train_loss 1.244343638420105
Iteration 177: train_loss 1.2696152925491333
Epoch 141: train_avg_loss 1.245411162322524 eval_avg_acc: 0.3495621740886148 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:23:03] [32mIntermediate result: 0.3495621740886148  (Index 140)[0m
================Epoch: 142================
Iteration 1: train_loss 1.1763166189193726
Iteration 2: train_loss 1.2302943468093872
Iteration 3: train_loss 1.1264194250106812
Iteration 4: train_loss 1.1838048696517944
Iteration 5: train_loss 1.1737706661224365
Iteration 6: train_loss 1.2367485761642456
Iteration 7: train_loss 1.193873643875122
Iteration 8: train_loss 1.2495532035827637
Iteration 9: train_loss 1.240942358970642
Iteration 10: train_loss 1.1715986728668213
Iteration 11: train_loss 1.2512178421020508
Iteration 12: train_loss 1.2433480024337769
Iteration 13: train_loss 1.203945517539978
Iteration 14: train_loss 1.21434485912323
Iteration 15: train_loss 1.2354693412780762
Iteration 16: train_loss 1.1999584436416626
Iteration 17: train_loss 1.233139991760254
Iteration 18: train_loss 1.1607418060302734
Iteration 19: train_loss 1.2580410242080688
Iteration 20: train_loss 1.1995787620544434
Iteration 21: train_loss 1.2625021934509277
Iteration 22: train_loss 1.2221485376358032
Iteration 23: train_loss 1.246528148651123
Iteration 24: train_loss 1.1967952251434326
Iteration 25: train_loss 1.2300435304641724
Iteration 26: train_loss 1.1745555400848389
Iteration 27: train_loss 1.152698040008545
Iteration 28: train_loss 1.287930965423584
Iteration 29: train_loss 1.2188498973846436
Iteration 30: train_loss 1.2242980003356934
Iteration 31: train_loss 1.2718623876571655
Iteration 32: train_loss 1.1919318437576294
Iteration 33: train_loss 1.301504135131836
Iteration 34: train_loss 1.2364050149917603
Iteration 35: train_loss 1.23167884349823
Iteration 36: train_loss 1.2210332155227661
Iteration 37: train_loss 1.2211887836456299
Iteration 38: train_loss 1.2359014749526978
Iteration 39: train_loss 1.2254770994186401
Iteration 40: train_loss 1.3467001914978027
Iteration 41: train_loss 1.2880570888519287
Iteration 42: train_loss 1.2990237474441528
Iteration 43: train_loss 1.2704336643218994
Iteration 44: train_loss 1.2411009073257446
Iteration 45: train_loss 1.2757837772369385
Iteration 46: train_loss 1.214766263961792
Iteration 47: train_loss 1.2584079504013062
Iteration 48: train_loss 1.2590320110321045
Iteration 49: train_loss 1.2633284330368042
Iteration 50: train_loss 1.2132679224014282
Iteration 51: train_loss 1.1449168920516968
Iteration 52: train_loss 1.2273987531661987
Iteration 53: train_loss 1.213384985923767
Iteration 54: train_loss 1.221422791481018
Iteration 55: train_loss 1.2268849611282349
Iteration 56: train_loss 1.1999530792236328
Iteration 57: train_loss 1.1737128496170044
Iteration 58: train_loss 1.2346577644348145
Iteration 59: train_loss 1.2380415201187134
Iteration 60: train_loss 1.235147476196289
Iteration 61: train_loss 1.2450714111328125
Iteration 62: train_loss 1.1718770265579224
Iteration 63: train_loss 1.185159683227539
Iteration 64: train_loss 1.2137128114700317
Iteration 65: train_loss 1.2755268812179565
Iteration 66: train_loss 1.2313259840011597
Iteration 67: train_loss 1.3162280321121216
Iteration 68: train_loss 1.2546584606170654
Iteration 69: train_loss 1.3404451608657837
Iteration 70: train_loss 1.2109624147415161
Iteration 71: train_loss 1.2648489475250244
Iteration 72: train_loss 1.2896312475204468
Iteration 73: train_loss 1.2732003927230835
Iteration 74: train_loss 1.2678930759429932
Iteration 75: train_loss 1.192466378211975
Iteration 76: train_loss 1.3113716840744019
Iteration 77: train_loss 1.2646150588989258
Iteration 78: train_loss 1.1880844831466675
Iteration 79: train_loss 1.2520595788955688
Iteration 80: train_loss 1.2120307683944702
Iteration 81: train_loss 1.2778007984161377
Iteration 82: train_loss 1.2485005855560303
Iteration 83: train_loss 1.2519327402114868
Iteration 84: train_loss 1.205366611480713
Iteration 85: train_loss 1.1791141033172607
Iteration 86: train_loss 1.271916151046753
Iteration 87: train_loss 1.2302519083023071
Iteration 88: train_loss 1.2312606573104858
Iteration 89: train_loss 1.1967421770095825
Iteration 90: train_loss 1.2082345485687256
Iteration 91: train_loss 1.2188259363174438
Iteration 92: train_loss 1.1649208068847656
Iteration 93: train_loss 1.2236942052841187
Iteration 94: train_loss 1.1713296175003052
Iteration 95: train_loss 1.2780903577804565
Iteration 96: train_loss 1.1353129148483276
Iteration 97: train_loss 1.1737220287322998
Iteration 98: train_loss 1.2116402387619019
Iteration 99: train_loss 1.227786660194397
Iteration 100: train_loss 1.2428011894226074
Iteration 101: train_loss 1.2095869779586792
Iteration 102: train_loss 1.1703646183013916
Iteration 103: train_loss 1.196722149848938
Iteration 104: train_loss 1.272110939025879
Iteration 105: train_loss 1.2833293676376343
Iteration 106: train_loss 1.280030608177185
Iteration 107: train_loss 1.231147050857544
Iteration 108: train_loss 1.1980669498443604
Iteration 109: train_loss 1.2178148031234741
Iteration 110: train_loss 1.282209873199463
Iteration 111: train_loss 1.2228299379348755
Iteration 112: train_loss 1.27198326587677
Iteration 113: train_loss 1.2109876871109009
Iteration 114: train_loss 1.2512081861495972
Iteration 115: train_loss 1.2102100849151611
Iteration 116: train_loss 1.2198565006256104
Iteration 117: train_loss 1.2251131534576416
Iteration 118: train_loss 1.2780168056488037
Iteration 119: train_loss 1.2517534494400024
Iteration 120: train_loss 1.2105536460876465
Iteration 121: train_loss 1.2176142930984497
Iteration 122: train_loss 1.2460671663284302
Iteration 123: train_loss 1.2340847253799438
Iteration 124: train_loss 1.2468476295471191
Iteration 125: train_loss 1.3022929430007935
Iteration 126: train_loss 1.2825312614440918
Iteration 127: train_loss 1.2691444158554077
Iteration 128: train_loss 1.242445468902588
Iteration 129: train_loss 1.242438793182373
Iteration 130: train_loss 1.2385183572769165
Iteration 131: train_loss 1.1991477012634277
Iteration 132: train_loss 1.276613473892212
Iteration 133: train_loss 1.2419190406799316
Iteration 134: train_loss 1.2647349834442139
Iteration 135: train_loss 1.2633498907089233
Iteration 136: train_loss 1.2797930240631104
Iteration 137: train_loss 1.272004246711731
Iteration 138: train_loss 1.2450144290924072
Iteration 139: train_loss 1.2228572368621826
Iteration 140: train_loss 1.2161141633987427
Iteration 141: train_loss 1.2292213439941406
Iteration 142: train_loss 1.2327369451522827
Iteration 143: train_loss 1.2620322704315186
Iteration 144: train_loss 1.20949125289917
Iteration 145: train_loss 1.2835437059402466
Iteration 146: train_loss 1.2410911321640015
Iteration 147: train_loss 1.2240182161331177
Iteration 148: train_loss 1.1853246688842773
Iteration 149: train_loss 1.280173659324646
Iteration 150: train_loss 1.2072947025299072
Iteration 151: train_loss 1.2813869714736938
Iteration 152: train_loss 1.2543035745620728
Iteration 153: train_loss 1.2053066492080688
Iteration 154: train_loss 1.257583737373352
Iteration 155: train_loss 1.2322578430175781
Iteration 156: train_loss 1.230583906173706
Iteration 157: train_loss 1.2342932224273682
Iteration 158: train_loss 1.2777206897735596
Iteration 159: train_loss 1.2543296813964844
Iteration 160: train_loss 1.2625796794891357
Iteration 161: train_loss 1.2547557353973389
Iteration 162: train_loss 1.2067341804504395
Iteration 163: train_loss 1.2137857675552368
Iteration 164: train_loss 1.219361424446106
Iteration 165: train_loss 1.2771894931793213
Iteration 166: train_loss 1.2575056552886963
Iteration 167: train_loss 1.2606996297836304
Iteration 168: train_loss 1.1543350219726562
Iteration 169: train_loss 1.2669267654418945
Iteration 170: train_loss 1.199499249458313
Iteration 171: train_loss 1.2489713430404663
Iteration 172: train_loss 1.306068778038025
Iteration 173: train_loss 1.186405897140503
Iteration 174: train_loss 1.2341283559799194
Iteration 175: train_loss 1.2132359743118286
Iteration 176: train_loss 1.2109118700027466
Iteration 177: train_loss 1.2592030763626099
Epoch 142: train_avg_loss 1.2339248529261788 eval_avg_acc: 0.34786139551599193 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:23:44] [32mIntermediate result: 0.34786139551599193  (Index 141)[0m
================Epoch: 143================
Iteration 1: train_loss 1.2284799814224243
Iteration 2: train_loss 1.2854796648025513
Iteration 3: train_loss 1.2195500135421753
Iteration 4: train_loss 1.233481526374817
Iteration 5: train_loss 1.2071059942245483
Iteration 6: train_loss 1.2511117458343506
Iteration 7: train_loss 1.2597379684448242
Iteration 8: train_loss 1.2610942125320435
Iteration 9: train_loss 1.2515790462493896
Iteration 10: train_loss 1.2982410192489624
Iteration 11: train_loss 1.2668445110321045
Iteration 12: train_loss 1.2617908716201782
Iteration 13: train_loss 1.2586666345596313
Iteration 14: train_loss 1.247027039527893
Iteration 15: train_loss 1.2563880681991577
Iteration 16: train_loss 1.244681477546692
Iteration 17: train_loss 1.3067272901535034
Iteration 18: train_loss 1.204702377319336
Iteration 19: train_loss 1.2623939514160156
Iteration 20: train_loss 1.2310001850128174
Iteration 21: train_loss 1.194938063621521
Iteration 22: train_loss 1.2020819187164307
Iteration 23: train_loss 1.2373408079147339
Iteration 24: train_loss 1.2599761486053467
Iteration 25: train_loss 1.19477117061615
Iteration 26: train_loss 1.1735601425170898
Iteration 27: train_loss 1.2270207405090332
Iteration 28: train_loss 1.172361969947815
Iteration 29: train_loss 1.185600757598877
Iteration 30: train_loss 1.1879870891571045
Iteration 31: train_loss 1.1929335594177246
Iteration 32: train_loss 1.1932642459869385
Iteration 33: train_loss 1.2040852308273315
Iteration 34: train_loss 1.2392317056655884
Iteration 35: train_loss 1.2419590950012207
Iteration 36: train_loss 1.2046644687652588
Iteration 37: train_loss 1.1946275234222412
Iteration 38: train_loss 1.2197082042694092
Iteration 39: train_loss 1.2695152759552002
Iteration 40: train_loss 1.1641836166381836
Iteration 41: train_loss 1.2221778631210327
Iteration 42: train_loss 1.205331563949585
Iteration 43: train_loss 1.1988635063171387
Iteration 44: train_loss 1.205485463142395
Iteration 45: train_loss 1.2084605693817139
Iteration 46: train_loss 1.224279522895813
Iteration 47: train_loss 1.2164247035980225
Iteration 48: train_loss 1.1963608264923096
Iteration 49: train_loss 1.2092061042785645
Iteration 50: train_loss 1.2766528129577637
Iteration 51: train_loss 1.1882548332214355
Iteration 52: train_loss 1.2258501052856445
Iteration 53: train_loss 1.2547575235366821
Iteration 54: train_loss 1.2888047695159912
Iteration 55: train_loss 1.1983978748321533
Iteration 56: train_loss 1.2217806577682495
Iteration 57: train_loss 1.2369672060012817
Iteration 58: train_loss 1.1789708137512207
Iteration 59: train_loss 1.1952341794967651
Iteration 60: train_loss 1.1972607374191284
Iteration 61: train_loss 1.2350366115570068
Iteration 62: train_loss 1.2323493957519531
Iteration 63: train_loss 1.1995251178741455
Iteration 64: train_loss 1.1957170963287354
Iteration 65: train_loss 1.229128122329712
Iteration 66: train_loss 1.1890783309936523
Iteration 67: train_loss 1.1980080604553223
Iteration 68: train_loss 1.2335712909698486
Iteration 69: train_loss 1.2386423349380493
Iteration 70: train_loss 1.164223551750183
Iteration 71: train_loss 1.2375351190567017
Iteration 72: train_loss 1.220934510231018
Iteration 73: train_loss 1.1836161613464355
Iteration 74: train_loss 1.2215778827667236
Iteration 75: train_loss 1.2165894508361816
Iteration 76: train_loss 1.2722126245498657
Iteration 77: train_loss 1.2737687826156616
Iteration 78: train_loss 1.2760052680969238
Iteration 79: train_loss 1.2565282583236694
Iteration 80: train_loss 1.2490266561508179
Iteration 81: train_loss 1.23992121219635
Iteration 82: train_loss 1.26712167263031
Iteration 83: train_loss 1.2021751403808594
Iteration 84: train_loss 1.232072353363037
Iteration 85: train_loss 1.2416807413101196
Iteration 86: train_loss 1.2031915187835693
Iteration 87: train_loss 1.281307339668274
Iteration 88: train_loss 1.2787387371063232
Iteration 89: train_loss 1.2059651613235474
Iteration 90: train_loss 1.2518415451049805
Iteration 91: train_loss 1.2713207006454468
Iteration 92: train_loss 1.2841970920562744
Iteration 93: train_loss 1.2188470363616943
Iteration 94: train_loss 1.1632097959518433
Iteration 95: train_loss 1.2093257904052734
Iteration 96: train_loss 1.2214603424072266
Iteration 97: train_loss 1.2632032632827759
Iteration 98: train_loss 1.202022910118103
Iteration 99: train_loss 1.199047327041626
Iteration 100: train_loss 1.178605318069458
Iteration 101: train_loss 1.2167119979858398
Iteration 102: train_loss 1.2082898616790771
Iteration 103: train_loss 1.2143830060958862
Iteration 104: train_loss 1.2467750310897827
Iteration 105: train_loss 1.2778042554855347
Iteration 106: train_loss 1.2472026348114014
Iteration 107: train_loss 1.2951714992523193
Iteration 108: train_loss 1.2410993576049805
Iteration 109: train_loss 1.2248930931091309
Iteration 110: train_loss 1.208947777748108
Iteration 111: train_loss 1.2750269174575806
Iteration 112: train_loss 1.2706645727157593
Iteration 113: train_loss 1.2407324314117432
Iteration 114: train_loss 1.1911180019378662
Iteration 115: train_loss 1.2036991119384766
Iteration 116: train_loss 1.2735275030136108
Iteration 117: train_loss 1.2691705226898193
Iteration 118: train_loss 1.275692343711853
Iteration 119: train_loss 1.2145345211029053
Iteration 120: train_loss 1.2528377771377563
Iteration 121: train_loss 1.2157573699951172
Iteration 122: train_loss 1.223925232887268
Iteration 123: train_loss 1.2586772441864014
Iteration 124: train_loss 1.3679463863372803
Iteration 125: train_loss 1.2363431453704834
Iteration 126: train_loss 1.2644798755645752
Iteration 127: train_loss 1.3068053722381592
Iteration 128: train_loss 1.2705715894699097
Iteration 129: train_loss 1.2729440927505493
Iteration 130: train_loss 1.329443335533142
Iteration 131: train_loss 1.3013763427734375
Iteration 132: train_loss 1.2771096229553223
Iteration 133: train_loss 1.2691013813018799
Iteration 134: train_loss 1.2365689277648926
Iteration 135: train_loss 1.294983148574829
Iteration 136: train_loss 1.2618067264556885
Iteration 137: train_loss 1.2564377784729004
Iteration 138: train_loss 1.2584779262542725
Iteration 139: train_loss 1.2991069555282593
Iteration 140: train_loss 1.2301228046417236
Iteration 141: train_loss 1.2533009052276611
Iteration 142: train_loss 1.307091474533081
Iteration 143: train_loss 1.2346316576004028
Iteration 144: train_loss 1.2741976976394653
Iteration 145: train_loss 1.2538074254989624
Iteration 146: train_loss 1.264773964881897
Iteration 147: train_loss 1.303857445716858
Iteration 148: train_loss 1.2776139974594116
Iteration 149: train_loss 1.2304078340530396
Iteration 150: train_loss 1.2821526527404785
Iteration 151: train_loss 1.2960608005523682
Iteration 152: train_loss 1.2763627767562866
Iteration 153: train_loss 1.2896020412445068
Iteration 154: train_loss 1.2614505290985107
Iteration 155: train_loss 1.2513234615325928
Iteration 156: train_loss 1.233736515045166
Iteration 157: train_loss 1.2685091495513916
Iteration 158: train_loss 1.276638388633728
Iteration 159: train_loss 1.2955604791641235
Iteration 160: train_loss 1.2591785192489624
Iteration 161: train_loss 1.2409608364105225
Iteration 162: train_loss 1.2865358591079712
Iteration 163: train_loss 1.1364004611968994
Iteration 164: train_loss 1.2860751152038574
Iteration 165: train_loss 1.2497801780700684
Iteration 166: train_loss 1.2068065404891968
Iteration 167: train_loss 1.2195477485656738
Iteration 168: train_loss 1.2675352096557617
Iteration 169: train_loss 1.2316535711288452
Iteration 170: train_loss 1.217024803161621
Iteration 171: train_loss 1.2495245933532715
Iteration 172: train_loss 1.2630375623703003
Iteration 173: train_loss 1.3017224073410034
Iteration 174: train_loss 1.2346553802490234
Iteration 175: train_loss 1.1790168285369873
Iteration 176: train_loss 1.224638819694519
Iteration 177: train_loss 1.2880282402038574
Epoch 143: train_avg_loss 1.239758282057983 eval_avg_acc: 0.33977865313449807 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:24:24] [32mIntermediate result: 0.33977865313449807  (Index 142)[0m
================Epoch: 144================
Iteration 1: train_loss 1.2230184078216553
Iteration 2: train_loss 1.2212400436401367
Iteration 3: train_loss 1.2153432369232178
Iteration 4: train_loss 1.2467764616012573
Iteration 5: train_loss 1.2631983757019043
Iteration 6: train_loss 1.2774415016174316
Iteration 7: train_loss 1.2401148080825806
Iteration 8: train_loss 1.2186146974563599
Iteration 9: train_loss 1.2446078062057495
Iteration 10: train_loss 1.1826725006103516
Iteration 11: train_loss 1.2056307792663574
Iteration 12: train_loss 1.2494312524795532
Iteration 13: train_loss 1.223151683807373
Iteration 14: train_loss 1.253560185432434
Iteration 15: train_loss 1.147145390510559
Iteration 16: train_loss 1.1709709167480469
Iteration 17: train_loss 1.2086975574493408
Iteration 18: train_loss 1.2171660661697388
Iteration 19: train_loss 1.2327991724014282
Iteration 20: train_loss 1.15113365650177
Iteration 21: train_loss 1.212782382965088
Iteration 22: train_loss 1.2270808219909668
Iteration 23: train_loss 1.186845064163208
Iteration 24: train_loss 1.2166187763214111
Iteration 25: train_loss 1.1955225467681885
Iteration 26: train_loss 1.2181706428527832
Iteration 27: train_loss 1.2265464067459106
Iteration 28: train_loss 1.210433006286621
Iteration 29: train_loss 1.2133718729019165
Iteration 30: train_loss 1.206663727760315
Iteration 31: train_loss 1.2451679706573486
Iteration 32: train_loss 1.19380521774292
Iteration 33: train_loss 1.1826210021972656
Iteration 34: train_loss 1.241633415222168
Iteration 35: train_loss 1.220984697341919
Iteration 36: train_loss 1.2002065181732178
Iteration 37: train_loss 1.2051355838775635
Iteration 38: train_loss 1.1822415590286255
Iteration 39: train_loss 1.2363330125808716
Iteration 40: train_loss 1.193281650543213
Iteration 41: train_loss 1.212051272392273
Iteration 42: train_loss 1.204094409942627
Iteration 43: train_loss 1.2034233808517456
Iteration 44: train_loss 1.2763502597808838
Iteration 45: train_loss 1.2497591972351074
Iteration 46: train_loss 1.2491751909255981
Iteration 47: train_loss 1.2252916097640991
Iteration 48: train_loss 1.2336262464523315
Iteration 49: train_loss 1.2082529067993164
Iteration 50: train_loss 1.266795039176941
Iteration 51: train_loss 1.243256688117981
Iteration 52: train_loss 1.2669214010238647
Iteration 53: train_loss 1.231302261352539
Iteration 54: train_loss 1.212515115737915
Iteration 55: train_loss 1.2959296703338623
Iteration 56: train_loss 1.2226499319076538
Iteration 57: train_loss 1.2770644426345825
Iteration 58: train_loss 1.247128963470459
Iteration 59: train_loss 1.2653319835662842
Iteration 60: train_loss 1.2966276407241821
Iteration 61: train_loss 1.234772801399231
Iteration 62: train_loss 1.3121733665466309
Iteration 63: train_loss 1.2418209314346313
Iteration 64: train_loss 1.176935076713562
Iteration 65: train_loss 1.2565233707427979
Iteration 66: train_loss 1.2433689832687378
Iteration 67: train_loss 1.216076374053955
Iteration 68: train_loss 1.2175257205963135
Iteration 69: train_loss 1.2730035781860352
Iteration 70: train_loss 1.260671615600586
Iteration 71: train_loss 1.1897200345993042
Iteration 72: train_loss 1.2440471649169922
Iteration 73: train_loss 1.2823576927185059
Iteration 74: train_loss 1.2073659896850586
Iteration 75: train_loss 1.1584404706954956
Iteration 76: train_loss 1.227173089981079
Iteration 77: train_loss 1.1823201179504395
Iteration 78: train_loss 1.253421425819397
Iteration 79: train_loss 1.1396068334579468
Iteration 80: train_loss 1.2734811305999756
Iteration 81: train_loss 1.2112281322479248
Iteration 82: train_loss 1.300752878189087
Iteration 83: train_loss 1.2381460666656494
Iteration 84: train_loss 1.215404987335205
Iteration 85: train_loss 1.189501166343689
Iteration 86: train_loss 1.2784003019332886
Iteration 87: train_loss 1.2375456094741821
Iteration 88: train_loss 1.1701650619506836
Iteration 89: train_loss 1.195407509803772
Iteration 90: train_loss 1.227965235710144
Iteration 91: train_loss 1.2181981801986694
Iteration 92: train_loss 1.2854148149490356
Iteration 93: train_loss 1.2476381063461304
Iteration 94: train_loss 1.1850767135620117
Iteration 95: train_loss 1.2277382612228394
Iteration 96: train_loss 1.2913165092468262
Iteration 97: train_loss 1.2559164762496948
Iteration 98: train_loss 1.2096524238586426
Iteration 99: train_loss 1.2344170808792114
Iteration 100: train_loss 1.2863023281097412
Iteration 101: train_loss 1.2119975090026855
Iteration 102: train_loss 1.1966967582702637
Iteration 103: train_loss 1.1887576580047607
Iteration 104: train_loss 1.2553783655166626
Iteration 105: train_loss 1.2237147092819214
Iteration 106: train_loss 1.239949345588684
Iteration 107: train_loss 1.2231040000915527
Iteration 108: train_loss 1.2462923526763916
Iteration 109: train_loss 1.2428770065307617
Iteration 110: train_loss 1.2368539571762085
Iteration 111: train_loss 1.2895002365112305
Iteration 112: train_loss 1.2464332580566406
Iteration 113: train_loss 1.2020800113677979
Iteration 114: train_loss 1.2189750671386719
Iteration 115: train_loss 1.3372347354888916
Iteration 116: train_loss 1.345086932182312
Iteration 117: train_loss 1.2361538410186768
Iteration 118: train_loss 1.209459900856018
Iteration 119: train_loss 1.2351359128952026
Iteration 120: train_loss 1.289944052696228
Iteration 121: train_loss 1.2763046026229858
Iteration 122: train_loss 1.2014249563217163
Iteration 123: train_loss 1.1968494653701782
Iteration 124: train_loss 1.2261959314346313
Iteration 125: train_loss 1.2637947797775269
Iteration 126: train_loss 1.2221736907958984
Iteration 127: train_loss 1.1606781482696533
Iteration 128: train_loss 1.1961528062820435
Iteration 129: train_loss 1.2511844635009766
Iteration 130: train_loss 1.1880056858062744
Iteration 131: train_loss 1.1678813695907593
Iteration 132: train_loss 1.2870585918426514
Iteration 133: train_loss 1.254411220550537
Iteration 134: train_loss 1.1600673198699951
Iteration 135: train_loss 1.2288835048675537
Iteration 136: train_loss 1.219824194908142
Iteration 137: train_loss 1.268441081047058
Iteration 138: train_loss 1.2696597576141357
Iteration 139: train_loss 1.2368899583816528
Iteration 140: train_loss 1.2797225713729858
Iteration 141: train_loss 1.2509105205535889
Iteration 142: train_loss 1.2198336124420166
Iteration 143: train_loss 1.159070611000061
Iteration 144: train_loss 1.227439284324646
Iteration 145: train_loss 1.1784694194793701
Iteration 146: train_loss 1.1607656478881836
Iteration 147: train_loss 1.2479485273361206
Iteration 148: train_loss 1.2107959985733032
Iteration 149: train_loss 1.289522409439087
Iteration 150: train_loss 1.2207359075546265
Iteration 151: train_loss 1.2407968044281006
Iteration 152: train_loss 1.2749828100204468
Iteration 153: train_loss 1.1930474042892456
Iteration 154: train_loss 1.2679991722106934
Iteration 155: train_loss 1.2602155208587646
Iteration 156: train_loss 1.3223778009414673
Iteration 157: train_loss 1.2989283800125122
Iteration 158: train_loss 1.2603548765182495
Iteration 159: train_loss 1.2815768718719482
Iteration 160: train_loss 1.330886721611023
Iteration 161: train_loss 1.2840297222137451
Iteration 162: train_loss 1.3240827322006226
Iteration 163: train_loss 1.2691893577575684
Iteration 164: train_loss 1.2167625427246094
Iteration 165: train_loss 1.3473650217056274
Iteration 166: train_loss 1.2272766828536987
Iteration 167: train_loss 1.2792047262191772
Iteration 168: train_loss 1.2639834880828857
Iteration 169: train_loss 1.267104148864746
Iteration 170: train_loss 1.2773704528808594
Iteration 171: train_loss 1.2201992273330688
Iteration 172: train_loss 1.243687391281128
Iteration 173: train_loss 1.2362934350967407
Iteration 174: train_loss 1.2726402282714844
Iteration 175: train_loss 1.2254997491836548
Iteration 176: train_loss 1.1850908994674683
Iteration 177: train_loss 1.3227217197418213
Epoch 144: train_avg_loss 1.2349327183039176 eval_avg_acc: 0.34258997881050945 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:25:05] [32mIntermediate result: 0.34258997881050945  (Index 143)[0m
================Epoch: 145================
Iteration 1: train_loss 1.255246877670288
Iteration 2: train_loss 1.2141492366790771
Iteration 3: train_loss 1.178979516029358
Iteration 4: train_loss 1.2475640773773193
Iteration 5: train_loss 1.156392216682434
Iteration 6: train_loss 1.2215425968170166
Iteration 7: train_loss 1.2003389596939087
Iteration 8: train_loss 1.235437273979187
Iteration 9: train_loss 1.2246803045272827
Iteration 10: train_loss 1.1619144678115845
Iteration 11: train_loss 1.1653975248336792
Iteration 12: train_loss 1.2066268920898438
Iteration 13: train_loss 1.1730563640594482
Iteration 14: train_loss 1.1775767803192139
Iteration 15: train_loss 1.2305476665496826
Iteration 16: train_loss 1.2211530208587646
Iteration 17: train_loss 1.231255292892456
Iteration 18: train_loss 1.2260452508926392
Iteration 19: train_loss 1.2607170343399048
Iteration 20: train_loss 1.195900559425354
Iteration 21: train_loss 1.23796808719635
Iteration 22: train_loss 1.1940373182296753
Iteration 23: train_loss 1.2227309942245483
Iteration 24: train_loss 1.1879918575286865
Iteration 25: train_loss 1.2058680057525635
Iteration 26: train_loss 1.1772515773773193
Iteration 27: train_loss 1.290831446647644
Iteration 28: train_loss 1.2501492500305176
Iteration 29: train_loss 1.2359602451324463
Iteration 30: train_loss 1.1884372234344482
Iteration 31: train_loss 1.1477640867233276
Iteration 32: train_loss 1.223280668258667
Iteration 33: train_loss 1.249426245689392
Iteration 34: train_loss 1.2145707607269287
Iteration 35: train_loss 1.3221577405929565
Iteration 36: train_loss 1.2735337018966675
Iteration 37: train_loss 1.2083770036697388
Iteration 38: train_loss 1.2075260877609253
Iteration 39: train_loss 1.2935866117477417
Iteration 40: train_loss 1.240941047668457
Iteration 41: train_loss 1.2258539199829102
Iteration 42: train_loss 1.228498101234436
Iteration 43: train_loss 1.231323003768921
Iteration 44: train_loss 1.1967281103134155
Iteration 45: train_loss 1.2549031972885132
Iteration 46: train_loss 1.2427222728729248
Iteration 47: train_loss 1.2456896305084229
Iteration 48: train_loss 1.2179292440414429
Iteration 49: train_loss 1.1710114479064941
Iteration 50: train_loss 1.2611006498336792
Iteration 51: train_loss 1.2497133016586304
Iteration 52: train_loss 1.2057578563690186
Iteration 53: train_loss 1.246832251548767
Iteration 54: train_loss 1.2085829973220825
Iteration 55: train_loss 1.2302652597427368
Iteration 56: train_loss 1.2452993392944336
Iteration 57: train_loss 1.2088980674743652
Iteration 58: train_loss 1.2278605699539185
Iteration 59: train_loss 1.23538339138031
Iteration 60: train_loss 1.240182876586914
Iteration 61: train_loss 1.2567468881607056
Iteration 62: train_loss 1.2146410942077637
Iteration 63: train_loss 1.2429527044296265
Iteration 64: train_loss 1.2109800577163696
Iteration 65: train_loss 1.2165778875350952
Iteration 66: train_loss 1.2222415208816528
Iteration 67: train_loss 1.1969579458236694
Iteration 68: train_loss 1.226425290107727
Iteration 69: train_loss 1.159565806388855
Iteration 70: train_loss 1.1973768472671509
Iteration 71: train_loss 1.2459975481033325
Iteration 72: train_loss 1.2287046909332275
Iteration 73: train_loss 1.2296266555786133
Iteration 74: train_loss 1.234405755996704
Iteration 75: train_loss 1.1754785776138306
Iteration 76: train_loss 1.2185169458389282
Iteration 77: train_loss 1.2112963199615479
Iteration 78: train_loss 1.26351797580719
Iteration 79: train_loss 1.2786438465118408
Iteration 80: train_loss 1.2209761142730713
Iteration 81: train_loss 1.2671364545822144
Iteration 82: train_loss 1.2832162380218506
Iteration 83: train_loss 1.2266353368759155
Iteration 84: train_loss 1.2595140933990479
Iteration 85: train_loss 1.1857880353927612
Iteration 86: train_loss 1.2366634607315063
Iteration 87: train_loss 1.2499580383300781
Iteration 88: train_loss 1.2438786029815674
Iteration 89: train_loss 1.2758663892745972
Iteration 90: train_loss 1.2220127582550049
Iteration 91: train_loss 1.2248921394348145
Iteration 92: train_loss 1.2062705755233765
Iteration 93: train_loss 1.2578386068344116
Iteration 94: train_loss 1.2603625059127808
Iteration 95: train_loss 1.217667818069458
Iteration 96: train_loss 1.224366545677185
Iteration 97: train_loss 1.201462984085083
Iteration 98: train_loss 1.2626723051071167
Iteration 99: train_loss 1.2222011089324951
Iteration 100: train_loss 1.2296048402786255
Iteration 101: train_loss 1.287761926651001
Iteration 102: train_loss 1.2653579711914062
Iteration 103: train_loss 1.2047386169433594
Iteration 104: train_loss 1.2222435474395752
Iteration 105: train_loss 1.2421809434890747
Iteration 106: train_loss 1.185638666152954
Iteration 107: train_loss 1.2187614440917969
Iteration 108: train_loss 1.2163702249526978
Iteration 109: train_loss 1.2075258493423462
Iteration 110: train_loss 1.2543960809707642
Iteration 111: train_loss 1.2663036584854126
Iteration 112: train_loss 1.260751485824585
Iteration 113: train_loss 1.2460384368896484
Iteration 114: train_loss 1.212504267692566
Iteration 115: train_loss 1.2890371084213257
Iteration 116: train_loss 1.2497185468673706
Iteration 117: train_loss 1.2618153095245361
Iteration 118: train_loss 1.2918734550476074
Iteration 119: train_loss 1.3046276569366455
Iteration 120: train_loss 1.281784176826477
Iteration 121: train_loss 1.2183462381362915
Iteration 122: train_loss 1.2374187707901
Iteration 123: train_loss 1.19655179977417
Iteration 124: train_loss 1.2683345079421997
Iteration 125: train_loss 1.2204163074493408
Iteration 126: train_loss 1.1589133739471436
Iteration 127: train_loss 1.2421636581420898
Iteration 128: train_loss 1.2612653970718384
Iteration 129: train_loss 1.2697535753250122
Iteration 130: train_loss 1.1857913732528687
Iteration 131: train_loss 1.2475154399871826
Iteration 132: train_loss 1.2705755233764648
Iteration 133: train_loss 1.2415392398834229
Iteration 134: train_loss 1.2653532028198242
Iteration 135: train_loss 1.2911218404769897
Iteration 136: train_loss 1.2703731060028076
Iteration 137: train_loss 1.208730697631836
Iteration 138: train_loss 1.2238487005233765
Iteration 139: train_loss 1.2383816242218018
Iteration 140: train_loss 1.2390376329421997
Iteration 141: train_loss 1.2323354482650757
Iteration 142: train_loss 1.2539088726043701
Iteration 143: train_loss 1.2507953643798828
Iteration 144: train_loss 1.290312647819519
Iteration 145: train_loss 1.3179014921188354
Iteration 146: train_loss 1.295296311378479
Iteration 147: train_loss 1.1739004850387573
Iteration 148: train_loss 1.2481449842453003
Iteration 149: train_loss 1.2224591970443726
Iteration 150: train_loss 1.2117291688919067
Iteration 151: train_loss 1.2313897609710693
Iteration 152: train_loss 1.2267489433288574
Iteration 153: train_loss 1.201281189918518
Iteration 154: train_loss 1.2172173261642456
Iteration 155: train_loss 1.2664507627487183
Iteration 156: train_loss 1.2689374685287476
Iteration 157: train_loss 1.2202486991882324
Iteration 158: train_loss 1.238435983657837
Iteration 159: train_loss 1.2578173875808716
Iteration 160: train_loss 1.3024653196334839
Iteration 161: train_loss 1.2524136304855347
Iteration 162: train_loss 1.1824979782104492
Iteration 163: train_loss 1.2229217290878296
Iteration 164: train_loss 1.2006443738937378
Iteration 165: train_loss 1.2579128742218018
Iteration 166: train_loss 1.2187516689300537
Iteration 167: train_loss 1.2554384469985962
Iteration 168: train_loss 1.2528233528137207
Iteration 169: train_loss 1.16856050491333
Iteration 170: train_loss 1.2785024642944336
Iteration 171: train_loss 1.2414631843566895
Iteration 172: train_loss 1.2198761701583862
Iteration 173: train_loss 1.3196964263916016
Iteration 174: train_loss 1.2697234153747559
Iteration 175: train_loss 1.3261891603469849
Iteration 176: train_loss 1.263567328453064
Iteration 177: train_loss 1.2098406553268433
Epoch 145: train_avg_loss 1.2335285211013536 eval_avg_acc: 0.3473830740273099 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:25:46] [32mIntermediate result: 0.3473830740273099  (Index 144)[0m
================Epoch: 146================
Iteration 1: train_loss 1.1811679601669312
Iteration 2: train_loss 1.2399035692214966
Iteration 3: train_loss 1.2307592630386353
Iteration 4: train_loss 1.2706724405288696
Iteration 5: train_loss 1.2440330982208252
Iteration 6: train_loss 1.1891167163848877
Iteration 7: train_loss 1.2048767805099487
Iteration 8: train_loss 1.2041043043136597
Iteration 9: train_loss 1.2050285339355469
Iteration 10: train_loss 1.1551233530044556
Iteration 11: train_loss 1.2178221940994263
Iteration 12: train_loss 1.2324461936950684
Iteration 13: train_loss 1.1873053312301636
Iteration 14: train_loss 1.2293715476989746
Iteration 15: train_loss 1.2212293148040771
Iteration 16: train_loss 1.2090586423873901
Iteration 17: train_loss 1.2171756029129028
Iteration 18: train_loss 1.1946895122528076
Iteration 19: train_loss 1.1653621196746826
Iteration 20: train_loss 1.229912519454956
Iteration 21: train_loss 1.2383173704147339
Iteration 22: train_loss 1.1572662591934204
Iteration 23: train_loss 1.1531651020050049
Iteration 24: train_loss 1.2430498600006104
Iteration 25: train_loss 1.2334859371185303
Iteration 26: train_loss 1.26969313621521
Iteration 27: train_loss 1.2409945726394653
Iteration 28: train_loss 1.2144557237625122
Iteration 29: train_loss 1.258522391319275
Iteration 30: train_loss 1.1975979804992676
Iteration 31: train_loss 1.1982598304748535
Iteration 32: train_loss 1.2087427377700806
Iteration 33: train_loss 1.2155848741531372
Iteration 34: train_loss 1.2221438884735107
Iteration 35: train_loss 1.1935765743255615
Iteration 36: train_loss 1.2037451267242432
Iteration 37: train_loss 1.2316559553146362
Iteration 38: train_loss 1.2139296531677246
Iteration 39: train_loss 1.2036045789718628
Iteration 40: train_loss 1.1494983434677124
Iteration 41: train_loss 1.2058748006820679
Iteration 42: train_loss 1.2184884548187256
Iteration 43: train_loss 1.2477893829345703
Iteration 44: train_loss 1.2348990440368652
Iteration 45: train_loss 1.1677929162979126
Iteration 46: train_loss 1.225124716758728
Iteration 47: train_loss 1.1891591548919678
Iteration 48: train_loss 1.2376351356506348
Iteration 49: train_loss 1.2585783004760742
Iteration 50: train_loss 1.1876351833343506
Iteration 51: train_loss 1.2344094514846802
Iteration 52: train_loss 1.1840863227844238
Iteration 53: train_loss 1.244147777557373
Iteration 54: train_loss 1.2402173280715942
Iteration 55: train_loss 1.335982084274292
Iteration 56: train_loss 1.2343330383300781
Iteration 57: train_loss 1.215866208076477
Iteration 58: train_loss 1.3287452459335327
Iteration 59: train_loss 1.2864017486572266
Iteration 60: train_loss 1.2416136264801025
Iteration 61: train_loss 1.214464783668518
Iteration 62: train_loss 1.2501907348632812
Iteration 63: train_loss 1.2741272449493408
Iteration 64: train_loss 1.2513222694396973
Iteration 65: train_loss 1.212018609046936
Iteration 66: train_loss 1.251554012298584
Iteration 67: train_loss 1.2622179985046387
Iteration 68: train_loss 1.2429518699645996
Iteration 69: train_loss 1.2601431608200073
Iteration 70: train_loss 1.2064625024795532
Iteration 71: train_loss 1.2544333934783936
Iteration 72: train_loss 1.2121520042419434
Iteration 73: train_loss 1.27629816532135
Iteration 74: train_loss 1.2138381004333496
Iteration 75: train_loss 1.227959394454956
Iteration 76: train_loss 1.30091392993927
Iteration 77: train_loss 1.179356575012207
Iteration 78: train_loss 1.231090784072876
Iteration 79: train_loss 1.214613676071167
Iteration 80: train_loss 1.1997212171554565
Iteration 81: train_loss 1.2838383913040161
Iteration 82: train_loss 1.2642618417739868
Iteration 83: train_loss 1.2724804878234863
Iteration 84: train_loss 1.24788498878479
Iteration 85: train_loss 1.194499135017395
Iteration 86: train_loss 1.2269511222839355
Iteration 87: train_loss 1.2270827293395996
Iteration 88: train_loss 1.2672723531723022
Iteration 89: train_loss 1.192759394645691
Iteration 90: train_loss 1.2320481538772583
Iteration 91: train_loss 1.2218503952026367
Iteration 92: train_loss 1.1798738241195679
Iteration 93: train_loss 1.2546236515045166
Iteration 94: train_loss 1.1875323057174683
Iteration 95: train_loss 1.2226823568344116
Iteration 96: train_loss 1.2212899923324585
Iteration 97: train_loss 1.2778806686401367
Iteration 98: train_loss 1.2133986949920654
Iteration 99: train_loss 1.2098034620285034
Iteration 100: train_loss 1.232419729232788
Iteration 101: train_loss 1.2414617538452148
Iteration 102: train_loss 1.2467020750045776
Iteration 103: train_loss 1.2261788845062256
Iteration 104: train_loss 1.2328085899353027
Iteration 105: train_loss 1.2747199535369873
Iteration 106: train_loss 1.211949110031128
Iteration 107: train_loss 1.2158572673797607
Iteration 108: train_loss 1.236316204071045
Iteration 109: train_loss 1.242836594581604
Iteration 110: train_loss 1.1476075649261475
Iteration 111: train_loss 1.1639925241470337
Iteration 112: train_loss 1.2055083513259888
Iteration 113: train_loss 1.1164345741271973
Iteration 114: train_loss 1.148336410522461
Iteration 115: train_loss 1.216566562652588
Iteration 116: train_loss 1.2521123886108398
Iteration 117: train_loss 1.2730098962783813
Iteration 118: train_loss 1.2003005743026733
Iteration 119: train_loss 1.2539119720458984
Iteration 120: train_loss 1.203910231590271
Iteration 121: train_loss 1.2442080974578857
Iteration 122: train_loss 1.2789266109466553
Iteration 123: train_loss 1.2961757183074951
Iteration 124: train_loss 1.218841552734375
Iteration 125: train_loss 1.2303383350372314
Iteration 126: train_loss 1.2581572532653809
Iteration 127: train_loss 1.2734500169754028
Iteration 128: train_loss 1.2621992826461792
Iteration 129: train_loss 1.2517787218093872
Iteration 130: train_loss 1.241595983505249
Iteration 131: train_loss 1.2190345525741577
Iteration 132: train_loss 1.2134904861450195
Iteration 133: train_loss 1.2279326915740967
Iteration 134: train_loss 1.205641269683838
Iteration 135: train_loss 1.1655919551849365
Iteration 136: train_loss 1.2254544496536255
Iteration 137: train_loss 1.2625449895858765
Iteration 138: train_loss 1.2434954643249512
Iteration 139: train_loss 1.2195419073104858
Iteration 140: train_loss 1.22055983543396
Iteration 141: train_loss 1.2160528898239136
Iteration 142: train_loss 1.2103309631347656
Iteration 143: train_loss 1.2215913534164429
Iteration 144: train_loss 1.173906922340393
Iteration 145: train_loss 1.2953643798828125
Iteration 146: train_loss 1.2157291173934937
Iteration 147: train_loss 1.2395328283309937
Iteration 148: train_loss 1.2545245885849
Iteration 149: train_loss 1.2132244110107422
Iteration 150: train_loss 1.2084921598434448
Iteration 151: train_loss 1.2267612218856812
Iteration 152: train_loss 1.2577497959136963
Iteration 153: train_loss 1.2166956663131714
Iteration 154: train_loss 1.239683747291565
Iteration 155: train_loss 1.2333909273147583
Iteration 156: train_loss 1.1992006301879883
Iteration 157: train_loss 1.181071162223816
Iteration 158: train_loss 1.1960902214050293
Iteration 159: train_loss 1.2704551219940186
Iteration 160: train_loss 1.2037333250045776
Iteration 161: train_loss 1.2734616994857788
Iteration 162: train_loss 1.186668872833252
Iteration 163: train_loss 1.2177504301071167
Iteration 164: train_loss 1.2090636491775513
Iteration 165: train_loss 1.2178765535354614
Iteration 166: train_loss 1.2056914567947388
Iteration 167: train_loss 1.2017292976379395
Iteration 168: train_loss 1.189263105392456
Iteration 169: train_loss 1.2166165113449097
Iteration 170: train_loss 1.213057041168213
Iteration 171: train_loss 1.20341157913208
Iteration 172: train_loss 1.2458629608154297
Iteration 173: train_loss 1.2756932973861694
Iteration 174: train_loss 1.2600892782211304
Iteration 175: train_loss 1.1960573196411133
Iteration 176: train_loss 1.2280857563018799
Iteration 177: train_loss 1.2767152786254883
Epoch 146: train_avg_loss 1.225546040103934 eval_avg_acc: 0.3473290921625965 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:26:26] [32mIntermediate result: 0.3473290921625965  (Index 145)[0m
================Epoch: 147================
Iteration 1: train_loss 1.2087655067443848
Iteration 2: train_loss 1.2342551946640015
Iteration 3: train_loss 1.232001781463623
Iteration 4: train_loss 1.2498923540115356
Iteration 5: train_loss 1.2055222988128662
Iteration 6: train_loss 1.2580269575119019
Iteration 7: train_loss 1.1740161180496216
Iteration 8: train_loss 1.2658251523971558
Iteration 9: train_loss 1.2438162565231323
Iteration 10: train_loss 1.2642278671264648
Iteration 11: train_loss 1.228495717048645
Iteration 12: train_loss 1.1710782051086426
Iteration 13: train_loss 1.1926627159118652
Iteration 14: train_loss 1.2592332363128662
Iteration 15: train_loss 1.2090202569961548
Iteration 16: train_loss 1.2170159816741943
Iteration 17: train_loss 1.1783581972122192
Iteration 18: train_loss 1.2167702913284302
Iteration 19: train_loss 1.1932114362716675
Iteration 20: train_loss 1.1811524629592896
Iteration 21: train_loss 1.2439136505126953
Iteration 22: train_loss 1.246356725692749
Iteration 23: train_loss 1.1906381845474243
Iteration 24: train_loss 1.2356425523757935
Iteration 25: train_loss 1.1679768562316895
Iteration 26: train_loss 1.2336009740829468
Iteration 27: train_loss 1.1690821647644043
Iteration 28: train_loss 1.2517801523208618
Iteration 29: train_loss 1.2186737060546875
Iteration 30: train_loss 1.1858676671981812
Iteration 31: train_loss 1.2430288791656494
Iteration 32: train_loss 1.2376564741134644
Iteration 33: train_loss 1.197433590888977
Iteration 34: train_loss 1.2892696857452393
Iteration 35: train_loss 1.2422038316726685
Iteration 36: train_loss 1.3213603496551514
Iteration 37: train_loss 1.1987929344177246
Iteration 38: train_loss 1.1969960927963257
Iteration 39: train_loss 1.2079604864120483
Iteration 40: train_loss 1.2334073781967163
Iteration 41: train_loss 1.2345844507217407
Iteration 42: train_loss 1.2000012397766113
Iteration 43: train_loss 1.1683553457260132
Iteration 44: train_loss 1.1940373182296753
Iteration 45: train_loss 1.1713063716888428
Iteration 46: train_loss 1.1488585472106934
Iteration 47: train_loss 1.229191541671753
Iteration 48: train_loss 1.2019083499908447
Iteration 49: train_loss 1.2079246044158936
Iteration 50: train_loss 1.1415306329727173
Iteration 51: train_loss 1.2148529291152954
Iteration 52: train_loss 1.2066136598587036
Iteration 53: train_loss 1.211219072341919
Iteration 54: train_loss 1.2402598857879639
Iteration 55: train_loss 1.1476457118988037
Iteration 56: train_loss 1.1700772047042847
Iteration 57: train_loss 1.2579140663146973
Iteration 58: train_loss 1.2701536417007446
Iteration 59: train_loss 1.200243592262268
Iteration 60: train_loss 1.250924825668335
Iteration 61: train_loss 1.2530487775802612
Iteration 62: train_loss 1.249245524406433
Iteration 63: train_loss 1.2319625616073608
Iteration 64: train_loss 1.211456060409546
Iteration 65: train_loss 1.2069851160049438
Iteration 66: train_loss 1.2276155948638916
Iteration 67: train_loss 1.2060229778289795
Iteration 68: train_loss 1.2420343160629272
Iteration 69: train_loss 1.187930941581726
Iteration 70: train_loss 1.1991264820098877
Iteration 71: train_loss 1.170739769935608
Iteration 72: train_loss 1.1934698820114136
Iteration 73: train_loss 1.2299036979675293
Iteration 74: train_loss 1.2034121751785278
Iteration 75: train_loss 1.1258649826049805
Iteration 76: train_loss 1.1682718992233276
Iteration 77: train_loss 1.1627055406570435
Iteration 78: train_loss 1.2047975063323975
Iteration 79: train_loss 1.2375189065933228
Iteration 80: train_loss 1.1922928094863892
Iteration 81: train_loss 1.141892671585083
Iteration 82: train_loss 1.2509831190109253
Iteration 83: train_loss 1.2272710800170898
Iteration 84: train_loss 1.2016444206237793
Iteration 85: train_loss 1.2233271598815918
Iteration 86: train_loss 1.171755313873291
Iteration 87: train_loss 1.183150053024292
Iteration 88: train_loss 1.2160954475402832
Iteration 89: train_loss 1.2380889654159546
Iteration 90: train_loss 1.2233372926712036
Iteration 91: train_loss 1.263255000114441
Iteration 92: train_loss 1.235832691192627
Iteration 93: train_loss 1.1796042919158936
Iteration 94: train_loss 1.2326254844665527
Iteration 95: train_loss 1.2541049718856812
Iteration 96: train_loss 1.233957290649414
Iteration 97: train_loss 1.2255643606185913
Iteration 98: train_loss 1.1980561017990112
Iteration 99: train_loss 1.2482165098190308
Iteration 100: train_loss 1.2328872680664062
Iteration 101: train_loss 1.2313138246536255
Iteration 102: train_loss 1.2119863033294678
Iteration 103: train_loss 1.2421622276306152
Iteration 104: train_loss 1.20108163356781
Iteration 105: train_loss 1.1981197595596313
Iteration 106: train_loss 1.2522770166397095
Iteration 107: train_loss 1.253480315208435
Iteration 108: train_loss 1.2365888357162476
Iteration 109: train_loss 1.2504916191101074
Iteration 110: train_loss 1.1865053176879883
Iteration 111: train_loss 1.2399479150772095
Iteration 112: train_loss 1.235613465309143
Iteration 113: train_loss 1.3090916872024536
Iteration 114: train_loss 1.2353284358978271
Iteration 115: train_loss 1.2204639911651611
Iteration 116: train_loss 1.196132779121399
Iteration 117: train_loss 1.2485986948013306
Iteration 118: train_loss 1.200457215309143
Iteration 119: train_loss 1.2752991914749146
Iteration 120: train_loss 1.196142554283142
Iteration 121: train_loss 1.2245537042617798
Iteration 122: train_loss 1.1978434324264526
Iteration 123: train_loss 1.206303358078003
Iteration 124: train_loss 1.2241038084030151
Iteration 125: train_loss 1.2096302509307861
Iteration 126: train_loss 1.2751119136810303
Iteration 127: train_loss 1.167631983757019
Iteration 128: train_loss 1.2326154708862305
Iteration 129: train_loss 1.1597824096679688
Iteration 130: train_loss 1.197584867477417
Iteration 131: train_loss 1.1827187538146973
Iteration 132: train_loss 1.2370660305023193
Iteration 133: train_loss 1.2236496210098267
Iteration 134: train_loss 1.192028522491455
Iteration 135: train_loss 1.1805434226989746
Iteration 136: train_loss 1.154882788658142
Iteration 137: train_loss 1.1746348142623901
Iteration 138: train_loss 1.209838628768921
Iteration 139: train_loss 1.1837003231048584
Iteration 140: train_loss 1.2483465671539307
Iteration 141: train_loss 1.1672471761703491
Iteration 142: train_loss 1.1486423015594482
Iteration 143: train_loss 1.217552900314331
Iteration 144: train_loss 1.237313985824585
Iteration 145: train_loss 1.191129207611084
Iteration 146: train_loss 1.14804208278656
Iteration 147: train_loss 1.2142345905303955
Iteration 148: train_loss 1.1979998350143433
Iteration 149: train_loss 1.18507981300354
Iteration 150: train_loss 1.209908366203308
Iteration 151: train_loss 1.205401062965393
Iteration 152: train_loss 1.1573039293289185
Iteration 153: train_loss 1.1955598592758179
Iteration 154: train_loss 1.2545102834701538
Iteration 155: train_loss 1.228472113609314
Iteration 156: train_loss 1.1888092756271362
Iteration 157: train_loss 1.2082610130310059
Iteration 158: train_loss 1.242821216583252
Iteration 159: train_loss 1.226033091545105
Iteration 160: train_loss 1.1882127523422241
Iteration 161: train_loss 1.2278690338134766
Iteration 162: train_loss 1.1545970439910889
Iteration 163: train_loss 1.229379415512085
Iteration 164: train_loss 1.2136491537094116
Iteration 165: train_loss 1.2032791376113892
Iteration 166: train_loss 1.2337405681610107
Iteration 167: train_loss 1.1788465976715088
Iteration 168: train_loss 1.2178884744644165
Iteration 169: train_loss 1.2393200397491455
Iteration 170: train_loss 1.2847723960876465
Iteration 171: train_loss 1.2833870649337769
Iteration 172: train_loss 1.2783664464950562
Iteration 173: train_loss 1.1818691492080688
Iteration 174: train_loss 1.1957982778549194
Iteration 175: train_loss 1.2088814973831177
Iteration 176: train_loss 1.2157654762268066
Iteration 177: train_loss 1.3051778078079224
Epoch 147: train_avg_loss 1.214787707490436 eval_avg_acc: 0.3370749996962696 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:27:06] [32mIntermediate result: 0.3370749996962696  (Index 146)[0m
================Epoch: 148================
Iteration 1: train_loss 1.2257323265075684
Iteration 2: train_loss 1.2187155485153198
Iteration 3: train_loss 1.2837131023406982
Iteration 4: train_loss 1.2330063581466675
Iteration 5: train_loss 1.2399178743362427
Iteration 6: train_loss 1.2724146842956543
Iteration 7: train_loss 1.1894720792770386
Iteration 8: train_loss 1.212848424911499
Iteration 9: train_loss 1.2189688682556152
Iteration 10: train_loss 1.189471960067749
Iteration 11: train_loss 1.2763214111328125
Iteration 12: train_loss 1.1936030387878418
Iteration 13: train_loss 1.2084293365478516
Iteration 14: train_loss 1.1869021654129028
Iteration 15: train_loss 1.1867213249206543
Iteration 16: train_loss 1.1953299045562744
Iteration 17: train_loss 1.2158777713775635
Iteration 18: train_loss 1.1765247583389282
Iteration 19: train_loss 1.2316800355911255
Iteration 20: train_loss 1.250235915184021
Iteration 21: train_loss 1.2097960710525513
Iteration 22: train_loss 1.2069294452667236
Iteration 23: train_loss 1.1815420389175415
Iteration 24: train_loss 1.2005834579467773
Iteration 25: train_loss 1.204771637916565
Iteration 26: train_loss 1.1954076290130615
Iteration 27: train_loss 1.1974862813949585
Iteration 28: train_loss 1.2666887044906616
Iteration 29: train_loss 1.2356784343719482
Iteration 30: train_loss 1.20989191532135
Iteration 31: train_loss 1.2122900485992432
Iteration 32: train_loss 1.2461013793945312
Iteration 33: train_loss 1.2180001735687256
Iteration 34: train_loss 1.201421856880188
Iteration 35: train_loss 1.2168290615081787
Iteration 36: train_loss 1.204682469367981
Iteration 37: train_loss 1.2729320526123047
Iteration 38: train_loss 1.2249186038970947
Iteration 39: train_loss 1.1646220684051514
Iteration 40: train_loss 1.216665267944336
Iteration 41: train_loss 1.142412781715393
Iteration 42: train_loss 1.1924018859863281
Iteration 43: train_loss 1.187337875366211
Iteration 44: train_loss 1.1433920860290527
Iteration 45: train_loss 1.2568690776824951
Iteration 46: train_loss 1.2671688795089722
Iteration 47: train_loss 1.2158262729644775
Iteration 48: train_loss 1.210853099822998
Iteration 49: train_loss 1.2495356798171997
Iteration 50: train_loss 1.201707363128662
Iteration 51: train_loss 1.188779354095459
Iteration 52: train_loss 1.2054591178894043
Iteration 53: train_loss 1.195188283920288
Iteration 54: train_loss 1.2255349159240723
Iteration 55: train_loss 1.1976251602172852
Iteration 56: train_loss 1.1914329528808594
Iteration 57: train_loss 1.2541598081588745
Iteration 58: train_loss 1.2378298044204712
Iteration 59: train_loss 1.2609262466430664
Iteration 60: train_loss 1.2075767517089844
Iteration 61: train_loss 1.2481874227523804
Iteration 62: train_loss 1.2054693698883057
Iteration 63: train_loss 1.1776816844940186
Iteration 64: train_loss 1.2621616125106812
Iteration 65: train_loss 1.2608375549316406
Iteration 66: train_loss 1.2413246631622314
Iteration 67: train_loss 1.1508175134658813
Iteration 68: train_loss 1.1701877117156982
Iteration 69: train_loss 1.16304349899292
Iteration 70: train_loss 1.2067821025848389
Iteration 71: train_loss 1.1937751770019531
Iteration 72: train_loss 1.2608002424240112
Iteration 73: train_loss 1.211042046546936
Iteration 74: train_loss 1.2207425832748413
Iteration 75: train_loss 1.2533962726593018
Iteration 76: train_loss 1.2101954221725464
Iteration 77: train_loss 1.2175889015197754
Iteration 78: train_loss 1.1617746353149414
Iteration 79: train_loss 1.174228310585022
Iteration 80: train_loss 1.1499249935150146
Iteration 81: train_loss 1.180807113647461
Iteration 82: train_loss 1.1946700811386108
Iteration 83: train_loss 1.246037483215332
Iteration 84: train_loss 1.1851154565811157
Iteration 85: train_loss 1.2062395811080933
Iteration 86: train_loss 1.1683188676834106
Iteration 87: train_loss 1.2183701992034912
Iteration 88: train_loss 1.2090446949005127
Iteration 89: train_loss 1.202488660812378
Iteration 90: train_loss 1.1667400598526
Iteration 91: train_loss 1.207627773284912
Iteration 92: train_loss 1.177734613418579
Iteration 93: train_loss 1.204856276512146
Iteration 94: train_loss 1.2028913497924805
Iteration 95: train_loss 1.2629308700561523
Iteration 96: train_loss 1.2268317937850952
Iteration 97: train_loss 1.1988829374313354
Iteration 98: train_loss 1.2856428623199463
Iteration 99: train_loss 1.2144526243209839
Iteration 100: train_loss 1.226246953010559
Iteration 101: train_loss 1.2693045139312744
Iteration 102: train_loss 1.235220193862915
Iteration 103: train_loss 1.2107863426208496
Iteration 104: train_loss 1.2300759553909302
Iteration 105: train_loss 1.2355931997299194
Iteration 106: train_loss 1.2154432535171509
Iteration 107: train_loss 1.241609811782837
Iteration 108: train_loss 1.2182968854904175
Iteration 109: train_loss 1.2647720575332642
Iteration 110: train_loss 1.2184420824050903
Iteration 111: train_loss 1.2545454502105713
Iteration 112: train_loss 1.2415090799331665
Iteration 113: train_loss 1.201035737991333
Iteration 114: train_loss 1.2099356651306152
Iteration 115: train_loss 1.2436087131500244
Iteration 116: train_loss 1.1747803688049316
Iteration 117: train_loss 1.2328732013702393
Iteration 118: train_loss 1.215091586112976
Iteration 119: train_loss 1.1864492893218994
Iteration 120: train_loss 1.238189458847046
Iteration 121: train_loss 1.209227442741394
Iteration 122: train_loss 1.2203969955444336
Iteration 123: train_loss 1.2400282621383667
Iteration 124: train_loss 1.199303388595581
Iteration 125: train_loss 1.1915385723114014
Iteration 126: train_loss 1.2655829191207886
Iteration 127: train_loss 1.2371392250061035
Iteration 128: train_loss 1.1647924184799194
Iteration 129: train_loss 1.2127779722213745
Iteration 130: train_loss 1.2443338632583618
Iteration 131: train_loss 1.1836178302764893
Iteration 132: train_loss 1.1977925300598145
Iteration 133: train_loss 1.1987054347991943
Iteration 134: train_loss 1.2155232429504395
Iteration 135: train_loss 1.240989327430725
Iteration 136: train_loss 1.2021981477737427
Iteration 137: train_loss 1.2067573070526123
Iteration 138: train_loss 1.215865969657898
Iteration 139: train_loss 1.216536521911621
Iteration 140: train_loss 1.3063621520996094
Iteration 141: train_loss 1.2714937925338745
Iteration 142: train_loss 1.2450283765792847
Iteration 143: train_loss 1.2304517030715942
Iteration 144: train_loss 1.1915323734283447
Iteration 145: train_loss 1.264296531677246
Iteration 146: train_loss 1.1858259439468384
Iteration 147: train_loss 1.2109551429748535
Iteration 148: train_loss 1.19336998462677
Iteration 149: train_loss 1.1713603734970093
Iteration 150: train_loss 1.2383509874343872
Iteration 151: train_loss 1.2194594144821167
Iteration 152: train_loss 1.2506483793258667
Iteration 153: train_loss 1.209075927734375
Iteration 154: train_loss 1.2312586307525635
Iteration 155: train_loss 1.1646182537078857
Iteration 156: train_loss 1.1992383003234863
Iteration 157: train_loss 1.1629610061645508
Iteration 158: train_loss 1.2173553705215454
Iteration 159: train_loss 1.2629576921463013
Iteration 160: train_loss 1.2528024911880493
Iteration 161: train_loss 1.2760440111160278
Iteration 162: train_loss 1.2552266120910645
Iteration 163: train_loss 1.2108765840530396
Iteration 164: train_loss 1.2735745906829834
Iteration 165: train_loss 1.1332052946090698
Iteration 166: train_loss 1.2501322031021118
Iteration 167: train_loss 1.2677329778671265
Iteration 168: train_loss 1.2350492477416992
Iteration 169: train_loss 1.2554577589035034
Iteration 170: train_loss 1.2123169898986816
Iteration 171: train_loss 1.2230180501937866
Iteration 172: train_loss 1.2157541513442993
Iteration 173: train_loss 1.2524133920669556
Iteration 174: train_loss 1.2373994588851929
Iteration 175: train_loss 1.1999963521957397
Iteration 176: train_loss 1.2048134803771973
Iteration 177: train_loss 1.2158095836639404
Epoch 148: train_avg_loss 1.2172312352616907 eval_avg_acc: 0.34866955781782155 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:27:47] [32mIntermediate result: 0.34866955781782155  (Index 147)[0m
================Epoch: 149================
Iteration 1: train_loss 1.1620506048202515
Iteration 2: train_loss 1.1833066940307617
Iteration 3: train_loss 1.1757258176803589
Iteration 4: train_loss 1.172365427017212
Iteration 5: train_loss 1.2262475490570068
Iteration 6: train_loss 1.1836074590682983
Iteration 7: train_loss 1.1807597875595093
Iteration 8: train_loss 1.1443122625350952
Iteration 9: train_loss 1.1778733730316162
Iteration 10: train_loss 1.236504077911377
Iteration 11: train_loss 1.190475344657898
Iteration 12: train_loss 1.1812055110931396
Iteration 13: train_loss 1.2156625986099243
Iteration 14: train_loss 1.1716315746307373
Iteration 15: train_loss 1.1987566947937012
Iteration 16: train_loss 1.2231295108795166
Iteration 17: train_loss 1.193856954574585
Iteration 18: train_loss 1.224216103553772
Iteration 19: train_loss 1.2525341510772705
Iteration 20: train_loss 1.2667235136032104
Iteration 21: train_loss 1.2763360738754272
Iteration 22: train_loss 1.1756079196929932
Iteration 23: train_loss 1.186446189880371
Iteration 24: train_loss 1.2380269765853882
Iteration 25: train_loss 1.2586787939071655
Iteration 26: train_loss 1.205992579460144
Iteration 27: train_loss 1.2262015342712402
Iteration 28: train_loss 1.2114965915679932
Iteration 29: train_loss 1.2523154020309448
Iteration 30: train_loss 1.2115821838378906
Iteration 31: train_loss 1.2375590801239014
Iteration 32: train_loss 1.233542799949646
Iteration 33: train_loss 1.2729898691177368
Iteration 34: train_loss 1.1201967000961304
Iteration 35: train_loss 1.2098314762115479
Iteration 36: train_loss 1.2368011474609375
Iteration 37: train_loss 1.1886826753616333
Iteration 38: train_loss 1.2116719484329224
Iteration 39: train_loss 1.196996808052063
Iteration 40: train_loss 1.2939443588256836
Iteration 41: train_loss 1.2225421667099
Iteration 42: train_loss 1.2524656057357788
Iteration 43: train_loss 1.2384129762649536
Iteration 44: train_loss 1.2148610353469849
Iteration 45: train_loss 1.2197853326797485
Iteration 46: train_loss 1.2015106678009033
Iteration 47: train_loss 1.3075200319290161
Iteration 48: train_loss 1.1895217895507812
Iteration 49: train_loss 1.2338558435440063
Iteration 50: train_loss 1.2506352663040161
Iteration 51: train_loss 1.1712887287139893
Iteration 52: train_loss 1.1508064270019531
Iteration 53: train_loss 1.2103033065795898
Iteration 54: train_loss 1.246219515800476
Iteration 55: train_loss 1.19674551486969
Iteration 56: train_loss 1.2169363498687744
Iteration 57: train_loss 1.2408535480499268
Iteration 58: train_loss 1.1799355745315552
Iteration 59: train_loss 1.1717067956924438
Iteration 60: train_loss 1.1695854663848877
Iteration 61: train_loss 1.1669045686721802
Iteration 62: train_loss 1.2710916996002197
Iteration 63: train_loss 1.2353895902633667
Iteration 64: train_loss 1.2058424949645996
Iteration 65: train_loss 1.2647250890731812
Iteration 66: train_loss 1.2311890125274658
Iteration 67: train_loss 1.19473397731781
Iteration 68: train_loss 1.2362223863601685
Iteration 69: train_loss 1.165777564048767
Iteration 70: train_loss 1.1840585470199585
Iteration 71: train_loss 1.1824705600738525
Iteration 72: train_loss 1.2478512525558472
Iteration 73: train_loss 1.2112332582473755
Iteration 74: train_loss 1.1990644931793213
Iteration 75: train_loss 1.259376883506775
Iteration 76: train_loss 1.2003355026245117
Iteration 77: train_loss 1.241071105003357
Iteration 78: train_loss 1.2038682699203491
Iteration 79: train_loss 1.1930251121520996
Iteration 80: train_loss 1.1556998491287231
Iteration 81: train_loss 1.18242609500885
Iteration 82: train_loss 1.2754895687103271
Iteration 83: train_loss 1.2028082609176636
Iteration 84: train_loss 1.2365190982818604
Iteration 85: train_loss 1.2851275205612183
Iteration 86: train_loss 1.2916316986083984
Iteration 87: train_loss 1.280501365661621
Iteration 88: train_loss 1.2582684755325317
Iteration 89: train_loss 1.182846188545227
Iteration 90: train_loss 1.1892575025558472
Iteration 91: train_loss 1.2520737648010254
Iteration 92: train_loss 1.2919881343841553
Iteration 93: train_loss 1.3224865198135376
Iteration 94: train_loss 1.2581366300582886
Iteration 95: train_loss 1.2237576246261597
Iteration 96: train_loss 1.2931194305419922
Iteration 97: train_loss 1.2094794511795044
Iteration 98: train_loss 1.209889531135559
Iteration 99: train_loss 1.2443195581436157
Iteration 100: train_loss 1.2098184823989868
Iteration 101: train_loss 1.240015983581543
Iteration 102: train_loss 1.1803613901138306
Iteration 103: train_loss 1.2273883819580078
Iteration 104: train_loss 1.1747252941131592
Iteration 105: train_loss 1.2431894540786743
Iteration 106: train_loss 1.2084593772888184
Iteration 107: train_loss 1.1693490743637085
Iteration 108: train_loss 1.1635149717330933
Iteration 109: train_loss 1.2130109071731567
Iteration 110: train_loss 1.1925804615020752
Iteration 111: train_loss 1.2040263414382935
Iteration 112: train_loss 1.1932792663574219
Iteration 113: train_loss 1.2400233745574951
Iteration 114: train_loss 1.1908340454101562
Iteration 115: train_loss 1.1934118270874023
Iteration 116: train_loss 1.2314428091049194
Iteration 117: train_loss 1.2364046573638916
Iteration 118: train_loss 1.2146596908569336
Iteration 119: train_loss 1.2630529403686523
Iteration 120: train_loss 1.175374150276184
Iteration 121: train_loss 1.2697021961212158
Iteration 122: train_loss 1.2115353345870972
Iteration 123: train_loss 1.1997159719467163
Iteration 124: train_loss 1.267694354057312
Iteration 125: train_loss 1.2405827045440674
Iteration 126: train_loss 1.1808278560638428
Iteration 127: train_loss 1.2306748628616333
Iteration 128: train_loss 1.1858837604522705
Iteration 129: train_loss 1.2964593172073364
Iteration 130: train_loss 1.2534263134002686
Iteration 131: train_loss 1.2237528562545776
Iteration 132: train_loss 1.2107799053192139
Iteration 133: train_loss 1.2485100030899048
Iteration 134: train_loss 1.1532957553863525
Iteration 135: train_loss 1.2288875579833984
Iteration 136: train_loss 1.2040958404541016
Iteration 137: train_loss 1.235387921333313
Iteration 138: train_loss 1.2386064529418945
Iteration 139: train_loss 1.2059688568115234
Iteration 140: train_loss 1.2341511249542236
Iteration 141: train_loss 1.1751065254211426
Iteration 142: train_loss 1.203540325164795
Iteration 143: train_loss 1.2376782894134521
Iteration 144: train_loss 1.193019986152649
Iteration 145: train_loss 1.2352405786514282
Iteration 146: train_loss 1.2105774879455566
Iteration 147: train_loss 1.220654010772705
Iteration 148: train_loss 1.2543500661849976
Iteration 149: train_loss 1.2187328338623047
Iteration 150: train_loss 1.2825820446014404
Iteration 151: train_loss 1.300145149230957
Iteration 152: train_loss 1.283974528312683
Iteration 153: train_loss 1.2322078943252563
Iteration 154: train_loss 1.2226362228393555
Iteration 155: train_loss 1.2904576063156128
Iteration 156: train_loss 1.3007891178131104
Iteration 157: train_loss 1.224480390548706
Iteration 158: train_loss 1.242602825164795
Iteration 159: train_loss 1.3097294569015503
Iteration 160: train_loss 1.2820745706558228
Iteration 161: train_loss 1.2305837869644165
Iteration 162: train_loss 1.241984486579895
Iteration 163: train_loss 1.238918662071228
Iteration 164: train_loss 1.2924851179122925
Iteration 165: train_loss 1.203365445137024
Iteration 166: train_loss 1.220017671585083
Iteration 167: train_loss 1.2430062294006348
Iteration 168: train_loss 1.200215220451355
Iteration 169: train_loss 1.2627005577087402
Iteration 170: train_loss 1.2231732606887817
Iteration 171: train_loss 1.2510253190994263
Iteration 172: train_loss 1.2845224142074585
Iteration 173: train_loss 1.2569994926452637
Iteration 174: train_loss 1.2456212043762207
Iteration 175: train_loss 1.236293911933899
Iteration 176: train_loss 1.2353194952011108
Iteration 177: train_loss 1.1425659656524658
Epoch 149: train_avg_loss 1.2228566987366327 eval_avg_acc: 0.3430479934135075 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:28:26] [32mIntermediate result: 0.3430479934135075  (Index 148)[0m
================Epoch: 150================
Iteration 1: train_loss 1.2283709049224854
Iteration 2: train_loss 1.2197964191436768
Iteration 3: train_loss 1.1795654296875
Iteration 4: train_loss 1.2598987817764282
Iteration 5: train_loss 1.2475590705871582
Iteration 6: train_loss 1.1987687349319458
Iteration 7: train_loss 1.1846282482147217
Iteration 8: train_loss 1.1799119710922241
Iteration 9: train_loss 1.2049975395202637
Iteration 10: train_loss 1.1379218101501465
Iteration 11: train_loss 1.2158071994781494
Iteration 12: train_loss 1.2254321575164795
Iteration 13: train_loss 1.2161335945129395
Iteration 14: train_loss 1.1916347742080688
Iteration 15: train_loss 1.2174293994903564
Iteration 16: train_loss 1.2073428630828857
Iteration 17: train_loss 1.2145085334777832
Iteration 18: train_loss 1.1904890537261963
Iteration 19: train_loss 1.201673984527588
Iteration 20: train_loss 1.1662317514419556
Iteration 21: train_loss 1.232141137123108
Iteration 22: train_loss 1.1690152883529663
Iteration 23: train_loss 1.1835517883300781
Iteration 24: train_loss 1.1548460721969604
Iteration 25: train_loss 1.1768546104431152
Iteration 26: train_loss 1.1674671173095703
Iteration 27: train_loss 1.2292115688323975
Iteration 28: train_loss 1.1466292142868042
Iteration 29: train_loss 1.216028094291687
Iteration 30: train_loss 1.181421160697937
Iteration 31: train_loss 1.156799077987671
Iteration 32: train_loss 1.1959025859832764
Iteration 33: train_loss 1.1444299221038818
Iteration 34: train_loss 1.1715399026870728
Iteration 35: train_loss 1.1970089673995972
Iteration 36: train_loss 1.2319120168685913
Iteration 37: train_loss 1.1808966398239136
Iteration 38: train_loss 1.1695903539657593
Iteration 39: train_loss 1.2026604413986206
Iteration 40: train_loss 1.283094048500061
Iteration 41: train_loss 1.2389826774597168
Iteration 42: train_loss 1.233534574508667
Iteration 43: train_loss 1.201887845993042
Iteration 44: train_loss 1.1844453811645508
Iteration 45: train_loss 1.238973617553711
Iteration 46: train_loss 1.2705106735229492
Iteration 47: train_loss 1.1433215141296387
Iteration 48: train_loss 1.2003060579299927
Iteration 49: train_loss 1.1479527950286865
Iteration 50: train_loss 1.2546640634536743
Iteration 51: train_loss 1.1813493967056274
Iteration 52: train_loss 1.1823856830596924
Iteration 53: train_loss 1.2600836753845215
Iteration 54: train_loss 1.1725143194198608
Iteration 55: train_loss 1.209080696105957
Iteration 56: train_loss 1.1791423559188843
Iteration 57: train_loss 1.1965440511703491
Iteration 58: train_loss 1.2296196222305298
Iteration 59: train_loss 1.221928358078003
Iteration 60: train_loss 1.256334900856018
Iteration 61: train_loss 1.1880457401275635
Iteration 62: train_loss 1.224583387374878
Iteration 63: train_loss 1.2391743659973145
Iteration 64: train_loss 1.181716799736023
Iteration 65: train_loss 1.1995737552642822
Iteration 66: train_loss 1.1925190687179565
Iteration 67: train_loss 1.257865071296692
Iteration 68: train_loss 1.2024515867233276
Iteration 69: train_loss 1.218465805053711
Iteration 70: train_loss 1.212092638015747
Iteration 71: train_loss 1.2072396278381348
Iteration 72: train_loss 1.254780650138855
Iteration 73: train_loss 1.2310094833374023
Iteration 74: train_loss 1.211432933807373
Iteration 75: train_loss 1.224022626876831
Iteration 76: train_loss 1.293459177017212
Iteration 77: train_loss 1.306472659111023
Iteration 78: train_loss 1.1949186325073242
Iteration 79: train_loss 1.244860053062439
Iteration 80: train_loss 1.222974419593811
Iteration 81: train_loss 1.2113337516784668
Iteration 82: train_loss 1.2300113439559937
Iteration 83: train_loss 1.1619030237197876
Iteration 84: train_loss 1.1962648630142212
Iteration 85: train_loss 1.1989390850067139
Iteration 86: train_loss 1.1993939876556396
Iteration 87: train_loss 1.256837010383606
Iteration 88: train_loss 1.2002251148223877
Iteration 89: train_loss 1.1835463047027588
Iteration 90: train_loss 1.2350517511367798
Iteration 91: train_loss 1.2296713590621948
Iteration 92: train_loss 1.20798921585083
Iteration 93: train_loss 1.232039213180542
Iteration 94: train_loss 1.2640682458877563
Iteration 95: train_loss 1.2471798658370972
Iteration 96: train_loss 1.2738049030303955
Iteration 97: train_loss 1.2173585891723633
Iteration 98: train_loss 1.2380045652389526
Iteration 99: train_loss 1.2088518142700195
Iteration 100: train_loss 1.23760187625885
Iteration 101: train_loss 1.2263693809509277
Iteration 102: train_loss 1.2764962911605835
Iteration 103: train_loss 1.2449933290481567
Iteration 104: train_loss 1.2126954793930054
Iteration 105: train_loss 1.1880232095718384
Iteration 106: train_loss 1.2487826347351074
Iteration 107: train_loss 1.1754200458526611
Iteration 108: train_loss 1.183531403541565
Iteration 109: train_loss 1.21251380443573
Iteration 110: train_loss 1.2588165998458862
Iteration 111: train_loss 1.196481466293335
Iteration 112: train_loss 1.2314045429229736
Iteration 113: train_loss 1.2088189125061035
Iteration 114: train_loss 1.2573727369308472
Iteration 115: train_loss 1.1943572759628296
Iteration 116: train_loss 1.1851398944854736
Iteration 117: train_loss 1.2313833236694336
Iteration 118: train_loss 1.2169276475906372
Iteration 119: train_loss 1.1784605979919434
Iteration 120: train_loss 1.2051758766174316
Iteration 121: train_loss 1.167531132698059
Iteration 122: train_loss 1.2668956518173218
Iteration 123: train_loss 1.2064825296401978
Iteration 124: train_loss 1.2006139755249023
Iteration 125: train_loss 1.2317864894866943
Iteration 126: train_loss 1.1892244815826416
Iteration 127: train_loss 1.222089409828186
Iteration 128: train_loss 1.2304123640060425
Iteration 129: train_loss 1.2155159711837769
Iteration 130: train_loss 1.2319599390029907
Iteration 131: train_loss 1.178849220275879
Iteration 132: train_loss 1.2167717218399048
Iteration 133: train_loss 1.2121552228927612
Iteration 134: train_loss 1.2473539113998413
Iteration 135: train_loss 1.262480616569519
Iteration 136: train_loss 1.2758103609085083
Iteration 137: train_loss 1.271357774734497
Iteration 138: train_loss 1.204161524772644
Iteration 139: train_loss 1.2478225231170654
Iteration 140: train_loss 1.244551658630371
Iteration 141: train_loss 1.254905343055725
Iteration 142: train_loss 1.2424803972244263
Iteration 143: train_loss 1.249572515487671
Iteration 144: train_loss 1.2930575609207153
Iteration 145: train_loss 1.2502704858779907
Iteration 146: train_loss 1.2537357807159424
Iteration 147: train_loss 1.2499446868896484
Iteration 148: train_loss 1.2293729782104492
Iteration 149: train_loss 1.2200038433074951
Iteration 150: train_loss 1.2580184936523438
Iteration 151: train_loss 1.3028112649917603
Iteration 152: train_loss 1.3186001777648926
Iteration 153: train_loss 1.3300058841705322
Iteration 154: train_loss 1.3475418090820312
Iteration 155: train_loss 1.3278065919876099
Iteration 156: train_loss 1.1809773445129395
Iteration 157: train_loss 1.2814661264419556
Iteration 158: train_loss 1.2210179567337036
Iteration 159: train_loss 1.2436383962631226
Iteration 160: train_loss 1.2761262655258179
Iteration 161: train_loss 1.3516294956207275
Iteration 162: train_loss 1.304128885269165
Iteration 163: train_loss 1.2825359106063843
Iteration 164: train_loss 1.2386622428894043
Iteration 165: train_loss 1.2049599885940552
Iteration 166: train_loss 1.2321580648422241
Iteration 167: train_loss 1.218204140663147
Iteration 168: train_loss 1.2069995403289795
Iteration 169: train_loss 1.20431649684906
Iteration 170: train_loss 1.2025045156478882
Iteration 171: train_loss 1.211027979850769
Iteration 172: train_loss 1.2461472749710083
Iteration 173: train_loss 1.2232762575149536
Iteration 174: train_loss 1.2450153827667236
Iteration 175: train_loss 1.2319799661636353
Iteration 176: train_loss 1.2851295471191406
Iteration 177: train_loss 1.2476260662078857
Epoch 150: train_avg_loss 1.222288392357907 eval_avg_acc: 0.3397220879690666 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:29:05] [32mIntermediate result: 0.3397220879690666  (Index 149)[0m
================Epoch: 151================
Iteration 1: train_loss 1.2107057571411133
Iteration 2: train_loss 1.206681251525879
Iteration 3: train_loss 1.2412891387939453
Iteration 4: train_loss 1.2004553079605103
Iteration 5: train_loss 1.2722941637039185
Iteration 6: train_loss 1.2050594091415405
Iteration 7: train_loss 1.211026668548584
Iteration 8: train_loss 1.2376092672348022
Iteration 9: train_loss 1.223883867263794
Iteration 10: train_loss 1.221561312675476
Iteration 11: train_loss 1.188117504119873
Iteration 12: train_loss 1.1597168445587158
Iteration 13: train_loss 1.223275065422058
Iteration 14: train_loss 1.2163429260253906
Iteration 15: train_loss 1.2541896104812622
Iteration 16: train_loss 1.2404720783233643
Iteration 17: train_loss 1.2201781272888184
Iteration 18: train_loss 1.2630228996276855
Iteration 19: train_loss 1.1691224575042725
Iteration 20: train_loss 1.2029743194580078
Iteration 21: train_loss 1.1840476989746094
Iteration 22: train_loss 1.1518172025680542
Iteration 23: train_loss 1.277815580368042
Iteration 24: train_loss 1.2335548400878906
Iteration 25: train_loss 1.219041347503662
Iteration 26: train_loss 1.138256311416626
Iteration 27: train_loss 1.2121620178222656
Iteration 28: train_loss 1.190380334854126
Iteration 29: train_loss 1.1792370080947876
Iteration 30: train_loss 1.2177672386169434
Iteration 31: train_loss 1.2051854133605957
Iteration 32: train_loss 1.2014471292495728
Iteration 33: train_loss 1.2012476921081543
Iteration 34: train_loss 1.2451069355010986
Iteration 35: train_loss 1.2305470705032349
Iteration 36: train_loss 1.1764509677886963
Iteration 37: train_loss 1.1715830564498901
Iteration 38: train_loss 1.2452715635299683
Iteration 39: train_loss 1.2280241250991821
Iteration 40: train_loss 1.1824113130569458
Iteration 41: train_loss 1.1831884384155273
Iteration 42: train_loss 1.1678924560546875
Iteration 43: train_loss 1.15632963180542
Iteration 44: train_loss 1.1970469951629639
Iteration 45: train_loss 1.2095630168914795
Iteration 46: train_loss 1.1950304508209229
Iteration 47: train_loss 1.2474499940872192
Iteration 48: train_loss 1.2054320573806763
Iteration 49: train_loss 1.2138456106185913
Iteration 50: train_loss 1.2101751565933228
Iteration 51: train_loss 1.257232427597046
Iteration 52: train_loss 1.2149392366409302
Iteration 53: train_loss 1.1832282543182373
Iteration 54: train_loss 1.1861344575881958
Iteration 55: train_loss 1.2036792039871216
Iteration 56: train_loss 1.1934502124786377
Iteration 57: train_loss 1.18813157081604
Iteration 58: train_loss 1.2058000564575195
Iteration 59: train_loss 1.2051035165786743
Iteration 60: train_loss 1.1903666257858276
Iteration 61: train_loss 1.2021976709365845
Iteration 62: train_loss 1.2008336782455444
Iteration 63: train_loss 1.1617897748947144
Iteration 64: train_loss 1.2271462678909302
Iteration 65: train_loss 1.1802095174789429
Iteration 66: train_loss 1.2136543989181519
Iteration 67: train_loss 1.207399845123291
Iteration 68: train_loss 1.2029989957809448
Iteration 69: train_loss 1.2298675775527954
Iteration 70: train_loss 1.2280687093734741
Iteration 71: train_loss 1.205491304397583
Iteration 72: train_loss 1.26353120803833
Iteration 73: train_loss 1.2388886213302612
Iteration 74: train_loss 1.2178243398666382
Iteration 75: train_loss 1.2414329051971436
Iteration 76: train_loss 1.2238945960998535
Iteration 77: train_loss 1.255828619003296
Iteration 78: train_loss 1.2194889783859253
Iteration 79: train_loss 1.2618368864059448
Iteration 80: train_loss 1.2872190475463867
Iteration 81: train_loss 1.2326042652130127
Iteration 82: train_loss 1.2722057104110718
Iteration 83: train_loss 1.2406575679779053
Iteration 84: train_loss 1.1976909637451172
Iteration 85: train_loss 1.2152602672576904
Iteration 86: train_loss 1.2283118963241577
Iteration 87: train_loss 1.194779396057129
Iteration 88: train_loss 1.2694365978240967
Iteration 89: train_loss 1.218098759651184
Iteration 90: train_loss 1.2812230587005615
Iteration 91: train_loss 1.2075486183166504
Iteration 92: train_loss 1.1928393840789795
Iteration 93: train_loss 1.1679290533065796
Iteration 94: train_loss 1.237891435623169
Iteration 95: train_loss 1.2073462009429932
Iteration 96: train_loss 1.2402573823928833
Iteration 97: train_loss 1.2469145059585571
Iteration 98: train_loss 1.2688390016555786
Iteration 99: train_loss 1.193138837814331
Iteration 100: train_loss 1.1844940185546875
Iteration 101: train_loss 1.1815921068191528
Iteration 102: train_loss 1.2438589334487915
Iteration 103: train_loss 1.2635657787322998
Iteration 104: train_loss 1.2191574573516846
Iteration 105: train_loss 1.2047756910324097
Iteration 106: train_loss 1.2586688995361328
Iteration 107: train_loss 1.195698857307434
Iteration 108: train_loss 1.2328693866729736
Iteration 109: train_loss 1.2354713678359985
Iteration 110: train_loss 1.2191832065582275
Iteration 111: train_loss 1.2093791961669922
Iteration 112: train_loss 1.2142828702926636
Iteration 113: train_loss 1.1915565729141235
Iteration 114: train_loss 1.2224173545837402
Iteration 115: train_loss 1.2301973104476929
Iteration 116: train_loss 1.2412207126617432
Iteration 117: train_loss 1.1916826963424683
Iteration 118: train_loss 1.2267005443572998
Iteration 119: train_loss 1.2435438632965088
Iteration 120: train_loss 1.2526311874389648
Iteration 121: train_loss 1.2496497631072998
Iteration 122: train_loss 1.2395511865615845
Iteration 123: train_loss 1.217800259590149
Iteration 124: train_loss 1.2283329963684082
Iteration 125: train_loss 1.2115238904953003
Iteration 126: train_loss 1.2240217924118042
Iteration 127: train_loss 1.1757150888442993
Iteration 128: train_loss 1.1919602155685425
Iteration 129: train_loss 1.1857426166534424
Iteration 130: train_loss 1.1734095811843872
Iteration 131: train_loss 1.2186877727508545
Iteration 132: train_loss 1.2030444145202637
Iteration 133: train_loss 1.2120904922485352
Iteration 134: train_loss 1.1945772171020508
Iteration 135: train_loss 1.1831716299057007
Iteration 136: train_loss 1.176283597946167
Iteration 137: train_loss 1.1769376993179321
Iteration 138: train_loss 1.2428699731826782
Iteration 139: train_loss 1.1855013370513916
Iteration 140: train_loss 1.2299398183822632
Iteration 141: train_loss 1.1898736953735352
Iteration 142: train_loss 1.2047151327133179
Iteration 143: train_loss 1.2415038347244263
Iteration 144: train_loss 1.2702908515930176
Iteration 145: train_loss 1.2126152515411377
Iteration 146: train_loss 1.1922717094421387
Iteration 147: train_loss 1.1705329418182373
Iteration 148: train_loss 1.257203459739685
Iteration 149: train_loss 1.235304594039917
Iteration 150: train_loss 1.18752121925354
Iteration 151: train_loss 1.2339022159576416
Iteration 152: train_loss 1.2630047798156738
Iteration 153: train_loss 1.2011972665786743
Iteration 154: train_loss 1.2092207670211792
Iteration 155: train_loss 1.2279565334320068
Iteration 156: train_loss 1.2233914136886597
Iteration 157: train_loss 1.2699811458587646
Iteration 158: train_loss 1.2531286478042603
Iteration 159: train_loss 1.2527376413345337
Iteration 160: train_loss 1.235853910446167
Iteration 161: train_loss 1.1997332572937012
Iteration 162: train_loss 1.2694885730743408
Iteration 163: train_loss 1.205296277999878
Iteration 164: train_loss 1.2451730966567993
Iteration 165: train_loss 1.2344634532928467
Iteration 166: train_loss 1.2548224925994873
Iteration 167: train_loss 1.2853922843933105
Iteration 168: train_loss 1.2858625650405884
Iteration 169: train_loss 1.3084925413131714
Iteration 170: train_loss 1.309388279914856
Iteration 171: train_loss 1.2515393495559692
Iteration 172: train_loss 1.2783387899398804
Iteration 173: train_loss 1.3347411155700684
Iteration 174: train_loss 1.253943920135498
Iteration 175: train_loss 1.2124499082565308
Iteration 176: train_loss 1.2009257078170776
Iteration 177: train_loss 1.2131717205047607
Epoch 151: train_avg_loss 1.2198594222634525 eval_avg_acc: 0.3450949862358664 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:29:44] [32mIntermediate result: 0.3450949862358664  (Index 150)[0m
================Epoch: 152================
Iteration 1: train_loss 1.2020765542984009
Iteration 2: train_loss 1.1941765546798706
Iteration 3: train_loss 1.196671962738037
Iteration 4: train_loss 1.167916178703308
Iteration 5: train_loss 1.2430336475372314
Iteration 6: train_loss 1.179663896560669
Iteration 7: train_loss 1.2647675275802612
Iteration 8: train_loss 1.3013362884521484
Iteration 9: train_loss 1.280288577079773
Iteration 10: train_loss 1.1882721185684204
Iteration 11: train_loss 1.2264602184295654
Iteration 12: train_loss 1.199854850769043
Iteration 13: train_loss 1.1755897998809814
Iteration 14: train_loss 1.2133556604385376
Iteration 15: train_loss 1.1550121307373047
Iteration 16: train_loss 1.2408143281936646
Iteration 17: train_loss 1.1763808727264404
Iteration 18: train_loss 1.1589223146438599
Iteration 19: train_loss 1.1410480737686157
Iteration 20: train_loss 1.1762586832046509
Iteration 21: train_loss 1.2036226987838745
Iteration 22: train_loss 1.1615543365478516
Iteration 23: train_loss 1.2032599449157715
Iteration 24: train_loss 1.141821265220642
Iteration 25: train_loss 1.162175178527832
Iteration 26: train_loss 1.1768699884414673
Iteration 27: train_loss 1.2047467231750488
Iteration 28: train_loss 1.1865350008010864
Iteration 29: train_loss 1.1949712038040161
Iteration 30: train_loss 1.2213654518127441
Iteration 31: train_loss 1.2245253324508667
Iteration 32: train_loss 1.282164216041565
Iteration 33: train_loss 1.231047511100769
Iteration 34: train_loss 1.2338372468948364
Iteration 35: train_loss 1.1776423454284668
Iteration 36: train_loss 1.2033640146255493
Iteration 37: train_loss 1.2048590183258057
Iteration 38: train_loss 1.1505218744277954
Iteration 39: train_loss 1.125582218170166
Iteration 40: train_loss 1.1713829040527344
Iteration 41: train_loss 1.19132661819458
Iteration 42: train_loss 1.1895214319229126
Iteration 43: train_loss 1.172903060913086
Iteration 44: train_loss 1.213370680809021
Iteration 45: train_loss 1.1302720308303833
Iteration 46: train_loss 1.1866838932037354
Iteration 47: train_loss 1.1522059440612793
Iteration 48: train_loss 1.154888391494751
Iteration 49: train_loss 1.2254095077514648
Iteration 50: train_loss 1.2066564559936523
Iteration 51: train_loss 1.221217155456543
Iteration 52: train_loss 1.198867917060852
Iteration 53: train_loss 1.1556334495544434
Iteration 54: train_loss 1.1949007511138916
Iteration 55: train_loss 1.2164480686187744
Iteration 56: train_loss 1.2260541915893555
Iteration 57: train_loss 1.1651175022125244
Iteration 58: train_loss 1.1781069040298462
Iteration 59: train_loss 1.1795051097869873
Iteration 60: train_loss 1.1589499711990356
Iteration 61: train_loss 1.1995444297790527
Iteration 62: train_loss 1.168839693069458
Iteration 63: train_loss 1.1345465183258057
Iteration 64: train_loss 1.1841871738433838
Iteration 65: train_loss 1.1392848491668701
Iteration 66: train_loss 1.2023060321807861
Iteration 67: train_loss 1.1661484241485596
Iteration 68: train_loss 1.1767982244491577
Iteration 69: train_loss 1.1343697309494019
Iteration 70: train_loss 1.1844297647476196
Iteration 71: train_loss 1.2116093635559082
Iteration 72: train_loss 1.2278378009796143
Iteration 73: train_loss 1.1203635931015015
Iteration 74: train_loss 1.1933212280273438
Iteration 75: train_loss 1.157163143157959
Iteration 76: train_loss 1.1586148738861084
Iteration 77: train_loss 1.161586880683899
Iteration 78: train_loss 1.2299474477767944
Iteration 79: train_loss 1.2317582368850708
Iteration 80: train_loss 1.197295904159546
Iteration 81: train_loss 1.2223421335220337
Iteration 82: train_loss 1.262524127960205
Iteration 83: train_loss 1.3485881090164185
Iteration 84: train_loss 1.2690303325653076
Iteration 85: train_loss 1.1983543634414673
Iteration 86: train_loss 1.2589291334152222
Iteration 87: train_loss 1.259046196937561
Iteration 88: train_loss 1.2364379167556763
Iteration 89: train_loss 1.1831848621368408
Iteration 90: train_loss 1.27606201171875
Iteration 91: train_loss 1.2695286273956299
Iteration 92: train_loss 1.2733759880065918
Iteration 93: train_loss 1.2926576137542725
Iteration 94: train_loss 1.2484396696090698
Iteration 95: train_loss 1.2366068363189697
Iteration 96: train_loss 1.2271682024002075
Iteration 97: train_loss 1.2125027179718018
Iteration 98: train_loss 1.1904282569885254
Iteration 99: train_loss 1.1940773725509644
Iteration 100: train_loss 1.2381631135940552
Iteration 101: train_loss 1.2200884819030762
Iteration 102: train_loss 1.1630644798278809
Iteration 103: train_loss 1.1992567777633667
Iteration 104: train_loss 1.232361912727356
Iteration 105: train_loss 1.189361572265625
Iteration 106: train_loss 1.23883855342865
Iteration 107: train_loss 1.2613790035247803
Iteration 108: train_loss 1.189090609550476
Iteration 109: train_loss 1.186140775680542
Iteration 110: train_loss 1.1959389448165894
Iteration 111: train_loss 1.2489701509475708
Iteration 112: train_loss 1.1921226978302002
Iteration 113: train_loss 1.1496367454528809
Iteration 114: train_loss 1.224723219871521
Iteration 115: train_loss 1.2348393201828003
Iteration 116: train_loss 1.2361747026443481
Iteration 117: train_loss 1.2147109508514404
Iteration 118: train_loss 1.1388448476791382
Iteration 119: train_loss 1.2297687530517578
Iteration 120: train_loss 1.1601016521453857
Iteration 121: train_loss 1.275159239768982
Iteration 122: train_loss 1.2291926145553589
Iteration 123: train_loss 1.2613418102264404
Iteration 124: train_loss 1.2148412466049194
Iteration 125: train_loss 1.2072060108184814
Iteration 126: train_loss 1.2046964168548584
Iteration 127: train_loss 1.2233293056488037
Iteration 128: train_loss 1.2700437307357788
Iteration 129: train_loss 1.1663897037506104
Iteration 130: train_loss 1.2760595083236694
Iteration 131: train_loss 1.2034085988998413
Iteration 132: train_loss 1.189929723739624
Iteration 133: train_loss 1.2023957967758179
Iteration 134: train_loss 1.1976615190505981
Iteration 135: train_loss 1.1867948770523071
Iteration 136: train_loss 1.1776665449142456
Iteration 137: train_loss 1.148036003112793
Iteration 138: train_loss 1.1654112339019775
Iteration 139: train_loss 1.2339588403701782
Iteration 140: train_loss 1.2288978099822998
Iteration 141: train_loss 1.265576958656311
Iteration 142: train_loss 1.2340898513793945
Iteration 143: train_loss 1.2009516954421997
Iteration 144: train_loss 1.2519010305404663
Iteration 145: train_loss 1.1881099939346313
Iteration 146: train_loss 1.190779685974121
Iteration 147: train_loss 1.2004798650741577
Iteration 148: train_loss 1.252408742904663
Iteration 149: train_loss 1.1812077760696411
Iteration 150: train_loss 1.2075973749160767
Iteration 151: train_loss 1.2367892265319824
Iteration 152: train_loss 1.232465147972107
Iteration 153: train_loss 1.2070964574813843
Iteration 154: train_loss 1.221861720085144
Iteration 155: train_loss 1.2101801633834839
Iteration 156: train_loss 1.2346346378326416
Iteration 157: train_loss 1.1539052724838257
Iteration 158: train_loss 1.1647014617919922
Iteration 159: train_loss 1.1771528720855713
Iteration 160: train_loss 1.2513645887374878
Iteration 161: train_loss 1.1979224681854248
Iteration 162: train_loss 1.2209982872009277
Iteration 163: train_loss 1.17510986328125
Iteration 164: train_loss 1.1980828046798706
Iteration 165: train_loss 1.194220781326294
Iteration 166: train_loss 1.1457757949829102
Iteration 167: train_loss 1.2043381929397583
Iteration 168: train_loss 1.195281982421875
Iteration 169: train_loss 1.2095521688461304
Iteration 170: train_loss 1.218148112297058
Iteration 171: train_loss 1.1957924365997314
Iteration 172: train_loss 1.1838347911834717
Iteration 173: train_loss 1.2359275817871094
Iteration 174: train_loss 1.2258777618408203
Iteration 175: train_loss 1.2270647287368774
Iteration 176: train_loss 1.1797492504119873
Iteration 177: train_loss 1.1026880741119385
Epoch 152: train_avg_loss 1.203845440331152 eval_avg_acc: 0.34821057534966543 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:30:23] [32mIntermediate result: 0.34821057534966543  (Index 151)[0m
================Epoch: 153================
Iteration 1: train_loss 1.1859685182571411
Iteration 2: train_loss 1.2121171951293945
Iteration 3: train_loss 1.2197448015213013
Iteration 4: train_loss 1.1742311716079712
Iteration 5: train_loss 1.1856646537780762
Iteration 6: train_loss 1.1739599704742432
Iteration 7: train_loss 1.1522188186645508
Iteration 8: train_loss 1.219821572303772
Iteration 9: train_loss 1.1120325326919556
Iteration 10: train_loss 1.1469687223434448
Iteration 11: train_loss 1.1717904806137085
Iteration 12: train_loss 1.2053338289260864
Iteration 13: train_loss 1.1875660419464111
Iteration 14: train_loss 1.152550220489502
Iteration 15: train_loss 1.196342945098877
Iteration 16: train_loss 1.1669853925704956
Iteration 17: train_loss 1.1860991716384888
Iteration 18: train_loss 1.1654269695281982
Iteration 19: train_loss 1.198188066482544
Iteration 20: train_loss 1.1678109169006348
Iteration 21: train_loss 1.183196783065796
Iteration 22: train_loss 1.152303695678711
Iteration 23: train_loss 1.1531355381011963
Iteration 24: train_loss 1.187295913696289
Iteration 25: train_loss 1.1819299459457397
Iteration 26: train_loss 1.1818877458572388
Iteration 27: train_loss 1.1688991785049438
Iteration 28: train_loss 1.1324656009674072
Iteration 29: train_loss 1.1912418603897095
Iteration 30: train_loss 1.133691668510437
Iteration 31: train_loss 1.1112200021743774
Iteration 32: train_loss 1.1183191537857056
Iteration 33: train_loss 1.223124384880066
Iteration 34: train_loss 1.15226149559021
Iteration 35: train_loss 1.1937776803970337
Iteration 36: train_loss 1.1878530979156494
Iteration 37: train_loss 1.1931978464126587
Iteration 38: train_loss 1.1439603567123413
Iteration 39: train_loss 1.1763253211975098
Iteration 40: train_loss 1.200561761856079
Iteration 41: train_loss 1.1985325813293457
Iteration 42: train_loss 1.2236614227294922
Iteration 43: train_loss 1.2048550844192505
Iteration 44: train_loss 1.1959614753723145
Iteration 45: train_loss 1.195981502532959
Iteration 46: train_loss 1.1283292770385742
Iteration 47: train_loss 1.1703696250915527
Iteration 48: train_loss 1.2224924564361572
Iteration 49: train_loss 1.2571367025375366
Iteration 50: train_loss 1.1914440393447876
Iteration 51: train_loss 1.1952468156814575
Iteration 52: train_loss 1.2396953105926514
Iteration 53: train_loss 1.1901336908340454
Iteration 54: train_loss 1.2120254039764404
Iteration 55: train_loss 1.202231526374817
Iteration 56: train_loss 1.148790717124939
Iteration 57: train_loss 1.2206820249557495
Iteration 58: train_loss 1.1960034370422363
Iteration 59: train_loss 1.1754316091537476
Iteration 60: train_loss 1.1904019117355347
Iteration 61: train_loss 1.1902642250061035
Iteration 62: train_loss 1.1958069801330566
Iteration 63: train_loss 1.2534027099609375
Iteration 64: train_loss 1.1785361766815186
Iteration 65: train_loss 1.1397758722305298
Iteration 66: train_loss 1.2315226793289185
Iteration 67: train_loss 1.2295029163360596
Iteration 68: train_loss 1.2108874320983887
Iteration 69: train_loss 1.2524833679199219
Iteration 70: train_loss 1.235364317893982
Iteration 71: train_loss 1.2215315103530884
Iteration 72: train_loss 1.1837831735610962
Iteration 73: train_loss 1.1849873065948486
Iteration 74: train_loss 1.24991774559021
Iteration 75: train_loss 1.2723180055618286
Iteration 76: train_loss 1.2430145740509033
Iteration 77: train_loss 1.2482391595840454
Iteration 78: train_loss 1.2667144536972046
Iteration 79: train_loss 1.1819896697998047
Iteration 80: train_loss 1.2555664777755737
Iteration 81: train_loss 1.244727611541748
Iteration 82: train_loss 1.2458925247192383
Iteration 83: train_loss 1.2029658555984497
Iteration 84: train_loss 1.2308679819107056
Iteration 85: train_loss 1.1974055767059326
Iteration 86: train_loss 1.2014790773391724
Iteration 87: train_loss 1.233271837234497
Iteration 88: train_loss 1.2318452596664429
Iteration 89: train_loss 1.172983169555664
Iteration 90: train_loss 1.1836963891983032
Iteration 91: train_loss 1.1400734186172485
Iteration 92: train_loss 1.074806571006775
Iteration 93: train_loss 1.160405158996582
Iteration 94: train_loss 1.1764638423919678
Iteration 95: train_loss 1.1808981895446777
Iteration 96: train_loss 1.0848551988601685
Iteration 97: train_loss 1.1834087371826172
Iteration 98: train_loss 1.2569489479064941
Iteration 99: train_loss 1.2324053049087524
Iteration 100: train_loss 1.119800329208374
Iteration 101: train_loss 1.1678107976913452
Iteration 102: train_loss 1.1853299140930176
Iteration 103: train_loss 1.1766629219055176
Iteration 104: train_loss 1.2352911233901978
Iteration 105: train_loss 1.2039110660552979
Iteration 106: train_loss 1.1924968957901
Iteration 107: train_loss 1.1847556829452515
Iteration 108: train_loss 1.1522139310836792
Iteration 109: train_loss 1.1768261194229126
Iteration 110: train_loss 1.2389363050460815
Iteration 111: train_loss 1.2152179479599
Iteration 112: train_loss 1.2100138664245605
Iteration 113: train_loss 1.1834372282028198
Iteration 114: train_loss 1.2112804651260376
Iteration 115: train_loss 1.2031948566436768
Iteration 116: train_loss 1.1852748394012451
Iteration 117: train_loss 1.2364400625228882
Iteration 118: train_loss 1.201282262802124
Iteration 119: train_loss 1.2023290395736694
Iteration 120: train_loss 1.2067643404006958
Iteration 121: train_loss 1.2156281471252441
Iteration 122: train_loss 1.1708139181137085
Iteration 123: train_loss 1.2314531803131104
Iteration 124: train_loss 1.2793421745300293
Iteration 125: train_loss 1.1964263916015625
Iteration 126: train_loss 1.219886064529419
Iteration 127: train_loss 1.2673367261886597
Iteration 128: train_loss 1.1891964673995972
Iteration 129: train_loss 1.2725483179092407
Iteration 130: train_loss 1.2469184398651123
Iteration 131: train_loss 1.2860077619552612
Iteration 132: train_loss 1.285821795463562
Iteration 133: train_loss 1.1832610368728638
Iteration 134: train_loss 1.2438188791275024
Iteration 135: train_loss 1.21518874168396
Iteration 136: train_loss 1.2719032764434814
Iteration 137: train_loss 1.211833119392395
Iteration 138: train_loss 1.1923574209213257
Iteration 139: train_loss 1.2002887725830078
Iteration 140: train_loss 1.2228974103927612
Iteration 141: train_loss 1.1656434535980225
Iteration 142: train_loss 1.1917810440063477
Iteration 143: train_loss 1.2068525552749634
Iteration 144: train_loss 1.2304296493530273
Iteration 145: train_loss 1.1725739240646362
Iteration 146: train_loss 1.1931371688842773
Iteration 147: train_loss 1.1622384786605835
Iteration 148: train_loss 1.1801639795303345
Iteration 149: train_loss 1.2860065698623657
Iteration 150: train_loss 1.2405184507369995
Iteration 151: train_loss 1.2077090740203857
Iteration 152: train_loss 1.1327353715896606
Iteration 153: train_loss 1.2014456987380981
Iteration 154: train_loss 1.1972469091415405
Iteration 155: train_loss 1.1875760555267334
Iteration 156: train_loss 1.252974510192871
Iteration 157: train_loss 1.1874041557312012
Iteration 158: train_loss 1.1993958950042725
Iteration 159: train_loss 1.1433771848678589
Iteration 160: train_loss 1.2478606700897217
Iteration 161: train_loss 1.1786558628082275
Iteration 162: train_loss 1.2121754884719849
Iteration 163: train_loss 1.2470258474349976
Iteration 164: train_loss 1.242461085319519
Iteration 165: train_loss 1.1922506093978882
Iteration 166: train_loss 1.2361736297607422
Iteration 167: train_loss 1.248719334602356
Iteration 168: train_loss 1.223711609840393
Iteration 169: train_loss 1.202147126197815
Iteration 170: train_loss 1.2090893983840942
Iteration 171: train_loss 1.2342948913574219
Iteration 172: train_loss 1.251652479171753
Iteration 173: train_loss 1.284265160560608
Iteration 174: train_loss 1.298431158065796
Iteration 175: train_loss 1.2631882429122925
Iteration 176: train_loss 1.2072653770446777
Iteration 177: train_loss 1.2467992305755615
Epoch 153: train_avg_loss 1.201273798942566 eval_avg_acc: 0.344674968491321 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:31:03] [32mIntermediate result: 0.344674968491321  (Index 152)[0m
================Epoch: 154================
Iteration 1: train_loss 1.2321563959121704
Iteration 2: train_loss 1.1868034601211548
Iteration 3: train_loss 1.2189064025878906
Iteration 4: train_loss 1.2099473476409912
Iteration 5: train_loss 1.1729539632797241
Iteration 6: train_loss 1.206465482711792
Iteration 7: train_loss 1.171863317489624
Iteration 8: train_loss 1.2709635496139526
Iteration 9: train_loss 1.2179985046386719
Iteration 10: train_loss 1.189828872680664
Iteration 11: train_loss 1.1751505136489868
Iteration 12: train_loss 1.164880633354187
Iteration 13: train_loss 1.238337516784668
Iteration 14: train_loss 1.2599282264709473
Iteration 15: train_loss 1.1727283000946045
Iteration 16: train_loss 1.1459249258041382
Iteration 17: train_loss 1.190239667892456
Iteration 18: train_loss 1.1919277906417847
Iteration 19: train_loss 1.1856051683425903
Iteration 20: train_loss 1.1700433492660522
Iteration 21: train_loss 1.1738895177841187
Iteration 22: train_loss 1.1912869215011597
Iteration 23: train_loss 1.113989233970642
Iteration 24: train_loss 1.1622029542922974
Iteration 25: train_loss 1.1954567432403564
Iteration 26: train_loss 1.1708539724349976
Iteration 27: train_loss 1.2177698612213135
Iteration 28: train_loss 1.1895880699157715
Iteration 29: train_loss 1.1960335969924927
Iteration 30: train_loss 1.1752632856369019
Iteration 31: train_loss 1.1721476316452026
Iteration 32: train_loss 1.2274569272994995
Iteration 33: train_loss 1.1717044115066528
Iteration 34: train_loss 1.214229702949524
Iteration 35: train_loss 1.2392865419387817
Iteration 36: train_loss 1.1496303081512451
Iteration 37: train_loss 1.1784591674804688
Iteration 38: train_loss 1.2204995155334473
Iteration 39: train_loss 1.1888798475265503
Iteration 40: train_loss 1.1866875886917114
Iteration 41: train_loss 1.2492058277130127
Iteration 42: train_loss 1.246330738067627
Iteration 43: train_loss 1.2428158521652222
Iteration 44: train_loss 1.287475347518921
Iteration 45: train_loss 1.2278419733047485
Iteration 46: train_loss 1.2610410451889038
Iteration 47: train_loss 1.2017550468444824
Iteration 48: train_loss 1.2238831520080566
Iteration 49: train_loss 1.276105523109436
Iteration 50: train_loss 1.2502415180206299
Iteration 51: train_loss 1.2424707412719727
Iteration 52: train_loss 1.2824348211288452
Iteration 53: train_loss 1.2097777128219604
Iteration 54: train_loss 1.2446448802947998
Iteration 55: train_loss 1.2041386365890503
Iteration 56: train_loss 1.2226535081863403
Iteration 57: train_loss 1.1904345750808716
Iteration 58: train_loss 1.207052230834961
Iteration 59: train_loss 1.1756815910339355
Iteration 60: train_loss 1.210005283355713
Iteration 61: train_loss 1.272519826889038
Iteration 62: train_loss 1.2186959981918335
Iteration 63: train_loss 1.1733907461166382
Iteration 64: train_loss 1.1624531745910645
Iteration 65: train_loss 1.172879934310913
Iteration 66: train_loss 1.2978514432907104
Iteration 67: train_loss 1.3040003776550293
Iteration 68: train_loss 1.2144356966018677
Iteration 69: train_loss 1.205628752708435
Iteration 70: train_loss 1.2256836891174316
Iteration 71: train_loss 1.195562481880188
Iteration 72: train_loss 1.1656407117843628
Iteration 73: train_loss 1.1354215145111084
Iteration 74: train_loss 1.2038629055023193
Iteration 75: train_loss 1.2108113765716553
Iteration 76: train_loss 1.1886634826660156
Iteration 77: train_loss 1.1891369819641113
Iteration 78: train_loss 1.1844861507415771
Iteration 79: train_loss 1.1831334829330444
Iteration 80: train_loss 1.1874439716339111
Iteration 81: train_loss 1.1634795665740967
Iteration 82: train_loss 1.167944312095642
Iteration 83: train_loss 1.2334685325622559
Iteration 84: train_loss 1.195304274559021
Iteration 85: train_loss 1.1326407194137573
Iteration 86: train_loss 1.223583459854126
Iteration 87: train_loss 1.1967705488204956
Iteration 88: train_loss 1.1821893453598022
Iteration 89: train_loss 1.1545277833938599
Iteration 90: train_loss 1.1996651887893677
Iteration 91: train_loss 1.1691550016403198
Iteration 92: train_loss 1.1862446069717407
Iteration 93: train_loss 1.200496792793274
Iteration 94: train_loss 1.2472354173660278
Iteration 95: train_loss 1.2084165811538696
Iteration 96: train_loss 1.220542073249817
Iteration 97: train_loss 1.2581032514572144
Iteration 98: train_loss 1.24099862575531
Iteration 99: train_loss 1.1749272346496582
Iteration 100: train_loss 1.1891261339187622
Iteration 101: train_loss 1.2204854488372803
Iteration 102: train_loss 1.2812691926956177
Iteration 103: train_loss 1.2008718252182007
Iteration 104: train_loss 1.2243990898132324
Iteration 105: train_loss 1.2276629209518433
Iteration 106: train_loss 1.2397040128707886
Iteration 107: train_loss 1.2786304950714111
Iteration 108: train_loss 1.1906784772872925
Iteration 109: train_loss 1.2355194091796875
Iteration 110: train_loss 1.2126461267471313
Iteration 111: train_loss 1.193588376045227
Iteration 112: train_loss 1.1367462873458862
Iteration 113: train_loss 1.2024530172348022
Iteration 114: train_loss 1.1853585243225098
Iteration 115: train_loss 1.2673834562301636
Iteration 116: train_loss 1.1830779314041138
Iteration 117: train_loss 1.208020567893982
Iteration 118: train_loss 1.3199567794799805
Iteration 119: train_loss 1.1878747940063477
Iteration 120: train_loss 1.2084845304489136
Iteration 121: train_loss 1.274088978767395
Iteration 122: train_loss 1.2954416275024414
Iteration 123: train_loss 1.2768198251724243
Iteration 124: train_loss 1.3214223384857178
Iteration 125: train_loss 1.2690891027450562
Iteration 126: train_loss 1.2493022680282593
Iteration 127: train_loss 1.2374931573867798
Iteration 128: train_loss 1.2794965505599976
Iteration 129: train_loss 1.2729666233062744
Iteration 130: train_loss 1.2690201997756958
Iteration 131: train_loss 1.1948816776275635
Iteration 132: train_loss 1.1610743999481201
Iteration 133: train_loss 1.1936835050582886
Iteration 134: train_loss 1.2260814905166626
Iteration 135: train_loss 1.2203534841537476
Iteration 136: train_loss 1.2375706434249878
Iteration 137: train_loss 1.173911213874817
Iteration 138: train_loss 1.24494206905365
Iteration 139: train_loss 1.2674973011016846
Iteration 140: train_loss 1.2445787191390991
Iteration 141: train_loss 1.2310328483581543
Iteration 142: train_loss 1.1491780281066895
Iteration 143: train_loss 1.1944482326507568
Iteration 144: train_loss 1.2333811521530151
Iteration 145: train_loss 1.2322927713394165
Iteration 146: train_loss 1.1919389963150024
Iteration 147: train_loss 1.193007469177246
Iteration 148: train_loss 1.21783447265625
Iteration 149: train_loss 1.199988842010498
Iteration 150: train_loss 1.2360050678253174
Iteration 151: train_loss 1.1955710649490356
Iteration 152: train_loss 1.228286862373352
Iteration 153: train_loss 1.212424874305725
Iteration 154: train_loss 1.270596981048584
Iteration 155: train_loss 1.222586750984192
Iteration 156: train_loss 1.229587197303772
Iteration 157: train_loss 1.1988377571105957
Iteration 158: train_loss 1.1735928058624268
Iteration 159: train_loss 1.237192153930664
Iteration 160: train_loss 1.2637771368026733
Iteration 161: train_loss 1.258309245109558
Iteration 162: train_loss 1.2200689315795898
Iteration 163: train_loss 1.2477341890335083
Iteration 164: train_loss 1.2764003276824951
Iteration 165: train_loss 1.2023966312408447
Iteration 166: train_loss 1.2369316816329956
Iteration 167: train_loss 1.2488280534744263
Iteration 168: train_loss 1.2157647609710693
Iteration 169: train_loss 1.246529459953308
Iteration 170: train_loss 1.2111226320266724
Iteration 171: train_loss 1.205869436264038
Iteration 172: train_loss 1.2885138988494873
Iteration 173: train_loss 1.2591934204101562
Iteration 174: train_loss 1.2111667394638062
Iteration 175: train_loss 1.1961455345153809
Iteration 176: train_loss 1.1827714443206787
Iteration 177: train_loss 1.26985764503479
Epoch 154: train_avg_loss 1.2147128433830994 eval_avg_acc: 0.34573082348487905 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:31:42] [32mIntermediate result: 0.34573082348487905  (Index 153)[0m
================Epoch: 155================
Iteration 1: train_loss 1.2135083675384521
Iteration 2: train_loss 1.1883907318115234
Iteration 3: train_loss 1.167381763458252
Iteration 4: train_loss 1.1964483261108398
Iteration 5: train_loss 1.19600248336792
Iteration 6: train_loss 1.1681686639785767
Iteration 7: train_loss 1.1938738822937012
Iteration 8: train_loss 1.1898541450500488
Iteration 9: train_loss 1.180402398109436
Iteration 10: train_loss 1.1873596906661987
Iteration 11: train_loss 1.2093678712844849
Iteration 12: train_loss 1.1755205392837524
Iteration 13: train_loss 1.183067798614502
Iteration 14: train_loss 1.1695681810379028
Iteration 15: train_loss 1.2152949571609497
Iteration 16: train_loss 1.198555588722229
Iteration 17: train_loss 1.213534951210022
Iteration 18: train_loss 1.223347783088684
Iteration 19: train_loss 1.202397346496582
Iteration 20: train_loss 1.1749651432037354
Iteration 21: train_loss 1.2173644304275513
Iteration 22: train_loss 1.1966431140899658
Iteration 23: train_loss 1.143608570098877
Iteration 24: train_loss 1.1754591464996338
Iteration 25: train_loss 1.2259924411773682
Iteration 26: train_loss 1.2593294382095337
Iteration 27: train_loss 1.2461906671524048
Iteration 28: train_loss 1.2147148847579956
Iteration 29: train_loss 1.2341254949569702
Iteration 30: train_loss 1.238869309425354
Iteration 31: train_loss 1.205956220626831
Iteration 32: train_loss 1.1942425966262817
Iteration 33: train_loss 1.21242356300354
Iteration 34: train_loss 1.2226214408874512
Iteration 35: train_loss 1.2102419137954712
Iteration 36: train_loss 1.1671768426895142
Iteration 37: train_loss 1.1953521966934204
Iteration 38: train_loss 1.2304903268814087
Iteration 39: train_loss 1.2023277282714844
Iteration 40: train_loss 1.1477904319763184
Iteration 41: train_loss 1.1469149589538574
Iteration 42: train_loss 1.1985394954681396
Iteration 43: train_loss 1.131125569343567
Iteration 44: train_loss 1.1641560792922974
Iteration 45: train_loss 1.2094227075576782
Iteration 46: train_loss 1.1396726369857788
Iteration 47: train_loss 1.1857423782348633
Iteration 48: train_loss 1.2167737483978271
Iteration 49: train_loss 1.1569870710372925
Iteration 50: train_loss 1.1345182657241821
Iteration 51: train_loss 1.1597380638122559
Iteration 52: train_loss 1.19036865234375
Iteration 53: train_loss 1.177843689918518
Iteration 54: train_loss 1.1862804889678955
Iteration 55: train_loss 1.221683144569397
Iteration 56: train_loss 1.1411161422729492
Iteration 57: train_loss 1.2330174446105957
Iteration 58: train_loss 1.1607192754745483
Iteration 59: train_loss 1.1813569068908691
Iteration 60: train_loss 1.1995465755462646
Iteration 61: train_loss 1.2055696249008179
Iteration 62: train_loss 1.174596905708313
Iteration 63: train_loss 1.1975867748260498
Iteration 64: train_loss 1.215203046798706
Iteration 65: train_loss 1.141417384147644
Iteration 66: train_loss 1.2017333507537842
Iteration 67: train_loss 1.2038787603378296
Iteration 68: train_loss 1.143690586090088
Iteration 69: train_loss 1.209413766860962
Iteration 70: train_loss 1.1604559421539307
Iteration 71: train_loss 1.1949645280838013
Iteration 72: train_loss 1.182493805885315
Iteration 73: train_loss 1.1999832391738892
Iteration 74: train_loss 1.1822280883789062
Iteration 75: train_loss 1.2333111763000488
Iteration 76: train_loss 1.2015573978424072
Iteration 77: train_loss 1.1973062753677368
Iteration 78: train_loss 1.1849687099456787
Iteration 79: train_loss 1.2145806550979614
Iteration 80: train_loss 1.159487009048462
Iteration 81: train_loss 1.2235252857208252
Iteration 82: train_loss 1.195538878440857
Iteration 83: train_loss 1.2251163721084595
Iteration 84: train_loss 1.2306593656539917
Iteration 85: train_loss 1.2356836795806885
Iteration 86: train_loss 1.2131541967391968
Iteration 87: train_loss 1.1953402757644653
Iteration 88: train_loss 1.2340525388717651
Iteration 89: train_loss 1.2129716873168945
Iteration 90: train_loss 1.2385368347167969
Iteration 91: train_loss 1.2583465576171875
Iteration 92: train_loss 1.1930773258209229
Iteration 93: train_loss 1.201405644416809
Iteration 94: train_loss 1.1333047151565552
Iteration 95: train_loss 1.2217671871185303
Iteration 96: train_loss 1.2946218252182007
Iteration 97: train_loss 1.1851410865783691
Iteration 98: train_loss 1.2220982313156128
Iteration 99: train_loss 1.1874511241912842
Iteration 100: train_loss 1.1292964220046997
Iteration 101: train_loss 1.1812599897384644
Iteration 102: train_loss 1.2315226793289185
Iteration 103: train_loss 1.1936862468719482
Iteration 104: train_loss 1.142994999885559
Iteration 105: train_loss 1.2422984838485718
Iteration 106: train_loss 1.2244853973388672
Iteration 107: train_loss 1.262762427330017
Iteration 108: train_loss 1.2073266506195068
Iteration 109: train_loss 1.22694730758667
Iteration 110: train_loss 1.1915637254714966
Iteration 111: train_loss 1.2517741918563843
Iteration 112: train_loss 1.1913570165634155
Iteration 113: train_loss 1.241395354270935
Iteration 114: train_loss 1.2301461696624756
Iteration 115: train_loss 1.1884801387786865
Iteration 116: train_loss 1.1897932291030884
Iteration 117: train_loss 1.2568483352661133
Iteration 118: train_loss 1.1811435222625732
Iteration 119: train_loss 1.228756308555603
Iteration 120: train_loss 1.1976968050003052
Iteration 121: train_loss 1.2122138738632202
Iteration 122: train_loss 1.1721382141113281
Iteration 123: train_loss 1.2089788913726807
Iteration 124: train_loss 1.2076733112335205
Iteration 125: train_loss 1.167989730834961
Iteration 126: train_loss 1.2366747856140137
Iteration 127: train_loss 1.1949759721755981
Iteration 128: train_loss 1.2505086660385132
Iteration 129: train_loss 1.2123245000839233
Iteration 130: train_loss 1.2040551900863647
Iteration 131: train_loss 1.2035634517669678
Iteration 132: train_loss 1.2028130292892456
Iteration 133: train_loss 1.2461875677108765
Iteration 134: train_loss 1.2256640195846558
Iteration 135: train_loss 1.2006031274795532
Iteration 136: train_loss 1.2421151399612427
Iteration 137: train_loss 1.2043464183807373
Iteration 138: train_loss 1.2407664060592651
Iteration 139: train_loss 1.2500478029251099
Iteration 140: train_loss 1.1482627391815186
Iteration 141: train_loss 1.1778578758239746
Iteration 142: train_loss 1.1573516130447388
Iteration 143: train_loss 1.2537870407104492
Iteration 144: train_loss 1.254363775253296
Iteration 145: train_loss 1.27824068069458
Iteration 146: train_loss 1.254231333732605
Iteration 147: train_loss 1.2489969730377197
Iteration 148: train_loss 1.179547667503357
Iteration 149: train_loss 1.1995370388031006
Iteration 150: train_loss 1.1925015449523926
Iteration 151: train_loss 1.2074334621429443
Iteration 152: train_loss 1.2041469812393188
Iteration 153: train_loss 1.214365005493164
Iteration 154: train_loss 1.2055782079696655
Iteration 155: train_loss 1.2334117889404297
Iteration 156: train_loss 1.1959789991378784
Iteration 157: train_loss 1.2616688013076782
Iteration 158: train_loss 1.2192515134811401
Iteration 159: train_loss 1.2431949377059937
Iteration 160: train_loss 1.1687523126602173
Iteration 161: train_loss 1.196795105934143
Iteration 162: train_loss 1.2072744369506836
Iteration 163: train_loss 1.181039810180664
Iteration 164: train_loss 1.2748538255691528
Iteration 165: train_loss 1.2736448049545288
Iteration 166: train_loss 1.2149723768234253
Iteration 167: train_loss 1.262342095375061
Iteration 168: train_loss 1.1999574899673462
Iteration 169: train_loss 1.2052555084228516
Iteration 170: train_loss 1.1855357885360718
Iteration 171: train_loss 1.2038381099700928
Iteration 172: train_loss 1.1855745315551758
Iteration 173: train_loss 1.213282585144043
Iteration 174: train_loss 1.2702327966690063
Iteration 175: train_loss 1.1908676624298096
Iteration 176: train_loss 1.2394678592681885
Iteration 177: train_loss 1.1707139015197754
Epoch 155: train_avg_loss 1.2038359264869474 eval_avg_acc: 0.3404085312140411 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:32:22] [32mIntermediate result: 0.3404085312140411  (Index 154)[0m
================Epoch: 156================
Iteration 1: train_loss 1.2081525325775146
Iteration 2: train_loss 1.1959779262542725
Iteration 3: train_loss 1.1755138635635376
Iteration 4: train_loss 1.2198927402496338
Iteration 5: train_loss 1.2373607158660889
Iteration 6: train_loss 1.1662232875823975
Iteration 7: train_loss 1.2245827913284302
Iteration 8: train_loss 1.2115132808685303
Iteration 9: train_loss 1.1971635818481445
Iteration 10: train_loss 1.1632983684539795
Iteration 11: train_loss 1.141530156135559
Iteration 12: train_loss 1.1391032934188843
Iteration 13: train_loss 1.1488984823226929
Iteration 14: train_loss 1.1458426713943481
Iteration 15: train_loss 1.2034229040145874
Iteration 16: train_loss 1.172044038772583
Iteration 17: train_loss 1.1471939086914062
Iteration 18: train_loss 1.157029151916504
Iteration 19: train_loss 1.161494255065918
Iteration 20: train_loss 1.1831355094909668
Iteration 21: train_loss 1.1895896196365356
Iteration 22: train_loss 1.1495418548583984
Iteration 23: train_loss 1.1198021173477173
Iteration 24: train_loss 1.223757028579712
Iteration 25: train_loss 1.1968450546264648
Iteration 26: train_loss 1.166731834411621
Iteration 27: train_loss 1.1579232215881348
Iteration 28: train_loss 1.1707391738891602
Iteration 29: train_loss 1.1515709161758423
Iteration 30: train_loss 1.2392176389694214
Iteration 31: train_loss 1.1121106147766113
Iteration 32: train_loss 1.1655166149139404
Iteration 33: train_loss 1.197495460510254
Iteration 34: train_loss 1.205705165863037
Iteration 35: train_loss 1.1846699714660645
Iteration 36: train_loss 1.1956584453582764
Iteration 37: train_loss 1.2364654541015625
Iteration 38: train_loss 1.2067737579345703
Iteration 39: train_loss 1.260459303855896
Iteration 40: train_loss 1.2079801559448242
Iteration 41: train_loss 1.1886485815048218
Iteration 42: train_loss 1.273044228553772
Iteration 43: train_loss 1.2654943466186523
Iteration 44: train_loss 1.1671415567398071
Iteration 45: train_loss 1.0866127014160156
Iteration 46: train_loss 1.1949548721313477
Iteration 47: train_loss 1.2030597925186157
Iteration 48: train_loss 1.1842572689056396
Iteration 49: train_loss 1.166967749595642
Iteration 50: train_loss 1.2269549369812012
Iteration 51: train_loss 1.2602647542953491
Iteration 52: train_loss 1.18773353099823
Iteration 53: train_loss 1.2382301092147827
Iteration 54: train_loss 1.2097417116165161
Iteration 55: train_loss 1.2264409065246582
Iteration 56: train_loss 1.2090051174163818
Iteration 57: train_loss 1.1943963766098022
Iteration 58: train_loss 1.2033716440200806
Iteration 59: train_loss 1.1434063911437988
Iteration 60: train_loss 1.1993671655654907
Iteration 61: train_loss 1.229131817817688
Iteration 62: train_loss 1.1863129138946533
Iteration 63: train_loss 1.1670796871185303
Iteration 64: train_loss 1.1830474138259888
Iteration 65: train_loss 1.1851807832717896
Iteration 66: train_loss 1.1965539455413818
Iteration 67: train_loss 1.2031911611557007
Iteration 68: train_loss 1.2132515907287598
Iteration 69: train_loss 1.2019156217575073
Iteration 70: train_loss 1.2015286684036255
Iteration 71: train_loss 1.229102611541748
Iteration 72: train_loss 1.1996631622314453
Iteration 73: train_loss 1.2281343936920166
Iteration 74: train_loss 1.186963438987732
Iteration 75: train_loss 1.2131470441818237
Iteration 76: train_loss 1.1703659296035767
Iteration 77: train_loss 1.2283530235290527
Iteration 78: train_loss 1.2194675207138062
Iteration 79: train_loss 1.2558499574661255
Iteration 80: train_loss 1.2323579788208008
Iteration 81: train_loss 1.2029473781585693
Iteration 82: train_loss 1.176607370376587
Iteration 83: train_loss 1.1425762176513672
Iteration 84: train_loss 1.196445107460022
Iteration 85: train_loss 1.3007230758666992
Iteration 86: train_loss 1.2844406366348267
Iteration 87: train_loss 1.2542376518249512
Iteration 88: train_loss 1.1847478151321411
Iteration 89: train_loss 1.1262387037277222
Iteration 90: train_loss 1.1806098222732544
Iteration 91: train_loss 1.1736160516738892
Iteration 92: train_loss 1.213755488395691
Iteration 93: train_loss 1.207680583000183
Iteration 94: train_loss 1.2160886526107788
Iteration 95: train_loss 1.2035127878189087
Iteration 96: train_loss 1.1958664655685425
Iteration 97: train_loss 1.1976710557937622
Iteration 98: train_loss 1.161733865737915
Iteration 99: train_loss 1.195326805114746
Iteration 100: train_loss 1.1753703355789185
Iteration 101: train_loss 1.1927238702774048
Iteration 102: train_loss 1.2293815612792969
Iteration 103: train_loss 1.1793296337127686
Iteration 104: train_loss 1.2166155576705933
Iteration 105: train_loss 1.2208596467971802
Iteration 106: train_loss 1.2077155113220215
Iteration 107: train_loss 1.2048200368881226
Iteration 108: train_loss 1.2260757684707642
Iteration 109: train_loss 1.1929118633270264
Iteration 110: train_loss 1.2686104774475098
Iteration 111: train_loss 1.2263405323028564
Iteration 112: train_loss 1.255218505859375
Iteration 113: train_loss 1.1385918855667114
Iteration 114: train_loss 1.2054270505905151
Iteration 115: train_loss 1.1940393447875977
Iteration 116: train_loss 1.1806684732437134
Iteration 117: train_loss 1.2243752479553223
Iteration 118: train_loss 1.1998215913772583
Iteration 119: train_loss 1.2281131744384766
Iteration 120: train_loss 1.2098549604415894
Iteration 121: train_loss 1.1766974925994873
Iteration 122: train_loss 1.2270262241363525
Iteration 123: train_loss 1.267866611480713
Iteration 124: train_loss 1.2088398933410645
Iteration 125: train_loss 1.1667336225509644
Iteration 126: train_loss 1.204949975013733
Iteration 127: train_loss 1.2344708442687988
Iteration 128: train_loss 1.267621397972107
Iteration 129: train_loss 1.1808186769485474
Iteration 130: train_loss 1.211199164390564
Iteration 131: train_loss 1.1873146295547485
Iteration 132: train_loss 1.181343674659729
Iteration 133: train_loss 1.2418251037597656
Iteration 134: train_loss 1.1858911514282227
Iteration 135: train_loss 1.1683151721954346
Iteration 136: train_loss 1.2455140352249146
Iteration 137: train_loss 1.2419604063034058
Iteration 138: train_loss 1.1866685152053833
Iteration 139: train_loss 1.2441260814666748
Iteration 140: train_loss 1.1880791187286377
Iteration 141: train_loss 1.2852755784988403
Iteration 142: train_loss 1.1672980785369873
Iteration 143: train_loss 1.2549176216125488
Iteration 144: train_loss 1.219434380531311
Iteration 145: train_loss 1.1647326946258545
Iteration 146: train_loss 1.2160820960998535
Iteration 147: train_loss 1.189578890800476
Iteration 148: train_loss 1.2136441469192505
Iteration 149: train_loss 1.210962176322937
Iteration 150: train_loss 1.2427469491958618
Iteration 151: train_loss 1.2178720235824585
Iteration 152: train_loss 1.2248268127441406
Iteration 153: train_loss 1.1708189249038696
Iteration 154: train_loss 1.208556890487671
Iteration 155: train_loss 1.207500696182251
Iteration 156: train_loss 1.2295207977294922
Iteration 157: train_loss 1.2439699172973633
Iteration 158: train_loss 1.2157233953475952
Iteration 159: train_loss 1.1551238298416138
Iteration 160: train_loss 1.184486985206604
Iteration 161: train_loss 1.1972659826278687
Iteration 162: train_loss 1.15055513381958
Iteration 163: train_loss 1.1900560855865479
Iteration 164: train_loss 1.2693308591842651
Iteration 165: train_loss 1.242397427558899
Iteration 166: train_loss 1.1911851167678833
Iteration 167: train_loss 1.1980509757995605
Iteration 168: train_loss 1.2511662244796753
Iteration 169: train_loss 1.3211930990219116
Iteration 170: train_loss 1.2759411334991455
Iteration 171: train_loss 1.2435556650161743
Iteration 172: train_loss 1.2063482999801636
Iteration 173: train_loss 1.2986977100372314
Iteration 174: train_loss 1.205162763595581
Iteration 175: train_loss 1.217533826828003
Iteration 176: train_loss 1.27780282497406
Iteration 177: train_loss 1.214242935180664
Epoch 156: train_avg_loss 1.2038425456332622 eval_avg_acc: 0.3469368413935258 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:33:02] [32mIntermediate result: 0.3469368413935258  (Index 155)[0m
================Epoch: 157================
Iteration 1: train_loss 1.1665222644805908
Iteration 2: train_loss 1.171586513519287
Iteration 3: train_loss 1.1775224208831787
Iteration 4: train_loss 1.2069519758224487
Iteration 5: train_loss 1.2190479040145874
Iteration 6: train_loss 1.1820800304412842
Iteration 7: train_loss 1.1009190082550049
Iteration 8: train_loss 1.2182835340499878
Iteration 9: train_loss 1.2010338306427002
Iteration 10: train_loss 1.142259955406189
Iteration 11: train_loss 1.1648294925689697
Iteration 12: train_loss 1.2466721534729004
Iteration 13: train_loss 1.2386062145233154
Iteration 14: train_loss 1.2122516632080078
Iteration 15: train_loss 1.1925431489944458
Iteration 16: train_loss 1.2438817024230957
Iteration 17: train_loss 1.2868105173110962
Iteration 18: train_loss 1.2277414798736572
Iteration 19: train_loss 1.2498152256011963
Iteration 20: train_loss 1.2016479969024658
Iteration 21: train_loss 1.2188329696655273
Iteration 22: train_loss 1.236680507659912
Iteration 23: train_loss 1.2117141485214233
Iteration 24: train_loss 1.158718466758728
Iteration 25: train_loss 1.1618634462356567
Iteration 26: train_loss 1.2279199361801147
Iteration 27: train_loss 1.170810580253601
Iteration 28: train_loss 1.1478943824768066
Iteration 29: train_loss 1.1653188467025757
Iteration 30: train_loss 1.1941558122634888
Iteration 31: train_loss 1.1802984476089478
Iteration 32: train_loss 1.1376289129257202
Iteration 33: train_loss 1.1608844995498657
Iteration 34: train_loss 1.168038010597229
Iteration 35: train_loss 1.1748254299163818
Iteration 36: train_loss 1.1819292306900024
Iteration 37: train_loss 1.1611756086349487
Iteration 38: train_loss 1.1731276512145996
Iteration 39: train_loss 1.198767066001892
Iteration 40: train_loss 1.160805344581604
Iteration 41: train_loss 1.1734355688095093
Iteration 42: train_loss 1.1209750175476074
Iteration 43: train_loss 1.1901451349258423
Iteration 44: train_loss 1.1910500526428223
Iteration 45: train_loss 1.1830264329910278
Iteration 46: train_loss 1.1621736288070679
Iteration 47: train_loss 1.1977665424346924
Iteration 48: train_loss 1.1626343727111816
Iteration 49: train_loss 1.1946368217468262
Iteration 50: train_loss 1.158525824546814
Iteration 51: train_loss 1.1750019788742065
Iteration 52: train_loss 1.1694982051849365
Iteration 53: train_loss 1.209713339805603
Iteration 54: train_loss 1.1706966161727905
Iteration 55: train_loss 1.2568986415863037
Iteration 56: train_loss 1.2231649160385132
Iteration 57: train_loss 1.2222844362258911
Iteration 58: train_loss 1.1990491151809692
Iteration 59: train_loss 1.1675119400024414
Iteration 60: train_loss 1.1516895294189453
Iteration 61: train_loss 1.2107535600662231
Iteration 62: train_loss 1.1988787651062012
Iteration 63: train_loss 1.1522794961929321
Iteration 64: train_loss 1.160880446434021
Iteration 65: train_loss 1.1601872444152832
Iteration 66: train_loss 1.2128978967666626
Iteration 67: train_loss 1.206329345703125
Iteration 68: train_loss 1.200160264968872
Iteration 69: train_loss 1.158846139907837
Iteration 70: train_loss 1.2171435356140137
Iteration 71: train_loss 1.1703271865844727
Iteration 72: train_loss 1.1836186647415161
Iteration 73: train_loss 1.1722110509872437
Iteration 74: train_loss 1.192396640777588
Iteration 75: train_loss 1.207893967628479
Iteration 76: train_loss 1.2012332677841187
Iteration 77: train_loss 1.2262763977050781
Iteration 78: train_loss 1.1958820819854736
Iteration 79: train_loss 1.1911474466323853
Iteration 80: train_loss 1.151392936706543
Iteration 81: train_loss 1.1729044914245605
Iteration 82: train_loss 1.1230889558792114
Iteration 83: train_loss 1.1583316326141357
Iteration 84: train_loss 1.178139328956604
Iteration 85: train_loss 1.1734620332717896
Iteration 86: train_loss 1.1817559003829956
Iteration 87: train_loss 1.1618396043777466
Iteration 88: train_loss 1.155431866645813
Iteration 89: train_loss 1.146606206893921
Iteration 90: train_loss 1.1840702295303345
Iteration 91: train_loss 1.1563594341278076
Iteration 92: train_loss 1.1748642921447754
Iteration 93: train_loss 1.1934897899627686
Iteration 94: train_loss 1.22475266456604
Iteration 95: train_loss 1.184366226196289
Iteration 96: train_loss 1.1835286617279053
Iteration 97: train_loss 1.1870262622833252
Iteration 98: train_loss 1.1535452604293823
Iteration 99: train_loss 1.1784355640411377
Iteration 100: train_loss 1.1955686807632446
Iteration 101: train_loss 1.1980583667755127
Iteration 102: train_loss 1.1658821105957031
Iteration 103: train_loss 1.2002007961273193
Iteration 104: train_loss 1.2549604177474976
Iteration 105: train_loss 1.1461693048477173
Iteration 106: train_loss 1.2481341361999512
Iteration 107: train_loss 1.242753267288208
Iteration 108: train_loss 1.2463891506195068
Iteration 109: train_loss 1.1902947425842285
Iteration 110: train_loss 1.1702929735183716
Iteration 111: train_loss 1.1951608657836914
Iteration 112: train_loss 1.2373783588409424
Iteration 113: train_loss 1.2046880722045898
Iteration 114: train_loss 1.1768903732299805
Iteration 115: train_loss 1.22294282913208
Iteration 116: train_loss 1.2398465871810913
Iteration 117: train_loss 1.2373229265213013
Iteration 118: train_loss 1.2871317863464355
Iteration 119: train_loss 1.209041714668274
Iteration 120: train_loss 1.169743537902832
Iteration 121: train_loss 1.1835832595825195
Iteration 122: train_loss 1.1745589971542358
Iteration 123: train_loss 1.18575119972229
Iteration 124: train_loss 1.1899082660675049
Iteration 125: train_loss 1.22580885887146
Iteration 126: train_loss 1.2284915447235107
Iteration 127: train_loss 1.2004010677337646
Iteration 128: train_loss 1.2101507186889648
Iteration 129: train_loss 1.2003318071365356
Iteration 130: train_loss 1.222292423248291
Iteration 131: train_loss 1.237940788269043
Iteration 132: train_loss 1.2367783784866333
Iteration 133: train_loss 1.2269458770751953
Iteration 134: train_loss 1.1758029460906982
Iteration 135: train_loss 1.248947262763977
Iteration 136: train_loss 1.259433627128601
Iteration 137: train_loss 1.224975824356079
Iteration 138: train_loss 1.2176951169967651
Iteration 139: train_loss 1.2417136430740356
Iteration 140: train_loss 1.2733404636383057
Iteration 141: train_loss 1.1676265001296997
Iteration 142: train_loss 1.193987250328064
Iteration 143: train_loss 1.2489241361618042
Iteration 144: train_loss 1.224280834197998
Iteration 145: train_loss 1.27054762840271
Iteration 146: train_loss 1.2145856618881226
Iteration 147: train_loss 1.244122862815857
Iteration 148: train_loss 1.2175418138504028
Iteration 149: train_loss 1.1985952854156494
Iteration 150: train_loss 1.1875361204147339
Iteration 151: train_loss 1.2087546586990356
Iteration 152: train_loss 1.1909821033477783
Iteration 153: train_loss 1.230234980583191
Iteration 154: train_loss 1.2632384300231934
Iteration 155: train_loss 1.1766916513442993
Iteration 156: train_loss 1.2179105281829834
Iteration 157: train_loss 1.1839418411254883
Iteration 158: train_loss 1.2454465627670288
Iteration 159: train_loss 1.2045520544052124
Iteration 160: train_loss 1.1858428716659546
Iteration 161: train_loss 1.1780263185501099
Iteration 162: train_loss 1.2793163061141968
Iteration 163: train_loss 1.2243585586547852
Iteration 164: train_loss 1.2881375551223755
Iteration 165: train_loss 1.1970709562301636
Iteration 166: train_loss 1.2562097311019897
Iteration 167: train_loss 1.2221475839614868
Iteration 168: train_loss 1.1486856937408447
Iteration 169: train_loss 1.2302707433700562
Iteration 170: train_loss 1.2583003044128418
Iteration 171: train_loss 1.2044684886932373
Iteration 172: train_loss 1.1893575191497803
Iteration 173: train_loss 1.1733613014221191
Iteration 174: train_loss 1.1889615058898926
Iteration 175: train_loss 1.2806720733642578
Iteration 176: train_loss 1.1742660999298096
Iteration 177: train_loss 1.2069801092147827
Epoch 157: train_avg_loss 1.1985573270226602 eval_avg_acc: 0.34632116786840894 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:33:40] [32mIntermediate result: 0.34632116786840894  (Index 156)[0m
================Epoch: 158================
Iteration 1: train_loss 1.1578147411346436
Iteration 2: train_loss 1.275728702545166
Iteration 3: train_loss 1.1889891624450684
Iteration 4: train_loss 1.2216870784759521
Iteration 5: train_loss 1.106124758720398
Iteration 6: train_loss 1.2075772285461426
Iteration 7: train_loss 1.1998181343078613
Iteration 8: train_loss 1.2510193586349487
Iteration 9: train_loss 1.1901750564575195
Iteration 10: train_loss 1.196160912513733
Iteration 11: train_loss 1.2449229955673218
Iteration 12: train_loss 1.2130509614944458
Iteration 13: train_loss 1.1666829586029053
Iteration 14: train_loss 1.19383704662323
Iteration 15: train_loss 1.1578091382980347
Iteration 16: train_loss 1.130377173423767
Iteration 17: train_loss 1.20966374874115
Iteration 18: train_loss 1.1533070802688599
Iteration 19: train_loss 1.177100419998169
Iteration 20: train_loss 1.2045022249221802
Iteration 21: train_loss 1.1193214654922485
Iteration 22: train_loss 1.16482675075531
Iteration 23: train_loss 1.2258983850479126
Iteration 24: train_loss 1.196875810623169
Iteration 25: train_loss 1.1229647397994995
Iteration 26: train_loss 1.1600030660629272
Iteration 27: train_loss 1.1985660791397095
Iteration 28: train_loss 1.177581548690796
Iteration 29: train_loss 1.234264850616455
Iteration 30: train_loss 1.1861587762832642
Iteration 31: train_loss 1.1953933238983154
Iteration 32: train_loss 1.1769405603408813
Iteration 33: train_loss 1.1412996053695679
Iteration 34: train_loss 1.1509945392608643
Iteration 35: train_loss 1.2212201356887817
Iteration 36: train_loss 1.0766940116882324
Iteration 37: train_loss 1.18662428855896
Iteration 38: train_loss 1.1522308588027954
Iteration 39: train_loss 1.2242302894592285
Iteration 40: train_loss 1.2509663105010986
Iteration 41: train_loss 1.1809093952178955
Iteration 42: train_loss 1.1138523817062378
Iteration 43: train_loss 1.100191593170166
Iteration 44: train_loss 1.1563981771469116
Iteration 45: train_loss 1.175600290298462
Iteration 46: train_loss 1.160898208618164
Iteration 47: train_loss 1.1176059246063232
Iteration 48: train_loss 1.1424064636230469
Iteration 49: train_loss 1.2060517072677612
Iteration 50: train_loss 1.1421107053756714
Iteration 51: train_loss 1.0899685621261597
Iteration 52: train_loss 1.2047678232192993
Iteration 53: train_loss 1.2123088836669922
Iteration 54: train_loss 1.1964596509933472
Iteration 55: train_loss 1.1629157066345215
Iteration 56: train_loss 1.1724385023117065
Iteration 57: train_loss 1.1601940393447876
Iteration 58: train_loss 1.234993815422058
Iteration 59: train_loss 1.1419106721878052
Iteration 60: train_loss 1.1412094831466675
Iteration 61: train_loss 1.184802770614624
Iteration 62: train_loss 1.2063109874725342
Iteration 63: train_loss 1.1747009754180908
Iteration 64: train_loss 1.2147787809371948
Iteration 65: train_loss 1.208439588546753
Iteration 66: train_loss 1.2398474216461182
Iteration 67: train_loss 1.2293061017990112
Iteration 68: train_loss 1.1899936199188232
Iteration 69: train_loss 1.154275894165039
Iteration 70: train_loss 1.2195130586624146
Iteration 71: train_loss 1.1779357194900513
Iteration 72: train_loss 1.1916816234588623
Iteration 73: train_loss 1.2033344507217407
Iteration 74: train_loss 1.1842319965362549
Iteration 75: train_loss 1.226039171218872
Iteration 76: train_loss 1.1657806634902954
Iteration 77: train_loss 1.1751004457473755
Iteration 78: train_loss 1.2322196960449219
Iteration 79: train_loss 1.1717263460159302
Iteration 80: train_loss 1.1219958066940308
Iteration 81: train_loss 1.1884714365005493
Iteration 82: train_loss 1.1793031692504883
Iteration 83: train_loss 1.1549007892608643
Iteration 84: train_loss 1.2510782480239868
Iteration 85: train_loss 1.1282340288162231
Iteration 86: train_loss 1.2119545936584473
Iteration 87: train_loss 1.2156819105148315
Iteration 88: train_loss 1.2419836521148682
Iteration 89: train_loss 1.2514269351959229
Iteration 90: train_loss 1.2441582679748535
Iteration 91: train_loss 1.18882155418396
Iteration 92: train_loss 1.2333701848983765
Iteration 93: train_loss 1.1971207857131958
Iteration 94: train_loss 1.1945780515670776
Iteration 95: train_loss 1.186249852180481
Iteration 96: train_loss 1.1926908493041992
Iteration 97: train_loss 1.2000384330749512
Iteration 98: train_loss 1.2539691925048828
Iteration 99: train_loss 1.1683317422866821
Iteration 100: train_loss 1.1964101791381836
Iteration 101: train_loss 1.2205997705459595
Iteration 102: train_loss 1.1815423965454102
Iteration 103: train_loss 1.1964892148971558
Iteration 104: train_loss 1.1864434480667114
Iteration 105: train_loss 1.2117509841918945
Iteration 106: train_loss 1.2251598834991455
Iteration 107: train_loss 1.1611605882644653
Iteration 108: train_loss 1.2214562892913818
Iteration 109: train_loss 1.1758755445480347
Iteration 110: train_loss 1.1421395540237427
Iteration 111: train_loss 1.1664894819259644
Iteration 112: train_loss 1.1732653379440308
Iteration 113: train_loss 1.1849892139434814
Iteration 114: train_loss 1.1830004453659058
Iteration 115: train_loss 1.2129653692245483
Iteration 116: train_loss 1.1631872653961182
Iteration 117: train_loss 1.2305530309677124
Iteration 118: train_loss 1.1727573871612549
Iteration 119: train_loss 1.1521440744400024
Iteration 120: train_loss 1.193083643913269
Iteration 121: train_loss 1.186081886291504
Iteration 122: train_loss 1.2514299154281616
Iteration 123: train_loss 1.2447409629821777
Iteration 124: train_loss 1.2143031358718872
Iteration 125: train_loss 1.1990339756011963
Iteration 126: train_loss 1.1747454404830933
Iteration 127: train_loss 1.2352268695831299
Iteration 128: train_loss 1.2086563110351562
Iteration 129: train_loss 1.1950801610946655
Iteration 130: train_loss 1.191845178604126
Iteration 131: train_loss 1.2306076288223267
Iteration 132: train_loss 1.2131718397140503
Iteration 133: train_loss 1.1465799808502197
Iteration 134: train_loss 1.190102458000183
Iteration 135: train_loss 1.2147549390792847
Iteration 136: train_loss 1.230870246887207
Iteration 137: train_loss 1.222894310951233
Iteration 138: train_loss 1.2475676536560059
Iteration 139: train_loss 1.2862600088119507
Iteration 140: train_loss 1.2053704261779785
Iteration 141: train_loss 1.2150927782058716
Iteration 142: train_loss 1.2754613161087036
Iteration 143: train_loss 1.2068111896514893
Iteration 144: train_loss 1.2566734552383423
Iteration 145: train_loss 1.228771448135376
Iteration 146: train_loss 1.1989316940307617
Iteration 147: train_loss 1.1921168565750122
Iteration 148: train_loss 1.1953784227371216
Iteration 149: train_loss 1.2152915000915527
Iteration 150: train_loss 1.2834904193878174
Iteration 151: train_loss 1.2256044149398804
Iteration 152: train_loss 1.1806268692016602
Iteration 153: train_loss 1.2158422470092773
Iteration 154: train_loss 1.2744907140731812
Iteration 155: train_loss 1.2614954710006714
Iteration 156: train_loss 1.195664882659912
Iteration 157: train_loss 1.2764930725097656
Iteration 158: train_loss 1.2112616300582886
Iteration 159: train_loss 1.2225693464279175
Iteration 160: train_loss 1.1951326131820679
Iteration 161: train_loss 1.2250598669052124
Iteration 162: train_loss 1.2302591800689697
Iteration 163: train_loss 1.2110880613327026
Iteration 164: train_loss 1.245355248451233
Iteration 165: train_loss 1.2230793237686157
Iteration 166: train_loss 1.1902250051498413
Iteration 167: train_loss 1.1782596111297607
Iteration 168: train_loss 1.2585011720657349
Iteration 169: train_loss 1.2142072916030884
Iteration 170: train_loss 1.180942416191101
Iteration 171: train_loss 1.1743874549865723
Iteration 172: train_loss 1.1900302171707153
Iteration 173: train_loss 1.1783394813537598
Iteration 174: train_loss 1.206291675567627
Iteration 175: train_loss 1.2188711166381836
Iteration 176: train_loss 1.237682819366455
Iteration 177: train_loss 1.171449899673462
Epoch 158: train_avg_loss 1.1959265066405473 eval_avg_acc: 0.3414021992944389 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:34:19] [32mIntermediate result: 0.3414021992944389  (Index 157)[0m
================Epoch: 159================
Iteration 1: train_loss 1.209089756011963
Iteration 2: train_loss 1.1358568668365479
Iteration 3: train_loss 1.1398767232894897
Iteration 4: train_loss 1.2175593376159668
Iteration 5: train_loss 1.174089789390564
Iteration 6: train_loss 1.1820857524871826
Iteration 7: train_loss 1.195925235748291
Iteration 8: train_loss 1.2307690382003784
Iteration 9: train_loss 1.1813493967056274
Iteration 10: train_loss 1.1443496942520142
Iteration 11: train_loss 1.2216078042984009
Iteration 12: train_loss 1.1855003833770752
Iteration 13: train_loss 1.2298263311386108
Iteration 14: train_loss 1.193029522895813
Iteration 15: train_loss 1.1559109687805176
Iteration 16: train_loss 1.186612606048584
Iteration 17: train_loss 1.1383715867996216
Iteration 18: train_loss 1.1803429126739502
Iteration 19: train_loss 1.2306419610977173
Iteration 20: train_loss 1.2219789028167725
Iteration 21: train_loss 1.1766825914382935
Iteration 22: train_loss 1.1687246561050415
Iteration 23: train_loss 1.1686742305755615
Iteration 24: train_loss 1.1615687608718872
Iteration 25: train_loss 1.1832712888717651
Iteration 26: train_loss 1.1800146102905273
Iteration 27: train_loss 1.2257983684539795
Iteration 28: train_loss 1.1385741233825684
Iteration 29: train_loss 1.165152668952942
Iteration 30: train_loss 1.1788493394851685
Iteration 31: train_loss 1.1712040901184082
Iteration 32: train_loss 1.1677298545837402
Iteration 33: train_loss 1.1443324089050293
Iteration 34: train_loss 1.1562637090682983
Iteration 35: train_loss 1.231619954109192
Iteration 36: train_loss 1.1766873598098755
Iteration 37: train_loss 1.2364134788513184
Iteration 38: train_loss 1.1535415649414062
Iteration 39: train_loss 1.1640981435775757
Iteration 40: train_loss 1.176176905632019
Iteration 41: train_loss 1.178324818611145
Iteration 42: train_loss 1.1840953826904297
Iteration 43: train_loss 1.1648277044296265
Iteration 44: train_loss 1.1502714157104492
Iteration 45: train_loss 1.233087420463562
Iteration 46: train_loss 1.2230422496795654
Iteration 47: train_loss 1.1884530782699585
Iteration 48: train_loss 1.1949284076690674
Iteration 49: train_loss 1.1884560585021973
Iteration 50: train_loss 1.2087260484695435
Iteration 51: train_loss 1.1774673461914062
Iteration 52: train_loss 1.2082204818725586
Iteration 53: train_loss 1.1834633350372314
Iteration 54: train_loss 1.2127714157104492
Iteration 55: train_loss 1.2274590730667114
Iteration 56: train_loss 1.169338345527649
Iteration 57: train_loss 1.205448031425476
Iteration 58: train_loss 1.2365883588790894
Iteration 59: train_loss 1.2659180164337158
Iteration 60: train_loss 1.2436772584915161
Iteration 61: train_loss 1.2200485467910767
Iteration 62: train_loss 1.172310471534729
Iteration 63: train_loss 1.2142255306243896
Iteration 64: train_loss 1.176250696182251
Iteration 65: train_loss 1.1678588390350342
Iteration 66: train_loss 1.2083289623260498
Iteration 67: train_loss 1.154056191444397
Iteration 68: train_loss 1.194334626197815
Iteration 69: train_loss 1.1397639513015747
Iteration 70: train_loss 1.1990872621536255
Iteration 71: train_loss 1.1569344997406006
Iteration 72: train_loss 1.2219966650009155
Iteration 73: train_loss 1.2176792621612549
Iteration 74: train_loss 1.1924347877502441
Iteration 75: train_loss 1.209107518196106
Iteration 76: train_loss 1.234298825263977
Iteration 77: train_loss 1.2249468564987183
Iteration 78: train_loss 1.1988636255264282
Iteration 79: train_loss 1.222580909729004
Iteration 80: train_loss 1.195429801940918
Iteration 81: train_loss 1.1484211683273315
Iteration 82: train_loss 1.1706784963607788
Iteration 83: train_loss 1.2126715183258057
Iteration 84: train_loss 1.219953179359436
Iteration 85: train_loss 1.1699477434158325
Iteration 86: train_loss 1.178911566734314
Iteration 87: train_loss 1.1563999652862549
Iteration 88: train_loss 1.1722239255905151
Iteration 89: train_loss 1.198225736618042
Iteration 90: train_loss 1.120779275894165
Iteration 91: train_loss 1.1876455545425415
Iteration 92: train_loss 1.1890472173690796
Iteration 93: train_loss 1.206761121749878
Iteration 94: train_loss 1.100691318511963
Iteration 95: train_loss 1.192750096321106
Iteration 96: train_loss 1.211496114730835
Iteration 97: train_loss 1.1702077388763428
Iteration 98: train_loss 1.191664218902588
Iteration 99: train_loss 1.1617792844772339
Iteration 100: train_loss 1.1353175640106201
Iteration 101: train_loss 1.151625156402588
Iteration 102: train_loss 1.2468147277832031
Iteration 103: train_loss 1.2135977745056152
Iteration 104: train_loss 1.212400197982788
Iteration 105: train_loss 1.2038767337799072
Iteration 106: train_loss 1.270990252494812
Iteration 107: train_loss 1.20887291431427
Iteration 108: train_loss 1.2519586086273193
Iteration 109: train_loss 1.2110683917999268
Iteration 110: train_loss 1.186592936515808
Iteration 111: train_loss 1.1500669717788696
Iteration 112: train_loss 1.2602033615112305
Iteration 113: train_loss 1.2055349349975586
Iteration 114: train_loss 1.181681752204895
Iteration 115: train_loss 1.1005594730377197
Iteration 116: train_loss 1.175459861755371
Iteration 117: train_loss 1.1522159576416016
Iteration 118: train_loss 1.225898027420044
Iteration 119: train_loss 1.1193608045578003
Iteration 120: train_loss 1.218538761138916
Iteration 121: train_loss 1.2072343826293945
Iteration 122: train_loss 1.24147367477417
Iteration 123: train_loss 1.2225745916366577
Iteration 124: train_loss 1.1579198837280273
Iteration 125: train_loss 1.2333067655563354
Iteration 126: train_loss 1.1805592775344849
Iteration 127: train_loss 1.2057785987854004
Iteration 128: train_loss 1.2387536764144897
Iteration 129: train_loss 1.2301450967788696
Iteration 130: train_loss 1.2081538438796997
Iteration 131: train_loss 1.2689529657363892
Iteration 132: train_loss 1.1392457485198975
Iteration 133: train_loss 1.239446997642517
Iteration 134: train_loss 1.223748803138733
Iteration 135: train_loss 1.1668485403060913
Iteration 136: train_loss 1.1808173656463623
Iteration 137: train_loss 1.177492380142212
Iteration 138: train_loss 1.1933706998825073
Iteration 139: train_loss 1.2180697917938232
Iteration 140: train_loss 1.1842219829559326
Iteration 141: train_loss 1.2388190031051636
Iteration 142: train_loss 1.1727579832077026
Iteration 143: train_loss 1.1418733596801758
Iteration 144: train_loss 1.1671206951141357
Iteration 145: train_loss 1.2354165315628052
Iteration 146: train_loss 1.1853222846984863
Iteration 147: train_loss 1.1930654048919678
Iteration 148: train_loss 1.1520872116088867
Iteration 149: train_loss 1.1692930459976196
Iteration 150: train_loss 1.147446632385254
Iteration 151: train_loss 1.166284441947937
Iteration 152: train_loss 1.225124478340149
Iteration 153: train_loss 1.1677144765853882
Iteration 154: train_loss 1.1643054485321045
Iteration 155: train_loss 1.1564700603485107
Iteration 156: train_loss 1.1843371391296387
Iteration 157: train_loss 1.2127398252487183
Iteration 158: train_loss 1.21376633644104
Iteration 159: train_loss 1.1534584760665894
Iteration 160: train_loss 1.138118028640747
Iteration 161: train_loss 1.237180233001709
Iteration 162: train_loss 1.2200127840042114
Iteration 163: train_loss 1.195587158203125
Iteration 164: train_loss 1.1186575889587402
Iteration 165: train_loss 1.2267431020736694
Iteration 166: train_loss 1.1741032600402832
Iteration 167: train_loss 1.154168963432312
Iteration 168: train_loss 1.1829341650009155
Iteration 169: train_loss 1.197596549987793
Iteration 170: train_loss 1.164576530456543
Iteration 171: train_loss 1.2313076257705688
Iteration 172: train_loss 1.1829323768615723
Iteration 173: train_loss 1.1740142107009888
Iteration 174: train_loss 1.1770551204681396
Iteration 175: train_loss 1.144444465637207
Iteration 176: train_loss 1.1146756410598755
Iteration 177: train_loss 1.2448093891143799
Epoch 159: train_avg_loss 1.1894496059687125 eval_avg_acc: 0.34515912612359356 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:34:57] [32mIntermediate result: 0.34515912612359356  (Index 158)[0m
================Epoch: 160================
Iteration 1: train_loss 1.1326320171356201
Iteration 2: train_loss 1.1076371669769287
Iteration 3: train_loss 1.145269751548767
Iteration 4: train_loss 1.1284427642822266
Iteration 5: train_loss 1.1289721727371216
Iteration 6: train_loss 1.1709736585617065
Iteration 7: train_loss 1.1570098400115967
Iteration 8: train_loss 1.1272153854370117
Iteration 9: train_loss 1.1431159973144531
Iteration 10: train_loss 1.1770466566085815
Iteration 11: train_loss 1.1539199352264404
Iteration 12: train_loss 1.186560869216919
Iteration 13: train_loss 1.2170945405960083
Iteration 14: train_loss 1.1689934730529785
Iteration 15: train_loss 1.1762285232543945
Iteration 16: train_loss 1.1077309846878052
Iteration 17: train_loss 1.1503841876983643
Iteration 18: train_loss 1.2169520854949951
Iteration 19: train_loss 1.1992697715759277
Iteration 20: train_loss 1.1531494855880737
Iteration 21: train_loss 1.1271096467971802
Iteration 22: train_loss 1.1651791334152222
Iteration 23: train_loss 1.1856937408447266
Iteration 24: train_loss 1.140058994293213
Iteration 25: train_loss 1.183539628982544
Iteration 26: train_loss 1.1838806867599487
Iteration 27: train_loss 1.1931217908859253
Iteration 28: train_loss 1.143174648284912
Iteration 29: train_loss 1.2429070472717285
Iteration 30: train_loss 1.203643560409546
Iteration 31: train_loss 1.1520479917526245
Iteration 32: train_loss 1.187135934829712
Iteration 33: train_loss 1.2508517503738403
Iteration 34: train_loss 1.1510857343673706
Iteration 35: train_loss 1.2065918445587158
Iteration 36: train_loss 1.2247464656829834
Iteration 37: train_loss 1.2054680585861206
Iteration 38: train_loss 1.1838821172714233
Iteration 39: train_loss 1.1428595781326294
Iteration 40: train_loss 1.2069790363311768
Iteration 41: train_loss 1.2285646200180054
Iteration 42: train_loss 1.1874477863311768
Iteration 43: train_loss 1.1787546873092651
Iteration 44: train_loss 1.2034212350845337
Iteration 45: train_loss 1.2109328508377075
Iteration 46: train_loss 1.260291576385498
Iteration 47: train_loss 1.154093623161316
Iteration 48: train_loss 1.2725963592529297
Iteration 49: train_loss 1.2286533117294312
Iteration 50: train_loss 1.2212308645248413
Iteration 51: train_loss 1.1857590675354004
Iteration 52: train_loss 1.1477069854736328
Iteration 53: train_loss 1.170478105545044
Iteration 54: train_loss 1.167365312576294
Iteration 55: train_loss 1.2024142742156982
Iteration 56: train_loss 1.1994966268539429
Iteration 57: train_loss 1.2711551189422607
Iteration 58: train_loss 1.193960189819336
Iteration 59: train_loss 1.1689109802246094
Iteration 60: train_loss 1.173680305480957
Iteration 61: train_loss 1.1396079063415527
Iteration 62: train_loss 1.1741441488265991
Iteration 63: train_loss 1.1157395839691162
Iteration 64: train_loss 1.1394647359848022
Iteration 65: train_loss 1.1424286365509033
Iteration 66: train_loss 1.204782485961914
Iteration 67: train_loss 1.1535322666168213
Iteration 68: train_loss 1.1402398347854614
Iteration 69: train_loss 1.1361056566238403
Iteration 70: train_loss 1.1725735664367676
Iteration 71: train_loss 1.2475388050079346
Iteration 72: train_loss 1.1432185173034668
Iteration 73: train_loss 1.212990403175354
Iteration 74: train_loss 1.2070304155349731
Iteration 75: train_loss 1.1660430431365967
Iteration 76: train_loss 1.1657730340957642
Iteration 77: train_loss 1.2580616474151611
Iteration 78: train_loss 1.2265499830245972
Iteration 79: train_loss 1.213319182395935
Iteration 80: train_loss 1.1666063070297241
Iteration 81: train_loss 1.1960933208465576
Iteration 82: train_loss 1.1721093654632568
Iteration 83: train_loss 1.2150747776031494
Iteration 84: train_loss 1.129085659980774
Iteration 85: train_loss 1.2003425359725952
Iteration 86: train_loss 1.1648958921432495
Iteration 87: train_loss 1.1484700441360474
Iteration 88: train_loss 1.167056679725647
Iteration 89: train_loss 1.2207000255584717
Iteration 90: train_loss 1.1873948574066162
Iteration 91: train_loss 1.1726548671722412
Iteration 92: train_loss 1.1596314907073975
Iteration 93: train_loss 1.1699033975601196
Iteration 94: train_loss 1.210019826889038
Iteration 95: train_loss 1.2233643531799316
Iteration 96: train_loss 1.2207062244415283
Iteration 97: train_loss 1.210069179534912
Iteration 98: train_loss 1.2335587739944458
Iteration 99: train_loss 1.1591345071792603
Iteration 100: train_loss 1.1984654664993286
Iteration 101: train_loss 1.169230580329895
Iteration 102: train_loss 1.2272270917892456
Iteration 103: train_loss 1.1547691822052002
Iteration 104: train_loss 1.1823748350143433
Iteration 105: train_loss 1.1401746273040771
Iteration 106: train_loss 1.1920876502990723
Iteration 107: train_loss 1.2106764316558838
Iteration 108: train_loss 1.2046546936035156
Iteration 109: train_loss 1.236235499382019
Iteration 110: train_loss 1.1891499757766724
Iteration 111: train_loss 1.17840576171875
Iteration 112: train_loss 1.2070144414901733
Iteration 113: train_loss 1.14365816116333
Iteration 114: train_loss 1.1697405576705933
Iteration 115: train_loss 1.2047384977340698
Iteration 116: train_loss 1.2619739770889282
Iteration 117: train_loss 1.1577109098434448
Iteration 118: train_loss 1.2080386877059937
Iteration 119: train_loss 1.1697521209716797
Iteration 120: train_loss 1.1794812679290771
Iteration 121: train_loss 1.1921603679656982
Iteration 122: train_loss 1.174686074256897
Iteration 123: train_loss 1.2027324438095093
Iteration 124: train_loss 1.1671788692474365
Iteration 125: train_loss 1.169259786605835
Iteration 126: train_loss 1.1596390008926392
Iteration 127: train_loss 1.1571890115737915
Iteration 128: train_loss 1.196946382522583
Iteration 129: train_loss 1.2507739067077637
Iteration 130: train_loss 1.1752605438232422
Iteration 131: train_loss 1.1816262006759644
Iteration 132: train_loss 1.1948268413543701
Iteration 133: train_loss 1.224552869796753
Iteration 134: train_loss 1.2727363109588623
Iteration 135: train_loss 1.1700246334075928
Iteration 136: train_loss 1.222206473350525
Iteration 137: train_loss 1.21133291721344
Iteration 138: train_loss 1.22594153881073
Iteration 139: train_loss 1.1822447776794434
Iteration 140: train_loss 1.2417558431625366
Iteration 141: train_loss 1.2419145107269287
Iteration 142: train_loss 1.1639344692230225
Iteration 143: train_loss 1.2092399597167969
Iteration 144: train_loss 1.156185507774353
Iteration 145: train_loss 1.1482164859771729
Iteration 146: train_loss 1.150111198425293
Iteration 147: train_loss 1.2234193086624146
Iteration 148: train_loss 1.2127515077590942
Iteration 149: train_loss 1.2153648138046265
Iteration 150: train_loss 1.1535110473632812
Iteration 151: train_loss 1.1484800577163696
Iteration 152: train_loss 1.1465903520584106
Iteration 153: train_loss 1.2087807655334473
Iteration 154: train_loss 1.1711456775665283
Iteration 155: train_loss 1.144714117050171
Iteration 156: train_loss 1.1831693649291992
Iteration 157: train_loss 1.1670563220977783
Iteration 158: train_loss 1.2372225522994995
Iteration 159: train_loss 1.1427160501480103
Iteration 160: train_loss 1.1998742818832397
Iteration 161: train_loss 1.1578422784805298
Iteration 162: train_loss 1.1685940027236938
Iteration 163: train_loss 1.2046012878417969
Iteration 164: train_loss 1.1748020648956299
Iteration 165: train_loss 1.1987875699996948
Iteration 166: train_loss 1.1932791471481323
Iteration 167: train_loss 1.1507301330566406
Iteration 168: train_loss 1.229678750038147
Iteration 169: train_loss 1.214475393295288
Iteration 170: train_loss 1.1895766258239746
Iteration 171: train_loss 1.2186939716339111
Iteration 172: train_loss 1.208616852760315
Iteration 173: train_loss 1.2187529802322388
Iteration 174: train_loss 1.2043918371200562
Iteration 175: train_loss 1.2303012609481812
Iteration 176: train_loss 1.1660840511322021
Iteration 177: train_loss 1.1202054023742676
Epoch 160: train_avg_loss 1.1851634669438593 eval_avg_acc: 0.34451560417091714 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:35:36] [32mIntermediate result: 0.34451560417091714  (Index 159)[0m
================Epoch: 161================
Iteration 1: train_loss 1.2063308954238892
Iteration 2: train_loss 1.2226330041885376
Iteration 3: train_loss 1.1575230360031128
Iteration 4: train_loss 1.2428412437438965
Iteration 5: train_loss 1.227195382118225
Iteration 6: train_loss 1.2089793682098389
Iteration 7: train_loss 1.2419023513793945
Iteration 8: train_loss 1.2437947988510132
Iteration 9: train_loss 1.168864369392395
Iteration 10: train_loss 1.235440969467163
Iteration 11: train_loss 1.2130889892578125
Iteration 12: train_loss 1.212794542312622
Iteration 13: train_loss 1.1505316495895386
Iteration 14: train_loss 1.1676201820373535
Iteration 15: train_loss 1.2010725736618042
Iteration 16: train_loss 1.1801093816757202
Iteration 17: train_loss 1.2137911319732666
Iteration 18: train_loss 1.1157469749450684
Iteration 19: train_loss 1.1285473108291626
Iteration 20: train_loss 1.1511869430541992
Iteration 21: train_loss 1.1719086170196533
Iteration 22: train_loss 1.1856952905654907
Iteration 23: train_loss 1.2175315618515015
Iteration 24: train_loss 1.1698510646820068
Iteration 25: train_loss 1.1972193717956543
Iteration 26: train_loss 1.1477869749069214
Iteration 27: train_loss 1.216973066329956
Iteration 28: train_loss 1.1459486484527588
Iteration 29: train_loss 1.127416968345642
Iteration 30: train_loss 1.172170639038086
Iteration 31: train_loss 1.1358451843261719
Iteration 32: train_loss 1.1739120483398438
Iteration 33: train_loss 1.1553528308868408
Iteration 34: train_loss 1.1913336515426636
Iteration 35: train_loss 1.164317011833191
Iteration 36: train_loss 1.1533385515213013
Iteration 37: train_loss 1.2072432041168213
Iteration 38: train_loss 1.077591896057129
Iteration 39: train_loss 1.1470389366149902
Iteration 40: train_loss 1.1693257093429565
Iteration 41: train_loss 1.1797231435775757
Iteration 42: train_loss 1.2012280225753784
Iteration 43: train_loss 1.1348122358322144
Iteration 44: train_loss 1.1501086950302124
Iteration 45: train_loss 1.162434697151184
Iteration 46: train_loss 1.2245349884033203
Iteration 47: train_loss 1.1313937902450562
Iteration 48: train_loss 1.150333046913147
Iteration 49: train_loss 1.1110988855361938
Iteration 50: train_loss 1.1363354921340942
Iteration 51: train_loss 1.1593914031982422
Iteration 52: train_loss 1.2068548202514648
Iteration 53: train_loss 1.2543644905090332
Iteration 54: train_loss 1.171610951423645
Iteration 55: train_loss 1.0719395875930786
Iteration 56: train_loss 1.1714458465576172
Iteration 57: train_loss 1.165263056755066
Iteration 58: train_loss 1.1679377555847168
Iteration 59: train_loss 1.2388628721237183
Iteration 60: train_loss 1.1879050731658936
Iteration 61: train_loss 1.2079246044158936
Iteration 62: train_loss 1.1670762300491333
Iteration 63: train_loss 1.192266583442688
Iteration 64: train_loss 1.1729724407196045
Iteration 65: train_loss 1.2405107021331787
Iteration 66: train_loss 1.2027722597122192
Iteration 67: train_loss 1.2006093263626099
Iteration 68: train_loss 1.2673615217208862
Iteration 69: train_loss 1.2413444519042969
Iteration 70: train_loss 1.1914210319519043
Iteration 71: train_loss 1.1815372705459595
Iteration 72: train_loss 1.2283620834350586
Iteration 73: train_loss 1.215857744216919
Iteration 74: train_loss 1.1945282220840454
Iteration 75: train_loss 1.2121577262878418
Iteration 76: train_loss 1.223095178604126
Iteration 77: train_loss 1.185170292854309
Iteration 78: train_loss 1.1510778665542603
Iteration 79: train_loss 1.2245402336120605
Iteration 80: train_loss 1.2086663246154785
Iteration 81: train_loss 1.2126588821411133
Iteration 82: train_loss 1.2114375829696655
Iteration 83: train_loss 1.2256708145141602
Iteration 84: train_loss 1.2132948637008667
Iteration 85: train_loss 1.249302625656128
Iteration 86: train_loss 1.230995774269104
Iteration 87: train_loss 1.1744722127914429
Iteration 88: train_loss 1.1601788997650146
Iteration 89: train_loss 1.2191699743270874
Iteration 90: train_loss 1.1840434074401855
Iteration 91: train_loss 1.1956859827041626
Iteration 92: train_loss 1.1288827657699585
Iteration 93: train_loss 1.1461877822875977
Iteration 94: train_loss 1.2431384325027466
Iteration 95: train_loss 1.1357619762420654
Iteration 96: train_loss 1.1987100839614868
Iteration 97: train_loss 1.2054908275604248
Iteration 98: train_loss 1.185150384902954
Iteration 99: train_loss 1.144126296043396
Iteration 100: train_loss 1.1616228818893433
Iteration 101: train_loss 1.1776496171951294
Iteration 102: train_loss 1.2072584629058838
Iteration 103: train_loss 1.1903597116470337
Iteration 104: train_loss 1.2439619302749634
Iteration 105: train_loss 1.1560381650924683
Iteration 106: train_loss 1.169461727142334
Iteration 107: train_loss 1.2215311527252197
Iteration 108: train_loss 1.1868689060211182
Iteration 109: train_loss 1.128625512123108
Iteration 110: train_loss 1.1994833946228027
Iteration 111: train_loss 1.1593332290649414
Iteration 112: train_loss 1.227081298828125
Iteration 113: train_loss 1.1915110349655151
Iteration 114: train_loss 1.1627609729766846
Iteration 115: train_loss 1.2047516107559204
Iteration 116: train_loss 1.2052366733551025
Iteration 117: train_loss 1.2092255353927612
Iteration 118: train_loss 1.3032019138336182
Iteration 119: train_loss 1.256800651550293
Iteration 120: train_loss 1.1936523914337158
Iteration 121: train_loss 1.186145305633545
Iteration 122: train_loss 1.2502425909042358
Iteration 123: train_loss 1.2137706279754639
Iteration 124: train_loss 1.1906492710113525
Iteration 125: train_loss 1.2090338468551636
Iteration 126: train_loss 1.217154622077942
Iteration 127: train_loss 1.1875039339065552
Iteration 128: train_loss 1.1679363250732422
Iteration 129: train_loss 1.163034439086914
Iteration 130: train_loss 1.1700537204742432
Iteration 131: train_loss 1.22537362575531
Iteration 132: train_loss 1.242962121963501
Iteration 133: train_loss 1.1881194114685059
Iteration 134: train_loss 1.2281190156936646
Iteration 135: train_loss 1.2237606048583984
Iteration 136: train_loss 1.2631739377975464
Iteration 137: train_loss 1.1570616960525513
Iteration 138: train_loss 1.217315673828125
Iteration 139: train_loss 1.228452205657959
Iteration 140: train_loss 1.2090036869049072
Iteration 141: train_loss 1.2083555459976196
Iteration 142: train_loss 1.2422943115234375
Iteration 143: train_loss 1.209356665611267
Iteration 144: train_loss 1.2079976797103882
Iteration 145: train_loss 1.2787392139434814
Iteration 146: train_loss 1.2168798446655273
Iteration 147: train_loss 1.269188404083252
Iteration 148: train_loss 1.2004075050354004
Iteration 149: train_loss 1.2332017421722412
Iteration 150: train_loss 1.2349830865859985
Iteration 151: train_loss 1.2146592140197754
Iteration 152: train_loss 1.2677632570266724
Iteration 153: train_loss 1.1874877214431763
Iteration 154: train_loss 1.1704496145248413
Iteration 155: train_loss 1.183390736579895
Iteration 156: train_loss 1.198947787284851
Iteration 157: train_loss 1.1568876504898071
Iteration 158: train_loss 1.1388887166976929
Iteration 159: train_loss 1.2218066453933716
Iteration 160: train_loss 1.1698172092437744
Iteration 161: train_loss 1.25399649143219
Iteration 162: train_loss 1.1342123746871948
Iteration 163: train_loss 1.2179034948349
Iteration 164: train_loss 1.212601900100708
Iteration 165: train_loss 1.2920697927474976
Iteration 166: train_loss 1.2225098609924316
Iteration 167: train_loss 1.252481460571289
Iteration 168: train_loss 1.2623530626296997
Iteration 169: train_loss 1.1795945167541504
Iteration 170: train_loss 1.1554816961288452
Iteration 171: train_loss 1.1143133640289307
Iteration 172: train_loss 1.2144522666931152
Iteration 173: train_loss 1.2112493515014648
Iteration 174: train_loss 1.1914299726486206
Iteration 175: train_loss 1.229994773864746
Iteration 176: train_loss 1.2249168157577515
Iteration 177: train_loss 1.210249423980713
Epoch 161: train_avg_loss 1.1946643132947932 eval_avg_acc: 0.3447203216759132 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:36:15] [32mIntermediate result: 0.3447203216759132  (Index 160)[0m
================Epoch: 162================
Iteration 1: train_loss 1.1561247110366821
Iteration 2: train_loss 1.1423470973968506
Iteration 3: train_loss 1.1571906805038452
Iteration 4: train_loss 1.229455590248108
Iteration 5: train_loss 1.2357367277145386
Iteration 6: train_loss 1.233363389968872
Iteration 7: train_loss 1.2337534427642822
Iteration 8: train_loss 1.1524382829666138
Iteration 9: train_loss 1.212569236755371
Iteration 10: train_loss 1.1731535196304321
Iteration 11: train_loss 1.2014141082763672
Iteration 12: train_loss 1.2051434516906738
Iteration 13: train_loss 1.2029001712799072
Iteration 14: train_loss 1.1788887977600098
Iteration 15: train_loss 1.1382465362548828
Iteration 16: train_loss 1.2009307146072388
Iteration 17: train_loss 1.205141544342041
Iteration 18: train_loss 1.181086778640747
Iteration 19: train_loss 1.2445026636123657
Iteration 20: train_loss 1.1991591453552246
Iteration 21: train_loss 1.1847254037857056
Iteration 22: train_loss 1.1522908210754395
Iteration 23: train_loss 1.2299089431762695
Iteration 24: train_loss 1.1951231956481934
Iteration 25: train_loss 1.1181581020355225
Iteration 26: train_loss 1.1471203565597534
Iteration 27: train_loss 1.163320541381836
Iteration 28: train_loss 1.125410556793213
Iteration 29: train_loss 1.1707706451416016
Iteration 30: train_loss 1.1846184730529785
Iteration 31: train_loss 1.1884841918945312
Iteration 32: train_loss 1.1528939008712769
Iteration 33: train_loss 1.149887204170227
Iteration 34: train_loss 1.1989384889602661
Iteration 35: train_loss 1.1598502397537231
Iteration 36: train_loss 1.1311967372894287
Iteration 37: train_loss 1.1825767755508423
Iteration 38: train_loss 1.2612589597702026
Iteration 39: train_loss 1.1274317502975464
Iteration 40: train_loss 1.191048502922058
Iteration 41: train_loss 1.206943154335022
Iteration 42: train_loss 1.2145459651947021
Iteration 43: train_loss 1.2167277336120605
Iteration 44: train_loss 1.1662203073501587
Iteration 45: train_loss 1.2511531114578247
Iteration 46: train_loss 1.202085018157959
Iteration 47: train_loss 1.2356449365615845
Iteration 48: train_loss 1.1685118675231934
Iteration 49: train_loss 1.2184243202209473
Iteration 50: train_loss 1.2141668796539307
Iteration 51: train_loss 1.2427955865859985
Iteration 52: train_loss 1.2320499420166016
Iteration 53: train_loss 1.1975268125534058
Iteration 54: train_loss 1.1720705032348633
Iteration 55: train_loss 1.2206974029541016
Iteration 56: train_loss 1.2015517950057983
Iteration 57: train_loss 1.1473075151443481
Iteration 58: train_loss 1.1588151454925537
Iteration 59: train_loss 1.1818138360977173
Iteration 60: train_loss 1.185939073562622
Iteration 61: train_loss 1.1677906513214111
Iteration 62: train_loss 1.1924571990966797
Iteration 63: train_loss 1.146222710609436
Iteration 64: train_loss 1.162644386291504
Iteration 65: train_loss 1.1697429418563843
Iteration 66: train_loss 1.1771197319030762
Iteration 67: train_loss 1.1483200788497925
Iteration 68: train_loss 1.2542355060577393
Iteration 69: train_loss 1.1778359413146973
Iteration 70: train_loss 1.1976213455200195
Iteration 71: train_loss 1.18220853805542
Iteration 72: train_loss 1.1774905920028687
Iteration 73: train_loss 1.214011788368225
Iteration 74: train_loss 1.1693984270095825
Iteration 75: train_loss 1.1594057083129883
Iteration 76: train_loss 1.2003902196884155
Iteration 77: train_loss 1.1652270555496216
Iteration 78: train_loss 1.2236889600753784
Iteration 79: train_loss 1.1750668287277222
Iteration 80: train_loss 1.1906198263168335
Iteration 81: train_loss 1.2065768241882324
Iteration 82: train_loss 1.2258936166763306
Iteration 83: train_loss 1.1489619016647339
Iteration 84: train_loss 1.2257544994354248
Iteration 85: train_loss 1.1644257307052612
Iteration 86: train_loss 1.1754076480865479
Iteration 87: train_loss 1.1394529342651367
Iteration 88: train_loss 1.1745942831039429
Iteration 89: train_loss 1.2076497077941895
Iteration 90: train_loss 1.1698496341705322
Iteration 91: train_loss 1.1950006484985352
Iteration 92: train_loss 1.1785508394241333
Iteration 93: train_loss 1.2059526443481445
Iteration 94: train_loss 1.2179114818572998
Iteration 95: train_loss 1.1705697774887085
Iteration 96: train_loss 1.20510995388031
Iteration 97: train_loss 1.1880218982696533
Iteration 98: train_loss 1.1848701238632202
Iteration 99: train_loss 1.14314603805542
Iteration 100: train_loss 1.188525676727295
Iteration 101: train_loss 1.2388522624969482
Iteration 102: train_loss 1.176902174949646
Iteration 103: train_loss 1.2384350299835205
Iteration 104: train_loss 1.1836482286453247
Iteration 105: train_loss 1.1516016721725464
Iteration 106: train_loss 1.1708316802978516
Iteration 107: train_loss 1.232194423675537
Iteration 108: train_loss 1.1584285497665405
Iteration 109: train_loss 1.2275781631469727
Iteration 110: train_loss 1.2379589080810547
Iteration 111: train_loss 1.2921181917190552
Iteration 112: train_loss 1.1824195384979248
Iteration 113: train_loss 1.205439567565918
Iteration 114: train_loss 1.1818017959594727
Iteration 115: train_loss 1.2931071519851685
Iteration 116: train_loss 1.1760615110397339
Iteration 117: train_loss 1.135650396347046
Iteration 118: train_loss 1.182453989982605
Iteration 119: train_loss 1.1745785474777222
Iteration 120: train_loss 1.163784146308899
Iteration 121: train_loss 1.1546919345855713
Iteration 122: train_loss 1.2174726724624634
Iteration 123: train_loss 1.2283824682235718
Iteration 124: train_loss 1.1840859651565552
Iteration 125: train_loss 1.2538081407546997
Iteration 126: train_loss 1.1926720142364502
Iteration 127: train_loss 1.212652564048767
Iteration 128: train_loss 1.207376480102539
Iteration 129: train_loss 1.2435071468353271
Iteration 130: train_loss 1.147265076637268
Iteration 131: train_loss 1.2407939434051514
Iteration 132: train_loss 1.1920897960662842
Iteration 133: train_loss 1.211320161819458
Iteration 134: train_loss 1.2103323936462402
Iteration 135: train_loss 1.1826704740524292
Iteration 136: train_loss 1.2911863327026367
Iteration 137: train_loss 1.215625286102295
Iteration 138: train_loss 1.1551457643508911
Iteration 139: train_loss 1.2264856100082397
Iteration 140: train_loss 1.1964843273162842
Iteration 141: train_loss 1.2066422700881958
Iteration 142: train_loss 1.2449663877487183
Iteration 143: train_loss 1.2073922157287598
Iteration 144: train_loss 1.2611161470413208
Iteration 145: train_loss 1.192387580871582
Iteration 146: train_loss 1.2032393217086792
Iteration 147: train_loss 1.1802239418029785
Iteration 148: train_loss 1.1676521301269531
Iteration 149: train_loss 1.2037124633789062
Iteration 150: train_loss 1.2279584407806396
Iteration 151: train_loss 1.170770525932312
Iteration 152: train_loss 1.1957855224609375
Iteration 153: train_loss 1.175735592842102
Iteration 154: train_loss 1.1785629987716675
Iteration 155: train_loss 1.2281136512756348
Iteration 156: train_loss 1.1437417268753052
Iteration 157: train_loss 1.1873862743377686
Iteration 158: train_loss 1.181571125984192
Iteration 159: train_loss 1.2298266887664795
Iteration 160: train_loss 1.2102242708206177
Iteration 161: train_loss 1.2241613864898682
Iteration 162: train_loss 1.1568416357040405
Iteration 163: train_loss 1.1814907789230347
Iteration 164: train_loss 1.1909470558166504
Iteration 165: train_loss 1.1928011178970337
Iteration 166: train_loss 1.1999619007110596
Iteration 167: train_loss 1.1100897789001465
Iteration 168: train_loss 1.2031253576278687
Iteration 169: train_loss 1.2160245180130005
Iteration 170: train_loss 1.210890769958496
Iteration 171: train_loss 1.1503359079360962
Iteration 172: train_loss 1.1898438930511475
Iteration 173: train_loss 1.210798740386963
Iteration 174: train_loss 1.2231541872024536
Iteration 175: train_loss 1.2405543327331543
Iteration 176: train_loss 1.2030588388442993
Iteration 177: train_loss 1.1852226257324219
Epoch 162: train_avg_loss 1.192968825835966 eval_avg_acc: 0.3421029707706631 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:36:54] [32mIntermediate result: 0.3421029707706631  (Index 161)[0m
================Epoch: 163================
Iteration 1: train_loss 1.2145400047302246
Iteration 2: train_loss 1.207470178604126
Iteration 3: train_loss 1.1974812746047974
Iteration 4: train_loss 1.2341430187225342
Iteration 5: train_loss 1.1840068101882935
Iteration 6: train_loss 1.1765542030334473
Iteration 7: train_loss 1.1386860609054565
Iteration 8: train_loss 1.1472983360290527
Iteration 9: train_loss 1.2067168951034546
Iteration 10: train_loss 1.1851561069488525
Iteration 11: train_loss 1.1332025527954102
Iteration 12: train_loss 1.2280282974243164
Iteration 13: train_loss 1.1151573657989502
Iteration 14: train_loss 1.1702244281768799
Iteration 15: train_loss 1.1368199586868286
Iteration 16: train_loss 1.197916865348816
Iteration 17: train_loss 1.2128723859786987
Iteration 18: train_loss 1.1926274299621582
Iteration 19: train_loss 1.2184538841247559
Iteration 20: train_loss 1.175583839416504
Iteration 21: train_loss 1.1692434549331665
Iteration 22: train_loss 1.1649901866912842
Iteration 23: train_loss 1.2255915403366089
Iteration 24: train_loss 1.1908529996871948
Iteration 25: train_loss 1.1426341533660889
Iteration 26: train_loss 1.1818618774414062
Iteration 27: train_loss 1.1744685173034668
Iteration 28: train_loss 1.197310209274292
Iteration 29: train_loss 1.1571128368377686
Iteration 30: train_loss 1.191110610961914
Iteration 31: train_loss 1.18825364112854
Iteration 32: train_loss 1.1599438190460205
Iteration 33: train_loss 1.2566622495651245
Iteration 34: train_loss 1.135506272315979
Iteration 35: train_loss 1.1311498880386353
Iteration 36: train_loss 1.1834763288497925
Iteration 37: train_loss 1.2017138004302979
Iteration 38: train_loss 1.1518499851226807
Iteration 39: train_loss 1.1770976781845093
Iteration 40: train_loss 1.2004247903823853
Iteration 41: train_loss 1.1677583456039429
Iteration 42: train_loss 1.1281932592391968
Iteration 43: train_loss 1.1835265159606934
Iteration 44: train_loss 1.1639975309371948
Iteration 45: train_loss 1.1524219512939453
Iteration 46: train_loss 1.1847461462020874
Iteration 47: train_loss 1.1636874675750732
Iteration 48: train_loss 1.146403193473816
Iteration 49: train_loss 1.2456661462783813
Iteration 50: train_loss 1.1897629499435425
Iteration 51: train_loss 1.1668548583984375
Iteration 52: train_loss 1.1456915140151978
Iteration 53: train_loss 1.1564797163009644
Iteration 54: train_loss 1.2036142349243164
Iteration 55: train_loss 1.2597224712371826
Iteration 56: train_loss 1.1769770383834839
Iteration 57: train_loss 1.1687039136886597
Iteration 58: train_loss 1.181598424911499
Iteration 59: train_loss 1.220863938331604
Iteration 60: train_loss 1.2399380207061768
Iteration 61: train_loss 1.1892743110656738
Iteration 62: train_loss 1.2178142070770264
Iteration 63: train_loss 1.1578319072723389
Iteration 64: train_loss 1.1995497941970825
Iteration 65: train_loss 1.2098946571350098
Iteration 66: train_loss 1.1255855560302734
Iteration 67: train_loss 1.1893326044082642
Iteration 68: train_loss 1.1443052291870117
Iteration 69: train_loss 1.1926419734954834
Iteration 70: train_loss 1.1540480852127075
Iteration 71: train_loss 1.1573337316513062
Iteration 72: train_loss 1.1702946424484253
Iteration 73: train_loss 1.1681649684906006
Iteration 74: train_loss 1.2090078592300415
Iteration 75: train_loss 1.2207562923431396
Iteration 76: train_loss 1.1348283290863037
Iteration 77: train_loss 1.206057071685791
Iteration 78: train_loss 1.2296255826950073
Iteration 79: train_loss 1.200501799583435
Iteration 80: train_loss 1.2116308212280273
Iteration 81: train_loss 1.198778748512268
Iteration 82: train_loss 1.2203642129898071
Iteration 83: train_loss 1.2149643898010254
Iteration 84: train_loss 1.2027133703231812
Iteration 85: train_loss 1.1730374097824097
Iteration 86: train_loss 1.151990294456482
Iteration 87: train_loss 1.2049877643585205
Iteration 88: train_loss 1.1975514888763428
Iteration 89: train_loss 1.1911784410476685
Iteration 90: train_loss 1.1754281520843506
Iteration 91: train_loss 1.2229869365692139
Iteration 92: train_loss 1.1698715686798096
Iteration 93: train_loss 1.1735965013504028
Iteration 94: train_loss 1.187330961227417
Iteration 95: train_loss 1.1530523300170898
Iteration 96: train_loss 1.194342017173767
Iteration 97: train_loss 1.2260395288467407
Iteration 98: train_loss 1.206527829170227
Iteration 99: train_loss 1.1850711107254028
Iteration 100: train_loss 1.2007296085357666
Iteration 101: train_loss 1.2368286848068237
Iteration 102: train_loss 1.2049814462661743
Iteration 103: train_loss 1.2151687145233154
Iteration 104: train_loss 1.170581579208374
Iteration 105: train_loss 1.184725284576416
Iteration 106: train_loss 1.1467375755310059
Iteration 107: train_loss 1.1906349658966064
Iteration 108: train_loss 1.1424165964126587
Iteration 109: train_loss 1.1474307775497437
Iteration 110: train_loss 1.1542032957077026
Iteration 111: train_loss 1.2216202020645142
Iteration 112: train_loss 1.1854407787322998
Iteration 113: train_loss 1.1665781736373901
Iteration 114: train_loss 1.219150185585022
Iteration 115: train_loss 1.1904264688491821
Iteration 116: train_loss 1.1665985584259033
Iteration 117: train_loss 1.2215030193328857
Iteration 118: train_loss 1.2255052328109741
Iteration 119: train_loss 1.1175134181976318
Iteration 120: train_loss 1.1796058416366577
Iteration 121: train_loss 1.1513175964355469
Iteration 122: train_loss 1.2816112041473389
Iteration 123: train_loss 1.185179352760315
Iteration 124: train_loss 1.1788179874420166
Iteration 125: train_loss 1.1328781843185425
Iteration 126: train_loss 1.1516127586364746
Iteration 127: train_loss 1.242060661315918
Iteration 128: train_loss 1.1756300926208496
Iteration 129: train_loss 1.1966294050216675
Iteration 130: train_loss 1.1954301595687866
Iteration 131: train_loss 1.1888099908828735
Iteration 132: train_loss 1.167760968208313
Iteration 133: train_loss 1.1585114002227783
Iteration 134: train_loss 1.2066118717193604
Iteration 135: train_loss 1.2034878730773926
Iteration 136: train_loss 1.1497399806976318
Iteration 137: train_loss 1.234773874282837
Iteration 138: train_loss 1.1306432485580444
Iteration 139: train_loss 1.1918516159057617
Iteration 140: train_loss 1.1564767360687256
Iteration 141: train_loss 1.1370701789855957
Iteration 142: train_loss 1.1740014553070068
Iteration 143: train_loss 1.121248722076416
Iteration 144: train_loss 1.1489391326904297
Iteration 145: train_loss 1.1580899953842163
Iteration 146: train_loss 1.2573601007461548
Iteration 147: train_loss 1.2193695306777954
Iteration 148: train_loss 1.2416620254516602
Iteration 149: train_loss 1.2152471542358398
Iteration 150: train_loss 1.182057499885559
Iteration 151: train_loss 1.2171703577041626
Iteration 152: train_loss 1.2094202041625977
Iteration 153: train_loss 1.2317864894866943
Iteration 154: train_loss 1.244322657585144
Iteration 155: train_loss 1.2148303985595703
Iteration 156: train_loss 1.1618846654891968
Iteration 157: train_loss 1.1866137981414795
Iteration 158: train_loss 1.2462143898010254
Iteration 159: train_loss 1.166077733039856
Iteration 160: train_loss 1.1739723682403564
Iteration 161: train_loss 1.254602313041687
Iteration 162: train_loss 1.2372117042541504
Iteration 163: train_loss 1.1983267068862915
Iteration 164: train_loss 1.1612119674682617
Iteration 165: train_loss 1.146711826324463
Iteration 166: train_loss 1.1466518640518188
Iteration 167: train_loss 1.2144290208816528
Iteration 168: train_loss 1.2346932888031006
Iteration 169: train_loss 1.132545828819275
Iteration 170: train_loss 1.1918729543685913
Iteration 171: train_loss 1.2561464309692383
Iteration 172: train_loss 1.2374464273452759
Iteration 173: train_loss 1.1912428140640259
Iteration 174: train_loss 1.2711446285247803
Iteration 175: train_loss 1.294811487197876
Iteration 176: train_loss 1.2911149263381958
Iteration 177: train_loss 1.2151587009429932
Epoch 163: train_avg_loss 1.1886439094435697 eval_avg_acc: 0.3440839690160981 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:37:32] [32mIntermediate result: 0.3440839690160981  (Index 162)[0m
================Epoch: 164================
Iteration 1: train_loss 1.208166480064392
Iteration 2: train_loss 1.1847516298294067
Iteration 3: train_loss 1.1896116733551025
Iteration 4: train_loss 1.150160789489746
Iteration 5: train_loss 1.220880389213562
Iteration 6: train_loss 1.1492624282836914
Iteration 7: train_loss 1.1938127279281616
Iteration 8: train_loss 1.173128604888916
Iteration 9: train_loss 1.1854742765426636
Iteration 10: train_loss 1.1777315139770508
Iteration 11: train_loss 1.1975144147872925
Iteration 12: train_loss 1.1329760551452637
Iteration 13: train_loss 1.2008488178253174
Iteration 14: train_loss 1.1458882093429565
Iteration 15: train_loss 1.1567740440368652
Iteration 16: train_loss 1.1580713987350464
Iteration 17: train_loss 1.1438027620315552
Iteration 18: train_loss 1.1478043794631958
Iteration 19: train_loss 1.1728929281234741
Iteration 20: train_loss 1.1427613496780396
Iteration 21: train_loss 1.2083799839019775
Iteration 22: train_loss 1.1996984481811523
Iteration 23: train_loss 1.1544594764709473
Iteration 24: train_loss 1.2256420850753784
Iteration 25: train_loss 1.1464606523513794
Iteration 26: train_loss 1.1415389776229858
Iteration 27: train_loss 1.2720412015914917
Iteration 28: train_loss 1.184416651725769
Iteration 29: train_loss 1.1870092153549194
Iteration 30: train_loss 1.2304110527038574
Iteration 31: train_loss 1.1185671091079712
Iteration 32: train_loss 1.2353602647781372
Iteration 33: train_loss 1.2031217813491821
Iteration 34: train_loss 1.2162024974822998
Iteration 35: train_loss 1.1269440650939941
Iteration 36: train_loss 1.1717941761016846
Iteration 37: train_loss 1.1420735120773315
Iteration 38: train_loss 1.176970362663269
Iteration 39: train_loss 1.2372026443481445
Iteration 40: train_loss 1.1747909784317017
Iteration 41: train_loss 1.2209504842758179
Iteration 42: train_loss 1.1654431819915771
Iteration 43: train_loss 1.1619294881820679
Iteration 44: train_loss 1.1643519401550293
Iteration 45: train_loss 1.1880598068237305
Iteration 46: train_loss 1.16095769405365
Iteration 47: train_loss 1.2031000852584839
Iteration 48: train_loss 1.1796764135360718
Iteration 49: train_loss 1.207366704940796
Iteration 50: train_loss 1.2087665796279907
Iteration 51: train_loss 1.1912256479263306
Iteration 52: train_loss 1.1416385173797607
Iteration 53: train_loss 1.1599589586257935
Iteration 54: train_loss 1.144177794456482
Iteration 55: train_loss 1.201683759689331
Iteration 56: train_loss 1.1263357400894165
Iteration 57: train_loss 1.1536561250686646
Iteration 58: train_loss 1.121107578277588
Iteration 59: train_loss 1.183939814567566
Iteration 60: train_loss 1.1846895217895508
Iteration 61: train_loss 1.146680235862732
Iteration 62: train_loss 1.1187254190444946
Iteration 63: train_loss 1.2209125757217407
Iteration 64: train_loss 1.157416820526123
Iteration 65: train_loss 1.1877942085266113
Iteration 66: train_loss 1.2181572914123535
Iteration 67: train_loss 1.2072887420654297
Iteration 68: train_loss 1.1668635606765747
Iteration 69: train_loss 1.2128340005874634
Iteration 70: train_loss 1.1571894884109497
Iteration 71: train_loss 1.1747890710830688
Iteration 72: train_loss 1.1422760486602783
Iteration 73: train_loss 1.2174135446548462
Iteration 74: train_loss 1.155389666557312
Iteration 75: train_loss 1.222943902015686
Iteration 76: train_loss 1.20246422290802
Iteration 77: train_loss 1.1640278100967407
Iteration 78: train_loss 1.2091307640075684
Iteration 79: train_loss 1.1941324472427368
Iteration 80: train_loss 1.139963150024414
Iteration 81: train_loss 1.1803427934646606
Iteration 82: train_loss 1.1153919696807861
Iteration 83: train_loss 1.200567603111267
Iteration 84: train_loss 1.1938494443893433
Iteration 85: train_loss 1.2166123390197754
Iteration 86: train_loss 1.2139450311660767
Iteration 87: train_loss 1.2102142572402954
Iteration 88: train_loss 1.1880780458450317
Iteration 89: train_loss 1.2050204277038574
Iteration 90: train_loss 1.1940544843673706
Iteration 91: train_loss 1.156704306602478
Iteration 92: train_loss 1.178814172744751
Iteration 93: train_loss 1.1868454217910767
Iteration 94: train_loss 1.160836935043335
Iteration 95: train_loss 1.215955376625061
Iteration 96: train_loss 1.2171951532363892
Iteration 97: train_loss 1.173648715019226
Iteration 98: train_loss 1.1857218742370605
Iteration 99: train_loss 1.1470088958740234
Iteration 100: train_loss 1.2208184003829956
Iteration 101: train_loss 1.2116601467132568
Iteration 102: train_loss 1.1507165431976318
Iteration 103: train_loss 1.1804579496383667
Iteration 104: train_loss 1.2163976430892944
Iteration 105: train_loss 1.2319746017456055
Iteration 106: train_loss 1.1560643911361694
Iteration 107: train_loss 1.137587308883667
Iteration 108: train_loss 1.1558566093444824
Iteration 109: train_loss 1.1447675228118896
Iteration 110: train_loss 1.1735566854476929
Iteration 111: train_loss 1.1198650598526
Iteration 112: train_loss 1.216842532157898
Iteration 113: train_loss 1.1431559324264526
Iteration 114: train_loss 1.2039566040039062
Iteration 115: train_loss 1.1537853479385376
Iteration 116: train_loss 1.1561068296432495
Iteration 117: train_loss 1.1937435865402222
Iteration 118: train_loss 1.1878162622451782
Iteration 119: train_loss 1.1842195987701416
Iteration 120: train_loss 1.1472755670547485
Iteration 121: train_loss 1.1718946695327759
Iteration 122: train_loss 1.1783945560455322
Iteration 123: train_loss 1.179664969444275
Iteration 124: train_loss 1.1564887762069702
Iteration 125: train_loss 1.1804530620574951
Iteration 126: train_loss 1.2099136114120483
Iteration 127: train_loss 1.1652209758758545
Iteration 128: train_loss 1.1555589437484741
Iteration 129: train_loss 1.227992296218872
Iteration 130: train_loss 1.2198315858840942
Iteration 131: train_loss 1.1600041389465332
Iteration 132: train_loss 1.2221304178237915
Iteration 133: train_loss 1.261579990386963
Iteration 134: train_loss 1.1749602556228638
Iteration 135: train_loss 1.1638646125793457
Iteration 136: train_loss 1.2062828540802002
Iteration 137: train_loss 1.1649285554885864
Iteration 138: train_loss 1.221067190170288
Iteration 139: train_loss 1.196577787399292
Iteration 140: train_loss 1.1375114917755127
Iteration 141: train_loss 1.2105859518051147
Iteration 142: train_loss 1.1193182468414307
Iteration 143: train_loss 1.210871696472168
Iteration 144: train_loss 1.1883749961853027
Iteration 145: train_loss 1.2168039083480835
Iteration 146: train_loss 1.1634899377822876
Iteration 147: train_loss 1.1875194311141968
Iteration 148: train_loss 1.2010924816131592
Iteration 149: train_loss 1.1661187410354614
Iteration 150: train_loss 1.2208952903747559
Iteration 151: train_loss 1.136501431465149
Iteration 152: train_loss 1.242027759552002
Iteration 153: train_loss 1.1610218286514282
Iteration 154: train_loss 1.145158290863037
Iteration 155: train_loss 1.1372241973876953
Iteration 156: train_loss 1.2192147970199585
Iteration 157: train_loss 1.172276258468628
Iteration 158: train_loss 1.2075636386871338
Iteration 159: train_loss 1.1660312414169312
Iteration 160: train_loss 1.2490923404693604
Iteration 161: train_loss 1.1669071912765503
Iteration 162: train_loss 1.2253493070602417
Iteration 163: train_loss 1.1817431449890137
Iteration 164: train_loss 1.177214503288269
Iteration 165: train_loss 1.2224907875061035
Iteration 166: train_loss 1.1909456253051758
Iteration 167: train_loss 1.1360357999801636
Iteration 168: train_loss 1.18961501121521
Iteration 169: train_loss 1.1605442762374878
Iteration 170: train_loss 1.1758116483688354
Iteration 171: train_loss 1.1789790391921997
Iteration 172: train_loss 1.212017297744751
Iteration 173: train_loss 1.1430569887161255
Iteration 174: train_loss 1.1503762006759644
Iteration 175: train_loss 1.1522955894470215
Iteration 176: train_loss 1.1744260787963867
Iteration 177: train_loss 1.2994977235794067
Epoch 164: train_avg_loss 1.1814183650043724 eval_avg_acc: 0.34226850750198756 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:38:12] [32mIntermediate result: 0.34226850750198756  (Index 163)[0m
================Epoch: 165================
Iteration 1: train_loss 1.1609817743301392
Iteration 2: train_loss 1.1349647045135498
Iteration 3: train_loss 1.1784650087356567
Iteration 4: train_loss 1.1488404273986816
Iteration 5: train_loss 1.155609130859375
Iteration 6: train_loss 1.1665023565292358
Iteration 7: train_loss 1.1013054847717285
Iteration 8: train_loss 1.1314241886138916
Iteration 9: train_loss 1.1572871208190918
Iteration 10: train_loss 1.1079000234603882
Iteration 11: train_loss 1.1460477113723755
Iteration 12: train_loss 1.1792103052139282
Iteration 13: train_loss 1.126303791999817
Iteration 14: train_loss 1.1909009218215942
Iteration 15: train_loss 1.1697514057159424
Iteration 16: train_loss 1.1320860385894775
Iteration 17: train_loss 1.1227807998657227
Iteration 18: train_loss 1.187986969947815
Iteration 19: train_loss 1.147691249847412
Iteration 20: train_loss 1.1405950784683228
Iteration 21: train_loss 1.1809682846069336
Iteration 22: train_loss 1.2088264226913452
Iteration 23: train_loss 1.211249828338623
Iteration 24: train_loss 1.1919406652450562
Iteration 25: train_loss 1.1797510385513306
Iteration 26: train_loss 1.1782866716384888
Iteration 27: train_loss 1.1913028955459595
Iteration 28: train_loss 1.172249436378479
Iteration 29: train_loss 1.1251860857009888
Iteration 30: train_loss 1.150835394859314
Iteration 31: train_loss 1.2252795696258545
Iteration 32: train_loss 1.1789124011993408
Iteration 33: train_loss 1.1339247226715088
Iteration 34: train_loss 1.1788372993469238
Iteration 35: train_loss 1.2190022468566895
Iteration 36: train_loss 1.2416198253631592
Iteration 37: train_loss 1.1910148859024048
Iteration 38: train_loss 1.1949924230575562
Iteration 39: train_loss 1.2080830335617065
Iteration 40: train_loss 1.1926823854446411
Iteration 41: train_loss 1.179078221321106
Iteration 42: train_loss 1.2669354677200317
Iteration 43: train_loss 1.214491367340088
Iteration 44: train_loss 1.141611099243164
Iteration 45: train_loss 1.103370189666748
Iteration 46: train_loss 1.1771868467330933
Iteration 47: train_loss 1.12984299659729
Iteration 48: train_loss 1.108964204788208
Iteration 49: train_loss 1.1578333377838135
Iteration 50: train_loss 1.169782280921936
Iteration 51: train_loss 1.1179821491241455
Iteration 52: train_loss 1.1562377214431763
Iteration 53: train_loss 1.1570650339126587
Iteration 54: train_loss 1.1468483209609985
Iteration 55: train_loss 1.2089570760726929
Iteration 56: train_loss 1.0983580350875854
Iteration 57: train_loss 1.160759687423706
Iteration 58: train_loss 1.2066465616226196
Iteration 59: train_loss 1.1337077617645264
Iteration 60: train_loss 1.1546255350112915
Iteration 61: train_loss 1.1367017030715942
Iteration 62: train_loss 1.1551131010055542
Iteration 63: train_loss 1.1249572038650513
Iteration 64: train_loss 1.186170220375061
Iteration 65: train_loss 1.168778419494629
Iteration 66: train_loss 1.1702347993850708
Iteration 67: train_loss 1.145096778869629
Iteration 68: train_loss 1.1678417921066284
Iteration 69: train_loss 1.1128621101379395
Iteration 70: train_loss 1.1872447729110718
Iteration 71: train_loss 1.145334243774414
Iteration 72: train_loss 1.1587144136428833
Iteration 73: train_loss 1.1947391033172607
Iteration 74: train_loss 1.1955416202545166
Iteration 75: train_loss 1.1698949337005615
Iteration 76: train_loss 1.1809684038162231
Iteration 77: train_loss 1.20635986328125
Iteration 78: train_loss 1.2146449089050293
Iteration 79: train_loss 1.1410977840423584
Iteration 80: train_loss 1.189913034439087
Iteration 81: train_loss 1.161484956741333
Iteration 82: train_loss 1.1272587776184082
Iteration 83: train_loss 1.1886966228485107
Iteration 84: train_loss 1.1863993406295776
Iteration 85: train_loss 1.1878608465194702
Iteration 86: train_loss 1.232601523399353
Iteration 87: train_loss 1.2189959287643433
Iteration 88: train_loss 1.1964906454086304
Iteration 89: train_loss 1.1208158731460571
Iteration 90: train_loss 1.2108627557754517
Iteration 91: train_loss 1.2163227796554565
Iteration 92: train_loss 1.2103917598724365
Iteration 93: train_loss 1.2743560075759888
Iteration 94: train_loss 1.2514928579330444
Iteration 95: train_loss 1.2037020921707153
Iteration 96: train_loss 1.220939040184021
Iteration 97: train_loss 1.1704407930374146
Iteration 98: train_loss 1.2250131368637085
Iteration 99: train_loss 1.2044349908828735
Iteration 100: train_loss 1.2387887239456177
Iteration 101: train_loss 1.248993992805481
Iteration 102: train_loss 1.276412844657898
Iteration 103: train_loss 1.19927978515625
Iteration 104: train_loss 1.198781132698059
Iteration 105: train_loss 1.1278373003005981
Iteration 106: train_loss 1.221383810043335
Iteration 107: train_loss 1.2085225582122803
Iteration 108: train_loss 1.200371503829956
Iteration 109: train_loss 1.1719988584518433
Iteration 110: train_loss 1.1960726976394653
Iteration 111: train_loss 1.166925311088562
Iteration 112: train_loss 1.1410057544708252
Iteration 113: train_loss 1.158231258392334
Iteration 114: train_loss 1.1385759115219116
Iteration 115: train_loss 1.1412259340286255
Iteration 116: train_loss 1.2209954261779785
Iteration 117: train_loss 1.2070612907409668
Iteration 118: train_loss 1.1517850160598755
Iteration 119: train_loss 1.1456948518753052
Iteration 120: train_loss 1.1972503662109375
Iteration 121: train_loss 1.2069374322891235
Iteration 122: train_loss 1.1512576341629028
Iteration 123: train_loss 1.1871767044067383
Iteration 124: train_loss 1.2038979530334473
Iteration 125: train_loss 1.191261887550354
Iteration 126: train_loss 1.2113844156265259
Iteration 127: train_loss 1.2058186531066895
Iteration 128: train_loss 1.1512442827224731
Iteration 129: train_loss 1.1644734144210815
Iteration 130: train_loss 1.1738674640655518
Iteration 131: train_loss 1.1695830821990967
Iteration 132: train_loss 1.1959389448165894
Iteration 133: train_loss 1.160317301750183
Iteration 134: train_loss 1.1608548164367676
Iteration 135: train_loss 1.1552215814590454
Iteration 136: train_loss 1.1885805130004883
Iteration 137: train_loss 1.1281994581222534
Iteration 138: train_loss 1.2022271156311035
Iteration 139: train_loss 1.1693650484085083
Iteration 140: train_loss 1.2069721221923828
Iteration 141: train_loss 1.1926196813583374
Iteration 142: train_loss 1.2186309099197388
Iteration 143: train_loss 1.2028497457504272
Iteration 144: train_loss 1.2270125150680542
Iteration 145: train_loss 1.2162050008773804
Iteration 146: train_loss 1.225534200668335
Iteration 147: train_loss 1.2246840000152588
Iteration 148: train_loss 1.2083148956298828
Iteration 149: train_loss 1.2601617574691772
Iteration 150: train_loss 1.197366714477539
Iteration 151: train_loss 1.222044825553894
Iteration 152: train_loss 1.2529767751693726
Iteration 153: train_loss 1.222288966178894
Iteration 154: train_loss 1.2149550914764404
Iteration 155: train_loss 1.231328010559082
Iteration 156: train_loss 1.2377281188964844
Iteration 157: train_loss 1.2127516269683838
Iteration 158: train_loss 1.2447433471679688
Iteration 159: train_loss 1.151909351348877
Iteration 160: train_loss 1.178323745727539
Iteration 161: train_loss 1.1854231357574463
Iteration 162: train_loss 1.121923565864563
Iteration 163: train_loss 1.194236397743225
Iteration 164: train_loss 1.240637183189392
Iteration 165: train_loss 1.1688302755355835
Iteration 166: train_loss 1.2359397411346436
Iteration 167: train_loss 1.2692636251449585
Iteration 168: train_loss 1.1685723066329956
Iteration 169: train_loss 1.2202584743499756
Iteration 170: train_loss 1.1879703998565674
Iteration 171: train_loss 1.1721373796463013
Iteration 172: train_loss 1.1666594743728638
Iteration 173: train_loss 1.1622620820999146
Iteration 174: train_loss 1.1330580711364746
Iteration 175: train_loss 1.1721093654632568
Iteration 176: train_loss 1.2142987251281738
Iteration 177: train_loss 1.2435832023620605
Epoch 165: train_avg_loss 1.1821129982080836 eval_avg_acc: 0.33664927761250896 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:38:49] [32mIntermediate result: 0.33664927761250896  (Index 164)[0m
================Epoch: 166================
Iteration 1: train_loss 1.233574390411377
Iteration 2: train_loss 1.2158143520355225
Iteration 3: train_loss 1.2691465616226196
Iteration 4: train_loss 1.1680246591567993
Iteration 5: train_loss 1.1746407747268677
Iteration 6: train_loss 1.1872433423995972
Iteration 7: train_loss 1.0999372005462646
Iteration 8: train_loss 1.1436560153961182
Iteration 9: train_loss 1.1778082847595215
Iteration 10: train_loss 1.1701899766921997
Iteration 11: train_loss 1.1711158752441406
Iteration 12: train_loss 1.1622288227081299
Iteration 13: train_loss 1.148500680923462
Iteration 14: train_loss 1.1665695905685425
Iteration 15: train_loss 1.2108749151229858
Iteration 16: train_loss 1.1769007444381714
Iteration 17: train_loss 1.1491193771362305
Iteration 18: train_loss 1.1670477390289307
Iteration 19: train_loss 1.1763269901275635
Iteration 20: train_loss 1.2505723237991333
Iteration 21: train_loss 1.2276442050933838
Iteration 22: train_loss 1.217775821685791
Iteration 23: train_loss 1.1723012924194336
Iteration 24: train_loss 1.1770379543304443
Iteration 25: train_loss 1.2060625553131104
Iteration 26: train_loss 1.1552557945251465
Iteration 27: train_loss 1.1832647323608398
Iteration 28: train_loss 1.125592589378357
Iteration 29: train_loss 1.0989376306533813
Iteration 30: train_loss 1.1728343963623047
Iteration 31: train_loss 1.1663153171539307
Iteration 32: train_loss 1.0904285907745361
Iteration 33: train_loss 1.1487239599227905
Iteration 34: train_loss 1.1938140392303467
Iteration 35: train_loss 1.1646109819412231
Iteration 36: train_loss 1.127476453781128
Iteration 37: train_loss 1.1458793878555298
Iteration 38: train_loss 1.1192049980163574
Iteration 39: train_loss 1.1237306594848633
Iteration 40: train_loss 1.1197113990783691
Iteration 41: train_loss 1.1674250364303589
Iteration 42: train_loss 1.1059733629226685
Iteration 43: train_loss 1.1291388273239136
Iteration 44: train_loss 1.1298125982284546
Iteration 45: train_loss 1.1125783920288086
Iteration 46: train_loss 1.148100733757019
Iteration 47: train_loss 1.1529603004455566
Iteration 48: train_loss 1.1835265159606934
Iteration 49: train_loss 1.1207128763198853
Iteration 50: train_loss 1.1747524738311768
Iteration 51: train_loss 1.1310062408447266
Iteration 52: train_loss 1.1657707691192627
Iteration 53: train_loss 1.1452885866165161
Iteration 54: train_loss 1.1354620456695557
Iteration 55: train_loss 1.0896662473678589
Iteration 56: train_loss 1.1565656661987305
Iteration 57: train_loss 1.1724961996078491
Iteration 58: train_loss 1.1258528232574463
Iteration 59: train_loss 1.1278904676437378
Iteration 60: train_loss 1.15830659866333
Iteration 61: train_loss 1.1302930116653442
Iteration 62: train_loss 1.1267023086547852
Iteration 63: train_loss 1.127215027809143
Iteration 64: train_loss 1.153691291809082
Iteration 65: train_loss 1.143992304801941
Iteration 66: train_loss 1.1597447395324707
Iteration 67: train_loss 1.1462194919586182
Iteration 68: train_loss 1.1348122358322144
Iteration 69: train_loss 1.1470246315002441
Iteration 70: train_loss 1.1805733442306519
Iteration 71: train_loss 1.1552410125732422
Iteration 72: train_loss 1.134017825126648
Iteration 73: train_loss 1.1698187589645386
Iteration 74: train_loss 1.1289876699447632
Iteration 75: train_loss 1.172720193862915
Iteration 76: train_loss 1.1559045314788818
Iteration 77: train_loss 1.1954237222671509
Iteration 78: train_loss 1.1687947511672974
Iteration 79: train_loss 1.1387183666229248
Iteration 80: train_loss 1.125495433807373
Iteration 81: train_loss 1.1506551504135132
Iteration 82: train_loss 1.1506149768829346
Iteration 83: train_loss 1.1477521657943726
Iteration 84: train_loss 1.1862291097640991
Iteration 85: train_loss 1.171023964881897
Iteration 86: train_loss 1.2040836811065674
Iteration 87: train_loss 1.174634575843811
Iteration 88: train_loss 1.1235965490341187
Iteration 89: train_loss 1.1758686304092407
Iteration 90: train_loss 1.234737753868103
Iteration 91: train_loss 1.230046272277832
Iteration 92: train_loss 1.1386092901229858
Iteration 93: train_loss 1.166001796722412
Iteration 94: train_loss 1.1243367195129395
Iteration 95: train_loss 1.199703574180603
Iteration 96: train_loss 1.1734458208084106
Iteration 97: train_loss 1.1763333082199097
Iteration 98: train_loss 1.177018165588379
Iteration 99: train_loss 1.169114112854004
Iteration 100: train_loss 1.1998838186264038
Iteration 101: train_loss 1.2109545469284058
Iteration 102: train_loss 1.2073692083358765
Iteration 103: train_loss 1.1892719268798828
Iteration 104: train_loss 1.1544013023376465
Iteration 105: train_loss 1.2399802207946777
Iteration 106: train_loss 1.2146918773651123
Iteration 107: train_loss 1.1665942668914795
Iteration 108: train_loss 1.174252986907959
Iteration 109: train_loss 1.1620140075683594
Iteration 110: train_loss 1.2187844514846802
Iteration 111: train_loss 1.1506502628326416
Iteration 112: train_loss 1.176822304725647
Iteration 113: train_loss 1.2157917022705078
Iteration 114: train_loss 1.1373858451843262
Iteration 115: train_loss 1.2152284383773804
Iteration 116: train_loss 1.2141964435577393
Iteration 117: train_loss 1.2345075607299805
Iteration 118: train_loss 1.1284480094909668
Iteration 119: train_loss 1.1551265716552734
Iteration 120: train_loss 1.1924549341201782
Iteration 121: train_loss 1.2511365413665771
Iteration 122: train_loss 1.1771506071090698
Iteration 123: train_loss 1.1948323249816895
Iteration 124: train_loss 1.2219629287719727
Iteration 125: train_loss 1.246882438659668
Iteration 126: train_loss 1.1852519512176514
Iteration 127: train_loss 1.0900696516036987
Iteration 128: train_loss 1.1400831937789917
Iteration 129: train_loss 1.220333456993103
Iteration 130: train_loss 1.173481822013855
Iteration 131: train_loss 1.1758015155792236
Iteration 132: train_loss 1.2235313653945923
Iteration 133: train_loss 1.2083227634429932
Iteration 134: train_loss 1.164992094039917
Iteration 135: train_loss 1.1513259410858154
Iteration 136: train_loss 1.2344746589660645
Iteration 137: train_loss 1.2345861196517944
Iteration 138: train_loss 1.2271558046340942
Iteration 139: train_loss 1.2464361190795898
Iteration 140: train_loss 1.206665277481079
Iteration 141: train_loss 1.2227903604507446
Iteration 142: train_loss 1.201650619506836
Iteration 143: train_loss 1.121705412864685
Iteration 144: train_loss 1.2254103422164917
Iteration 145: train_loss 1.1808357238769531
Iteration 146: train_loss 1.2155969142913818
Iteration 147: train_loss 1.2036464214324951
Iteration 148: train_loss 1.221281886100769
Iteration 149: train_loss 1.1839348077774048
Iteration 150: train_loss 1.1834559440612793
Iteration 151: train_loss 1.1704388856887817
Iteration 152: train_loss 1.26572585105896
Iteration 153: train_loss 1.2067188024520874
Iteration 154: train_loss 1.1803319454193115
Iteration 155: train_loss 1.1922364234924316
Iteration 156: train_loss 1.2048336267471313
Iteration 157: train_loss 1.1848483085632324
Iteration 158: train_loss 1.1431677341461182
Iteration 159: train_loss 1.187357783317566
Iteration 160: train_loss 1.1390377283096313
Iteration 161: train_loss 1.115610957145691
Iteration 162: train_loss 1.1573591232299805
Iteration 163: train_loss 1.1788763999938965
Iteration 164: train_loss 1.1424413919448853
Iteration 165: train_loss 1.1901516914367676
Iteration 166: train_loss 1.2284836769104004
Iteration 167: train_loss 1.1838195323944092
Iteration 168: train_loss 1.1974365711212158
Iteration 169: train_loss 1.1471467018127441
Iteration 170: train_loss 1.1498346328735352
Iteration 171: train_loss 1.0927592515945435
Iteration 172: train_loss 1.2103862762451172
Iteration 173: train_loss 1.1628432273864746
Iteration 174: train_loss 1.1451411247253418
Iteration 175: train_loss 1.1428762674331665
Iteration 176: train_loss 1.1670325994491577
Iteration 177: train_loss 1.1219881772994995
Epoch 166: train_avg_loss 1.171530275695068 eval_avg_acc: 0.34556900222176506 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:39:22] [32mIntermediate result: 0.34556900222176506  (Index 165)[0m
================Epoch: 167================
Iteration 1: train_loss 1.1642284393310547
Iteration 2: train_loss 1.1718872785568237
Iteration 3: train_loss 1.1592351198196411
Iteration 4: train_loss 1.173071265220642
Iteration 5: train_loss 1.1487921476364136
Iteration 6: train_loss 1.1581168174743652
Iteration 7: train_loss 1.1751222610473633
Iteration 8: train_loss 1.1613689661026
Iteration 9: train_loss 1.2578760385513306
Iteration 10: train_loss 1.205613136291504
Iteration 11: train_loss 1.1770557165145874
Iteration 12: train_loss 1.2026417255401611
Iteration 13: train_loss 1.2166553735733032
Iteration 14: train_loss 1.116731882095337
Iteration 15: train_loss 1.1331111192703247
Iteration 16: train_loss 1.1587473154067993
Iteration 17: train_loss 1.1463420391082764
Iteration 18: train_loss 1.1280115842819214
Iteration 19: train_loss 1.1986268758773804
Iteration 20: train_loss 1.2161678075790405
Iteration 21: train_loss 1.170741081237793
Iteration 22: train_loss 1.0882670879364014
Iteration 23: train_loss 1.2068909406661987
Iteration 24: train_loss 1.1601512432098389
Iteration 25: train_loss 1.2019588947296143
Iteration 26: train_loss 1.1586551666259766
Iteration 27: train_loss 1.2088117599487305
Iteration 28: train_loss 1.1998552083969116
Iteration 29: train_loss 1.2010618448257446
Iteration 30: train_loss 1.17548668384552
Iteration 31: train_loss 1.2225228548049927
Iteration 32: train_loss 1.2080596685409546
Iteration 33: train_loss 1.150186538696289
Iteration 34: train_loss 1.1718261241912842
Iteration 35: train_loss 1.1523051261901855
Iteration 36: train_loss 1.1661474704742432
Iteration 37: train_loss 1.1819305419921875
Iteration 38: train_loss 1.1441936492919922
Iteration 39: train_loss 1.156101107597351
Iteration 40: train_loss 1.1681121587753296
Iteration 41: train_loss 1.1314408779144287
Iteration 42: train_loss 1.1186306476593018
Iteration 43: train_loss 1.2320690155029297
Iteration 44: train_loss 1.1935818195343018
Iteration 45: train_loss 1.158095121383667
Iteration 46: train_loss 1.1474144458770752
Iteration 47: train_loss 1.1296465396881104
Iteration 48: train_loss 1.1595789194107056
Iteration 49: train_loss 1.1781408786773682
Iteration 50: train_loss 1.139094352722168
Iteration 51: train_loss 1.150462031364441
Iteration 52: train_loss 1.1403396129608154
Iteration 53: train_loss 1.145198941230774
Iteration 54: train_loss 1.1761976480484009
Iteration 55: train_loss 1.1552460193634033
Iteration 56: train_loss 1.2296241521835327
Iteration 57: train_loss 1.1517982482910156
Iteration 58: train_loss 1.188717007637024
Iteration 59: train_loss 1.17345130443573
Iteration 60: train_loss 1.1276077032089233
Iteration 61: train_loss 1.1357009410858154
Iteration 62: train_loss 1.2194501161575317
Iteration 63: train_loss 1.185886263847351
Iteration 64: train_loss 1.1985080242156982
Iteration 65: train_loss 1.0824357271194458
Iteration 66: train_loss 1.1356910467147827
Iteration 67: train_loss 1.1916030645370483
Iteration 68: train_loss 1.1966925859451294
Iteration 69: train_loss 1.151291847229004
Iteration 70: train_loss 1.1777719259262085
Iteration 71: train_loss 1.143460750579834
Iteration 72: train_loss 1.1601839065551758
Iteration 73: train_loss 1.2219675779342651
Iteration 74: train_loss 1.2171729803085327
Iteration 75: train_loss 1.13749361038208
Iteration 76: train_loss 1.1529979705810547
Iteration 77: train_loss 1.151391625404358
Iteration 78: train_loss 1.1918772459030151
Iteration 79: train_loss 1.1493672132492065
Iteration 80: train_loss 1.1394169330596924
Iteration 81: train_loss 1.1134097576141357
Iteration 82: train_loss 1.1342260837554932
Iteration 83: train_loss 1.2081328630447388
Iteration 84: train_loss 1.1903996467590332
Iteration 85: train_loss 1.1584666967391968
Iteration 86: train_loss 1.2121142148971558
Iteration 87: train_loss 1.1978555917739868
Iteration 88: train_loss 1.136132836341858
Iteration 89: train_loss 1.1305278539657593
Iteration 90: train_loss 1.1208409070968628
Iteration 91: train_loss 1.1666587591171265
Iteration 92: train_loss 1.1492124795913696
Iteration 93: train_loss 1.2371177673339844
Iteration 94: train_loss 1.2083079814910889
Iteration 95: train_loss 1.1406269073486328
Iteration 96: train_loss 1.1044505834579468
Iteration 97: train_loss 1.1866376399993896
Iteration 98: train_loss 1.1503748893737793
Iteration 99: train_loss 1.1550811529159546
Iteration 100: train_loss 1.199194312095642
Iteration 101: train_loss 1.1796592473983765
Iteration 102: train_loss 1.0913785696029663
Iteration 103: train_loss 1.176695704460144
Iteration 104: train_loss 1.101773977279663
Iteration 105: train_loss 1.1393036842346191
Iteration 106: train_loss 1.1512523889541626
Iteration 107: train_loss 1.198810338973999
Iteration 108: train_loss 1.1693159341812134
Iteration 109: train_loss 1.1558259725570679
Iteration 110: train_loss 1.1812641620635986
Iteration 111: train_loss 1.1265419721603394
Iteration 112: train_loss 1.1621509790420532
Iteration 113: train_loss 1.1462167501449585
Iteration 114: train_loss 1.1810518503189087
Iteration 115: train_loss 1.1662522554397583
Iteration 116: train_loss 1.149654746055603
Iteration 117: train_loss 1.1810674667358398
Iteration 118: train_loss 1.1097108125686646
Iteration 119: train_loss 1.1779083013534546
Iteration 120: train_loss 1.1117559671401978
Iteration 121: train_loss 1.203015923500061
Iteration 122: train_loss 1.132006287574768
Iteration 123: train_loss 1.173927664756775
Iteration 124: train_loss 1.1613689661026
Iteration 125: train_loss 1.1715316772460938
Iteration 126: train_loss 1.148329496383667
Iteration 127: train_loss 1.1858984231948853
Iteration 128: train_loss 1.1683133840560913
Iteration 129: train_loss 1.2130873203277588
Iteration 130: train_loss 1.1396968364715576
Iteration 131: train_loss 1.1453425884246826
Iteration 132: train_loss 1.1854915618896484
Iteration 133: train_loss 1.1779956817626953
Iteration 134: train_loss 1.1356370449066162
Iteration 135: train_loss 1.1616795063018799
Iteration 136: train_loss 1.2097790241241455
Iteration 137: train_loss 1.1723518371582031
Iteration 138: train_loss 1.1078336238861084
Iteration 139: train_loss 1.1869785785675049
Iteration 140: train_loss 1.1342331171035767
Iteration 141: train_loss 1.17353093624115
Iteration 142: train_loss 1.1669235229492188
Iteration 143: train_loss 1.1474583148956299
Iteration 144: train_loss 1.1576732397079468
Iteration 145: train_loss 1.1958943605422974
Iteration 146: train_loss 1.2203081846237183
Iteration 147: train_loss 1.2534626722335815
Iteration 148: train_loss 1.1939059495925903
Iteration 149: train_loss 1.219997525215149
Iteration 150: train_loss 1.2836412191390991
Iteration 151: train_loss 1.2276301383972168
Iteration 152: train_loss 1.234004259109497
Iteration 153: train_loss 1.1965587139129639
Iteration 154: train_loss 1.2133623361587524
Iteration 155: train_loss 1.2133816480636597
Iteration 156: train_loss 1.1592897176742554
Iteration 157: train_loss 1.1268876791000366
Iteration 158: train_loss 1.1686925888061523
Iteration 159: train_loss 1.2421270608901978
Iteration 160: train_loss 1.2098596096038818
Iteration 161: train_loss 1.1778398752212524
Iteration 162: train_loss 1.2197291851043701
Iteration 163: train_loss 1.1940313577651978
Iteration 164: train_loss 1.1656954288482666
Iteration 165: train_loss 1.1409486532211304
Iteration 166: train_loss 1.2080626487731934
Iteration 167: train_loss 1.170040249824524
Iteration 168: train_loss 1.1307330131530762
Iteration 169: train_loss 1.1898759603500366
Iteration 170: train_loss 1.1710339784622192
Iteration 171: train_loss 1.1049257516860962
Iteration 172: train_loss 1.1842983961105347
Iteration 173: train_loss 1.201302409172058
Iteration 174: train_loss 1.174748420715332
Iteration 175: train_loss 1.1896064281463623
Iteration 176: train_loss 1.2048982381820679
Iteration 177: train_loss 1.1410796642303467
Epoch 167: train_avg_loss 1.1704783197176658 eval_avg_acc: 0.3432309640637436 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:40:04] [32mIntermediate result: 0.3432309640637436  (Index 166)[0m
================Epoch: 168================
Iteration 1: train_loss 1.2155801057815552
Iteration 2: train_loss 1.1930458545684814
Iteration 3: train_loss 1.1805975437164307
Iteration 4: train_loss 1.2049187421798706
Iteration 5: train_loss 1.2053085565567017
Iteration 6: train_loss 1.2164338827133179
Iteration 7: train_loss 1.20353102684021
Iteration 8: train_loss 1.1440669298171997
Iteration 9: train_loss 1.1541305780410767
Iteration 10: train_loss 1.1864384412765503
Iteration 11: train_loss 1.191625714302063
Iteration 12: train_loss 1.2314021587371826
Iteration 13: train_loss 1.1691524982452393
Iteration 14: train_loss 1.220096468925476
Iteration 15: train_loss 1.2333810329437256
Iteration 16: train_loss 1.2526402473449707
Iteration 17: train_loss 1.184244155883789
Iteration 18: train_loss 1.2337960004806519
Iteration 19: train_loss 1.1308557987213135
Iteration 20: train_loss 1.189170479774475
Iteration 21: train_loss 1.1553926467895508
Iteration 22: train_loss 1.1785699129104614
Iteration 23: train_loss 1.1727476119995117
Iteration 24: train_loss 1.1628612279891968
Iteration 25: train_loss 1.1699855327606201
Iteration 26: train_loss 1.1490283012390137
Iteration 27: train_loss 1.1766806840896606
Iteration 28: train_loss 1.1975204944610596
Iteration 29: train_loss 1.1824382543563843
Iteration 30: train_loss 1.1601476669311523
Iteration 31: train_loss 1.1807758808135986
Iteration 32: train_loss 1.1897788047790527
Iteration 33: train_loss 1.173973560333252
Iteration 34: train_loss 1.2002369165420532
Iteration 35: train_loss 1.164360523223877
Iteration 36: train_loss 1.1721744537353516
Iteration 37: train_loss 1.192177414894104
Iteration 38: train_loss 1.16541588306427
Iteration 39: train_loss 1.145020842552185
Iteration 40: train_loss 1.1796917915344238
Iteration 41: train_loss 1.096256971359253
Iteration 42: train_loss 1.15510892868042
Iteration 43: train_loss 1.1421351432800293
Iteration 44: train_loss 1.1577236652374268
Iteration 45: train_loss 1.1884275674819946
Iteration 46: train_loss 1.1377856731414795
Iteration 47: train_loss 1.1759215593338013
Iteration 48: train_loss 1.1708284616470337
Iteration 49: train_loss 1.2089837789535522
Iteration 50: train_loss 1.1338123083114624
Iteration 51: train_loss 1.1929700374603271
Iteration 52: train_loss 1.166786551475525
Iteration 53: train_loss 1.2191166877746582
Iteration 54: train_loss 1.1621825695037842
Iteration 55: train_loss 1.1721208095550537
Iteration 56: train_loss 1.1268117427825928
Iteration 57: train_loss 1.173176884651184
Iteration 58: train_loss 1.1243290901184082
Iteration 59: train_loss 1.1692450046539307
Iteration 60: train_loss 1.153387427330017
Iteration 61: train_loss 1.157874345779419
Iteration 62: train_loss 1.1333342790603638
Iteration 63: train_loss 1.1354365348815918
Iteration 64: train_loss 1.1254620552062988
Iteration 65: train_loss 1.128364086151123
Iteration 66: train_loss 1.133183479309082
Iteration 67: train_loss 1.2074352502822876
Iteration 68: train_loss 1.1946794986724854
Iteration 69: train_loss 1.1846259832382202
Iteration 70: train_loss 1.1527700424194336
Iteration 71: train_loss 1.1724671125411987
Iteration 72: train_loss 1.1222196817398071
Iteration 73: train_loss 1.0998177528381348
Iteration 74: train_loss 1.170074224472046
Iteration 75: train_loss 1.1569280624389648
Iteration 76: train_loss 1.1412627696990967
Iteration 77: train_loss 1.1596927642822266
Iteration 78: train_loss 1.1099488735198975
Iteration 79: train_loss 1.2064746618270874
Iteration 80: train_loss 1.1370292901992798
Iteration 81: train_loss 1.2064226865768433
Iteration 82: train_loss 1.133876085281372
Iteration 83: train_loss 1.138262391090393
Iteration 84: train_loss 1.143410086631775
Iteration 85: train_loss 1.1366223096847534
Iteration 86: train_loss 1.1523407697677612
Iteration 87: train_loss 1.1803988218307495
Iteration 88: train_loss 1.1975177526474
Iteration 89: train_loss 1.1397124528884888
Iteration 90: train_loss 1.1016238927841187
Iteration 91: train_loss 1.210086703300476
Iteration 92: train_loss 1.1508713960647583
Iteration 93: train_loss 1.226210594177246
Iteration 94: train_loss 1.1891857385635376
Iteration 95: train_loss 1.1040385961532593
Iteration 96: train_loss 1.167794942855835
Iteration 97: train_loss 1.1786670684814453
Iteration 98: train_loss 1.2522104978561401
Iteration 99: train_loss 1.223879337310791
Iteration 100: train_loss 1.1345041990280151
Iteration 101: train_loss 1.194157361984253
Iteration 102: train_loss 1.1492723226547241
Iteration 103: train_loss 1.1298679113388062
Iteration 104: train_loss 1.0945321321487427
Iteration 105: train_loss 1.1227105855941772
Iteration 106: train_loss 1.1733791828155518
Iteration 107: train_loss 1.1699897050857544
Iteration 108: train_loss 1.1734435558319092
Iteration 109: train_loss 1.1611131429672241
Iteration 110: train_loss 1.183552622795105
Iteration 111: train_loss 1.0977058410644531
Iteration 112: train_loss 1.1341156959533691
Iteration 113: train_loss 1.1779382228851318
Iteration 114: train_loss 1.157996654510498
Iteration 115: train_loss 1.1592211723327637
Iteration 116: train_loss 1.1473866701126099
Iteration 117: train_loss 1.183394432067871
Iteration 118: train_loss 1.228074312210083
Iteration 119: train_loss 1.1635410785675049
Iteration 120: train_loss 1.2196329832077026
Iteration 121: train_loss 1.1613831520080566
Iteration 122: train_loss 1.1997981071472168
Iteration 123: train_loss 1.1922434568405151
Iteration 124: train_loss 1.166412591934204
Iteration 125: train_loss 1.2043062448501587
Iteration 126: train_loss 1.1775063276290894
Iteration 127: train_loss 1.1690436601638794
Iteration 128: train_loss 1.216027855873108
Iteration 129: train_loss 1.1675736904144287
Iteration 130: train_loss 1.1932483911514282
Iteration 131: train_loss 1.1898294687271118
Iteration 132: train_loss 1.1869233846664429
Iteration 133: train_loss 1.2382638454437256
Iteration 134: train_loss 1.2153804302215576
Iteration 135: train_loss 1.2523828744888306
Iteration 136: train_loss 1.2031482458114624
Iteration 137: train_loss 1.2200363874435425
Iteration 138: train_loss 1.232385277748108
Iteration 139: train_loss 1.2211854457855225
Iteration 140: train_loss 1.1984061002731323
Iteration 141: train_loss 1.1406325101852417
Iteration 142: train_loss 1.2133876085281372
Iteration 143: train_loss 1.2729377746582031
Iteration 144: train_loss 1.1975111961364746
Iteration 145: train_loss 1.2019565105438232
Iteration 146: train_loss 1.197889804840088
Iteration 147: train_loss 1.2177817821502686
Iteration 148: train_loss 1.1883609294891357
Iteration 149: train_loss 1.2274396419525146
Iteration 150: train_loss 1.239101529121399
Iteration 151: train_loss 1.1951849460601807
Iteration 152: train_loss 1.1795424222946167
Iteration 153: train_loss 1.1429803371429443
Iteration 154: train_loss 1.134597659111023
Iteration 155: train_loss 1.1708968877792358
Iteration 156: train_loss 1.1933064460754395
Iteration 157: train_loss 1.1758184432983398
Iteration 158: train_loss 1.2499804496765137
Iteration 159: train_loss 1.2262377738952637
Iteration 160: train_loss 1.1920651197433472
Iteration 161: train_loss 1.1798906326293945
Iteration 162: train_loss 1.1942460536956787
Iteration 163: train_loss 1.191430687904358
Iteration 164: train_loss 1.1971136331558228
Iteration 165: train_loss 1.189133644104004
Iteration 166: train_loss 1.220332384109497
Iteration 167: train_loss 1.2219032049179077
Iteration 168: train_loss 1.248834252357483
Iteration 169: train_loss 1.225507378578186
Iteration 170: train_loss 1.2531710863113403
Iteration 171: train_loss 1.1606296300888062
Iteration 172: train_loss 1.2281748056411743
Iteration 173: train_loss 1.1643508672714233
Iteration 174: train_loss 1.1814663410186768
Iteration 175: train_loss 1.2167760133743286
Iteration 176: train_loss 1.238385558128357
Iteration 177: train_loss 1.208674669265747
Epoch 168: train_avg_loss 1.1793071395259793 eval_avg_acc: 0.34331682199155944 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:40:45] [32mIntermediate result: 0.34331682199155944  (Index 167)[0m
================Epoch: 169================
Iteration 1: train_loss 1.170954704284668
Iteration 2: train_loss 1.1717876195907593
Iteration 3: train_loss 1.1951370239257812
Iteration 4: train_loss 1.1654683351516724
Iteration 5: train_loss 1.166846752166748
Iteration 6: train_loss 1.2091004848480225
Iteration 7: train_loss 1.1165657043457031
Iteration 8: train_loss 1.1965745687484741
Iteration 9: train_loss 1.1894311904907227
Iteration 10: train_loss 1.2100028991699219
Iteration 11: train_loss 1.187860131263733
Iteration 12: train_loss 1.1533437967300415
Iteration 13: train_loss 1.1827751398086548
Iteration 14: train_loss 1.1677701473236084
Iteration 15: train_loss 1.1943923234939575
Iteration 16: train_loss 1.1389647722244263
Iteration 17: train_loss 1.1756716966629028
Iteration 18: train_loss 1.177620530128479
Iteration 19: train_loss 1.1585133075714111
Iteration 20: train_loss 1.13690185546875
Iteration 21: train_loss 1.225126028060913
Iteration 22: train_loss 1.1705049276351929
Iteration 23: train_loss 1.1354798078536987
Iteration 24: train_loss 1.2066584825515747
Iteration 25: train_loss 1.1844764947891235
Iteration 26: train_loss 1.144247055053711
Iteration 27: train_loss 1.1247385740280151
Iteration 28: train_loss 1.2233242988586426
Iteration 29: train_loss 1.1966149806976318
Iteration 30: train_loss 1.1376192569732666
Iteration 31: train_loss 1.195686936378479
Iteration 32: train_loss 1.181185245513916
Iteration 33: train_loss 1.2124890089035034
Iteration 34: train_loss 1.2092580795288086
Iteration 35: train_loss 1.23960280418396
Iteration 36: train_loss 1.2248125076293945
Iteration 37: train_loss 1.1866672039031982
Iteration 38: train_loss 1.1642566919326782
Iteration 39: train_loss 1.1232237815856934
Iteration 40: train_loss 1.1454401016235352
Iteration 41: train_loss 1.1220285892486572
Iteration 42: train_loss 1.1443493366241455
Iteration 43: train_loss 1.1171404123306274
Iteration 44: train_loss 1.1528631448745728
Iteration 45: train_loss 1.1542136669158936
Iteration 46: train_loss 1.1562609672546387
Iteration 47: train_loss 1.1729278564453125
Iteration 48: train_loss 1.1753509044647217
Iteration 49: train_loss 1.1512391567230225
Iteration 50: train_loss 1.1316174268722534
Iteration 51: train_loss 1.1722010374069214
Iteration 52: train_loss 1.1127605438232422
Iteration 53: train_loss 1.1292006969451904
Iteration 54: train_loss 1.2121522426605225
Iteration 55: train_loss 1.1813839673995972
Iteration 56: train_loss 1.2045276165008545
Iteration 57: train_loss 1.1717190742492676
Iteration 58: train_loss 1.1806421279907227
Iteration 59: train_loss 1.22959303855896
Iteration 60: train_loss 1.2105610370635986
Iteration 61: train_loss 1.2370426654815674
Iteration 62: train_loss 1.1761159896850586
Iteration 63: train_loss 1.1645125150680542
Iteration 64: train_loss 1.1393530368804932
Iteration 65: train_loss 1.1435884237289429
Iteration 66: train_loss 1.1434094905853271
Iteration 67: train_loss 1.1386154890060425
Iteration 68: train_loss 1.1427747011184692
Iteration 69: train_loss 1.168700098991394
Iteration 70: train_loss 1.2169034481048584
Iteration 71: train_loss 1.1767739057540894
Iteration 72: train_loss 1.2106150388717651
Iteration 73: train_loss 1.1444212198257446
Iteration 74: train_loss 1.189513087272644
Iteration 75: train_loss 1.1693994998931885
Iteration 76: train_loss 1.1807931661605835
Iteration 77: train_loss 1.1834614276885986
Iteration 78: train_loss 1.1877988576889038
Iteration 79: train_loss 1.2473480701446533
Iteration 80: train_loss 1.2147057056427002
Iteration 81: train_loss 1.20803701877594
Iteration 82: train_loss 1.1320303678512573
Iteration 83: train_loss 1.1984301805496216
Iteration 84: train_loss 1.1580954790115356
Iteration 85: train_loss 1.2047444581985474
Iteration 86: train_loss 1.1271789073944092
Iteration 87: train_loss 1.161108136177063
Iteration 88: train_loss 1.2445124387741089
Iteration 89: train_loss 1.2194931507110596
Iteration 90: train_loss 1.2024065256118774
Iteration 91: train_loss 1.2199348211288452
Iteration 92: train_loss 1.1953139305114746
Iteration 93: train_loss 1.2788944244384766
Iteration 94: train_loss 1.205678939819336
Iteration 95: train_loss 1.3057096004486084
Iteration 96: train_loss 1.1841583251953125
Iteration 97: train_loss 1.2686030864715576
Iteration 98: train_loss 1.227069616317749
Iteration 99: train_loss 1.1708238124847412
Iteration 100: train_loss 1.2381259202957153
Iteration 101: train_loss 1.1614577770233154
Iteration 102: train_loss 1.2069456577301025
Iteration 103: train_loss 1.1973187923431396
Iteration 104: train_loss 1.2151530981063843
Iteration 105: train_loss 1.2318010330200195
Iteration 106: train_loss 1.1400086879730225
Iteration 107: train_loss 1.2264870405197144
Iteration 108: train_loss 1.2129647731781006
Iteration 109: train_loss 1.1952111721038818
Iteration 110: train_loss 1.2275569438934326
Iteration 111: train_loss 1.182593822479248
Iteration 112: train_loss 1.1659473180770874
Iteration 113: train_loss 1.202770709991455
Iteration 114: train_loss 1.1892362833023071
Iteration 115: train_loss 1.2357549667358398
Iteration 116: train_loss 1.1400046348571777
Iteration 117: train_loss 1.2142972946166992
Iteration 118: train_loss 1.1867763996124268
Iteration 119: train_loss 1.1805951595306396
Iteration 120: train_loss 1.1935621500015259
Iteration 121: train_loss 1.1352828741073608
Iteration 122: train_loss 1.1225172281265259
Iteration 123: train_loss 1.2069683074951172
Iteration 124: train_loss 1.182866096496582
Iteration 125: train_loss 1.1656934022903442
Iteration 126: train_loss 1.1773343086242676
Iteration 127: train_loss 1.1538622379302979
Iteration 128: train_loss 1.1956390142440796
Iteration 129: train_loss 1.2080329656600952
Iteration 130: train_loss 1.16987144947052
Iteration 131: train_loss 1.2563211917877197
Iteration 132: train_loss 1.197274923324585
Iteration 133: train_loss 1.1578986644744873
Iteration 134: train_loss 1.2400509119033813
Iteration 135: train_loss 1.2164356708526611
Iteration 136: train_loss 1.1265233755111694
Iteration 137: train_loss 1.239951729774475
Iteration 138: train_loss 1.194456934928894
Iteration 139: train_loss 1.2189359664916992
Iteration 140: train_loss 1.1565974950790405
Iteration 141: train_loss 1.237585425376892
Iteration 142: train_loss 1.21920907497406
Iteration 143: train_loss 1.2025898694992065
Iteration 144: train_loss 1.1881978511810303
Iteration 145: train_loss 1.1697264909744263
Iteration 146: train_loss 1.2024956941604614
Iteration 147: train_loss 1.1649986505508423
Iteration 148: train_loss 1.196961522102356
Iteration 149: train_loss 1.1487528085708618
Iteration 150: train_loss 1.1674015522003174
Iteration 151: train_loss 1.2167993783950806
Iteration 152: train_loss 1.1475955247879028
Iteration 153: train_loss 1.1896462440490723
Iteration 154: train_loss 1.1896663904190063
Iteration 155: train_loss 1.1885732412338257
Iteration 156: train_loss 1.156359314918518
Iteration 157: train_loss 1.1283204555511475
Iteration 158: train_loss 1.1588952541351318
Iteration 159: train_loss 1.1500262022018433
Iteration 160: train_loss 1.1547948122024536
Iteration 161: train_loss 1.1574606895446777
Iteration 162: train_loss 1.1737104654312134
Iteration 163: train_loss 1.2244009971618652
Iteration 164: train_loss 1.2451319694519043
Iteration 165: train_loss 1.1836341619491577
Iteration 166: train_loss 1.2591787576675415
Iteration 167: train_loss 1.1775623559951782
Iteration 168: train_loss 1.1922565698623657
Iteration 169: train_loss 1.1989760398864746
Iteration 170: train_loss 1.2009601593017578
Iteration 171: train_loss 1.235733151435852
Iteration 172: train_loss 1.1834558248519897
Iteration 173: train_loss 1.2726893424987793
Iteration 174: train_loss 1.2549521923065186
Iteration 175: train_loss 1.1755690574645996
Iteration 176: train_loss 1.2346251010894775
Iteration 177: train_loss 1.1767414808273315
Epoch 169: train_avg_loss 1.1856531955428042 eval_avg_acc: 0.34473684545371036 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:41:26] [32mIntermediate result: 0.34473684545371036  (Index 168)[0m
================Epoch: 170================
Iteration 1: train_loss 1.1034821271896362
Iteration 2: train_loss 1.1704920530319214
Iteration 3: train_loss 1.1272951364517212
Iteration 4: train_loss 1.1553136110305786
Iteration 5: train_loss 1.2344766855239868
Iteration 6: train_loss 1.148621678352356
Iteration 7: train_loss 1.1637448072433472
Iteration 8: train_loss 1.154826283454895
Iteration 9: train_loss 1.1845171451568604
Iteration 10: train_loss 1.1187777519226074
Iteration 11: train_loss 1.1785434484481812
Iteration 12: train_loss 1.1790318489074707
Iteration 13: train_loss 1.1826790571212769
Iteration 14: train_loss 1.162351131439209
Iteration 15: train_loss 1.1257448196411133
Iteration 16: train_loss 1.1459596157073975
Iteration 17: train_loss 1.189997911453247
Iteration 18: train_loss 1.1716796159744263
Iteration 19: train_loss 1.105663537979126
Iteration 20: train_loss 1.1865582466125488
Iteration 21: train_loss 1.131347894668579
Iteration 22: train_loss 1.1401352882385254
Iteration 23: train_loss 1.1404467821121216
Iteration 24: train_loss 1.1430679559707642
Iteration 25: train_loss 1.175021767616272
Iteration 26: train_loss 1.1476975679397583
Iteration 27: train_loss 1.1471120119094849
Iteration 28: train_loss 1.1253955364227295
Iteration 29: train_loss 1.14171302318573
Iteration 30: train_loss 1.0926011800765991
Iteration 31: train_loss 1.1565545797348022
Iteration 32: train_loss 1.1308225393295288
Iteration 33: train_loss 1.1698055267333984
Iteration 34: train_loss 1.1361777782440186
Iteration 35: train_loss 1.201141119003296
Iteration 36: train_loss 1.200661540031433
Iteration 37: train_loss 1.1661672592163086
Iteration 38: train_loss 1.1817184686660767
Iteration 39: train_loss 1.163372278213501
Iteration 40: train_loss 1.1644198894500732
Iteration 41: train_loss 1.1761009693145752
Iteration 42: train_loss 1.1554373502731323
Iteration 43: train_loss 1.207214117050171
Iteration 44: train_loss 1.1678032875061035
Iteration 45: train_loss 1.175519347190857
Iteration 46: train_loss 1.1429773569107056
Iteration 47: train_loss 1.1531636714935303
Iteration 48: train_loss 1.1551727056503296
Iteration 49: train_loss 1.0920023918151855
Iteration 50: train_loss 1.191107988357544
Iteration 51: train_loss 1.2225770950317383
Iteration 52: train_loss 1.1762536764144897
Iteration 53: train_loss 1.1499738693237305
Iteration 54: train_loss 1.1439411640167236
Iteration 55: train_loss 1.1564289331436157
Iteration 56: train_loss 1.1169958114624023
Iteration 57: train_loss 1.137888789176941
Iteration 58: train_loss 1.2096827030181885
Iteration 59: train_loss 1.1872493028640747
Iteration 60: train_loss 1.1819998025894165
Iteration 61: train_loss 1.1693871021270752
Iteration 62: train_loss 1.1402608156204224
Iteration 63: train_loss 1.1860880851745605
Iteration 64: train_loss 1.2168744802474976
Iteration 65: train_loss 1.2150543928146362
Iteration 66: train_loss 1.145340919494629
Iteration 67: train_loss 1.165588617324829
Iteration 68: train_loss 1.1523404121398926
Iteration 69: train_loss 1.1228519678115845
Iteration 70: train_loss 1.1850943565368652
Iteration 71: train_loss 1.2050031423568726
Iteration 72: train_loss 1.153439998626709
Iteration 73: train_loss 1.1499996185302734
Iteration 74: train_loss 1.1890895366668701
Iteration 75: train_loss 1.1375572681427002
Iteration 76: train_loss 1.116580843925476
Iteration 77: train_loss 1.238827109336853
Iteration 78: train_loss 1.1843830347061157
Iteration 79: train_loss 1.2094804048538208
Iteration 80: train_loss 1.1437510251998901
Iteration 81: train_loss 1.189499020576477
Iteration 82: train_loss 1.2045729160308838
Iteration 83: train_loss 1.1835999488830566
Iteration 84: train_loss 1.1738865375518799
Iteration 85: train_loss 1.2148350477218628
Iteration 86: train_loss 1.151639699935913
Iteration 87: train_loss 1.1820322275161743
Iteration 88: train_loss 1.1560732126235962
Iteration 89: train_loss 1.1574851274490356
Iteration 90: train_loss 1.1462434530258179
Iteration 91: train_loss 1.126865029335022
Iteration 92: train_loss 1.187870979309082
Iteration 93: train_loss 1.1899100542068481
Iteration 94: train_loss 1.1973302364349365
Iteration 95: train_loss 1.2411576509475708
Iteration 96: train_loss 1.211461067199707
Iteration 97: train_loss 1.144281029701233
Iteration 98: train_loss 1.153825283050537
Iteration 99: train_loss 1.2133822441101074
Iteration 100: train_loss 1.1875616312026978
Iteration 101: train_loss 1.1737746000289917
Iteration 102: train_loss 1.1549365520477295
Iteration 103: train_loss 1.1659846305847168
Iteration 104: train_loss 1.234265923500061
Iteration 105: train_loss 1.1995078325271606
Iteration 106: train_loss 1.1569546461105347
Iteration 107: train_loss 1.201796293258667
Iteration 108: train_loss 1.1818572282791138
Iteration 109: train_loss 1.1390351057052612
Iteration 110: train_loss 1.0988534688949585
Iteration 111: train_loss 1.1400378942489624
Iteration 112: train_loss 1.162827968597412
Iteration 113: train_loss 1.157589077949524
Iteration 114: train_loss 1.1318995952606201
Iteration 115: train_loss 1.1668082475662231
Iteration 116: train_loss 1.1720057725906372
Iteration 117: train_loss 1.17604398727417
Iteration 118: train_loss 1.1748570203781128
Iteration 119: train_loss 1.1835720539093018
Iteration 120: train_loss 1.2165107727050781
Iteration 121: train_loss 1.1414051055908203
Iteration 122: train_loss 1.1199464797973633
Iteration 123: train_loss 1.1333121061325073
Iteration 124: train_loss 1.1593003273010254
Iteration 125: train_loss 1.148271918296814
Iteration 126: train_loss 1.1487994194030762
Iteration 127: train_loss 1.17828369140625
Iteration 128: train_loss 1.1450004577636719
Iteration 129: train_loss 1.2119063138961792
Iteration 130: train_loss 1.1273729801177979
Iteration 131: train_loss 1.1623213291168213
Iteration 132: train_loss 1.1569325923919678
Iteration 133: train_loss 1.1923115253448486
Iteration 134: train_loss 1.1286367177963257
Iteration 135: train_loss 1.1878185272216797
Iteration 136: train_loss 1.1954469680786133
Iteration 137: train_loss 1.1020127534866333
Iteration 138: train_loss 1.150367259979248
Iteration 139: train_loss 1.2241201400756836
Iteration 140: train_loss 1.2163275480270386
Iteration 141: train_loss 1.2334939241409302
Iteration 142: train_loss 1.1573095321655273
Iteration 143: train_loss 1.1514651775360107
Iteration 144: train_loss 1.1614961624145508
Iteration 145: train_loss 1.1724340915679932
Iteration 146: train_loss 1.168432354927063
Iteration 147: train_loss 1.151174783706665
Iteration 148: train_loss 1.1730029582977295
Iteration 149: train_loss 1.1647969484329224
Iteration 150: train_loss 1.1354918479919434
Iteration 151: train_loss 1.1755989789962769
Iteration 152: train_loss 1.1283478736877441
Iteration 153: train_loss 1.1526052951812744
Iteration 154: train_loss 1.1787413358688354
Iteration 155: train_loss 1.1174437999725342
Iteration 156: train_loss 1.1775681972503662
Iteration 157: train_loss 1.1579108238220215
Iteration 158: train_loss 1.1986819505691528
Iteration 159: train_loss 1.1769222021102905
Iteration 160: train_loss 1.1753367185592651
Iteration 161: train_loss 1.1934597492218018
Iteration 162: train_loss 1.1049890518188477
Iteration 163: train_loss 1.1659088134765625
Iteration 164: train_loss 1.1883292198181152
Iteration 165: train_loss 1.1676788330078125
Iteration 166: train_loss 1.2425590753555298
Iteration 167: train_loss 1.1586167812347412
Iteration 168: train_loss 1.2044739723205566
Iteration 169: train_loss 1.168664574623108
Iteration 170: train_loss 1.1752703189849854
Iteration 171: train_loss 1.1701668500900269
Iteration 172: train_loss 1.153259038925171
Iteration 173: train_loss 1.2344435453414917
Iteration 174: train_loss 1.179398775100708
Iteration 175: train_loss 1.2064151763916016
Iteration 176: train_loss 1.2084792852401733
Iteration 177: train_loss 1.2555636167526245
Epoch 170: train_avg_loss 1.167740547050864 eval_avg_acc: 0.34199534604598186 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:42:07] [32mIntermediate result: 0.34199534604598186  (Index 169)[0m
================Epoch: 171================
Iteration 1: train_loss 1.133678674697876
Iteration 2: train_loss 1.167913556098938
Iteration 3: train_loss 1.18525230884552
Iteration 4: train_loss 1.205086588859558
Iteration 5: train_loss 1.2243322134017944
Iteration 6: train_loss 1.221328854560852
Iteration 7: train_loss 1.1764941215515137
Iteration 8: train_loss 1.1807280778884888
Iteration 9: train_loss 1.2320677042007446
Iteration 10: train_loss 1.190018653869629
Iteration 11: train_loss 1.174102783203125
Iteration 12: train_loss 1.1670899391174316
Iteration 13: train_loss 1.1140269041061401
Iteration 14: train_loss 1.1495813131332397
Iteration 15: train_loss 1.1779870986938477
Iteration 16: train_loss 1.1837977170944214
Iteration 17: train_loss 1.1621276140213013
Iteration 18: train_loss 1.1286413669586182
Iteration 19: train_loss 1.1835755109786987
Iteration 20: train_loss 1.16173255443573
Iteration 21: train_loss 1.162818193435669
Iteration 22: train_loss 1.119632363319397
Iteration 23: train_loss 1.1108413934707642
Iteration 24: train_loss 1.1693812608718872
Iteration 25: train_loss 1.1674728393554688
Iteration 26: train_loss 1.1575015783309937
Iteration 27: train_loss 1.1906853914260864
Iteration 28: train_loss 1.1614166498184204
Iteration 29: train_loss 1.122033953666687
Iteration 30: train_loss 1.0973812341690063
Iteration 31: train_loss 1.2209773063659668
Iteration 32: train_loss 1.1880513429641724
Iteration 33: train_loss 1.190166711807251
Iteration 34: train_loss 1.1713396310806274
Iteration 35: train_loss 1.2265158891677856
Iteration 36: train_loss 1.2077473402023315
Iteration 37: train_loss 1.1688354015350342
Iteration 38: train_loss 1.1587775945663452
Iteration 39: train_loss 1.2183982133865356
Iteration 40: train_loss 1.1645106077194214
Iteration 41: train_loss 1.1575647592544556
Iteration 42: train_loss 1.1896191835403442
Iteration 43: train_loss 1.1795400381088257
Iteration 44: train_loss 1.1547516584396362
Iteration 45: train_loss 1.1688218116760254
Iteration 46: train_loss 1.1981710195541382
Iteration 47: train_loss 1.1542034149169922
Iteration 48: train_loss 1.1944175958633423
Iteration 49: train_loss 1.1272870302200317
Iteration 50: train_loss 1.1822068691253662
Iteration 51: train_loss 1.168519139289856
Iteration 52: train_loss 1.1817594766616821
Iteration 53: train_loss 1.2100019454956055
Iteration 54: train_loss 1.2025922536849976
Iteration 55: train_loss 1.1358989477157593
Iteration 56: train_loss 1.2401190996170044
Iteration 57: train_loss 1.1797974109649658
Iteration 58: train_loss 1.1614445447921753
Iteration 59: train_loss 1.160682201385498
Iteration 60: train_loss 1.190015435218811
Iteration 61: train_loss 1.140453815460205
Iteration 62: train_loss 1.1662416458129883
Iteration 63: train_loss 1.1123043298721313
Iteration 64: train_loss 1.1262086629867554
Iteration 65: train_loss 1.184714674949646
Iteration 66: train_loss 1.092228889465332
Iteration 67: train_loss 1.1751891374588013
Iteration 68: train_loss 1.139731526374817
Iteration 69: train_loss 1.1597901582717896
Iteration 70: train_loss 1.2254997491836548
Iteration 71: train_loss 1.1860734224319458
Iteration 72: train_loss 1.218809723854065
Iteration 73: train_loss 1.142678141593933
Iteration 74: train_loss 1.17203688621521
Iteration 75: train_loss 1.169886827468872
Iteration 76: train_loss 1.1907492876052856
Iteration 77: train_loss 1.18598210811615
Iteration 78: train_loss 1.220186471939087
Iteration 79: train_loss 1.2078255414962769
Iteration 80: train_loss 1.155800461769104
Iteration 81: train_loss 1.2181135416030884
Iteration 82: train_loss 1.2127900123596191
Iteration 83: train_loss 1.1457397937774658
Iteration 84: train_loss 1.1374154090881348
Iteration 85: train_loss 1.1688134670257568
Iteration 86: train_loss 1.158642292022705
Iteration 87: train_loss 1.173566460609436
Iteration 88: train_loss 1.1948325634002686
Iteration 89: train_loss 1.180252194404602
Iteration 90: train_loss 1.1608127355575562
Iteration 91: train_loss 1.1593092679977417
Iteration 92: train_loss 1.2103052139282227
Iteration 93: train_loss 1.1805832386016846
Iteration 94: train_loss 1.1949729919433594
Iteration 95: train_loss 1.169217824935913
Iteration 96: train_loss 1.2051233053207397
Iteration 97: train_loss 1.1849091053009033
Iteration 98: train_loss 1.1551917791366577
Iteration 99: train_loss 1.1504294872283936
Iteration 100: train_loss 1.238769769668579
Iteration 101: train_loss 1.17462158203125
Iteration 102: train_loss 1.1632038354873657
Iteration 103: train_loss 1.1198086738586426
Iteration 104: train_loss 1.1458145380020142
Iteration 105: train_loss 1.2164428234100342
Iteration 106: train_loss 1.149841547012329
Iteration 107: train_loss 1.1712877750396729
Iteration 108: train_loss 1.0835407972335815
Iteration 109: train_loss 1.1586101055145264
Iteration 110: train_loss 1.2051007747650146
Iteration 111: train_loss 1.1411933898925781
Iteration 112: train_loss 1.2254939079284668
Iteration 113: train_loss 1.2242119312286377
Iteration 114: train_loss 1.1659891605377197
Iteration 115: train_loss 1.223324179649353
Iteration 116: train_loss 1.2416865825653076
Iteration 117: train_loss 1.2205874919891357
Iteration 118: train_loss 1.1562492847442627
Iteration 119: train_loss 1.1905128955841064
Iteration 120: train_loss 1.1876286268234253
Iteration 121: train_loss 1.1727795600891113
Iteration 122: train_loss 1.1512150764465332
Iteration 123: train_loss 1.10944664478302
Iteration 124: train_loss 1.2070362567901611
Iteration 125: train_loss 1.1730597019195557
Iteration 126: train_loss 1.1545766592025757
Iteration 127: train_loss 1.1840239763259888
Iteration 128: train_loss 1.1716625690460205
Iteration 129: train_loss 1.226802945137024
Iteration 130: train_loss 1.1865373849868774
Iteration 131: train_loss 1.1233187913894653
Iteration 132: train_loss 1.1990888118743896
Iteration 133: train_loss 1.192696213722229
Iteration 134: train_loss 1.1680728197097778
Iteration 135: train_loss 1.1894009113311768
Iteration 136: train_loss 1.1739988327026367
Iteration 137: train_loss 1.1489536762237549
Iteration 138: train_loss 1.2168267965316772
Iteration 139: train_loss 1.1400498151779175
Iteration 140: train_loss 1.1565964221954346
Iteration 141: train_loss 1.1850212812423706
Iteration 142: train_loss 1.186932921409607
Iteration 143: train_loss 1.1341227293014526
Iteration 144: train_loss 1.1566569805145264
Iteration 145: train_loss 1.1726146936416626
Iteration 146: train_loss 1.225346565246582
Iteration 147: train_loss 1.168779969215393
Iteration 148: train_loss 1.1428794860839844
Iteration 149: train_loss 1.1631667613983154
Iteration 150: train_loss 1.1196651458740234
Iteration 151: train_loss 1.1415146589279175
Iteration 152: train_loss 1.190996527671814
Iteration 153: train_loss 1.155544638633728
Iteration 154: train_loss 1.2170016765594482
Iteration 155: train_loss 1.130360722541809
Iteration 156: train_loss 1.149178147315979
Iteration 157: train_loss 1.1899701356887817
Iteration 158: train_loss 1.2242066860198975
Iteration 159: train_loss 1.1533201932907104
Iteration 160: train_loss 1.182917833328247
Iteration 161: train_loss 1.1825319528579712
Iteration 162: train_loss 1.2292762994766235
Iteration 163: train_loss 1.189430594444275
Iteration 164: train_loss 1.2032428979873657
Iteration 165: train_loss 1.129747986793518
Iteration 166: train_loss 1.2152165174484253
Iteration 167: train_loss 1.1951507329940796
Iteration 168: train_loss 1.1784592866897583
Iteration 169: train_loss 1.1674528121948242
Iteration 170: train_loss 1.1717790365219116
Iteration 171: train_loss 1.1897897720336914
Iteration 172: train_loss 1.1935335397720337
Iteration 173: train_loss 1.1626412868499756
Iteration 174: train_loss 1.1992957592010498
Iteration 175: train_loss 1.2099379301071167
Iteration 176: train_loss 1.1407312154769897
Iteration 177: train_loss 1.17860746383667
Epoch 171: train_avg_loss 1.1748133379187287 eval_avg_acc: 0.34390130063776503 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:42:47] [32mIntermediate result: 0.34390130063776503  (Index 170)[0m
================Epoch: 172================
Iteration 1: train_loss 1.1660171747207642
Iteration 2: train_loss 1.1847431659698486
Iteration 3: train_loss 1.1820639371871948
Iteration 4: train_loss 1.1216342449188232
Iteration 5: train_loss 1.102202296257019
Iteration 6: train_loss 1.153355360031128
Iteration 7: train_loss 1.1893810033798218
Iteration 8: train_loss 1.1180499792099
Iteration 9: train_loss 1.1276953220367432
Iteration 10: train_loss 1.1762906312942505
Iteration 11: train_loss 1.1580859422683716
Iteration 12: train_loss 1.1904611587524414
Iteration 13: train_loss 1.178113341331482
Iteration 14: train_loss 1.230342984199524
Iteration 15: train_loss 1.1551789045333862
Iteration 16: train_loss 1.2101044654846191
Iteration 17: train_loss 1.1845614910125732
Iteration 18: train_loss 1.1903915405273438
Iteration 19: train_loss 1.1965839862823486
Iteration 20: train_loss 1.2105845212936401
Iteration 21: train_loss 1.1302156448364258
Iteration 22: train_loss 1.2629656791687012
Iteration 23: train_loss 1.1987335681915283
Iteration 24: train_loss 1.1874644756317139
Iteration 25: train_loss 1.2391122579574585
Iteration 26: train_loss 1.1668578386306763
Iteration 27: train_loss 1.1811821460723877
Iteration 28: train_loss 1.168915033340454
Iteration 29: train_loss 1.154868483543396
Iteration 30: train_loss 1.1787428855895996
Iteration 31: train_loss 1.124799370765686
Iteration 32: train_loss 1.1239362955093384
Iteration 33: train_loss 1.1431465148925781
Iteration 34: train_loss 1.1296584606170654
Iteration 35: train_loss 1.1525366306304932
Iteration 36: train_loss 1.117819905281067
Iteration 37: train_loss 1.1103310585021973
Iteration 38: train_loss 1.0920569896697998
Iteration 39: train_loss 1.168703317642212
Iteration 40: train_loss 1.1387596130371094
Iteration 41: train_loss 1.1199023723602295
Iteration 42: train_loss 1.1537939310073853
Iteration 43: train_loss 1.1707338094711304
Iteration 44: train_loss 1.1805216073989868
Iteration 45: train_loss 1.1267240047454834
Iteration 46: train_loss 1.1263900995254517
Iteration 47: train_loss 1.133354663848877
Iteration 48: train_loss 1.1127392053604126
Iteration 49: train_loss 1.1233735084533691
Iteration 50: train_loss 1.1021746397018433
Iteration 51: train_loss 1.1706238985061646
Iteration 52: train_loss 1.1724426746368408
Iteration 53: train_loss 1.1720796823501587
Iteration 54: train_loss 1.1372793912887573
Iteration 55: train_loss 1.0933544635772705
Iteration 56: train_loss 1.1329364776611328
Iteration 57: train_loss 1.1100751161575317
Iteration 58: train_loss 1.1129658222198486
Iteration 59: train_loss 1.0887606143951416
Iteration 60: train_loss 1.1323652267456055
Iteration 61: train_loss 1.172013521194458
Iteration 62: train_loss 1.119797706604004
Iteration 63: train_loss 1.0867949724197388
Iteration 64: train_loss 1.1659904718399048
Iteration 65: train_loss 1.173852562904358
Iteration 66: train_loss 1.173346757888794
Iteration 67: train_loss 1.1703919172286987
Iteration 68: train_loss 1.1629964113235474
Iteration 69: train_loss 1.1905542612075806
Iteration 70: train_loss 1.1571394205093384
Iteration 71: train_loss 1.1429120302200317
Iteration 72: train_loss 1.1856989860534668
Iteration 73: train_loss 1.178141713142395
Iteration 74: train_loss 1.138406753540039
Iteration 75: train_loss 1.1924307346343994
Iteration 76: train_loss 1.2056907415390015
Iteration 77: train_loss 1.180074691772461
Iteration 78: train_loss 1.1566845178604126
Iteration 79: train_loss 1.1709128618240356
Iteration 80: train_loss 1.217395305633545
Iteration 81: train_loss 1.1903572082519531
Iteration 82: train_loss 1.2169079780578613
Iteration 83: train_loss 1.1340916156768799
Iteration 84: train_loss 1.1576272249221802
Iteration 85: train_loss 1.1271454095840454
Iteration 86: train_loss 1.2351514101028442
Iteration 87: train_loss 1.100361943244934
Iteration 88: train_loss 1.2178070545196533
Iteration 89: train_loss 1.1658549308776855
Iteration 90: train_loss 1.1813511848449707
Iteration 91: train_loss 1.1575331687927246
Iteration 92: train_loss 1.1905306577682495
Iteration 93: train_loss 1.140550971031189
Iteration 94: train_loss 1.127640724182129
Iteration 95: train_loss 1.1029552221298218
Iteration 96: train_loss 1.161598801612854
Iteration 97: train_loss 1.1935029029846191
Iteration 98: train_loss 1.1853615045547485
Iteration 99: train_loss 1.213722586631775
Iteration 100: train_loss 1.1927452087402344
Iteration 101: train_loss 1.1326904296875
Iteration 102: train_loss 1.1551530361175537
Iteration 103: train_loss 1.215516209602356
Iteration 104: train_loss 1.1436522006988525
Iteration 105: train_loss 1.12240469455719
Iteration 106: train_loss 1.137090802192688
Iteration 107: train_loss 1.1578521728515625
Iteration 108: train_loss 1.1870455741882324
Iteration 109: train_loss 1.1725823879241943
Iteration 110: train_loss 1.1612600088119507
Iteration 111: train_loss 1.1832664012908936
Iteration 112: train_loss 1.1843034029006958
Iteration 113: train_loss 1.1746255159378052
Iteration 114: train_loss 1.1544740200042725
Iteration 115: train_loss 1.2187023162841797
Iteration 116: train_loss 1.1709305047988892
Iteration 117: train_loss 1.1353914737701416
Iteration 118: train_loss 1.1150583028793335
Iteration 119: train_loss 1.1542706489562988
Iteration 120: train_loss 1.1113277673721313
Iteration 121: train_loss 1.1271289587020874
Iteration 122: train_loss 1.159368872642517
Iteration 123: train_loss 1.162314534187317
Iteration 124: train_loss 1.1529443264007568
Iteration 125: train_loss 1.157789945602417
Iteration 126: train_loss 1.1224268674850464
Iteration 127: train_loss 1.185704231262207
Iteration 128: train_loss 1.1853457689285278
Iteration 129: train_loss 1.200232744216919
Iteration 130: train_loss 1.1728204488754272
Iteration 131: train_loss 1.2295360565185547
Iteration 132: train_loss 1.175318956375122
Iteration 133: train_loss 1.1924701929092407
Iteration 134: train_loss 1.1816872358322144
Iteration 135: train_loss 1.1782686710357666
Iteration 136: train_loss 1.1612695455551147
Iteration 137: train_loss 1.1742455959320068
Iteration 138: train_loss 1.1675469875335693
Iteration 139: train_loss 1.1756401062011719
Iteration 140: train_loss 1.1822843551635742
Iteration 141: train_loss 1.1570711135864258
Iteration 142: train_loss 1.1391781568527222
Iteration 143: train_loss 1.2068359851837158
Iteration 144: train_loss 1.1809362173080444
Iteration 145: train_loss 1.2151906490325928
Iteration 146: train_loss 1.194108247756958
Iteration 147: train_loss 1.184433937072754
Iteration 148: train_loss 1.1235212087631226
Iteration 149: train_loss 1.1745853424072266
Iteration 150: train_loss 1.2216401100158691
Iteration 151: train_loss 1.1597442626953125
Iteration 152: train_loss 1.139093279838562
Iteration 153: train_loss 1.170004963874817
Iteration 154: train_loss 1.1845654249191284
Iteration 155: train_loss 1.191478967666626
Iteration 156: train_loss 1.1229016780853271
Iteration 157: train_loss 1.1047180891036987
Iteration 158: train_loss 1.123653531074524
Iteration 159: train_loss 1.1117016077041626
Iteration 160: train_loss 1.1058567762374878
Iteration 161: train_loss 1.1640139818191528
Iteration 162: train_loss 1.2183834314346313
Iteration 163: train_loss 1.1919797658920288
Iteration 164: train_loss 1.1911412477493286
Iteration 165: train_loss 1.1256422996520996
Iteration 166: train_loss 1.1538691520690918
Iteration 167: train_loss 1.1486550569534302
Iteration 168: train_loss 1.225236177444458
Iteration 169: train_loss 1.23824143409729
Iteration 170: train_loss 1.232444405555725
Iteration 171: train_loss 1.1945881843566895
Iteration 172: train_loss 1.1965477466583252
Iteration 173: train_loss 1.1989059448242188
Iteration 174: train_loss 1.1247624158859253
Iteration 175: train_loss 1.17192542552948
Iteration 176: train_loss 1.1755670309066772
Iteration 177: train_loss 1.0513008832931519
Epoch 172: train_avg_loss 1.1629922558358834 eval_avg_acc: 0.34549167539903874 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:43:28] [32mIntermediate result: 0.34549167539903874  (Index 171)[0m
================Epoch: 173================
Iteration 1: train_loss 1.1576275825500488
Iteration 2: train_loss 1.1927810907363892
Iteration 3: train_loss 1.1478846073150635
Iteration 4: train_loss 1.1203070878982544
Iteration 5: train_loss 1.1480504274368286
Iteration 6: train_loss 1.19318687915802
Iteration 7: train_loss 1.1679832935333252
Iteration 8: train_loss 1.1919864416122437
Iteration 9: train_loss 1.1669403314590454
Iteration 10: train_loss 1.169762372970581
Iteration 11: train_loss 1.1383389234542847
Iteration 12: train_loss 1.2257415056228638
Iteration 13: train_loss 1.1509308815002441
Iteration 14: train_loss 1.129773497581482
Iteration 15: train_loss 1.18114173412323
Iteration 16: train_loss 1.1448829174041748
Iteration 17: train_loss 1.1537246704101562
Iteration 18: train_loss 1.1810435056686401
Iteration 19: train_loss 1.1453357934951782
Iteration 20: train_loss 1.1527879238128662
Iteration 21: train_loss 1.1014729738235474
Iteration 22: train_loss 1.1146620512008667
Iteration 23: train_loss 1.1838852167129517
Iteration 24: train_loss 1.1429708003997803
Iteration 25: train_loss 1.193792462348938
Iteration 26: train_loss 1.1890400648117065
Iteration 27: train_loss 1.176253318786621
Iteration 28: train_loss 1.1843838691711426
Iteration 29: train_loss 1.1788806915283203
Iteration 30: train_loss 1.139821171760559
Iteration 31: train_loss 1.1413459777832031
Iteration 32: train_loss 1.182838797569275
Iteration 33: train_loss 1.0923024415969849
Iteration 34: train_loss 1.1609489917755127
Iteration 35: train_loss 1.1216601133346558
Iteration 36: train_loss 1.0965555906295776
Iteration 37: train_loss 1.1898198127746582
Iteration 38: train_loss 1.1707615852355957
Iteration 39: train_loss 1.1308597326278687
Iteration 40: train_loss 1.1618478298187256
Iteration 41: train_loss 1.1418548822402954
Iteration 42: train_loss 1.1585824489593506
Iteration 43: train_loss 1.17714262008667
Iteration 44: train_loss 1.1116812229156494
Iteration 45: train_loss 1.152104139328003
Iteration 46: train_loss 1.1544421911239624
Iteration 47: train_loss 1.1747667789459229
Iteration 48: train_loss 1.1538857221603394
Iteration 49: train_loss 1.173606276512146
Iteration 50: train_loss 1.1225932836532593
Iteration 51: train_loss 1.1834990978240967
Iteration 52: train_loss 1.1496362686157227
Iteration 53: train_loss 1.1427454948425293
Iteration 54: train_loss 1.1180214881896973
Iteration 55: train_loss 1.1351211071014404
Iteration 56: train_loss 1.1524763107299805
Iteration 57: train_loss 1.1296541690826416
Iteration 58: train_loss 1.1459590196609497
Iteration 59: train_loss 1.1321660280227661
Iteration 60: train_loss 1.1669834852218628
Iteration 61: train_loss 1.1725691556930542
Iteration 62: train_loss 1.1803650856018066
Iteration 63: train_loss 1.160261869430542
Iteration 64: train_loss 1.1740813255310059
Iteration 65: train_loss 1.1329392194747925
Iteration 66: train_loss 1.201179027557373
Iteration 67: train_loss 1.1710354089736938
Iteration 68: train_loss 1.1702957153320312
Iteration 69: train_loss 1.141941785812378
Iteration 70: train_loss 1.1369723081588745
Iteration 71: train_loss 1.139808177947998
Iteration 72: train_loss 1.1492369174957275
Iteration 73: train_loss 1.1699128150939941
Iteration 74: train_loss 1.1954572200775146
Iteration 75: train_loss 1.1085031032562256
Iteration 76: train_loss 1.18149733543396
Iteration 77: train_loss 1.1506574153900146
Iteration 78: train_loss 1.2162127494812012
Iteration 79: train_loss 1.159533977508545
Iteration 80: train_loss 1.2218267917633057
Iteration 81: train_loss 1.1936416625976562
Iteration 82: train_loss 1.1191434860229492
Iteration 83: train_loss 1.1733089685440063
Iteration 84: train_loss 1.204972743988037
Iteration 85: train_loss 1.1196835041046143
Iteration 86: train_loss 1.1526585817337036
Iteration 87: train_loss 1.139710783958435
Iteration 88: train_loss 1.1226519346237183
Iteration 89: train_loss 1.1109198331832886
Iteration 90: train_loss 1.1592662334442139
Iteration 91: train_loss 1.0836787223815918
Iteration 92: train_loss 1.1613398790359497
Iteration 93: train_loss 1.1730437278747559
Iteration 94: train_loss 1.1638344526290894
Iteration 95: train_loss 1.1603713035583496
Iteration 96: train_loss 1.1302688121795654
Iteration 97: train_loss 1.1951361894607544
Iteration 98: train_loss 1.1012438535690308
Iteration 99: train_loss 1.1480604410171509
Iteration 100: train_loss 1.1548779010772705
Iteration 101: train_loss 1.1621344089508057
Iteration 102: train_loss 1.13070547580719
Iteration 103: train_loss 1.1597827672958374
Iteration 104: train_loss 1.1889606714248657
Iteration 105: train_loss 1.2220972776412964
Iteration 106: train_loss 1.104027271270752
Iteration 107: train_loss 1.158669114112854
Iteration 108: train_loss 1.1095733642578125
Iteration 109: train_loss 1.158332109451294
Iteration 110: train_loss 1.131001591682434
Iteration 111: train_loss 1.1397515535354614
Iteration 112: train_loss 1.1560217142105103
Iteration 113: train_loss 1.1077942848205566
Iteration 114: train_loss 1.1179865598678589
Iteration 115: train_loss 1.1662338972091675
Iteration 116: train_loss 1.165420413017273
Iteration 117: train_loss 1.1875662803649902
Iteration 118: train_loss 1.136134386062622
Iteration 119: train_loss 1.2002041339874268
Iteration 120: train_loss 1.1384849548339844
Iteration 121: train_loss 1.2291971445083618
Iteration 122: train_loss 1.1411011219024658
Iteration 123: train_loss 1.1382272243499756
Iteration 124: train_loss 1.1942096948623657
Iteration 125: train_loss 1.2092045545578003
Iteration 126: train_loss 1.1569340229034424
Iteration 127: train_loss 1.2152973413467407
Iteration 128: train_loss 1.1655948162078857
Iteration 129: train_loss 1.2474511861801147
Iteration 130: train_loss 1.188309907913208
Iteration 131: train_loss 1.1648367643356323
Iteration 132: train_loss 1.234367847442627
Iteration 133: train_loss 1.2102562189102173
Iteration 134: train_loss 1.2074840068817139
Iteration 135: train_loss 1.1662545204162598
Iteration 136: train_loss 1.148610234260559
Iteration 137: train_loss 1.2353439331054688
Iteration 138: train_loss 1.1684465408325195
Iteration 139: train_loss 1.2012882232666016
Iteration 140: train_loss 1.2180922031402588
Iteration 141: train_loss 1.17281973361969
Iteration 142: train_loss 1.1427192687988281
Iteration 143: train_loss 1.1641788482666016
Iteration 144: train_loss 1.115273118019104
Iteration 145: train_loss 1.1815396547317505
Iteration 146: train_loss 1.1687073707580566
Iteration 147: train_loss 1.205312728881836
Iteration 148: train_loss 1.2436511516571045
Iteration 149: train_loss 1.188359260559082
Iteration 150: train_loss 1.2197939157485962
Iteration 151: train_loss 1.2453681230545044
Iteration 152: train_loss 1.2283581495285034
Iteration 153: train_loss 1.232126235961914
Iteration 154: train_loss 1.1956480741500854
Iteration 155: train_loss 1.1651973724365234
Iteration 156: train_loss 1.1744216680526733
Iteration 157: train_loss 1.2326737642288208
Iteration 158: train_loss 1.218734622001648
Iteration 159: train_loss 1.2263380289077759
Iteration 160: train_loss 1.1690231561660767
Iteration 161: train_loss 1.2217693328857422
Iteration 162: train_loss 1.1749154329299927
Iteration 163: train_loss 1.09713613986969
Iteration 164: train_loss 1.176066517829895
Iteration 165: train_loss 1.2065626382827759
Iteration 166: train_loss 1.2127596139907837
Iteration 167: train_loss 1.1911720037460327
Iteration 168: train_loss 1.1974166631698608
Iteration 169: train_loss 1.1363285779953003
Iteration 170: train_loss 1.1590914726257324
Iteration 171: train_loss 1.1920875310897827
Iteration 172: train_loss 1.200805425643921
Iteration 173: train_loss 1.2005460262298584
Iteration 174: train_loss 1.1348047256469727
Iteration 175: train_loss 1.2072335481643677
Iteration 176: train_loss 1.1962283849716187
Iteration 177: train_loss 1.1211501359939575
Epoch 173: train_avg_loss 1.1660511049173645 eval_avg_acc: 0.3409585366635258 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:44:12] [32mIntermediate result: 0.3409585366635258  (Index 172)[0m
================Epoch: 174================
Iteration 1: train_loss 1.1770085096359253
Iteration 2: train_loss 1.2310341596603394
Iteration 3: train_loss 1.1487735509872437
Iteration 4: train_loss 1.1385602951049805
Iteration 5: train_loss 1.2028017044067383
Iteration 6: train_loss 1.1178377866744995
Iteration 7: train_loss 1.1467320919036865
Iteration 8: train_loss 1.1379239559173584
Iteration 9: train_loss 1.1742292642593384
Iteration 10: train_loss 1.1392700672149658
Iteration 11: train_loss 1.1764636039733887
Iteration 12: train_loss 1.124901533126831
Iteration 13: train_loss 1.201869249343872
Iteration 14: train_loss 1.1667996644973755
Iteration 15: train_loss 1.096331000328064
Iteration 16: train_loss 1.1593376398086548
Iteration 17: train_loss 1.1346412897109985
Iteration 18: train_loss 1.2481921911239624
Iteration 19: train_loss 1.1297513246536255
Iteration 20: train_loss 1.1667004823684692
Iteration 21: train_loss 1.1225463151931763
Iteration 22: train_loss 1.2038242816925049
Iteration 23: train_loss 1.1819597482681274
Iteration 24: train_loss 1.1590781211853027
Iteration 25: train_loss 1.1130248308181763
Iteration 26: train_loss 1.1610939502716064
Iteration 27: train_loss 1.1441975831985474
Iteration 28: train_loss 1.1548395156860352
Iteration 29: train_loss 1.195841670036316
Iteration 30: train_loss 1.1643617153167725
Iteration 31: train_loss 1.1926888227462769
Iteration 32: train_loss 1.22165048122406
Iteration 33: train_loss 1.1183278560638428
Iteration 34: train_loss 1.1971641778945923
Iteration 35: train_loss 1.1353726387023926
Iteration 36: train_loss 1.0615079402923584
Iteration 37: train_loss 1.151208519935608
Iteration 38: train_loss 1.134300947189331
Iteration 39: train_loss 1.1831449270248413
Iteration 40: train_loss 1.2286137342453003
Iteration 41: train_loss 1.1765036582946777
Iteration 42: train_loss 1.2230478525161743
Iteration 43: train_loss 1.1554360389709473
Iteration 44: train_loss 1.2178865671157837
Iteration 45: train_loss 1.2322471141815186
Iteration 46: train_loss 1.2185002565383911
Iteration 47: train_loss 1.198104739189148
Iteration 48: train_loss 1.214531660079956
Iteration 49: train_loss 1.1841548681259155
Iteration 50: train_loss 1.1456594467163086
Iteration 51: train_loss 1.1828265190124512
Iteration 52: train_loss 1.1643781661987305
Iteration 53: train_loss 1.1856595277786255
Iteration 54: train_loss 1.1724069118499756
Iteration 55: train_loss 1.1450873613357544
Iteration 56: train_loss 1.1744393110275269
Iteration 57: train_loss 1.180493712425232
Iteration 58: train_loss 1.1448675394058228
Iteration 59: train_loss 1.1644704341888428
Iteration 60: train_loss 1.1363930702209473
Iteration 61: train_loss 1.1845550537109375
Iteration 62: train_loss 1.1966150999069214
Iteration 63: train_loss 1.2178713083267212
Iteration 64: train_loss 1.1979883909225464
Iteration 65: train_loss 1.1667816638946533
Iteration 66: train_loss 1.1190907955169678
Iteration 67: train_loss 1.127941608428955
Iteration 68: train_loss 1.2218202352523804
Iteration 69: train_loss 1.179150104522705
Iteration 70: train_loss 1.1577770709991455
Iteration 71: train_loss 1.160630464553833
Iteration 72: train_loss 1.2182351350784302
Iteration 73: train_loss 1.1721715927124023
Iteration 74: train_loss 1.1621838808059692
Iteration 75: train_loss 1.211622714996338
Iteration 76: train_loss 1.1960067749023438
Iteration 77: train_loss 1.2065479755401611
Iteration 78: train_loss 1.1640233993530273
Iteration 79: train_loss 1.1667473316192627
Iteration 80: train_loss 1.149558663368225
Iteration 81: train_loss 1.1729239225387573
Iteration 82: train_loss 1.1493979692459106
Iteration 83: train_loss 1.1734858751296997
Iteration 84: train_loss 1.1188896894454956
Iteration 85: train_loss 1.115249514579773
Iteration 86: train_loss 1.1183983087539673
Iteration 87: train_loss 1.1576728820800781
Iteration 88: train_loss 1.1052857637405396
Iteration 89: train_loss 1.078895092010498
Iteration 90: train_loss 1.1642792224884033
Iteration 91: train_loss 1.0833176374435425
Iteration 92: train_loss 1.1867332458496094
Iteration 93: train_loss 1.175410270690918
Iteration 94: train_loss 1.10642671585083
Iteration 95: train_loss 1.175755500793457
Iteration 96: train_loss 1.1576920747756958
Iteration 97: train_loss 1.1428883075714111
Iteration 98: train_loss 1.1588999032974243
Iteration 99: train_loss 1.1486247777938843
Iteration 100: train_loss 1.158190369606018
Iteration 101: train_loss 1.1905653476715088
Iteration 102: train_loss 1.1521533727645874
Iteration 103: train_loss 1.1247258186340332
Iteration 104: train_loss 1.21290922164917
Iteration 105: train_loss 1.150626301765442
Iteration 106: train_loss 1.2088626623153687
Iteration 107: train_loss 1.1406958103179932
Iteration 108: train_loss 1.1847152709960938
Iteration 109: train_loss 1.161520004272461
Iteration 110: train_loss 1.2162754535675049
Iteration 111: train_loss 1.1437081098556519
Iteration 112: train_loss 1.1479533910751343
Iteration 113: train_loss 1.2090508937835693
Iteration 114: train_loss 1.1544917821884155
Iteration 115: train_loss 1.1556564569473267
Iteration 116: train_loss 1.1450610160827637
Iteration 117: train_loss 1.1607811450958252
Iteration 118: train_loss 1.1659029722213745
Iteration 119: train_loss 1.2245463132858276
Iteration 120: train_loss 1.189070701599121
Iteration 121: train_loss 1.2406370639801025
Iteration 122: train_loss 1.178204894065857
Iteration 123: train_loss 1.1397329568862915
Iteration 124: train_loss 1.1709107160568237
Iteration 125: train_loss 1.215565800666809
Iteration 126: train_loss 1.2004972696304321
Iteration 127: train_loss 1.1324524879455566
Iteration 128: train_loss 1.1923273801803589
Iteration 129: train_loss 1.1235995292663574
Iteration 130: train_loss 1.1399270296096802
Iteration 131: train_loss 1.1569511890411377
Iteration 132: train_loss 1.1651188135147095
Iteration 133: train_loss 1.1927918195724487
Iteration 134: train_loss 1.1736841201782227
Iteration 135: train_loss 1.14646315574646
Iteration 136: train_loss 1.1536643505096436
Iteration 137: train_loss 1.1573619842529297
Iteration 138: train_loss 1.1701139211654663
Iteration 139: train_loss 1.1872130632400513
Iteration 140: train_loss 1.1554075479507446
Iteration 141: train_loss 1.132154107093811
Iteration 142: train_loss 1.2339601516723633
Iteration 143: train_loss 1.1849316358566284
Iteration 144: train_loss 1.1655099391937256
Iteration 145: train_loss 1.1443158388137817
Iteration 146: train_loss 1.218995213508606
Iteration 147: train_loss 1.2168670892715454
Iteration 148: train_loss 1.1136022806167603
Iteration 149: train_loss 1.1731590032577515
Iteration 150: train_loss 1.229088544845581
Iteration 151: train_loss 1.1822643280029297
Iteration 152: train_loss 1.1596956253051758
Iteration 153: train_loss 1.1649235486984253
Iteration 154: train_loss 1.1777501106262207
Iteration 155: train_loss 1.1593601703643799
Iteration 156: train_loss 1.1181825399398804
Iteration 157: train_loss 1.1687756776809692
Iteration 158: train_loss 1.1698375940322876
Iteration 159: train_loss 1.1507556438446045
Iteration 160: train_loss 1.174635887145996
Iteration 161: train_loss 1.152371883392334
Iteration 162: train_loss 1.1336121559143066
Iteration 163: train_loss 1.165112018585205
Iteration 164: train_loss 1.1460506916046143
Iteration 165: train_loss 1.1954303979873657
Iteration 166: train_loss 1.1594116687774658
Iteration 167: train_loss 1.1727551221847534
Iteration 168: train_loss 1.1333487033843994
Iteration 169: train_loss 1.1548842191696167
Iteration 170: train_loss 1.1624513864517212
Iteration 171: train_loss 1.0944256782531738
Iteration 172: train_loss 1.100115180015564
Iteration 173: train_loss 1.127877950668335
Iteration 174: train_loss 1.1051491498947144
Iteration 175: train_loss 1.1543606519699097
Iteration 176: train_loss 1.122585415840149
Iteration 177: train_loss 1.0943667888641357
Epoch 174: train_avg_loss 1.164585928458952 eval_avg_acc: 0.34811093904075513 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:44:55] [32mIntermediate result: 0.34811093904075513  (Index 173)[0m
================Epoch: 175================
Iteration 1: train_loss 1.172396183013916
Iteration 2: train_loss 1.101171851158142
Iteration 3: train_loss 1.1591072082519531
Iteration 4: train_loss 1.1309534311294556
Iteration 5: train_loss 1.1158019304275513
Iteration 6: train_loss 1.1152533292770386
Iteration 7: train_loss 1.1037794351577759
Iteration 8: train_loss 1.0713914632797241
Iteration 9: train_loss 1.1319363117218018
Iteration 10: train_loss 1.1810493469238281
Iteration 11: train_loss 1.111854076385498
Iteration 12: train_loss 1.179167628288269
Iteration 13: train_loss 1.1565120220184326
Iteration 14: train_loss 1.1401803493499756
Iteration 15: train_loss 1.1324560642242432
Iteration 16: train_loss 1.169438123703003
Iteration 17: train_loss 1.1010990142822266
Iteration 18: train_loss 1.19745934009552
Iteration 19: train_loss 1.179162859916687
Iteration 20: train_loss 1.1810612678527832
Iteration 21: train_loss 1.1354753971099854
Iteration 22: train_loss 1.121143102645874
Iteration 23: train_loss 1.1187537908554077
Iteration 24: train_loss 1.155529260635376
Iteration 25: train_loss 1.1087772846221924
Iteration 26: train_loss 1.0716761350631714
Iteration 27: train_loss 1.1656255722045898
Iteration 28: train_loss 1.1140189170837402
Iteration 29: train_loss 1.1406192779541016
Iteration 30: train_loss 1.1683930158615112
Iteration 31: train_loss 1.1575829982757568
Iteration 32: train_loss 1.16946542263031
Iteration 33: train_loss 1.1702964305877686
Iteration 34: train_loss 1.1412527561187744
Iteration 35: train_loss 1.1443846225738525
Iteration 36: train_loss 1.1362553834915161
Iteration 37: train_loss 1.1213799715042114
Iteration 38: train_loss 1.1400210857391357
Iteration 39: train_loss 1.1474957466125488
Iteration 40: train_loss 1.1239275932312012
Iteration 41: train_loss 1.143340826034546
Iteration 42: train_loss 1.1169323921203613
Iteration 43: train_loss 1.1048017740249634
Iteration 44: train_loss 1.1214993000030518
Iteration 45: train_loss 1.1289432048797607
Iteration 46: train_loss 1.1251298189163208
Iteration 47: train_loss 1.1194173097610474
Iteration 48: train_loss 1.1940441131591797
Iteration 49: train_loss 1.1404701471328735
Iteration 50: train_loss 1.163910150527954
Iteration 51: train_loss 1.123826265335083
Iteration 52: train_loss 1.1654586791992188
Iteration 53: train_loss 1.1237223148345947
Iteration 54: train_loss 1.1203149557113647
Iteration 55: train_loss 1.1518630981445312
Iteration 56: train_loss 1.1970880031585693
Iteration 57: train_loss 1.1489919424057007
Iteration 58: train_loss 1.1750609874725342
Iteration 59: train_loss 1.1732292175292969
Iteration 60: train_loss 1.1713366508483887
Iteration 61: train_loss 1.2128334045410156
Iteration 62: train_loss 1.2307666540145874
Iteration 63: train_loss 1.1839377880096436
Iteration 64: train_loss 1.1330146789550781
Iteration 65: train_loss 1.1578178405761719
Iteration 66: train_loss 1.2265018224716187
Iteration 67: train_loss 1.1860263347625732
Iteration 68: train_loss 1.2186003923416138
Iteration 69: train_loss 1.213466763496399
Iteration 70: train_loss 1.1928249597549438
Iteration 71: train_loss 1.1738078594207764
Iteration 72: train_loss 1.206242561340332
Iteration 73: train_loss 1.2111297845840454
Iteration 74: train_loss 1.160281777381897
Iteration 75: train_loss 1.1186586618423462
Iteration 76: train_loss 1.1553373336791992
Iteration 77: train_loss 1.1919742822647095
Iteration 78: train_loss 1.1753257513046265
Iteration 79: train_loss 1.1515302658081055
Iteration 80: train_loss 1.1460906267166138
Iteration 81: train_loss 1.1649233102798462
Iteration 82: train_loss 1.1969878673553467
Iteration 83: train_loss 1.188185453414917
Iteration 84: train_loss 1.1443452835083008
Iteration 85: train_loss 1.1836167573928833
Iteration 86: train_loss 1.1613620519638062
Iteration 87: train_loss 1.1962885856628418
Iteration 88: train_loss 1.1872638463974
Iteration 89: train_loss 1.1207842826843262
Iteration 90: train_loss 1.1921974420547485
Iteration 91: train_loss 1.160167932510376
Iteration 92: train_loss 1.1242650747299194
Iteration 93: train_loss 1.2495570182800293
Iteration 94: train_loss 1.1784485578536987
Iteration 95: train_loss 1.200899600982666
Iteration 96: train_loss 1.191054344177246
Iteration 97: train_loss 1.10198175907135
Iteration 98: train_loss 1.147618055343628
Iteration 99: train_loss 1.1786582469940186
Iteration 100: train_loss 1.1737455129623413
Iteration 101: train_loss 1.1633573770523071
Iteration 102: train_loss 1.1336421966552734
Iteration 103: train_loss 1.1647248268127441
Iteration 104: train_loss 1.2414973974227905
Iteration 105: train_loss 1.1849030256271362
Iteration 106: train_loss 1.1745530366897583
Iteration 107: train_loss 1.1547706127166748
Iteration 108: train_loss 1.0849363803863525
Iteration 109: train_loss 1.1925350427627563
Iteration 110: train_loss 1.1553188562393188
Iteration 111: train_loss 1.1696197986602783
Iteration 112: train_loss 1.1628211736679077
Iteration 113: train_loss 1.1847965717315674
Iteration 114: train_loss 1.1706541776657104
Iteration 115: train_loss 1.182784080505371
Iteration 116: train_loss 1.1118305921554565
Iteration 117: train_loss 1.2156729698181152
Iteration 118: train_loss 1.187220573425293
Iteration 119: train_loss 1.1881848573684692
Iteration 120: train_loss 1.1478267908096313
Iteration 121: train_loss 1.1579738855361938
Iteration 122: train_loss 1.132032036781311
Iteration 123: train_loss 1.1586625576019287
Iteration 124: train_loss 1.2388312816619873
Iteration 125: train_loss 1.1652655601501465
Iteration 126: train_loss 1.1161096096038818
Iteration 127: train_loss 1.1988648176193237
Iteration 128: train_loss 1.1973975896835327
Iteration 129: train_loss 1.1468685865402222
Iteration 130: train_loss 1.1304577589035034
Iteration 131: train_loss 1.1302951574325562
Iteration 132: train_loss 1.1482822895050049
Iteration 133: train_loss 1.1532422304153442
Iteration 134: train_loss 1.147717833518982
Iteration 135: train_loss 1.158848524093628
Iteration 136: train_loss 1.1462632417678833
Iteration 137: train_loss 1.1374861001968384
Iteration 138: train_loss 1.1494834423065186
Iteration 139: train_loss 1.0985904932022095
Iteration 140: train_loss 1.1166694164276123
Iteration 141: train_loss 1.1936697959899902
Iteration 142: train_loss 1.2072765827178955
Iteration 143: train_loss 1.1961452960968018
Iteration 144: train_loss 1.1982202529907227
Iteration 145: train_loss 1.1642094850540161
Iteration 146: train_loss 1.169276475906372
Iteration 147: train_loss 1.1329349279403687
Iteration 148: train_loss 1.2171857357025146
Iteration 149: train_loss 1.1412498950958252
Iteration 150: train_loss 1.1640863418579102
Iteration 151: train_loss 1.1336219310760498
Iteration 152: train_loss 1.1620688438415527
Iteration 153: train_loss 1.1280521154403687
Iteration 154: train_loss 1.143349289894104
Iteration 155: train_loss 1.1566598415374756
Iteration 156: train_loss 1.1202762126922607
Iteration 157: train_loss 1.1794956922531128
Iteration 158: train_loss 1.1357496976852417
Iteration 159: train_loss 1.1650339365005493
Iteration 160: train_loss 1.1385737657546997
Iteration 161: train_loss 1.1873090267181396
Iteration 162: train_loss 1.1654402017593384
Iteration 163: train_loss 1.1997822523117065
Iteration 164: train_loss 1.1848288774490356
Iteration 165: train_loss 1.1540179252624512
Iteration 166: train_loss 1.1306474208831787
Iteration 167: train_loss 1.1729081869125366
Iteration 168: train_loss 1.1515883207321167
Iteration 169: train_loss 1.1443119049072266
Iteration 170: train_loss 1.126787781715393
Iteration 171: train_loss 1.122977375984192
Iteration 172: train_loss 1.16661536693573
Iteration 173: train_loss 1.1382328271865845
Iteration 174: train_loss 1.1383700370788574
Iteration 175: train_loss 1.16536545753479
Iteration 176: train_loss 1.1660696268081665
Iteration 177: train_loss 1.0914446115493774
Epoch 175: train_avg_loss 1.1572657217413693 eval_avg_acc: 0.3426708011040956 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:45:39] [32mIntermediate result: 0.3426708011040956  (Index 174)[0m
================Epoch: 176================
Iteration 1: train_loss 1.0956026315689087
Iteration 2: train_loss 1.145702600479126
Iteration 3: train_loss 1.1667159795761108
Iteration 4: train_loss 1.1656734943389893
Iteration 5: train_loss 1.2383311986923218
Iteration 6: train_loss 1.0856162309646606
Iteration 7: train_loss 1.1659973859786987
Iteration 8: train_loss 1.126960277557373
Iteration 9: train_loss 1.1004257202148438
Iteration 10: train_loss 1.187592625617981
Iteration 11: train_loss 1.139247179031372
Iteration 12: train_loss 1.1294236183166504
Iteration 13: train_loss 1.1264413595199585
Iteration 14: train_loss 1.1699327230453491
Iteration 15: train_loss 1.1458300352096558
Iteration 16: train_loss 1.1900235414505005
Iteration 17: train_loss 1.1452839374542236
Iteration 18: train_loss 1.152254343032837
Iteration 19: train_loss 1.1056596040725708
Iteration 20: train_loss 1.186698317527771
Iteration 21: train_loss 1.1273589134216309
Iteration 22: train_loss 1.1834678649902344
Iteration 23: train_loss 1.2212567329406738
Iteration 24: train_loss 1.1952745914459229
Iteration 25: train_loss 1.2033356428146362
Iteration 26: train_loss 1.2152494192123413
Iteration 27: train_loss 1.2170330286026
Iteration 28: train_loss 1.1488244533538818
Iteration 29: train_loss 1.159586787223816
Iteration 30: train_loss 1.1845500469207764
Iteration 31: train_loss 1.1723237037658691
Iteration 32: train_loss 1.1839768886566162
Iteration 33: train_loss 1.1732527017593384
Iteration 34: train_loss 1.1755411624908447
Iteration 35: train_loss 1.1487990617752075
Iteration 36: train_loss 1.1478487253189087
Iteration 37: train_loss 1.1013485193252563
Iteration 38: train_loss 1.11385178565979
Iteration 39: train_loss 1.1221082210540771
Iteration 40: train_loss 1.0905267000198364
Iteration 41: train_loss 1.1720833778381348
Iteration 42: train_loss 1.1065412759780884
Iteration 43: train_loss 1.1637033224105835
Iteration 44: train_loss 1.1743652820587158
Iteration 45: train_loss 1.1777085065841675
Iteration 46: train_loss 1.1279922723770142
Iteration 47: train_loss 1.126708745956421
Iteration 48: train_loss 1.1850842237472534
Iteration 49: train_loss 1.1470247507095337
Iteration 50: train_loss 1.130902886390686
Iteration 51: train_loss 1.1467676162719727
Iteration 52: train_loss 1.1203738451004028
Iteration 53: train_loss 1.1079907417297363
Iteration 54: train_loss 1.2162833213806152
Iteration 55: train_loss 1.1850030422210693
Iteration 56: train_loss 1.1589301824569702
Iteration 57: train_loss 1.1893904209136963
Iteration 58: train_loss 1.2057561874389648
Iteration 59: train_loss 1.1688146591186523
Iteration 60: train_loss 1.1323597431182861
Iteration 61: train_loss 1.1171072721481323
Iteration 62: train_loss 1.159287691116333
Iteration 63: train_loss 1.1228538751602173
Iteration 64: train_loss 1.1655200719833374
Iteration 65: train_loss 1.1580065488815308
Iteration 66: train_loss 1.1500701904296875
Iteration 67: train_loss 1.169646143913269
Iteration 68: train_loss 1.125758409500122
Iteration 69: train_loss 1.1598936319351196
Iteration 70: train_loss 1.1590496301651
Iteration 71: train_loss 1.1626191139221191
Iteration 72: train_loss 1.217734932899475
Iteration 73: train_loss 1.1438493728637695
Iteration 74: train_loss 1.1967164278030396
Iteration 75: train_loss 1.1326473951339722
Iteration 76: train_loss 1.2403203248977661
Iteration 77: train_loss 1.1541078090667725
Iteration 78: train_loss 1.1324293613433838
Iteration 79: train_loss 1.155650019645691
Iteration 80: train_loss 1.1526416540145874
Iteration 81: train_loss 1.2115799188613892
Iteration 82: train_loss 1.1278830766677856
Iteration 83: train_loss 1.1977787017822266
Iteration 84: train_loss 1.1575531959533691
Iteration 85: train_loss 1.150641918182373
Iteration 86: train_loss 1.1753754615783691
Iteration 87: train_loss 1.178503394126892
Iteration 88: train_loss 1.1612368822097778
Iteration 89: train_loss 1.1385446786880493
Iteration 90: train_loss 1.196792483329773
Iteration 91: train_loss 1.136279821395874
Iteration 92: train_loss 1.160300612449646
Iteration 93: train_loss 1.2067241668701172
Iteration 94: train_loss 1.1452378034591675
Iteration 95: train_loss 1.1473889350891113
Iteration 96: train_loss 1.1777952909469604
Iteration 97: train_loss 1.1707611083984375
Iteration 98: train_loss 1.0551249980926514
Iteration 99: train_loss 1.1021164655685425
Iteration 100: train_loss 1.1962846517562866
Iteration 101: train_loss 1.1500494480133057
Iteration 102: train_loss 1.1103912591934204
Iteration 103: train_loss 1.1740550994873047
Iteration 104: train_loss 1.1348779201507568
Iteration 105: train_loss 1.114273190498352
Iteration 106: train_loss 1.12636399269104
Iteration 107: train_loss 1.1558679342269897
Iteration 108: train_loss 1.1304092407226562
Iteration 109: train_loss 1.1644389629364014
Iteration 110: train_loss 1.0962899923324585
Iteration 111: train_loss 1.1302282810211182
Iteration 112: train_loss 1.1889854669570923
Iteration 113: train_loss 1.1471638679504395
Iteration 114: train_loss 1.1590262651443481
Iteration 115: train_loss 1.181336522102356
Iteration 116: train_loss 1.1843966245651245
Iteration 117: train_loss 1.1282817125320435
Iteration 118: train_loss 1.1228755712509155
Iteration 119: train_loss 1.1302754878997803
Iteration 120: train_loss 1.1209176778793335
Iteration 121: train_loss 1.1250238418579102
Iteration 122: train_loss 1.1724284887313843
Iteration 123: train_loss 1.13998281955719
Iteration 124: train_loss 1.218369960784912
Iteration 125: train_loss 1.1754862070083618
Iteration 126: train_loss 1.1519514322280884
Iteration 127: train_loss 1.1627625226974487
Iteration 128: train_loss 1.1937625408172607
Iteration 129: train_loss 1.1603516340255737
Iteration 130: train_loss 1.167358636856079
Iteration 131: train_loss 1.164608359336853
Iteration 132: train_loss 1.1719924211502075
Iteration 133: train_loss 1.1590816974639893
Iteration 134: train_loss 1.1408196687698364
Iteration 135: train_loss 1.1958576440811157
Iteration 136: train_loss 1.238699197769165
Iteration 137: train_loss 1.226035475730896
Iteration 138: train_loss 1.152295708656311
Iteration 139: train_loss 1.1424535512924194
Iteration 140: train_loss 1.1717394590377808
Iteration 141: train_loss 1.1502569913864136
Iteration 142: train_loss 1.1545913219451904
Iteration 143: train_loss 1.1744717359542847
Iteration 144: train_loss 1.1367084980010986
Iteration 145: train_loss 1.1845483779907227
Iteration 146: train_loss 1.116266131401062
Iteration 147: train_loss 1.1492676734924316
Iteration 148: train_loss 1.1550848484039307
Iteration 149: train_loss 1.2463188171386719
Iteration 150: train_loss 1.1381007432937622
Iteration 151: train_loss 1.1118903160095215
Iteration 152: train_loss 1.0803266763687134
Iteration 153: train_loss 1.1668064594268799
Iteration 154: train_loss 1.132238507270813
Iteration 155: train_loss 1.154080867767334
Iteration 156: train_loss 1.1394213438034058
Iteration 157: train_loss 1.0941282510757446
Iteration 158: train_loss 1.0879082679748535
Iteration 159: train_loss 1.154715657234192
Iteration 160: train_loss 1.1679511070251465
Iteration 161: train_loss 1.176041841506958
Iteration 162: train_loss 1.1928287744522095
Iteration 163: train_loss 1.2558399438858032
Iteration 164: train_loss 1.2042241096496582
Iteration 165: train_loss 1.1706796884536743
Iteration 166: train_loss 1.157739281654358
Iteration 167: train_loss 1.1461071968078613
Iteration 168: train_loss 1.1660137176513672
Iteration 169: train_loss 1.1468228101730347
Iteration 170: train_loss 1.150669813156128
Iteration 171: train_loss 1.1633715629577637
Iteration 172: train_loss 1.153840184211731
Iteration 173: train_loss 1.1165218353271484
Iteration 174: train_loss 1.0952250957489014
Iteration 175: train_loss 1.1687947511672974
Iteration 176: train_loss 1.0838114023208618
Iteration 177: train_loss 1.1802518367767334
Epoch 176: train_avg_loss 1.1563500442073844 eval_avg_acc: 0.3439565564358047 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:46:20] [32mIntermediate result: 0.3439565564358047  (Index 175)[0m
================Epoch: 177================
Iteration 1: train_loss 1.1355520486831665
Iteration 2: train_loss 1.1186481714248657
Iteration 3: train_loss 1.0724678039550781
Iteration 4: train_loss 1.1007359027862549
Iteration 5: train_loss 1.1308172941207886
Iteration 6: train_loss 1.1581400632858276
Iteration 7: train_loss 1.212562084197998
Iteration 8: train_loss 1.1250059604644775
Iteration 9: train_loss 1.1327109336853027
Iteration 10: train_loss 1.1387773752212524
Iteration 11: train_loss 1.1541569232940674
Iteration 12: train_loss 1.1807142496109009
Iteration 13: train_loss 1.1263757944107056
Iteration 14: train_loss 1.0749297142028809
Iteration 15: train_loss 1.0925825834274292
Iteration 16: train_loss 1.1030246019363403
Iteration 17: train_loss 1.121269941329956
Iteration 18: train_loss 1.1176793575286865
Iteration 19: train_loss 1.1478897333145142
Iteration 20: train_loss 1.137942910194397
Iteration 21: train_loss 1.188795566558838
Iteration 22: train_loss 1.1330645084381104
Iteration 23: train_loss 1.187209963798523
Iteration 24: train_loss 1.1969871520996094
Iteration 25: train_loss 1.138796329498291
Iteration 26: train_loss 1.1826503276824951
Iteration 27: train_loss 1.1478536128997803
Iteration 28: train_loss 1.231089472770691
Iteration 29: train_loss 1.093689203262329
Iteration 30: train_loss 1.1697856187820435
Iteration 31: train_loss 1.1215674877166748
Iteration 32: train_loss 1.1928435564041138
Iteration 33: train_loss 1.1285138130187988
Iteration 34: train_loss 1.1693229675292969
Iteration 35: train_loss 1.087584137916565
Iteration 36: train_loss 1.1954368352890015
Iteration 37: train_loss 1.1333118677139282
Iteration 38: train_loss 1.099238634109497
Iteration 39: train_loss 1.1393886804580688
Iteration 40: train_loss 1.1448519229888916
Iteration 41: train_loss 1.1093480587005615
Iteration 42: train_loss 1.1418952941894531
Iteration 43: train_loss 1.1381491422653198
Iteration 44: train_loss 1.167980670928955
Iteration 45: train_loss 1.163055658340454
Iteration 46: train_loss 1.1916884183883667
Iteration 47: train_loss 1.090589165687561
Iteration 48: train_loss 1.1752790212631226
Iteration 49: train_loss 1.1021933555603027
Iteration 50: train_loss 1.1927775144577026
Iteration 51: train_loss 1.1535495519638062
Iteration 52: train_loss 1.2123957872390747
Iteration 53: train_loss 1.1982595920562744
Iteration 54: train_loss 1.187792420387268
Iteration 55: train_loss 1.201636552810669
Iteration 56: train_loss 1.181567907333374
Iteration 57: train_loss 1.2061142921447754
Iteration 58: train_loss 1.1991479396820068
Iteration 59: train_loss 1.1807595491409302
Iteration 60: train_loss 1.224778413772583
Iteration 61: train_loss 1.1290576457977295
Iteration 62: train_loss 1.1927924156188965
Iteration 63: train_loss 1.1590118408203125
Iteration 64: train_loss 1.1534240245819092
Iteration 65: train_loss 1.1521599292755127
Iteration 66: train_loss 1.192927598953247
Iteration 67: train_loss 1.2107270956039429
Iteration 68: train_loss 1.145603060722351
Iteration 69: train_loss 1.1505316495895386
Iteration 70: train_loss 1.1834936141967773
Iteration 71: train_loss 1.137161135673523
Iteration 72: train_loss 1.1240867376327515
Iteration 73: train_loss 1.1162974834442139
Iteration 74: train_loss 1.1784967184066772
Iteration 75: train_loss 1.1680153608322144
Iteration 76: train_loss 1.2184616327285767
Iteration 77: train_loss 1.2163060903549194
Iteration 78: train_loss 1.12691068649292
Iteration 79: train_loss 1.1382395029067993
Iteration 80: train_loss 1.1411393880844116
Iteration 81: train_loss 1.1491385698318481
Iteration 82: train_loss 1.1849963665008545
Iteration 83: train_loss 1.1216446161270142
Iteration 84: train_loss 1.1495745182037354
Iteration 85: train_loss 1.0931628942489624
Iteration 86: train_loss 1.0716121196746826
Iteration 87: train_loss 1.189958095550537
Iteration 88: train_loss 1.1336586475372314
Iteration 89: train_loss 1.1234837770462036
Iteration 90: train_loss 1.113118052482605
Iteration 91: train_loss 1.201634168624878
Iteration 92: train_loss 1.1768944263458252
Iteration 93: train_loss 1.1875077486038208
Iteration 94: train_loss 1.160578727722168
Iteration 95: train_loss 1.1417418718338013
Iteration 96: train_loss 1.1683648824691772
Iteration 97: train_loss 1.1321698427200317
Iteration 98: train_loss 1.1437581777572632
Iteration 99: train_loss 1.1464104652404785
Iteration 100: train_loss 1.156677484512329
Iteration 101: train_loss 1.1567405462265015
Iteration 102: train_loss 1.161057710647583
Iteration 103: train_loss 1.1206235885620117
Iteration 104: train_loss 1.073159098625183
Iteration 105: train_loss 1.1657521724700928
Iteration 106: train_loss 1.164210557937622
Iteration 107: train_loss 1.1501868963241577
Iteration 108: train_loss 1.158063530921936
Iteration 109: train_loss 1.150053858757019
Iteration 110: train_loss 1.2238759994506836
Iteration 111: train_loss 1.16130793094635
Iteration 112: train_loss 1.1391993761062622
Iteration 113: train_loss 1.1811715364456177
Iteration 114: train_loss 1.286637306213379
Iteration 115: train_loss 1.2417142391204834
Iteration 116: train_loss 1.1598886251449585
Iteration 117: train_loss 1.1378800868988037
Iteration 118: train_loss 1.202208161354065
Iteration 119: train_loss 1.206940770149231
Iteration 120: train_loss 1.1665409803390503
Iteration 121: train_loss 1.1872855424880981
Iteration 122: train_loss 1.1501373052597046
Iteration 123: train_loss 1.1507359743118286
Iteration 124: train_loss 1.1756165027618408
Iteration 125: train_loss 1.129645824432373
Iteration 126: train_loss 1.1462280750274658
Iteration 127: train_loss 1.122514009475708
Iteration 128: train_loss 1.16558837890625
Iteration 129: train_loss 1.1003293991088867
Iteration 130: train_loss 1.1260226964950562
Iteration 131: train_loss 1.1193021535873413
Iteration 132: train_loss 1.1343094110488892
Iteration 133: train_loss 1.1367483139038086
Iteration 134: train_loss 1.1187373399734497
Iteration 135: train_loss 1.1625306606292725
Iteration 136: train_loss 1.154036283493042
Iteration 137: train_loss 1.1422228813171387
Iteration 138: train_loss 1.1633548736572266
Iteration 139: train_loss 1.1046432256698608
Iteration 140: train_loss 1.1215908527374268
Iteration 141: train_loss 1.1342216730117798
Iteration 142: train_loss 1.1804454326629639
Iteration 143: train_loss 1.218613624572754
Iteration 144: train_loss 1.0780025720596313
Iteration 145: train_loss 1.103381633758545
Iteration 146: train_loss 1.155251145362854
Iteration 147: train_loss 1.1395902633666992
Iteration 148: train_loss 1.19487726688385
Iteration 149: train_loss 1.148374080657959
Iteration 150: train_loss 1.1667476892471313
Iteration 151: train_loss 1.0863806009292603
Iteration 152: train_loss 1.0981677770614624
Iteration 153: train_loss 1.1037317514419556
Iteration 154: train_loss 1.1363317966461182
Iteration 155: train_loss 1.1849913597106934
Iteration 156: train_loss 1.1091738939285278
Iteration 157: train_loss 1.1367357969284058
Iteration 158: train_loss 1.1350291967391968
Iteration 159: train_loss 1.136472225189209
Iteration 160: train_loss 1.1498688459396362
Iteration 161: train_loss 1.1796358823776245
Iteration 162: train_loss 1.1643441915512085
Iteration 163: train_loss 1.0955456495285034
Iteration 164: train_loss 1.135335087776184
Iteration 165: train_loss 1.186222791671753
Iteration 166: train_loss 1.128783106803894
Iteration 167: train_loss 1.1332738399505615
Iteration 168: train_loss 1.1741167306900024
Iteration 169: train_loss 1.1875731945037842
Iteration 170: train_loss 1.2012646198272705
Iteration 171: train_loss 1.1410880088806152
Iteration 172: train_loss 1.1372779607772827
Iteration 173: train_loss 1.114046573638916
Iteration 174: train_loss 1.1372926235198975
Iteration 175: train_loss 1.1890023946762085
Iteration 176: train_loss 1.1400502920150757
Iteration 177: train_loss 1.127251148223877
Epoch 177: train_avg_loss 1.1517013439350883 eval_avg_acc: 0.3470048256684917 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:47:03] [32mIntermediate result: 0.3470048256684917  (Index 176)[0m
================Epoch: 178================
Iteration 1: train_loss 1.1943144798278809
Iteration 2: train_loss 1.1428838968276978
Iteration 3: train_loss 1.1738526821136475
Iteration 4: train_loss 1.0984097719192505
Iteration 5: train_loss 1.168906569480896
Iteration 6: train_loss 1.191427230834961
Iteration 7: train_loss 1.0794806480407715
Iteration 8: train_loss 1.1476421356201172
Iteration 9: train_loss 1.0868619680404663
Iteration 10: train_loss 1.164001226425171
Iteration 11: train_loss 1.1418378353118896
Iteration 12: train_loss 1.1425784826278687
Iteration 13: train_loss 1.100569248199463
Iteration 14: train_loss 1.1652668714523315
Iteration 15: train_loss 1.1597005128860474
Iteration 16: train_loss 1.1630816459655762
Iteration 17: train_loss 1.1732827425003052
Iteration 18: train_loss 1.1532173156738281
Iteration 19: train_loss 1.2414333820343018
Iteration 20: train_loss 1.2021818161010742
Iteration 21: train_loss 1.1492657661437988
Iteration 22: train_loss 1.158464789390564
Iteration 23: train_loss 1.1188781261444092
Iteration 24: train_loss 1.1788432598114014
Iteration 25: train_loss 1.2195851802825928
Iteration 26: train_loss 1.1320679187774658
Iteration 27: train_loss 1.130500078201294
Iteration 28: train_loss 1.1670939922332764
Iteration 29: train_loss 1.177627444267273
Iteration 30: train_loss 1.1833349466323853
Iteration 31: train_loss 1.1411839723587036
Iteration 32: train_loss 1.1171090602874756
Iteration 33: train_loss 1.152133584022522
Iteration 34: train_loss 1.1341619491577148
Iteration 35: train_loss 1.120243787765503
Iteration 36: train_loss 1.149333119392395
Iteration 37: train_loss 1.2320618629455566
Iteration 38: train_loss 1.1664879322052002
Iteration 39: train_loss 1.1734639406204224
Iteration 40: train_loss 1.1339812278747559
Iteration 41: train_loss 1.215151071548462
Iteration 42: train_loss 1.1839672327041626
Iteration 43: train_loss 1.1435027122497559
Iteration 44: train_loss 1.1402939558029175
Iteration 45: train_loss 1.1710454225540161
Iteration 46: train_loss 1.123145580291748
Iteration 47: train_loss 1.1429436206817627
Iteration 48: train_loss 1.1106371879577637
Iteration 49: train_loss 1.1773805618286133
Iteration 50: train_loss 1.1929618120193481
Iteration 51: train_loss 1.1275821924209595
Iteration 52: train_loss 1.1539530754089355
Iteration 53: train_loss 1.1725469827651978
Iteration 54: train_loss 1.1372828483581543
Iteration 55: train_loss 1.1891988515853882
Iteration 56: train_loss 1.121060848236084
Iteration 57: train_loss 1.1613916158676147
Iteration 58: train_loss 1.166198968887329
Iteration 59: train_loss 1.169511079788208
Iteration 60: train_loss 1.1590776443481445
Iteration 61: train_loss 1.1178832054138184
Iteration 62: train_loss 1.1282480955123901
Iteration 63: train_loss 1.1822922229766846
Iteration 64: train_loss 1.1328518390655518
Iteration 65: train_loss 1.130631685256958
Iteration 66: train_loss 1.164589524269104
Iteration 67: train_loss 1.1408432722091675
Iteration 68: train_loss 1.13377046585083
Iteration 69: train_loss 1.0882763862609863
Iteration 70: train_loss 1.1096720695495605
Iteration 71: train_loss 1.1292232275009155
Iteration 72: train_loss 1.1512058973312378
Iteration 73: train_loss 1.1465332508087158
Iteration 74: train_loss 1.1363590955734253
Iteration 75: train_loss 1.0984563827514648
Iteration 76: train_loss 1.1319385766983032
Iteration 77: train_loss 1.234912633895874
Iteration 78: train_loss 1.1290130615234375
Iteration 79: train_loss 1.1458287239074707
Iteration 80: train_loss 1.1449049711227417
Iteration 81: train_loss 1.1457748413085938
Iteration 82: train_loss 1.1636555194854736
Iteration 83: train_loss 1.1183828115463257
Iteration 84: train_loss 1.1753551959991455
Iteration 85: train_loss 1.1438747644424438
Iteration 86: train_loss 1.1223307847976685
Iteration 87: train_loss 1.1451386213302612
Iteration 88: train_loss 1.1461660861968994
Iteration 89: train_loss 1.1683993339538574
Iteration 90: train_loss 1.191460132598877
Iteration 91: train_loss 1.208221673965454
Iteration 92: train_loss 1.1576781272888184
Iteration 93: train_loss 1.1379364728927612
Iteration 94: train_loss 1.1306830644607544
Iteration 95: train_loss 1.1446609497070312
Iteration 96: train_loss 1.181282877922058
Iteration 97: train_loss 1.132532000541687
Iteration 98: train_loss 1.1747246980667114
Iteration 99: train_loss 1.1817635297775269
Iteration 100: train_loss 1.1306790113449097
Iteration 101: train_loss 1.0717535018920898
Iteration 102: train_loss 1.1428347826004028
Iteration 103: train_loss 1.130963683128357
Iteration 104: train_loss 1.162510871887207
Iteration 105: train_loss 1.1788280010223389
Iteration 106: train_loss 1.1802047491073608
Iteration 107: train_loss 1.165616512298584
Iteration 108: train_loss 1.2286827564239502
Iteration 109: train_loss 1.195021390914917
Iteration 110: train_loss 1.150710105895996
Iteration 111: train_loss 1.1720354557037354
Iteration 112: train_loss 1.131447434425354
Iteration 113: train_loss 1.148044228553772
Iteration 114: train_loss 1.1703355312347412
Iteration 115: train_loss 1.1946830749511719
Iteration 116: train_loss 1.1670143604278564
Iteration 117: train_loss 1.1223299503326416
Iteration 118: train_loss 1.0986601114273071
Iteration 119: train_loss 1.1451795101165771
Iteration 120: train_loss 1.1324050426483154
Iteration 121: train_loss 1.1442064046859741
Iteration 122: train_loss 1.2147749662399292
Iteration 123: train_loss 1.2226548194885254
Iteration 124: train_loss 1.1671525239944458
Iteration 125: train_loss 1.1679598093032837
Iteration 126: train_loss 1.158629298210144
Iteration 127: train_loss 1.2056503295898438
Iteration 128: train_loss 1.1956619024276733
Iteration 129: train_loss 1.150304913520813
Iteration 130: train_loss 1.1490299701690674
Iteration 131: train_loss 1.156999111175537
Iteration 132: train_loss 1.1817772388458252
Iteration 133: train_loss 1.1376560926437378
Iteration 134: train_loss 1.1510024070739746
Iteration 135: train_loss 1.1507433652877808
Iteration 136: train_loss 1.1517002582550049
Iteration 137: train_loss 1.1570549011230469
Iteration 138: train_loss 1.1548105478286743
Iteration 139: train_loss 1.1364940404891968
Iteration 140: train_loss 1.124842643737793
Iteration 141: train_loss 1.2116509675979614
Iteration 142: train_loss 1.2515294551849365
Iteration 143: train_loss 1.1444333791732788
Iteration 144: train_loss 1.1343780755996704
Iteration 145: train_loss 1.1698330640792847
Iteration 146: train_loss 1.171228051185608
Iteration 147: train_loss 1.1280465126037598
Iteration 148: train_loss 1.1160917282104492
Iteration 149: train_loss 1.1514067649841309
Iteration 150: train_loss 1.151650309562683
Iteration 151: train_loss 1.1671984195709229
Iteration 152: train_loss 1.1255463361740112
Iteration 153: train_loss 1.1774290800094604
Iteration 154: train_loss 1.1509450674057007
Iteration 155: train_loss 1.187111258506775
Iteration 156: train_loss 1.0877341032028198
Iteration 157: train_loss 1.1404540538787842
Iteration 158: train_loss 1.1924976110458374
Iteration 159: train_loss 1.1777466535568237
Iteration 160: train_loss 1.123868465423584
Iteration 161: train_loss 1.1145291328430176
Iteration 162: train_loss 1.1660133600234985
Iteration 163: train_loss 1.0928813219070435
Iteration 164: train_loss 1.2062643766403198
Iteration 165: train_loss 1.1040699481964111
Iteration 166: train_loss 1.1468805074691772
Iteration 167: train_loss 1.1171036958694458
Iteration 168: train_loss 1.1815892457962036
Iteration 169: train_loss 1.0722723007202148
Iteration 170: train_loss 1.1033185720443726
Iteration 171: train_loss 1.1449248790740967
Iteration 172: train_loss 1.1031591892242432
Iteration 173: train_loss 1.2046306133270264
Iteration 174: train_loss 1.1430917978286743
Iteration 175: train_loss 1.140302062034607
Iteration 176: train_loss 1.1251707077026367
Iteration 177: train_loss 1.190656065940857
Epoch 178: train_avg_loss 1.1533882739180226 eval_avg_acc: 0.3465781672855163 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:47:45] [32mIntermediate result: 0.3465781672855163  (Index 177)[0m
================Epoch: 179================
Iteration 1: train_loss 1.1470564603805542
Iteration 2: train_loss 1.1707448959350586
Iteration 3: train_loss 1.1719602346420288
Iteration 4: train_loss 1.1310378313064575
Iteration 5: train_loss 1.1471055746078491
Iteration 6: train_loss 1.188108205795288
Iteration 7: train_loss 1.1488523483276367
Iteration 8: train_loss 1.1216398477554321
Iteration 9: train_loss 1.1424674987792969
Iteration 10: train_loss 1.0982720851898193
Iteration 11: train_loss 1.1224826574325562
Iteration 12: train_loss 1.1460272073745728
Iteration 13: train_loss 1.1201368570327759
Iteration 14: train_loss 1.1683210134506226
Iteration 15: train_loss 1.1211506128311157
Iteration 16: train_loss 1.1230432987213135
Iteration 17: train_loss 1.1758695840835571
Iteration 18: train_loss 1.0947214365005493
Iteration 19: train_loss 1.1057618856430054
Iteration 20: train_loss 1.1086026430130005
Iteration 21: train_loss 1.1209412813186646
Iteration 22: train_loss 1.1063164472579956
Iteration 23: train_loss 1.1174064874649048
Iteration 24: train_loss 1.1401580572128296
Iteration 25: train_loss 1.137878656387329
Iteration 26: train_loss 1.1087708473205566
Iteration 27: train_loss 1.0854579210281372
Iteration 28: train_loss 1.1222093105316162
Iteration 29: train_loss 1.153020977973938
Iteration 30: train_loss 1.1470303535461426
Iteration 31: train_loss 1.0907843112945557
Iteration 32: train_loss 1.1016870737075806
Iteration 33: train_loss 1.1114354133605957
Iteration 34: train_loss 1.094963788986206
Iteration 35: train_loss 1.115687608718872
Iteration 36: train_loss 1.1125191450119019
Iteration 37: train_loss 1.1460044384002686
Iteration 38: train_loss 1.1055607795715332
Iteration 39: train_loss 1.1080862283706665
Iteration 40: train_loss 1.1333582401275635
Iteration 41: train_loss 1.125993013381958
Iteration 42: train_loss 1.1492252349853516
Iteration 43: train_loss 1.1479512453079224
Iteration 44: train_loss 1.1135692596435547
Iteration 45: train_loss 1.2064690589904785
Iteration 46: train_loss 1.1348429918289185
Iteration 47: train_loss 1.1128175258636475
Iteration 48: train_loss 1.1493254899978638
Iteration 49: train_loss 1.1421067714691162
Iteration 50: train_loss 1.154250144958496
Iteration 51: train_loss 1.1368104219436646
Iteration 52: train_loss 1.1069504022598267
Iteration 53: train_loss 1.154992699623108
Iteration 54: train_loss 1.1164747476577759
Iteration 55: train_loss 1.116685390472412
Iteration 56: train_loss 1.2040070295333862
Iteration 57: train_loss 1.1954091787338257
Iteration 58: train_loss 1.1133582592010498
Iteration 59: train_loss 1.2003647089004517
Iteration 60: train_loss 1.1202309131622314
Iteration 61: train_loss 1.1674443483352661
Iteration 62: train_loss 1.12950599193573
Iteration 63: train_loss 1.1368639469146729
Iteration 64: train_loss 1.1498321294784546
Iteration 65: train_loss 1.1906648874282837
Iteration 66: train_loss 1.1514872312545776
Iteration 67: train_loss 1.113311767578125
Iteration 68: train_loss 1.1130479574203491
Iteration 69: train_loss 1.2390187978744507
Iteration 70: train_loss 1.1830612421035767
Iteration 71: train_loss 1.1382004022598267
Iteration 72: train_loss 1.172783613204956
Iteration 73: train_loss 1.1388605833053589
Iteration 74: train_loss 1.1258056163787842
Iteration 75: train_loss 1.2196567058563232
Iteration 76: train_loss 1.1934927701950073
Iteration 77: train_loss 1.1629809141159058
Iteration 78: train_loss 1.1967135667800903
Iteration 79: train_loss 1.1391494274139404
Iteration 80: train_loss 1.189934492111206
Iteration 81: train_loss 1.184496283531189
Iteration 82: train_loss 1.2150342464447021
Iteration 83: train_loss 1.1896055936813354
Iteration 84: train_loss 1.1753604412078857
Iteration 85: train_loss 1.203357219696045
Iteration 86: train_loss 1.193973183631897
Iteration 87: train_loss 1.143858790397644
Iteration 88: train_loss 1.088818907737732
Iteration 89: train_loss 1.1598962545394897
Iteration 90: train_loss 1.1972659826278687
Iteration 91: train_loss 1.173907995223999
Iteration 92: train_loss 1.1753792762756348
Iteration 93: train_loss 1.2114421129226685
Iteration 94: train_loss 1.1536728143692017
Iteration 95: train_loss 1.1493362188339233
Iteration 96: train_loss 1.1360399723052979
Iteration 97: train_loss 1.2052545547485352
Iteration 98: train_loss 1.2154098749160767
Iteration 99: train_loss 1.1579252481460571
Iteration 100: train_loss 1.1437077522277832
Iteration 101: train_loss 1.1798968315124512
Iteration 102: train_loss 1.1292203664779663
Iteration 103: train_loss 1.1553328037261963
Iteration 104: train_loss 1.1960575580596924
Iteration 105: train_loss 1.2066583633422852
Iteration 106: train_loss 1.166336178779602
Iteration 107: train_loss 1.2415372133255005
Iteration 108: train_loss 1.1576677560806274
Iteration 109: train_loss 1.1047614812850952
Iteration 110: train_loss 1.1362444162368774
Iteration 111: train_loss 1.1683295965194702
Iteration 112: train_loss 1.1166741847991943
Iteration 113: train_loss 1.0936055183410645
Iteration 114: train_loss 1.1082661151885986
Iteration 115: train_loss 1.1565251350402832
Iteration 116: train_loss 1.1711081266403198
Iteration 117: train_loss 1.127575159072876
Iteration 118: train_loss 1.1038113832473755
Iteration 119: train_loss 1.1948257684707642
Iteration 120: train_loss 1.1693984270095825
Iteration 121: train_loss 1.214635968208313
Iteration 122: train_loss 1.1187998056411743
Iteration 123: train_loss 1.2152268886566162
Iteration 124: train_loss 1.2166136503219604
Iteration 125: train_loss 1.1335417032241821
Iteration 126: train_loss 1.1325287818908691
Iteration 127: train_loss 1.133907675743103
Iteration 128: train_loss 1.1810134649276733
Iteration 129: train_loss 1.1062995195388794
Iteration 130: train_loss 1.1753796339035034
Iteration 131: train_loss 1.167883276939392
Iteration 132: train_loss 1.131630778312683
Iteration 133: train_loss 1.21153724193573
Iteration 134: train_loss 1.0941078662872314
Iteration 135: train_loss 1.121734619140625
Iteration 136: train_loss 1.1874103546142578
Iteration 137: train_loss 1.1869769096374512
Iteration 138: train_loss 1.2002410888671875
Iteration 139: train_loss 1.1063634157180786
Iteration 140: train_loss 1.1675148010253906
Iteration 141: train_loss 1.142421007156372
Iteration 142: train_loss 1.1111738681793213
Iteration 143: train_loss 1.16850745677948
Iteration 144: train_loss 1.1390941143035889
Iteration 145: train_loss 1.2270680665969849
Iteration 146: train_loss 1.0803236961364746
Iteration 147: train_loss 1.148643970489502
Iteration 148: train_loss 1.141351580619812
Iteration 149: train_loss 1.0986295938491821
Iteration 150: train_loss 1.1092901229858398
Iteration 151: train_loss 1.1492431163787842
Iteration 152: train_loss 1.1393940448760986
Iteration 153: train_loss 1.1065953969955444
Iteration 154: train_loss 1.1958587169647217
Iteration 155: train_loss 1.0679339170455933
Iteration 156: train_loss 1.1158497333526611
Iteration 157: train_loss 1.0977582931518555
Iteration 158: train_loss 1.1342220306396484
Iteration 159: train_loss 1.1354098320007324
Iteration 160: train_loss 1.1149449348449707
Iteration 161: train_loss 1.1574753522872925
Iteration 162: train_loss 1.1435540914535522
Iteration 163: train_loss 1.1716649532318115
Iteration 164: train_loss 1.1621930599212646
Iteration 165: train_loss 1.1423091888427734
Iteration 166: train_loss 1.1183491945266724
Iteration 167: train_loss 1.17316472530365
Iteration 168: train_loss 1.2366279363632202
Iteration 169: train_loss 1.2053896188735962
Iteration 170: train_loss 1.1646068096160889
Iteration 171: train_loss 1.1794567108154297
Iteration 172: train_loss 1.203870415687561
Iteration 173: train_loss 1.1068787574768066
Iteration 174: train_loss 1.1907165050506592
Iteration 175: train_loss 1.1786303520202637
Iteration 176: train_loss 1.1616926193237305
Iteration 177: train_loss 1.1884822845458984
Epoch 179: train_avg_loss 1.1499208420683436 eval_avg_acc: 0.34599689305766573 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:48:27] [32mIntermediate result: 0.34599689305766573  (Index 178)[0m
================Epoch: 180================
Iteration 1: train_loss 1.105931282043457
Iteration 2: train_loss 1.105399250984192
Iteration 3: train_loss 1.1651076078414917
Iteration 4: train_loss 1.1857088804244995
Iteration 5: train_loss 1.1138836145401
Iteration 6: train_loss 1.1810256242752075
Iteration 7: train_loss 1.1357080936431885
Iteration 8: train_loss 1.1572006940841675
Iteration 9: train_loss 1.1275352239608765
Iteration 10: train_loss 1.135785460472107
Iteration 11: train_loss 1.178146243095398
Iteration 12: train_loss 1.1376352310180664
Iteration 13: train_loss 1.1122316122055054
Iteration 14: train_loss 1.1273354291915894
Iteration 15: train_loss 1.1126470565795898
Iteration 16: train_loss 1.1312466859817505
Iteration 17: train_loss 1.141969084739685
Iteration 18: train_loss 1.1456748247146606
Iteration 19: train_loss 1.1229839324951172
Iteration 20: train_loss 1.1507482528686523
Iteration 21: train_loss 1.1995127201080322
Iteration 22: train_loss 1.1676875352859497
Iteration 23: train_loss 1.113768219947815
Iteration 24: train_loss 1.153749942779541
Iteration 25: train_loss 1.1457058191299438
Iteration 26: train_loss 1.1560611724853516
Iteration 27: train_loss 1.1459382772445679
Iteration 28: train_loss 1.1666970252990723
Iteration 29: train_loss 1.1450133323669434
Iteration 30: train_loss 1.1400686502456665
Iteration 31: train_loss 1.1135931015014648
Iteration 32: train_loss 1.1251029968261719
Iteration 33: train_loss 1.1504206657409668
Iteration 34: train_loss 1.1083664894104004
Iteration 35: train_loss 1.1108089685440063
Iteration 36: train_loss 1.1565592288970947
Iteration 37: train_loss 1.0996415615081787
Iteration 38: train_loss 1.135376214981079
Iteration 39: train_loss 1.1166471242904663
Iteration 40: train_loss 1.0962787866592407
Iteration 41: train_loss 1.1336748600006104
Iteration 42: train_loss 1.1471681594848633
Iteration 43: train_loss 1.1417683362960815
Iteration 44: train_loss 1.1477171182632446
Iteration 45: train_loss 1.119185209274292
Iteration 46: train_loss 1.1090840101242065
Iteration 47: train_loss 1.2004973888397217
Iteration 48: train_loss 1.2017238140106201
Iteration 49: train_loss 1.1297022104263306
Iteration 50: train_loss 1.0820637941360474
Iteration 51: train_loss 1.1670448780059814
Iteration 52: train_loss 1.1591823101043701
Iteration 53: train_loss 1.1406477689743042
Iteration 54: train_loss 1.0988823175430298
Iteration 55: train_loss 1.1309138536453247
Iteration 56: train_loss 1.1180566549301147
Iteration 57: train_loss 1.0816296339035034
Iteration 58: train_loss 1.1694800853729248
Iteration 59: train_loss 1.1667792797088623
Iteration 60: train_loss 1.1127309799194336
Iteration 61: train_loss 1.0828287601470947
Iteration 62: train_loss 1.121638298034668
Iteration 63: train_loss 1.14625084400177
Iteration 64: train_loss 1.1260969638824463
Iteration 65: train_loss 1.1374311447143555
Iteration 66: train_loss 1.1426901817321777
Iteration 67: train_loss 1.1210651397705078
Iteration 68: train_loss 1.133309245109558
Iteration 69: train_loss 1.1424986124038696
Iteration 70: train_loss 1.1251250505447388
Iteration 71: train_loss 1.0934269428253174
Iteration 72: train_loss 1.1598401069641113
Iteration 73: train_loss 1.112898349761963
Iteration 74: train_loss 1.117274522781372
Iteration 75: train_loss 1.1425838470458984
Iteration 76: train_loss 1.077831745147705
Iteration 77: train_loss 1.1078251600265503
Iteration 78: train_loss 1.161106824874878
Iteration 79: train_loss 1.1472121477127075
Iteration 80: train_loss 1.1721757650375366
Iteration 81: train_loss 1.1163054704666138
Iteration 82: train_loss 1.1352537870407104
Iteration 83: train_loss 1.145705223083496
Iteration 84: train_loss 1.1369000673294067
Iteration 85: train_loss 1.160783052444458
Iteration 86: train_loss 1.129534125328064
Iteration 87: train_loss 1.1825329065322876
Iteration 88: train_loss 1.1638236045837402
Iteration 89: train_loss 1.1279432773590088
Iteration 90: train_loss 1.086285948753357
Iteration 91: train_loss 1.1316179037094116
Iteration 92: train_loss 1.1418973207473755
Iteration 93: train_loss 1.1740468740463257
Iteration 94: train_loss 1.1391493082046509
Iteration 95: train_loss 1.117829442024231
Iteration 96: train_loss 1.125808596611023
Iteration 97: train_loss 1.2140321731567383
Iteration 98: train_loss 1.1911273002624512
Iteration 99: train_loss 1.1502635478973389
Iteration 100: train_loss 1.180720567703247
Iteration 101: train_loss 1.1682226657867432
Iteration 102: train_loss 1.128172755241394
Iteration 103: train_loss 1.1351827383041382
Iteration 104: train_loss 1.1927517652511597
Iteration 105: train_loss 1.1984237432479858
Iteration 106: train_loss 1.1522400379180908
Iteration 107: train_loss 1.1087969541549683
Iteration 108: train_loss 1.151402473449707
Iteration 109: train_loss 1.1048202514648438
Iteration 110: train_loss 1.2087522745132446
Iteration 111: train_loss 1.196352481842041
Iteration 112: train_loss 1.2140450477600098
Iteration 113: train_loss 1.127476692199707
Iteration 114: train_loss 1.2002040147781372
Iteration 115: train_loss 1.1704059839248657
Iteration 116: train_loss 1.1161895990371704
Iteration 117: train_loss 1.1413754224777222
Iteration 118: train_loss 1.106390357017517
Iteration 119: train_loss 1.1588590145111084
Iteration 120: train_loss 1.1777962446212769
Iteration 121: train_loss 1.1968564987182617
Iteration 122: train_loss 1.2004832029342651
Iteration 123: train_loss 1.118674635887146
Iteration 124: train_loss 1.151305913925171
Iteration 125: train_loss 1.1567362546920776
Iteration 126: train_loss 1.1512044668197632
Iteration 127: train_loss 1.1199735403060913
Iteration 128: train_loss 1.152627944946289
Iteration 129: train_loss 1.1584018468856812
Iteration 130: train_loss 1.1366890668869019
Iteration 131: train_loss 1.1849958896636963
Iteration 132: train_loss 1.1852986812591553
Iteration 133: train_loss 1.123094081878662
Iteration 134: train_loss 1.1596438884735107
Iteration 135: train_loss 1.1150256395339966
Iteration 136: train_loss 1.115486979484558
Iteration 137: train_loss 1.1586893796920776
Iteration 138: train_loss 1.1737326383590698
Iteration 139: train_loss 1.2018245458602905
Iteration 140: train_loss 1.1239982843399048
Iteration 141: train_loss 1.1813303232192993
Iteration 142: train_loss 1.1406315565109253
Iteration 143: train_loss 1.142251968383789
Iteration 144: train_loss 1.1389219760894775
Iteration 145: train_loss 1.2276902198791504
Iteration 146: train_loss 1.1733015775680542
Iteration 147: train_loss 1.1709599494934082
Iteration 148: train_loss 1.1966875791549683
Iteration 149: train_loss 1.1420912742614746
Iteration 150: train_loss 1.2393734455108643
Iteration 151: train_loss 1.1747026443481445
Iteration 152: train_loss 1.1575169563293457
Iteration 153: train_loss 1.1810364723205566
Iteration 154: train_loss 1.1554654836654663
Iteration 155: train_loss 1.168211817741394
Iteration 156: train_loss 1.1547044515609741
Iteration 157: train_loss 1.217604160308838
Iteration 158: train_loss 1.1608997583389282
Iteration 159: train_loss 1.1751422882080078
Iteration 160: train_loss 1.1938868761062622
Iteration 161: train_loss 1.1376006603240967
Iteration 162: train_loss 1.1260604858398438
Iteration 163: train_loss 1.167102575302124
Iteration 164: train_loss 1.1512364149093628
Iteration 165: train_loss 1.1144535541534424
Iteration 166: train_loss 1.127769112586975
Iteration 167: train_loss 1.1201554536819458
Iteration 168: train_loss 1.0461751222610474
Iteration 169: train_loss 1.167726993560791
Iteration 170: train_loss 1.1692861318588257
Iteration 171: train_loss 1.0575273036956787
Iteration 172: train_loss 1.1699601411819458
Iteration 173: train_loss 1.157572627067566
Iteration 174: train_loss 1.1484711170196533
Iteration 175: train_loss 1.1604728698730469
Iteration 176: train_loss 1.1715631484985352
Iteration 177: train_loss 1.178745985031128
Epoch 180: train_avg_loss 1.1463751361868475 eval_avg_acc: 0.34180459205278213 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:49:09] [32mIntermediate result: 0.34180459205278213  (Index 179)[0m
================Epoch: 181================
Iteration 1: train_loss 1.15645432472229
Iteration 2: train_loss 1.1769906282424927
Iteration 3: train_loss 1.1662769317626953
Iteration 4: train_loss 1.1543653011322021
Iteration 5: train_loss 1.1243410110473633
Iteration 6: train_loss 1.2286427021026611
Iteration 7: train_loss 1.1816033124923706
Iteration 8: train_loss 1.1801888942718506
Iteration 9: train_loss 1.1803303956985474
Iteration 10: train_loss 1.1218996047973633
Iteration 11: train_loss 1.139086365699768
Iteration 12: train_loss 1.14713716506958
Iteration 13: train_loss 1.1486464738845825
Iteration 14: train_loss 1.1565345525741577
Iteration 15: train_loss 1.2206590175628662
Iteration 16: train_loss 1.2040257453918457
Iteration 17: train_loss 1.1350120306015015
Iteration 18: train_loss 1.129766821861267
Iteration 19: train_loss 1.1264506578445435
Iteration 20: train_loss 1.23643958568573
Iteration 21: train_loss 1.1696213483810425
Iteration 22: train_loss 1.1417121887207031
Iteration 23: train_loss 1.151209831237793
Iteration 24: train_loss 1.168925166130066
Iteration 25: train_loss 1.2236109972000122
Iteration 26: train_loss 1.1845823526382446
Iteration 27: train_loss 1.1343473196029663
Iteration 28: train_loss 1.1699436902999878
Iteration 29: train_loss 1.0964477062225342
Iteration 30: train_loss 1.1644028425216675
Iteration 31: train_loss 1.1433604955673218
Iteration 32: train_loss 1.1293041706085205
Iteration 33: train_loss 1.1565134525299072
Iteration 34: train_loss 1.120598554611206
Iteration 35: train_loss 1.2026152610778809
Iteration 36: train_loss 1.1323412656784058
Iteration 37: train_loss 1.1160378456115723
Iteration 38: train_loss 1.1838436126708984
Iteration 39: train_loss 1.1383048295974731
Iteration 40: train_loss 1.0979771614074707
Iteration 41: train_loss 1.1198523044586182
Iteration 42: train_loss 1.154816746711731
Iteration 43: train_loss 1.1269023418426514
Iteration 44: train_loss 1.1603975296020508
Iteration 45: train_loss 1.1626430749893188
Iteration 46: train_loss 1.173797845840454
Iteration 47: train_loss 1.1592199802398682
Iteration 48: train_loss 1.21836519241333
Iteration 49: train_loss 1.209989309310913
Iteration 50: train_loss 1.1129132509231567
Iteration 51: train_loss 1.1777245998382568
Iteration 52: train_loss 1.1687229871749878
Iteration 53: train_loss 1.1163502931594849
Iteration 54: train_loss 1.1577051877975464
Iteration 55: train_loss 1.138511300086975
Iteration 56: train_loss 1.0984185934066772
Iteration 57: train_loss 1.1798443794250488
Iteration 58: train_loss 1.0826481580734253
Iteration 59: train_loss 1.1258478164672852
Iteration 60: train_loss 1.1772675514221191
Iteration 61: train_loss 1.1882508993148804
Iteration 62: train_loss 1.1955738067626953
Iteration 63: train_loss 1.2097822427749634
Iteration 64: train_loss 1.1657477617263794
Iteration 65: train_loss 1.228999376296997
Iteration 66: train_loss 1.1351394653320312
Iteration 67: train_loss 1.214145302772522
Iteration 68: train_loss 1.177962303161621
Iteration 69: train_loss 1.165924310684204
Iteration 70: train_loss 1.2111760377883911
Iteration 71: train_loss 1.1436680555343628
Iteration 72: train_loss 1.1954554319381714
Iteration 73: train_loss 1.1606487035751343
Iteration 74: train_loss 1.154972791671753
Iteration 75: train_loss 1.1508259773254395
Iteration 76: train_loss 1.150835394859314
Iteration 77: train_loss 1.1509939432144165
Iteration 78: train_loss 1.1468729972839355
Iteration 79: train_loss 1.1210558414459229
Iteration 80: train_loss 1.1723384857177734
Iteration 81: train_loss 1.235499382019043
Iteration 82: train_loss 1.2305322885513306
Iteration 83: train_loss 1.1046087741851807
Iteration 84: train_loss 1.1748899221420288
Iteration 85: train_loss 1.137856364250183
Iteration 86: train_loss 1.1589187383651733
Iteration 87: train_loss 1.1801745891571045
Iteration 88: train_loss 1.2160272598266602
Iteration 89: train_loss 1.1277097463607788
Iteration 90: train_loss 1.1635576486587524
Iteration 91: train_loss 1.1548783779144287
Iteration 92: train_loss 1.138476848602295
Iteration 93: train_loss 1.13351309299469
Iteration 94: train_loss 1.084916591644287
Iteration 95: train_loss 1.1194112300872803
Iteration 96: train_loss 1.1502654552459717
Iteration 97: train_loss 1.192441701889038
Iteration 98: train_loss 1.1306463479995728
Iteration 99: train_loss 1.1460930109024048
Iteration 100: train_loss 1.1636979579925537
Iteration 101: train_loss 1.1459553241729736
Iteration 102: train_loss 1.1325024366378784
Iteration 103: train_loss 1.0973817110061646
Iteration 104: train_loss 1.1208184957504272
Iteration 105: train_loss 1.1159113645553589
Iteration 106: train_loss 1.0973072052001953
Iteration 107: train_loss 1.1326195001602173
Iteration 108: train_loss 1.1190738677978516
Iteration 109: train_loss 1.174532413482666
Iteration 110: train_loss 1.099822759628296
Iteration 111: train_loss 1.065108060836792
Iteration 112: train_loss 1.101688027381897
Iteration 113: train_loss 1.0978516340255737
Iteration 114: train_loss 1.1470754146575928
Iteration 115: train_loss 1.1349509954452515
Iteration 116: train_loss 1.1911141872406006
Iteration 117: train_loss 1.1851487159729004
Iteration 118: train_loss 1.1966685056686401
Iteration 119: train_loss 1.1112655401229858
Iteration 120: train_loss 1.1201971769332886
Iteration 121: train_loss 1.1740281581878662
Iteration 122: train_loss 1.2032718658447266
Iteration 123: train_loss 1.1374528408050537
Iteration 124: train_loss 1.141394853591919
Iteration 125: train_loss 1.1492325067520142
Iteration 126: train_loss 1.1200323104858398
Iteration 127: train_loss 1.1604498624801636
Iteration 128: train_loss 1.0993150472640991
Iteration 129: train_loss 1.1987292766571045
Iteration 130: train_loss 1.1692421436309814
Iteration 131: train_loss 1.1852425336837769
Iteration 132: train_loss 1.1374059915542603
Iteration 133: train_loss 1.1061763763427734
Iteration 134: train_loss 1.1545941829681396
Iteration 135: train_loss 1.1531758308410645
Iteration 136: train_loss 1.0974608659744263
Iteration 137: train_loss 1.1581510305404663
Iteration 138: train_loss 1.1620277166366577
Iteration 139: train_loss 1.2114545106887817
Iteration 140: train_loss 1.2039127349853516
Iteration 141: train_loss 1.1397771835327148
Iteration 142: train_loss 1.133224606513977
Iteration 143: train_loss 1.1474015712738037
Iteration 144: train_loss 1.1405478715896606
Iteration 145: train_loss 1.143294095993042
Iteration 146: train_loss 1.1512809991836548
Iteration 147: train_loss 1.1243300437927246
Iteration 148: train_loss 1.1488209962844849
Iteration 149: train_loss 1.1322112083435059
Iteration 150: train_loss 1.1787396669387817
Iteration 151: train_loss 1.1826366186141968
Iteration 152: train_loss 1.129896879196167
Iteration 153: train_loss 1.1017109155654907
Iteration 154: train_loss 1.1495908498764038
Iteration 155: train_loss 1.2036858797073364
Iteration 156: train_loss 1.1258535385131836
Iteration 157: train_loss 1.144245982170105
Iteration 158: train_loss 1.1609396934509277
Iteration 159: train_loss 1.133876919746399
Iteration 160: train_loss 1.155299186706543
Iteration 161: train_loss 1.1027837991714478
Iteration 162: train_loss 1.1174818277359009
Iteration 163: train_loss 1.123653531074524
Iteration 164: train_loss 1.1993507146835327
Iteration 165: train_loss 1.181252121925354
Iteration 166: train_loss 1.1816332340240479
Iteration 167: train_loss 1.2021411657333374
Iteration 168: train_loss 1.2014902830123901
Iteration 169: train_loss 1.1383905410766602
Iteration 170: train_loss 1.2185200452804565
Iteration 171: train_loss 1.1558834314346313
Iteration 172: train_loss 1.1425503492355347
Iteration 173: train_loss 1.1833643913269043
Iteration 174: train_loss 1.2199684381484985
Iteration 175: train_loss 1.170764684677124
Iteration 176: train_loss 1.1916007995605469
Iteration 177: train_loss 1.2602676153182983
Epoch 181: train_avg_loss 1.1557919783780803 eval_avg_acc: 0.33943328937897294 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:49:50] [32mIntermediate result: 0.33943328937897294  (Index 180)[0m
================Epoch: 182================
Iteration 1: train_loss 1.222670555114746
Iteration 2: train_loss 1.1529393196105957
Iteration 3: train_loss 1.1433088779449463
Iteration 4: train_loss 1.1831364631652832
Iteration 5: train_loss 1.1464753150939941
Iteration 6: train_loss 1.1583564281463623
Iteration 7: train_loss 1.1697794198989868
Iteration 8: train_loss 1.1870105266571045
Iteration 9: train_loss 1.0972408056259155
Iteration 10: train_loss 1.1068017482757568
Iteration 11: train_loss 1.121651291847229
Iteration 12: train_loss 1.083052158355713
Iteration 13: train_loss 1.110642433166504
Iteration 14: train_loss 1.0693038702011108
Iteration 15: train_loss 1.1131505966186523
Iteration 16: train_loss 1.1685864925384521
Iteration 17: train_loss 1.0823768377304077
Iteration 18: train_loss 1.1148717403411865
Iteration 19: train_loss 1.1733111143112183
Iteration 20: train_loss 1.0787839889526367
Iteration 21: train_loss 1.0976487398147583
Iteration 22: train_loss 1.1264598369598389
Iteration 23: train_loss 1.1456947326660156
Iteration 24: train_loss 1.1296080350875854
Iteration 25: train_loss 1.142248272895813
Iteration 26: train_loss 1.1623759269714355
Iteration 27: train_loss 1.1224324703216553
Iteration 28: train_loss 1.1243590116500854
Iteration 29: train_loss 1.1599425077438354
Iteration 30: train_loss 1.1849019527435303
Iteration 31: train_loss 1.1970199346542358
Iteration 32: train_loss 1.1758263111114502
Iteration 33: train_loss 1.146611213684082
Iteration 34: train_loss 1.1680201292037964
Iteration 35: train_loss 1.1874878406524658
Iteration 36: train_loss 1.1236315965652466
Iteration 37: train_loss 1.166833758354187
Iteration 38: train_loss 1.1333853006362915
Iteration 39: train_loss 1.140005111694336
Iteration 40: train_loss 1.1398835182189941
Iteration 41: train_loss 1.114213228225708
Iteration 42: train_loss 1.0968002080917358
Iteration 43: train_loss 1.1002562046051025
Iteration 44: train_loss 1.181274175643921
Iteration 45: train_loss 1.1236186027526855
Iteration 46: train_loss 1.1046054363250732
Iteration 47: train_loss 1.102264404296875
Iteration 48: train_loss 1.151363492012024
Iteration 49: train_loss 1.2033755779266357
Iteration 50: train_loss 1.1342679262161255
Iteration 51: train_loss 1.0938926935195923
Iteration 52: train_loss 1.1226210594177246
Iteration 53: train_loss 1.1535699367523193
Iteration 54: train_loss 1.20485258102417
Iteration 55: train_loss 1.1403007507324219
Iteration 56: train_loss 1.1902624368667603
Iteration 57: train_loss 1.1210479736328125
Iteration 58: train_loss 1.1313064098358154
Iteration 59: train_loss 1.1778219938278198
Iteration 60: train_loss 1.139469027519226
Iteration 61: train_loss 1.1785643100738525
Iteration 62: train_loss 1.1692944765090942
Iteration 63: train_loss 1.158814787864685
Iteration 64: train_loss 1.2215291261672974
Iteration 65: train_loss 1.1876953840255737
Iteration 66: train_loss 1.1862540245056152
Iteration 67: train_loss 1.1478092670440674
Iteration 68: train_loss 1.1196552515029907
Iteration 69: train_loss 1.1044600009918213
Iteration 70: train_loss 1.1628825664520264
Iteration 71: train_loss 1.134974479675293
Iteration 72: train_loss 1.1978135108947754
Iteration 73: train_loss 1.083369255065918
Iteration 74: train_loss 1.1527183055877686
Iteration 75: train_loss 1.0326881408691406
Iteration 76: train_loss 1.1150500774383545
Iteration 77: train_loss 1.123365879058838
Iteration 78: train_loss 1.1486473083496094
Iteration 79: train_loss 1.1467429399490356
Iteration 80: train_loss 1.1275869607925415
Iteration 81: train_loss 1.1370539665222168
Iteration 82: train_loss 1.095176339149475
Iteration 83: train_loss 1.143104910850525
Iteration 84: train_loss 1.1242272853851318
Iteration 85: train_loss 1.1849727630615234
Iteration 86: train_loss 1.052105188369751
Iteration 87: train_loss 1.0912564992904663
Iteration 88: train_loss 1.1164822578430176
Iteration 89: train_loss 1.0968239307403564
Iteration 90: train_loss 1.1204867362976074
Iteration 91: train_loss 1.092721939086914
Iteration 92: train_loss 1.1080169677734375
Iteration 93: train_loss 1.1162641048431396
Iteration 94: train_loss 1.1562620401382446
Iteration 95: train_loss 1.1024645566940308
Iteration 96: train_loss 1.109381914138794
Iteration 97: train_loss 1.1400405168533325
Iteration 98: train_loss 1.1173418760299683
Iteration 99: train_loss 1.0907807350158691
Iteration 100: train_loss 1.1160058975219727
Iteration 101: train_loss 1.143113613128662
Iteration 102: train_loss 1.1402561664581299
Iteration 103: train_loss 1.0911438465118408
Iteration 104: train_loss 1.0924222469329834
Iteration 105: train_loss 1.13117253780365
Iteration 106: train_loss 1.114507794380188
Iteration 107: train_loss 1.1436254978179932
Iteration 108: train_loss 1.1296656131744385
Iteration 109: train_loss 1.2105108499526978
Iteration 110: train_loss 1.119156002998352
Iteration 111: train_loss 1.1252669095993042
Iteration 112: train_loss 1.1303024291992188
Iteration 113: train_loss 1.1441959142684937
Iteration 114: train_loss 1.1284537315368652
Iteration 115: train_loss 1.1370975971221924
Iteration 116: train_loss 1.1222139596939087
Iteration 117: train_loss 1.1368136405944824
Iteration 118: train_loss 1.1766245365142822
Iteration 119: train_loss 1.1773896217346191
Iteration 120: train_loss 1.20787513256073
Iteration 121: train_loss 1.1879855394363403
Iteration 122: train_loss 1.157467007637024
Iteration 123: train_loss 1.1531072854995728
Iteration 124: train_loss 1.1584404706954956
Iteration 125: train_loss 1.1180297136306763
Iteration 126: train_loss 1.1400196552276611
Iteration 127: train_loss 1.1629583835601807
Iteration 128: train_loss 1.137697458267212
Iteration 129: train_loss 1.1700961589813232
Iteration 130: train_loss 1.1678972244262695
Iteration 131: train_loss 1.1464866399765015
Iteration 132: train_loss 1.1458170413970947
Iteration 133: train_loss 1.0990780591964722
Iteration 134: train_loss 1.0922406911849976
Iteration 135: train_loss 1.150076150894165
Iteration 136: train_loss 1.1785967350006104
Iteration 137: train_loss 1.2084711790084839
Iteration 138: train_loss 1.161767601966858
Iteration 139: train_loss 1.2094088792800903
Iteration 140: train_loss 1.1449357271194458
Iteration 141: train_loss 1.1458804607391357
Iteration 142: train_loss 1.1558477878570557
Iteration 143: train_loss 1.1872103214263916
Iteration 144: train_loss 1.1784467697143555
Iteration 145: train_loss 1.188659906387329
Iteration 146: train_loss 1.0777089595794678
Iteration 147: train_loss 1.1570091247558594
Iteration 148: train_loss 1.1505398750305176
Iteration 149: train_loss 1.090485692024231
Iteration 150: train_loss 1.1518385410308838
Iteration 151: train_loss 1.1088134050369263
Iteration 152: train_loss 1.1522945165634155
Iteration 153: train_loss 1.1162912845611572
Iteration 154: train_loss 1.1813042163848877
Iteration 155: train_loss 1.1445064544677734
Iteration 156: train_loss 1.1354615688323975
Iteration 157: train_loss 1.1103644371032715
Iteration 158: train_loss 1.1169407367706299
Iteration 159: train_loss 1.1644113063812256
Iteration 160: train_loss 1.1006016731262207
Iteration 161: train_loss 1.114657998085022
Iteration 162: train_loss 1.0723484754562378
Iteration 163: train_loss 1.204906940460205
Iteration 164: train_loss 1.1534913778305054
Iteration 165: train_loss 1.23797607421875
Iteration 166: train_loss 1.1657100915908813
Iteration 167: train_loss 1.152851939201355
Iteration 168: train_loss 1.213039517402649
Iteration 169: train_loss 1.1547154188156128
Iteration 170: train_loss 1.1917043924331665
Iteration 171: train_loss 1.174420952796936
Iteration 172: train_loss 1.1378554105758667
Iteration 173: train_loss 1.1458570957183838
Iteration 174: train_loss 1.1773269176483154
Iteration 175: train_loss 1.1925126314163208
Iteration 176: train_loss 1.1165674924850464
Iteration 177: train_loss 1.2235751152038574
Epoch 182: train_avg_loss 1.142330039018965 eval_avg_acc: 0.3410707022193932 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:50:33] [32mIntermediate result: 0.3410707022193932  (Index 181)[0m
================Epoch: 183================
Iteration 1: train_loss 1.1867903470993042
Iteration 2: train_loss 1.1918007135391235
Iteration 3: train_loss 1.192610263824463
Iteration 4: train_loss 1.1746909618377686
Iteration 5: train_loss 1.096645474433899
Iteration 6: train_loss 1.1684536933898926
Iteration 7: train_loss 1.176684856414795
Iteration 8: train_loss 1.111872673034668
Iteration 9: train_loss 1.1941542625427246
Iteration 10: train_loss 1.1048811674118042
Iteration 11: train_loss 1.1107877492904663
Iteration 12: train_loss 1.157038688659668
Iteration 13: train_loss 1.1645582914352417
Iteration 14: train_loss 1.1161675453186035
Iteration 15: train_loss 1.110595703125
Iteration 16: train_loss 1.098799228668213
Iteration 17: train_loss 1.1058567762374878
Iteration 18: train_loss 1.1172996759414673
Iteration 19: train_loss 1.1078757047653198
Iteration 20: train_loss 1.119869589805603
Iteration 21: train_loss 1.1436747312545776
Iteration 22: train_loss 1.1353892087936401
Iteration 23: train_loss 1.114730954170227
Iteration 24: train_loss 1.0918923616409302
Iteration 25: train_loss 1.1082009077072144
Iteration 26: train_loss 1.1111948490142822
Iteration 27: train_loss 1.1139992475509644
Iteration 28: train_loss 1.1834683418273926
Iteration 29: train_loss 1.1357688903808594
Iteration 30: train_loss 1.1170951128005981
Iteration 31: train_loss 1.1123648881912231
Iteration 32: train_loss 1.1369887590408325
Iteration 33: train_loss 1.117832899093628
Iteration 34: train_loss 1.125178337097168
Iteration 35: train_loss 1.1079264879226685
Iteration 36: train_loss 1.1388640403747559
Iteration 37: train_loss 1.1173206567764282
Iteration 38: train_loss 1.1314711570739746
Iteration 39: train_loss 1.1467050313949585
Iteration 40: train_loss 1.1386706829071045
Iteration 41: train_loss 1.082881212234497
Iteration 42: train_loss 1.1483540534973145
Iteration 43: train_loss 1.1998436450958252
Iteration 44: train_loss 1.176498532295227
Iteration 45: train_loss 1.1050556898117065
Iteration 46: train_loss 1.1378118991851807
Iteration 47: train_loss 1.117566704750061
Iteration 48: train_loss 1.1735833883285522
Iteration 49: train_loss 1.0859501361846924
Iteration 50: train_loss 1.148978352546692
Iteration 51: train_loss 1.1362791061401367
Iteration 52: train_loss 1.1428667306900024
Iteration 53: train_loss 1.1453911066055298
Iteration 54: train_loss 1.1534161567687988
Iteration 55: train_loss 1.1290501356124878
Iteration 56: train_loss 1.1304227113723755
Iteration 57: train_loss 1.1461490392684937
Iteration 58: train_loss 1.1052494049072266
Iteration 59: train_loss 1.2016832828521729
Iteration 60: train_loss 1.1477441787719727
Iteration 61: train_loss 1.119297742843628
Iteration 62: train_loss 1.1258760690689087
Iteration 63: train_loss 1.0863237380981445
Iteration 64: train_loss 1.1018768548965454
Iteration 65: train_loss 1.1174098253250122
Iteration 66: train_loss 1.1297180652618408
Iteration 67: train_loss 1.0834100246429443
Iteration 68: train_loss 1.1698853969573975
Iteration 69: train_loss 1.1166260242462158
Iteration 70: train_loss 1.1727123260498047
Iteration 71: train_loss 1.1231166124343872
Iteration 72: train_loss 1.2186081409454346
Iteration 73: train_loss 1.209836483001709
Iteration 74: train_loss 1.1587995290756226
Iteration 75: train_loss 1.0857301950454712
Iteration 76: train_loss 1.1390846967697144
Iteration 77: train_loss 1.1049048900604248
Iteration 78: train_loss 1.1618303060531616
Iteration 79: train_loss 1.1415679454803467
Iteration 80: train_loss 1.1521310806274414
Iteration 81: train_loss 1.1409657001495361
Iteration 82: train_loss 1.1840075254440308
Iteration 83: train_loss 1.133756160736084
Iteration 84: train_loss 1.1280537843704224
Iteration 85: train_loss 1.0888168811798096
Iteration 86: train_loss 1.165630578994751
Iteration 87: train_loss 1.1282951831817627
Iteration 88: train_loss 1.1528280973434448
Iteration 89: train_loss 1.134269118309021
Iteration 90: train_loss 1.1214160919189453
Iteration 91: train_loss 1.1120624542236328
Iteration 92: train_loss 1.0890971422195435
Iteration 93: train_loss 1.0788421630859375
Iteration 94: train_loss 1.0783123970031738
Iteration 95: train_loss 1.1293998956680298
Iteration 96: train_loss 1.110418677330017
Iteration 97: train_loss 1.1303294897079468
Iteration 98: train_loss 1.1170707941055298
Iteration 99: train_loss 1.0680434703826904
Iteration 100: train_loss 1.1336979866027832
Iteration 101: train_loss 1.1352413892745972
Iteration 102: train_loss 1.1080665588378906
Iteration 103: train_loss 1.1213785409927368
Iteration 104: train_loss 1.1491777896881104
Iteration 105: train_loss 1.1279633045196533
Iteration 106: train_loss 1.1321979761123657
Iteration 107: train_loss 1.1461690664291382
Iteration 108: train_loss 1.098653793334961
Iteration 109: train_loss 1.1381351947784424
Iteration 110: train_loss 1.1054189205169678
Iteration 111: train_loss 1.1349527835845947
Iteration 112: train_loss 1.1116669178009033
Iteration 113: train_loss 1.1304317712783813
Iteration 114: train_loss 1.1991419792175293
Iteration 115: train_loss 1.1267471313476562
Iteration 116: train_loss 1.141737937927246
Iteration 117: train_loss 1.1504486799240112
Iteration 118: train_loss 1.1314619779586792
Iteration 119: train_loss 1.1524428129196167
Iteration 120: train_loss 1.199397087097168
Iteration 121: train_loss 1.090852975845337
Iteration 122: train_loss 1.1322208642959595
Iteration 123: train_loss 1.1479088068008423
Iteration 124: train_loss 1.144594430923462
Iteration 125: train_loss 1.1274503469467163
Iteration 126: train_loss 1.1378756761550903
Iteration 127: train_loss 1.1601121425628662
Iteration 128: train_loss 1.1978214979171753
Iteration 129: train_loss 1.1471662521362305
Iteration 130: train_loss 1.1923282146453857
Iteration 131: train_loss 1.1530804634094238
Iteration 132: train_loss 1.1769367456436157
Iteration 133: train_loss 1.1141527891159058
Iteration 134: train_loss 1.168264389038086
Iteration 135: train_loss 1.138910174369812
Iteration 136: train_loss 1.1479438543319702
Iteration 137: train_loss 1.1587855815887451
Iteration 138: train_loss 1.1168330907821655
Iteration 139: train_loss 1.1489689350128174
Iteration 140: train_loss 1.1625019311904907
Iteration 141: train_loss 1.1139764785766602
Iteration 142: train_loss 1.1127732992172241
Iteration 143: train_loss 1.114245891571045
Iteration 144: train_loss 1.1334607601165771
Iteration 145: train_loss 1.1925091743469238
Iteration 146: train_loss 1.118923306465149
Iteration 147: train_loss 1.2048192024230957
Iteration 148: train_loss 1.1615262031555176
Iteration 149: train_loss 1.1588717699050903
Iteration 150: train_loss 1.1161162853240967
Iteration 151: train_loss 1.121886134147644
Iteration 152: train_loss 1.1965888738632202
Iteration 153: train_loss 1.1293500661849976
Iteration 154: train_loss 1.1640571355819702
Iteration 155: train_loss 1.1231064796447754
Iteration 156: train_loss 1.1011244058609009
Iteration 157: train_loss 1.1023492813110352
Iteration 158: train_loss 1.163469910621643
Iteration 159: train_loss 1.106261134147644
Iteration 160: train_loss 1.2205888032913208
Iteration 161: train_loss 1.126172423362732
Iteration 162: train_loss 1.1335158348083496
Iteration 163: train_loss 1.1175391674041748
Iteration 164: train_loss 1.1117881536483765
Iteration 165: train_loss 1.118855357170105
Iteration 166: train_loss 1.1582369804382324
Iteration 167: train_loss 1.2023214101791382
Iteration 168: train_loss 1.1434452533721924
Iteration 169: train_loss 1.185456395149231
Iteration 170: train_loss 1.222752332687378
Iteration 171: train_loss 1.1136548519134521
Iteration 172: train_loss 1.1608749628067017
Iteration 173: train_loss 1.1853920221328735
Iteration 174: train_loss 1.1893857717514038
Iteration 175: train_loss 1.153894066810608
Iteration 176: train_loss 1.1487451791763306
Iteration 177: train_loss 1.2000502347946167
Epoch 183: train_avg_loss 1.1385798400404763 eval_avg_acc: 0.34058317007989647 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:51:16] [32mIntermediate result: 0.34058317007989647  (Index 182)[0m
================Epoch: 184================
Iteration 1: train_loss 1.1156392097473145
Iteration 2: train_loss 1.1372867822647095
Iteration 3: train_loss 1.1331210136413574
Iteration 4: train_loss 1.1402256488800049
Iteration 5: train_loss 1.1127753257751465
Iteration 6: train_loss 1.0519517660140991
Iteration 7: train_loss 1.1322884559631348
Iteration 8: train_loss 1.1530903577804565
Iteration 9: train_loss 1.1323227882385254
Iteration 10: train_loss 1.151860237121582
Iteration 11: train_loss 1.136777639389038
Iteration 12: train_loss 1.1632230281829834
Iteration 13: train_loss 1.16874098777771
Iteration 14: train_loss 1.153455376625061
Iteration 15: train_loss 1.1574097871780396
Iteration 16: train_loss 1.2319183349609375
Iteration 17: train_loss 1.2018016576766968
Iteration 18: train_loss 1.1534488201141357
Iteration 19: train_loss 1.1333248615264893
Iteration 20: train_loss 1.1389508247375488
Iteration 21: train_loss 1.1263618469238281
Iteration 22: train_loss 1.099733591079712
Iteration 23: train_loss 1.1785496473312378
Iteration 24: train_loss 1.1880820989608765
Iteration 25: train_loss 1.1091431379318237
Iteration 26: train_loss 1.1229859590530396
Iteration 27: train_loss 1.1664894819259644
Iteration 28: train_loss 1.1265838146209717
Iteration 29: train_loss 1.1575376987457275
Iteration 30: train_loss 1.1302683353424072
Iteration 31: train_loss 1.1299172639846802
Iteration 32: train_loss 1.0676417350769043
Iteration 33: train_loss 1.1354910135269165
Iteration 34: train_loss 1.1064541339874268
Iteration 35: train_loss 1.1326173543930054
Iteration 36: train_loss 1.1151645183563232
Iteration 37: train_loss 1.1892962455749512
Iteration 38: train_loss 1.1339287757873535
Iteration 39: train_loss 1.1731971502304077
Iteration 40: train_loss 1.0997666120529175
Iteration 41: train_loss 1.1309349536895752
Iteration 42: train_loss 1.1330171823501587
Iteration 43: train_loss 1.1201848983764648
Iteration 44: train_loss 1.1430449485778809
Iteration 45: train_loss 1.118883490562439
Iteration 46: train_loss 1.1665982007980347
Iteration 47: train_loss 1.1828670501708984
Iteration 48: train_loss 1.1723096370697021
Iteration 49: train_loss 1.1661643981933594
Iteration 50: train_loss 1.1299049854278564
Iteration 51: train_loss 1.1149320602416992
Iteration 52: train_loss 1.1440223455429077
Iteration 53: train_loss 1.142228126525879
Iteration 54: train_loss 1.1204806566238403
Iteration 55: train_loss 1.2162195444107056
Iteration 56: train_loss 1.1591298580169678
Iteration 57: train_loss 1.1304975748062134
Iteration 58: train_loss 1.1289117336273193
Iteration 59: train_loss 1.124869465827942
Iteration 60: train_loss 1.1671168804168701
Iteration 61: train_loss 1.155190110206604
Iteration 62: train_loss 1.1117851734161377
Iteration 63: train_loss 1.1030911207199097
Iteration 64: train_loss 1.135373592376709
Iteration 65: train_loss 1.111731767654419
Iteration 66: train_loss 1.1142826080322266
Iteration 67: train_loss 1.0902918577194214
Iteration 68: train_loss 1.1454578638076782
Iteration 69: train_loss 1.1283130645751953
Iteration 70: train_loss 1.1641038656234741
Iteration 71: train_loss 1.1380441188812256
Iteration 72: train_loss 1.1665120124816895
Iteration 73: train_loss 1.1501686573028564
Iteration 74: train_loss 1.1721045970916748
Iteration 75: train_loss 1.2358601093292236
Iteration 76: train_loss 1.1978285312652588
Iteration 77: train_loss 1.1962904930114746
Iteration 78: train_loss 1.2284153699874878
Iteration 79: train_loss 1.1623609066009521
Iteration 80: train_loss 1.1704380512237549
Iteration 81: train_loss 1.1766465902328491
Iteration 82: train_loss 1.1964075565338135
Iteration 83: train_loss 1.2301559448242188
Iteration 84: train_loss 1.1906623840332031
Iteration 85: train_loss 1.239099383354187
Iteration 86: train_loss 1.2109469175338745
Iteration 87: train_loss 1.2284646034240723
Iteration 88: train_loss 1.1952968835830688
Iteration 89: train_loss 1.1512459516525269
Iteration 90: train_loss 1.1310104131698608
Iteration 91: train_loss 1.1574044227600098
Iteration 92: train_loss 1.091624140739441
Iteration 93: train_loss 1.2182201147079468
Iteration 94: train_loss 1.1757586002349854
Iteration 95: train_loss 1.1862744092941284
Iteration 96: train_loss 1.2108315229415894
Iteration 97: train_loss 1.1864389181137085
Iteration 98: train_loss 1.219139814376831
Iteration 99: train_loss 1.232614278793335
Iteration 100: train_loss 1.1394708156585693
Iteration 101: train_loss 1.1753329038619995
Iteration 102: train_loss 1.1801629066467285
Iteration 103: train_loss 1.1393097639083862
Iteration 104: train_loss 1.1578599214553833
Iteration 105: train_loss 1.1957099437713623
Iteration 106: train_loss 1.1606159210205078
Iteration 107: train_loss 1.1696488857269287
Iteration 108: train_loss 1.1595172882080078
Iteration 109: train_loss 1.1320478916168213
Iteration 110: train_loss 1.1398025751113892
Iteration 111: train_loss 1.1964256763458252
Iteration 112: train_loss 1.0958768129348755
Iteration 113: train_loss 1.074931263923645
Iteration 114: train_loss 1.1503962278366089
Iteration 115: train_loss 1.154446005821228
Iteration 116: train_loss 1.172045111656189
Iteration 117: train_loss 1.13887619972229
Iteration 118: train_loss 1.095790982246399
Iteration 119: train_loss 1.1616984605789185
Iteration 120: train_loss 1.093194603919983
Iteration 121: train_loss 1.1172086000442505
Iteration 122: train_loss 1.1458675861358643
Iteration 123: train_loss 1.1462390422821045
Iteration 124: train_loss 1.1481330394744873
Iteration 125: train_loss 1.161269187927246
Iteration 126: train_loss 1.10406494140625
Iteration 127: train_loss 1.1481674909591675
Iteration 128: train_loss 1.1147342920303345
Iteration 129: train_loss 1.0923209190368652
Iteration 130: train_loss 1.1037273406982422
Iteration 131: train_loss 1.2044681310653687
Iteration 132: train_loss 1.1323801279067993
Iteration 133: train_loss 1.1170446872711182
Iteration 134: train_loss 1.1646825075149536
Iteration 135: train_loss 1.1654549837112427
Iteration 136: train_loss 1.1670734882354736
Iteration 137: train_loss 1.1654353141784668
Iteration 138: train_loss 1.0960044860839844
Iteration 139: train_loss 1.1684261560440063
Iteration 140: train_loss 1.1659212112426758
Iteration 141: train_loss 1.1746101379394531
Iteration 142: train_loss 1.2100963592529297
Iteration 143: train_loss 1.1291576623916626
Iteration 144: train_loss 1.1717740297317505
Iteration 145: train_loss 1.1607218980789185
Iteration 146: train_loss 1.2188587188720703
Iteration 147: train_loss 1.1624035835266113
Iteration 148: train_loss 1.1935726404190063
Iteration 149: train_loss 1.1790260076522827
Iteration 150: train_loss 1.1861910820007324
Iteration 151: train_loss 1.120723009109497
Iteration 152: train_loss 1.1186050176620483
Iteration 153: train_loss 1.1429519653320312
Iteration 154: train_loss 1.182544469833374
Iteration 155: train_loss 1.1670421361923218
Iteration 156: train_loss 1.1364061832427979
Iteration 157: train_loss 1.1152681112289429
Iteration 158: train_loss 1.1670314073562622
Iteration 159: train_loss 1.1902388334274292
Iteration 160: train_loss 1.1991193294525146
Iteration 161: train_loss 1.15653657913208
Iteration 162: train_loss 1.1933009624481201
Iteration 163: train_loss 1.1662839651107788
Iteration 164: train_loss 1.1224279403686523
Iteration 165: train_loss 1.1622684001922607
Iteration 166: train_loss 1.1897121667861938
Iteration 167: train_loss 1.2017767429351807
Iteration 168: train_loss 1.1741503477096558
Iteration 169: train_loss 1.1848464012145996
Iteration 170: train_loss 1.1567124128341675
Iteration 171: train_loss 1.2028943300247192
Iteration 172: train_loss 1.171034574508667
Iteration 173: train_loss 1.2010117769241333
Iteration 174: train_loss 1.138196587562561
Iteration 175: train_loss 1.1934175491333008
Iteration 176: train_loss 1.2595330476760864
Iteration 177: train_loss 1.1921530961990356
Epoch 184: train_avg_loss 1.1554317016386042 eval_avg_acc: 0.3361808973672717 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:51:59] [32mIntermediate result: 0.3361808973672717  (Index 183)[0m
================Epoch: 185================
Iteration 1: train_loss 1.134096384048462
Iteration 2: train_loss 1.1166794300079346
Iteration 3: train_loss 1.1950801610946655
Iteration 4: train_loss 1.103479027748108
Iteration 5: train_loss 1.170133113861084
Iteration 6: train_loss 1.1788641214370728
Iteration 7: train_loss 1.1217964887619019
Iteration 8: train_loss 1.1328895092010498
Iteration 9: train_loss 1.089713215827942
Iteration 10: train_loss 1.144291639328003
Iteration 11: train_loss 1.113411545753479
Iteration 12: train_loss 1.150650143623352
Iteration 13: train_loss 1.1812115907669067
Iteration 14: train_loss 1.1056160926818848
Iteration 15: train_loss 1.1006011962890625
Iteration 16: train_loss 1.1486073732376099
Iteration 17: train_loss 1.176787257194519
Iteration 18: train_loss 1.086778163909912
Iteration 19: train_loss 1.101935625076294
Iteration 20: train_loss 1.0922114849090576
Iteration 21: train_loss 1.1600066423416138
Iteration 22: train_loss 1.087422251701355
Iteration 23: train_loss 1.1149319410324097
Iteration 24: train_loss 1.0737535953521729
Iteration 25: train_loss 1.1511995792388916
Iteration 26: train_loss 1.0926178693771362
Iteration 27: train_loss 1.102744221687317
Iteration 28: train_loss 1.0960139036178589
Iteration 29: train_loss 1.1096917390823364
Iteration 30: train_loss 1.0630630254745483
Iteration 31: train_loss 1.1383353471755981
Iteration 32: train_loss 1.160514235496521
Iteration 33: train_loss 1.1489183902740479
Iteration 34: train_loss 1.1346546411514282
Iteration 35: train_loss 1.1616560220718384
Iteration 36: train_loss 1.1868722438812256
Iteration 37: train_loss 1.1344152688980103
Iteration 38: train_loss 1.124146580696106
Iteration 39: train_loss 1.0979368686676025
Iteration 40: train_loss 1.0770189762115479
Iteration 41: train_loss 1.1613694429397583
Iteration 42: train_loss 1.1424778699874878
Iteration 43: train_loss 1.1689118146896362
Iteration 44: train_loss 1.1094831228256226
Iteration 45: train_loss 1.1267634630203247
Iteration 46: train_loss 1.1619670391082764
Iteration 47: train_loss 1.143401026725769
Iteration 48: train_loss 1.1004364490509033
Iteration 49: train_loss 1.0953519344329834
Iteration 50: train_loss 1.1231664419174194
Iteration 51: train_loss 1.1125712394714355
Iteration 52: train_loss 1.1056009531021118
Iteration 53: train_loss 1.1161000728607178
Iteration 54: train_loss 1.1474809646606445
Iteration 55: train_loss 1.1446223258972168
Iteration 56: train_loss 1.1154811382293701
Iteration 57: train_loss 1.1304585933685303
Iteration 58: train_loss 1.0903152227401733
Iteration 59: train_loss 1.0981734991073608
Iteration 60: train_loss 1.077462077140808
Iteration 61: train_loss 1.130379319190979
Iteration 62: train_loss 1.1432678699493408
Iteration 63: train_loss 1.1360443830490112
Iteration 64: train_loss 1.089824914932251
Iteration 65: train_loss 1.0823392868041992
Iteration 66: train_loss 1.1001498699188232
Iteration 67: train_loss 1.177915334701538
Iteration 68: train_loss 1.1065608263015747
Iteration 69: train_loss 1.1339256763458252
Iteration 70: train_loss 1.1517339944839478
Iteration 71: train_loss 1.1104381084442139
Iteration 72: train_loss 1.1837631464004517
Iteration 73: train_loss 1.1523046493530273
Iteration 74: train_loss 1.1281601190567017
Iteration 75: train_loss 1.1848368644714355
Iteration 76: train_loss 1.1239620447158813
Iteration 77: train_loss 1.1316630840301514
Iteration 78: train_loss 1.117962121963501
Iteration 79: train_loss 1.2365483045578003
Iteration 80: train_loss 1.1271568536758423
Iteration 81: train_loss 1.1054993867874146
Iteration 82: train_loss 1.1688942909240723
Iteration 83: train_loss 1.1652740240097046
Iteration 84: train_loss 1.1921346187591553
Iteration 85: train_loss 1.1323187351226807
Iteration 86: train_loss 1.180851936340332
Iteration 87: train_loss 1.1880791187286377
Iteration 88: train_loss 1.1323496103286743
Iteration 89: train_loss 1.1541264057159424
Iteration 90: train_loss 1.1872565746307373
Iteration 91: train_loss 1.1054946184158325
Iteration 92: train_loss 1.1753498315811157
Iteration 93: train_loss 1.1694921255111694
Iteration 94: train_loss 1.1448287963867188
Iteration 95: train_loss 1.1622912883758545
Iteration 96: train_loss 1.1044279336929321
Iteration 97: train_loss 1.1763362884521484
Iteration 98: train_loss 1.1186083555221558
Iteration 99: train_loss 1.179632544517517
Iteration 100: train_loss 1.1310709714889526
Iteration 101: train_loss 1.1522833108901978
Iteration 102: train_loss 1.1762713193893433
Iteration 103: train_loss 1.2358134984970093
Iteration 104: train_loss 1.148398518562317
Iteration 105: train_loss 1.1295868158340454
Iteration 106: train_loss 1.1204243898391724
Iteration 107: train_loss 1.137705683708191
Iteration 108: train_loss 1.1600027084350586
Iteration 109: train_loss 1.0892888307571411
Iteration 110: train_loss 1.1054011583328247
Iteration 111: train_loss 1.1314845085144043
Iteration 112: train_loss 1.1877050399780273
Iteration 113: train_loss 1.189328908920288
Iteration 114: train_loss 1.1262847185134888
Iteration 115: train_loss 1.1577200889587402
Iteration 116: train_loss 1.0954761505126953
Iteration 117: train_loss 1.100448727607727
Iteration 118: train_loss 1.1673392057418823
Iteration 119: train_loss 1.1359142065048218
Iteration 120: train_loss 1.1382508277893066
Iteration 121: train_loss 1.1345674991607666
Iteration 122: train_loss 1.1183418035507202
Iteration 123: train_loss 1.1076637506484985
Iteration 124: train_loss 1.1566870212554932
Iteration 125: train_loss 1.151535987854004
Iteration 126: train_loss 1.1630628108978271
Iteration 127: train_loss 1.1119648218154907
Iteration 128: train_loss 1.1869502067565918
Iteration 129: train_loss 1.1263073682785034
Iteration 130: train_loss 1.1422492265701294
Iteration 131: train_loss 1.1416194438934326
Iteration 132: train_loss 1.1800222396850586
Iteration 133: train_loss 1.1859129667282104
Iteration 134: train_loss 1.1424225568771362
Iteration 135: train_loss 1.1915019750595093
Iteration 136: train_loss 1.2175977230072021
Iteration 137: train_loss 1.1600450277328491
Iteration 138: train_loss 1.1018950939178467
Iteration 139: train_loss 1.1826708316802979
Iteration 140: train_loss 1.1152565479278564
Iteration 141: train_loss 1.1613798141479492
Iteration 142: train_loss 1.139629602432251
Iteration 143: train_loss 1.1484593152999878
Iteration 144: train_loss 1.0983874797821045
Iteration 145: train_loss 1.1584112644195557
Iteration 146: train_loss 1.2097378969192505
Iteration 147: train_loss 1.0825464725494385
Iteration 148: train_loss 1.1756093502044678
Iteration 149: train_loss 1.1846257448196411
Iteration 150: train_loss 1.0892046689987183
Iteration 151: train_loss 1.1375312805175781
Iteration 152: train_loss 1.185694694519043
Iteration 153: train_loss 1.1730276346206665
Iteration 154: train_loss 1.17104971408844
Iteration 155: train_loss 1.1896618604660034
Iteration 156: train_loss 1.2039194107055664
Iteration 157: train_loss 1.2231239080429077
Iteration 158: train_loss 1.210815668106079
Iteration 159: train_loss 1.214621663093567
Iteration 160: train_loss 1.1379363536834717
Iteration 161: train_loss 1.13746178150177
Iteration 162: train_loss 1.1254584789276123
Iteration 163: train_loss 1.14152193069458
Iteration 164: train_loss 1.0980329513549805
Iteration 165: train_loss 1.1289114952087402
Iteration 166: train_loss 1.1474522352218628
Iteration 167: train_loss 1.1206071376800537
Iteration 168: train_loss 1.1984699964523315
Iteration 169: train_loss 1.1259301900863647
Iteration 170: train_loss 1.1086466312408447
Iteration 171: train_loss 1.166397213935852
Iteration 172: train_loss 1.1899001598358154
Iteration 173: train_loss 1.1865195035934448
Iteration 174: train_loss 1.1259596347808838
Iteration 175: train_loss 1.1715455055236816
Iteration 176: train_loss 1.1375086307525635
Iteration 177: train_loss 1.1621335744857788
Epoch 185: train_avg_loss 1.1413945208835063 eval_avg_acc: 0.3440660158303813 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:52:43] [32mIntermediate result: 0.3440660158303813  (Index 184)[0m
================Epoch: 186================
Iteration 1: train_loss 1.1143534183502197
Iteration 2: train_loss 1.1678522825241089
Iteration 3: train_loss 1.2011487483978271
Iteration 4: train_loss 1.174655795097351
Iteration 5: train_loss 1.1557643413543701
Iteration 6: train_loss 1.1732017993927002
Iteration 7: train_loss 1.2318909168243408
Iteration 8: train_loss 1.211478352546692
Iteration 9: train_loss 1.150820255279541
Iteration 10: train_loss 1.1908572912216187
Iteration 11: train_loss 1.1381887197494507
Iteration 12: train_loss 1.1260024309158325
Iteration 13: train_loss 1.1535632610321045
Iteration 14: train_loss 1.0789321660995483
Iteration 15: train_loss 1.1584856510162354
Iteration 16: train_loss 1.1842252016067505
Iteration 17: train_loss 1.1943576335906982
Iteration 18: train_loss 1.1513832807540894
Iteration 19: train_loss 1.1384960412979126
Iteration 20: train_loss 1.1951019763946533
Iteration 21: train_loss 1.191776156425476
Iteration 22: train_loss 1.1923002004623413
Iteration 23: train_loss 1.1503937244415283
Iteration 24: train_loss 1.1219193935394287
Iteration 25: train_loss 1.1422545909881592
Iteration 26: train_loss 1.1153850555419922
Iteration 27: train_loss 1.1284784078598022
Iteration 28: train_loss 1.1105775833129883
Iteration 29: train_loss 1.1711004972457886
Iteration 30: train_loss 1.1512224674224854
Iteration 31: train_loss 1.2070317268371582
Iteration 32: train_loss 1.1334619522094727
Iteration 33: train_loss 1.1075340509414673
Iteration 34: train_loss 1.1288280487060547
Iteration 35: train_loss 1.1151901483535767
Iteration 36: train_loss 1.1077525615692139
Iteration 37: train_loss 1.0927602052688599
Iteration 38: train_loss 1.1095141172409058
Iteration 39: train_loss 1.1285613775253296
Iteration 40: train_loss 1.127627968788147
Iteration 41: train_loss 1.149678349494934
Iteration 42: train_loss 1.1022127866744995
Iteration 43: train_loss 1.216758131980896
Iteration 44: train_loss 1.130068063735962
Iteration 45: train_loss 1.150791883468628
Iteration 46: train_loss 1.1804265975952148
Iteration 47: train_loss 1.216185212135315
Iteration 48: train_loss 1.2614610195159912
Iteration 49: train_loss 1.1626513004302979
Iteration 50: train_loss 1.131279468536377
Iteration 51: train_loss 1.2461962699890137
Iteration 52: train_loss 1.2592145204544067
Iteration 53: train_loss 1.2005597352981567
Iteration 54: train_loss 1.1750534772872925
Iteration 55: train_loss 1.1615725755691528
Iteration 56: train_loss 1.1325119733810425
Iteration 57: train_loss 1.2091522216796875
Iteration 58: train_loss 1.1659210920333862
Iteration 59: train_loss 1.1923025846481323
Iteration 60: train_loss 1.1100655794143677
Iteration 61: train_loss 1.1330318450927734
Iteration 62: train_loss 1.1536495685577393
Iteration 63: train_loss 1.204553484916687
Iteration 64: train_loss 1.154881477355957
Iteration 65: train_loss 1.1226619482040405
Iteration 66: train_loss 1.0871260166168213
Iteration 67: train_loss 1.1428378820419312
Iteration 68: train_loss 1.1904317140579224
Iteration 69: train_loss 1.122391700744629
Iteration 70: train_loss 1.161958932876587
Iteration 71: train_loss 1.1326133012771606
Iteration 72: train_loss 1.1049902439117432
Iteration 73: train_loss 1.1361345052719116
Iteration 74: train_loss 1.1751035451889038
Iteration 75: train_loss 1.0864498615264893
Iteration 76: train_loss 1.1423232555389404
Iteration 77: train_loss 1.1467037200927734
Iteration 78: train_loss 1.1202815771102905
Iteration 79: train_loss 1.141975998878479
Iteration 80: train_loss 1.1249445676803589
Iteration 81: train_loss 1.1224840879440308
Iteration 82: train_loss 1.1137889623641968
Iteration 83: train_loss 1.1520295143127441
Iteration 84: train_loss 1.1328948736190796
Iteration 85: train_loss 1.1604082584381104
Iteration 86: train_loss 1.0956472158432007
Iteration 87: train_loss 1.1108438968658447
Iteration 88: train_loss 1.135546326637268
Iteration 89: train_loss 1.1690751314163208
Iteration 90: train_loss 1.146546721458435
Iteration 91: train_loss 1.1548882722854614
Iteration 92: train_loss 1.1535494327545166
Iteration 93: train_loss 1.106013536453247
Iteration 94: train_loss 1.15080726146698
Iteration 95: train_loss 1.1147525310516357
Iteration 96: train_loss 1.0948259830474854
Iteration 97: train_loss 1.103239893913269
Iteration 98: train_loss 1.1068094968795776
Iteration 99: train_loss 1.075085163116455
Iteration 100: train_loss 1.1232831478118896
Iteration 101: train_loss 1.1047850847244263
Iteration 102: train_loss 1.0914416313171387
Iteration 103: train_loss 1.137245774269104
Iteration 104: train_loss 1.1586835384368896
Iteration 105: train_loss 1.1869597434997559
Iteration 106: train_loss 1.1565709114074707
Iteration 107: train_loss 1.1428918838500977
Iteration 108: train_loss 1.1350092887878418
Iteration 109: train_loss 1.1850104331970215
Iteration 110: train_loss 1.1448931694030762
Iteration 111: train_loss 1.176084041595459
Iteration 112: train_loss 1.2135449647903442
Iteration 113: train_loss 1.145921230316162
Iteration 114: train_loss 1.214500069618225
Iteration 115: train_loss 1.2211334705352783
Iteration 116: train_loss 1.1211974620819092
Iteration 117: train_loss 1.191145896911621
Iteration 118: train_loss 1.095440149307251
Iteration 119: train_loss 1.179738998413086
Iteration 120: train_loss 1.154746174812317
Iteration 121: train_loss 1.1431841850280762
Iteration 122: train_loss 1.1141937971115112
Iteration 123: train_loss 1.1309852600097656
Iteration 124: train_loss 1.1679039001464844
Iteration 125: train_loss 1.175297737121582
Iteration 126: train_loss 1.1348533630371094
Iteration 127: train_loss 1.1478676795959473
Iteration 128: train_loss 1.1318409442901611
Iteration 129: train_loss 1.1655255556106567
Iteration 130: train_loss 1.133741855621338
Iteration 131: train_loss 1.1614683866500854
Iteration 132: train_loss 1.150683879852295
Iteration 133: train_loss 1.1522817611694336
Iteration 134: train_loss 1.110506534576416
Iteration 135: train_loss 1.1269350051879883
Iteration 136: train_loss 1.1546005010604858
Iteration 137: train_loss 1.0945470333099365
Iteration 138: train_loss 1.1713457107543945
Iteration 139: train_loss 1.1333531141281128
Iteration 140: train_loss 1.0882800817489624
Iteration 141: train_loss 1.1637827157974243
Iteration 142: train_loss 1.1505763530731201
Iteration 143: train_loss 1.0911046266555786
Iteration 144: train_loss 1.1109639406204224
Iteration 145: train_loss 1.159430742263794
Iteration 146: train_loss 1.1200413703918457
Iteration 147: train_loss 1.0797003507614136
Iteration 148: train_loss 1.1609340906143188
Iteration 149: train_loss 1.1387648582458496
Iteration 150: train_loss 1.1547333002090454
Iteration 151: train_loss 1.1461389064788818
Iteration 152: train_loss 1.15236234664917
Iteration 153: train_loss 1.1469194889068604
Iteration 154: train_loss 1.171636939048767
Iteration 155: train_loss 1.1168336868286133
Iteration 156: train_loss 1.2141070365905762
Iteration 157: train_loss 1.1851485967636108
Iteration 158: train_loss 1.1843640804290771
Iteration 159: train_loss 1.1878167390823364
Iteration 160: train_loss 1.1828927993774414
Iteration 161: train_loss 1.1593785285949707
Iteration 162: train_loss 1.1884623765945435
Iteration 163: train_loss 1.2356210947036743
Iteration 164: train_loss 1.180721402168274
Iteration 165: train_loss 1.1614151000976562
Iteration 166: train_loss 1.165104866027832
Iteration 167: train_loss 1.1729196310043335
Iteration 168: train_loss 1.208864450454712
Iteration 169: train_loss 1.1255418062210083
Iteration 170: train_loss 1.0744047164916992
Iteration 171: train_loss 1.2039687633514404
Iteration 172: train_loss 1.1157407760620117
Iteration 173: train_loss 1.1824203729629517
Iteration 174: train_loss 1.2047828435897827
Iteration 175: train_loss 1.1396350860595703
Iteration 176: train_loss 1.1679084300994873
Iteration 177: train_loss 1.2046998739242554
Epoch 186: train_avg_loss 1.1510861061387143 eval_avg_acc: 0.34321871685829175 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:53:25] [32mIntermediate result: 0.34321871685829175  (Index 185)[0m
================Epoch: 187================
Iteration 1: train_loss 1.1246358156204224
Iteration 2: train_loss 1.120299220085144
Iteration 3: train_loss 1.1788852214813232
Iteration 4: train_loss 1.160123348236084
Iteration 5: train_loss 1.1091290712356567
Iteration 6: train_loss 1.1120123863220215
Iteration 7: train_loss 1.1652330160140991
Iteration 8: train_loss 1.0752357244491577
Iteration 9: train_loss 1.210070252418518
Iteration 10: train_loss 1.08646559715271
Iteration 11: train_loss 1.062620997428894
Iteration 12: train_loss 1.1358652114868164
Iteration 13: train_loss 1.064041256904602
Iteration 14: train_loss 1.1372671127319336
Iteration 15: train_loss 1.0815882682800293
Iteration 16: train_loss 1.1570063829421997
Iteration 17: train_loss 1.1147940158843994
Iteration 18: train_loss 1.0954560041427612
Iteration 19: train_loss 1.1137441396713257
Iteration 20: train_loss 1.1122806072235107
Iteration 21: train_loss 1.1098301410675049
Iteration 22: train_loss 1.1307599544525146
Iteration 23: train_loss 1.1093828678131104
Iteration 24: train_loss 1.1263096332550049
Iteration 25: train_loss 1.0868139266967773
Iteration 26: train_loss 1.1324981451034546
Iteration 27: train_loss 1.1079561710357666
Iteration 28: train_loss 1.1176337003707886
Iteration 29: train_loss 1.119860053062439
Iteration 30: train_loss 1.1127361059188843
Iteration 31: train_loss 1.1160097122192383
Iteration 32: train_loss 1.1290429830551147
Iteration 33: train_loss 1.0686055421829224
Iteration 34: train_loss 1.0992231369018555
Iteration 35: train_loss 1.1190528869628906
Iteration 36: train_loss 1.1617133617401123
Iteration 37: train_loss 1.0921134948730469
Iteration 38: train_loss 1.1235287189483643
Iteration 39: train_loss 1.1377251148223877
Iteration 40: train_loss 1.1471883058547974
Iteration 41: train_loss 1.1121236085891724
Iteration 42: train_loss 1.1070914268493652
Iteration 43: train_loss 1.0741323232650757
Iteration 44: train_loss 1.1278643608093262
Iteration 45: train_loss 1.1644920110702515
Iteration 46: train_loss 1.1834125518798828
Iteration 47: train_loss 1.144578456878662
Iteration 48: train_loss 1.1457520723342896
Iteration 49: train_loss 1.1331720352172852
Iteration 50: train_loss 1.1869460344314575
Iteration 51: train_loss 1.2393077611923218
Iteration 52: train_loss 1.1417587995529175
Iteration 53: train_loss 1.1684173345565796
Iteration 54: train_loss 1.1468627452850342
Iteration 55: train_loss 1.1509579420089722
Iteration 56: train_loss 1.1014901399612427
Iteration 57: train_loss 1.0899170637130737
Iteration 58: train_loss 1.1262778043746948
Iteration 59: train_loss 1.1000354290008545
Iteration 60: train_loss 1.1089197397232056
Iteration 61: train_loss 1.1929539442062378
Iteration 62: train_loss 1.1224614381790161
Iteration 63: train_loss 1.1539323329925537
Iteration 64: train_loss 1.0727952718734741
Iteration 65: train_loss 1.070163607597351
Iteration 66: train_loss 1.1180189847946167
Iteration 67: train_loss 1.076020359992981
Iteration 68: train_loss 1.091902732849121
Iteration 69: train_loss 1.1302419900894165
Iteration 70: train_loss 1.1801364421844482
Iteration 71: train_loss 1.1438484191894531
Iteration 72: train_loss 1.0907933712005615
Iteration 73: train_loss 1.067862629890442
Iteration 74: train_loss 1.1152832508087158
Iteration 75: train_loss 1.1014807224273682
Iteration 76: train_loss 1.1341263055801392
Iteration 77: train_loss 1.0886833667755127
Iteration 78: train_loss 1.1719610691070557
Iteration 79: train_loss 1.0974335670471191
Iteration 80: train_loss 1.1277039051055908
Iteration 81: train_loss 1.1181225776672363
Iteration 82: train_loss 1.0414576530456543
Iteration 83: train_loss 1.1248435974121094
Iteration 84: train_loss 1.188737154006958
Iteration 85: train_loss 1.1375997066497803
Iteration 86: train_loss 1.1638070344924927
Iteration 87: train_loss 1.1215251684188843
Iteration 88: train_loss 1.0913702249526978
Iteration 89: train_loss 1.0314252376556396
Iteration 90: train_loss 1.0877764225006104
Iteration 91: train_loss 1.1271055936813354
Iteration 92: train_loss 1.1125967502593994
Iteration 93: train_loss 1.1257895231246948
Iteration 94: train_loss 1.0876266956329346
Iteration 95: train_loss 1.103218913078308
Iteration 96: train_loss 1.147514820098877
Iteration 97: train_loss 1.047211766242981
Iteration 98: train_loss 1.1347891092300415
Iteration 99: train_loss 1.1263798475265503
Iteration 100: train_loss 1.1325428485870361
Iteration 101: train_loss 1.149001955986023
Iteration 102: train_loss 1.1385009288787842
Iteration 103: train_loss 1.1584845781326294
Iteration 104: train_loss 1.1492338180541992
Iteration 105: train_loss 1.0755484104156494
Iteration 106: train_loss 1.0975914001464844
Iteration 107: train_loss 1.1999484300613403
Iteration 108: train_loss 1.1262931823730469
Iteration 109: train_loss 1.1611372232437134
Iteration 110: train_loss 1.1136802434921265
Iteration 111: train_loss 1.1674329042434692
Iteration 112: train_loss 1.1528257131576538
Iteration 113: train_loss 1.129452109336853
Iteration 114: train_loss 1.1038613319396973
Iteration 115: train_loss 1.1791857481002808
Iteration 116: train_loss 1.1295210123062134
Iteration 117: train_loss 1.0652471780776978
Iteration 118: train_loss 1.1209934949874878
Iteration 119: train_loss 1.1418325901031494
Iteration 120: train_loss 1.085654616355896
Iteration 121: train_loss 1.1400716304779053
Iteration 122: train_loss 1.1614000797271729
Iteration 123: train_loss 1.110237956047058
Iteration 124: train_loss 1.0924711227416992
Iteration 125: train_loss 1.1247165203094482
Iteration 126: train_loss 1.105486273765564
Iteration 127: train_loss 1.1330537796020508
Iteration 128: train_loss 1.1619793176651
Iteration 129: train_loss 1.1277661323547363
Iteration 130: train_loss 1.1098666191101074
Iteration 131: train_loss 1.1114325523376465
Iteration 132: train_loss 1.1811503171920776
Iteration 133: train_loss 1.0854498147964478
Iteration 134: train_loss 1.0775197744369507
Iteration 135: train_loss 1.1418545246124268
Iteration 136: train_loss 1.1598988771438599
Iteration 137: train_loss 1.143868088722229
Iteration 138: train_loss 1.1468255519866943
Iteration 139: train_loss 1.12949800491333
Iteration 140: train_loss 1.1314830780029297
Iteration 141: train_loss 1.109852910041809
Iteration 142: train_loss 1.1412104368209839
Iteration 143: train_loss 1.065825343132019
Iteration 144: train_loss 1.1712779998779297
Iteration 145: train_loss 1.0865812301635742
Iteration 146: train_loss 1.1659785509109497
Iteration 147: train_loss 1.0995484590530396
Iteration 148: train_loss 1.102440595626831
Iteration 149: train_loss 1.1994996070861816
Iteration 150: train_loss 1.1701008081436157
Iteration 151: train_loss 1.1290186643600464
Iteration 152: train_loss 1.1325650215148926
Iteration 153: train_loss 1.1388002634048462
Iteration 154: train_loss 1.1478068828582764
Iteration 155: train_loss 1.0796215534210205
Iteration 156: train_loss 1.1305077075958252
Iteration 157: train_loss 1.1475340127944946
Iteration 158: train_loss 1.1694937944412231
Iteration 159: train_loss 1.0855993032455444
Iteration 160: train_loss 1.1487261056900024
Iteration 161: train_loss 1.1743658781051636
Iteration 162: train_loss 1.1673808097839355
Iteration 163: train_loss 1.1467972993850708
Iteration 164: train_loss 1.168684720993042
Iteration 165: train_loss 1.1428419351577759
Iteration 166: train_loss 1.2193642854690552
Iteration 167: train_loss 1.1098238229751587
Iteration 168: train_loss 1.1494905948638916
Iteration 169: train_loss 1.213459849357605
Iteration 170: train_loss 1.1895785331726074
Iteration 171: train_loss 1.1592028141021729
Iteration 172: train_loss 1.1459237337112427
Iteration 173: train_loss 1.1076617240905762
Iteration 174: train_loss 1.2042505741119385
Iteration 175: train_loss 1.1835055351257324
Iteration 176: train_loss 1.1329317092895508
Iteration 177: train_loss 1.1495121717453003
Epoch 187: train_avg_loss 1.1283938628805559 eval_avg_acc: 0.34005657827833957 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:54:07] [32mIntermediate result: 0.34005657827833957  (Index 186)[0m
================Epoch: 188================
Iteration 1: train_loss 1.1723291873931885
Iteration 2: train_loss 1.1860277652740479
Iteration 3: train_loss 1.0903385877609253
Iteration 4: train_loss 1.125924825668335
Iteration 5: train_loss 1.1824225187301636
Iteration 6: train_loss 1.1376540660858154
Iteration 7: train_loss 1.208155632019043
Iteration 8: train_loss 1.2021288871765137
Iteration 9: train_loss 1.1678606271743774
Iteration 10: train_loss 1.2378826141357422
Iteration 11: train_loss 1.1698733568191528
Iteration 12: train_loss 1.2534865140914917
Iteration 13: train_loss 1.1119064092636108
Iteration 14: train_loss 1.1247367858886719
Iteration 15: train_loss 1.122731328010559
Iteration 16: train_loss 1.1822668313980103
Iteration 17: train_loss 1.108419418334961
Iteration 18: train_loss 1.0928069353103638
Iteration 19: train_loss 1.1508469581604004
Iteration 20: train_loss 1.1258265972137451
Iteration 21: train_loss 1.1177507638931274
Iteration 22: train_loss 1.0994960069656372
Iteration 23: train_loss 1.089967131614685
Iteration 24: train_loss 1.1433135271072388
Iteration 25: train_loss 1.1014254093170166
Iteration 26: train_loss 1.1181906461715698
Iteration 27: train_loss 1.1532646417617798
Iteration 28: train_loss 1.1023335456848145
Iteration 29: train_loss 1.0737556219100952
Iteration 30: train_loss 1.180378794670105
Iteration 31: train_loss 1.1255393028259277
Iteration 32: train_loss 1.1316314935684204
Iteration 33: train_loss 1.130210518836975
Iteration 34: train_loss 1.1664739847183228
Iteration 35: train_loss 1.1992757320404053
Iteration 36: train_loss 1.0834897756576538
Iteration 37: train_loss 1.168898344039917
Iteration 38: train_loss 1.180806040763855
Iteration 39: train_loss 1.1416956186294556
Iteration 40: train_loss 1.1577836275100708
Iteration 41: train_loss 1.1370882987976074
Iteration 42: train_loss 1.1345685720443726
Iteration 43: train_loss 1.1404422521591187
Iteration 44: train_loss 1.145445466041565
Iteration 45: train_loss 1.102613925933838
Iteration 46: train_loss 1.1375635862350464
Iteration 47: train_loss 1.129611849784851
Iteration 48: train_loss 1.1943315267562866
Iteration 49: train_loss 1.180639624595642
Iteration 50: train_loss 1.1841681003570557
Iteration 51: train_loss 1.1735597848892212
Iteration 52: train_loss 1.1361613273620605
Iteration 53: train_loss 1.1714001893997192
Iteration 54: train_loss 1.0719187259674072
Iteration 55: train_loss 1.0825811624526978
Iteration 56: train_loss 1.1031004190444946
Iteration 57: train_loss 1.1432316303253174
Iteration 58: train_loss 1.14138925075531
Iteration 59: train_loss 1.1982320547103882
Iteration 60: train_loss 1.1615608930587769
Iteration 61: train_loss 1.1810708045959473
Iteration 62: train_loss 1.2056580781936646
Iteration 63: train_loss 1.0998836755752563
Iteration 64: train_loss 1.1645797491073608
Iteration 65: train_loss 1.181017518043518
Iteration 66: train_loss 1.049569845199585
Iteration 67: train_loss 1.0885895490646362
Iteration 68: train_loss 1.1238325834274292
Iteration 69: train_loss 1.1182546615600586
Iteration 70: train_loss 1.2137011289596558
Iteration 71: train_loss 1.1632800102233887
Iteration 72: train_loss 1.167289137840271
Iteration 73: train_loss 1.1527705192565918
Iteration 74: train_loss 1.1802173852920532
Iteration 75: train_loss 1.1930145025253296
Iteration 76: train_loss 1.1640102863311768
Iteration 77: train_loss 1.1320418119430542
Iteration 78: train_loss 1.2176604270935059
Iteration 79: train_loss 1.0822151899337769
Iteration 80: train_loss 1.1714286804199219
Iteration 81: train_loss 1.1251581907272339
Iteration 82: train_loss 1.1704519987106323
Iteration 83: train_loss 1.1899135112762451
Iteration 84: train_loss 1.2035601139068604
Iteration 85: train_loss 1.1793032884597778
Iteration 86: train_loss 1.13131844997406
Iteration 87: train_loss 1.2058639526367188
Iteration 88: train_loss 1.0716392993927002
Iteration 89: train_loss 1.1145765781402588
Iteration 90: train_loss 1.138713002204895
Iteration 91: train_loss 1.1195683479309082
Iteration 92: train_loss 1.1388767957687378
Iteration 93: train_loss 1.1237897872924805
Iteration 94: train_loss 1.1350688934326172
Iteration 95: train_loss 1.1466699838638306
Iteration 96: train_loss 1.1667015552520752
Iteration 97: train_loss 1.1200231313705444
Iteration 98: train_loss 1.1895045042037964
Iteration 99: train_loss 1.1384061574935913
Iteration 100: train_loss 1.1335846185684204
Iteration 101: train_loss 1.1229016780853271
Iteration 102: train_loss 1.078896403312683
Iteration 103: train_loss 1.1006137132644653
Iteration 104: train_loss 1.1780885457992554
Iteration 105: train_loss 1.0999001264572144
Iteration 106: train_loss 1.0811046361923218
Iteration 107: train_loss 1.1206573247909546
Iteration 108: train_loss 1.1294519901275635
Iteration 109: train_loss 1.11184823513031
Iteration 110: train_loss 1.0802637338638306
Iteration 111: train_loss 1.0769762992858887
Iteration 112: train_loss 1.0965851545333862
Iteration 113: train_loss 1.132271647453308
Iteration 114: train_loss 1.0506023168563843
Iteration 115: train_loss 1.092063307762146
Iteration 116: train_loss 1.1829568147659302
Iteration 117: train_loss 1.1750292778015137
Iteration 118: train_loss 1.152851939201355
Iteration 119: train_loss 1.2006385326385498
Iteration 120: train_loss 1.2177177667617798
Iteration 121: train_loss 1.1300837993621826
Iteration 122: train_loss 1.1701197624206543
Iteration 123: train_loss 1.1361268758773804
Iteration 124: train_loss 1.1316922903060913
Iteration 125: train_loss 1.1346383094787598
Iteration 126: train_loss 1.117867350578308
Iteration 127: train_loss 1.1691222190856934
Iteration 128: train_loss 1.069832682609558
Iteration 129: train_loss 1.148136019706726
Iteration 130: train_loss 1.1215966939926147
Iteration 131: train_loss 1.0697306394577026
Iteration 132: train_loss 1.110247254371643
Iteration 133: train_loss 1.1606123447418213
Iteration 134: train_loss 1.1842786073684692
Iteration 135: train_loss 1.1179125308990479
Iteration 136: train_loss 1.1438350677490234
Iteration 137: train_loss 1.1029452085494995
Iteration 138: train_loss 1.1432276964187622
Iteration 139: train_loss 1.1176700592041016
Iteration 140: train_loss 1.1632492542266846
Iteration 141: train_loss 1.0743898153305054
Iteration 142: train_loss 1.143314242362976
Iteration 143: train_loss 1.1392664909362793
Iteration 144: train_loss 1.1261073350906372
Iteration 145: train_loss 1.13463294506073
Iteration 146: train_loss 1.177079439163208
Iteration 147: train_loss 1.1590322256088257
Iteration 148: train_loss 1.1616533994674683
Iteration 149: train_loss 1.186153769493103
Iteration 150: train_loss 1.140289545059204
Iteration 151: train_loss 1.1862965822219849
Iteration 152: train_loss 1.1421128511428833
Iteration 153: train_loss 1.121913194656372
Iteration 154: train_loss 1.0914676189422607
Iteration 155: train_loss 1.0976201295852661
Iteration 156: train_loss 1.1340503692626953
Iteration 157: train_loss 1.0952224731445312
Iteration 158: train_loss 1.1168043613433838
Iteration 159: train_loss 1.1115113496780396
Iteration 160: train_loss 1.0671350955963135
Iteration 161: train_loss 1.1181941032409668
Iteration 162: train_loss 1.1535208225250244
Iteration 163: train_loss 1.0696310997009277
Iteration 164: train_loss 1.143970251083374
Iteration 165: train_loss 1.10092031955719
Iteration 166: train_loss 1.1263196468353271
Iteration 167: train_loss 1.1148700714111328
Iteration 168: train_loss 1.1486254930496216
Iteration 169: train_loss 1.1703922748565674
Iteration 170: train_loss 1.134124517440796
Iteration 171: train_loss 1.1572370529174805
Iteration 172: train_loss 1.1573232412338257
Iteration 173: train_loss 1.2071703672409058
Iteration 174: train_loss 1.1535645723342896
Iteration 175: train_loss 1.124093770980835
Iteration 176: train_loss 1.134878158569336
Iteration 177: train_loss 1.173802137374878
Epoch 188: train_avg_loss 1.140117107138122 eval_avg_acc: 0.34478464125088637 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:54:50] [32mIntermediate result: 0.34478464125088637  (Index 187)[0m
================Epoch: 189================
Iteration 1: train_loss 1.0925843715667725
Iteration 2: train_loss 1.089555263519287
Iteration 3: train_loss 1.1324968338012695
Iteration 4: train_loss 1.193779706954956
Iteration 5: train_loss 1.158189296722412
Iteration 6: train_loss 1.0712542533874512
Iteration 7: train_loss 1.150216817855835
Iteration 8: train_loss 1.176120638847351
Iteration 9: train_loss 1.1901376247406006
Iteration 10: train_loss 1.079393982887268
Iteration 11: train_loss 1.1017539501190186
Iteration 12: train_loss 1.1357433795928955
Iteration 13: train_loss 1.1927475929260254
Iteration 14: train_loss 1.1117782592773438
Iteration 15: train_loss 1.0824041366577148
Iteration 16: train_loss 1.1732831001281738
Iteration 17: train_loss 1.143035888671875
Iteration 18: train_loss 1.10868239402771
Iteration 19: train_loss 1.1015228033065796
Iteration 20: train_loss 1.0558973550796509
Iteration 21: train_loss 1.0727378129959106
Iteration 22: train_loss 1.0847290754318237
Iteration 23: train_loss 1.086365818977356
Iteration 24: train_loss 1.0650794506072998
Iteration 25: train_loss 1.0645259618759155
Iteration 26: train_loss 1.1239659786224365
Iteration 27: train_loss 1.0760955810546875
Iteration 28: train_loss 1.073596715927124
Iteration 29: train_loss 1.1238573789596558
Iteration 30: train_loss 1.1174771785736084
Iteration 31: train_loss 1.0883991718292236
Iteration 32: train_loss 1.098142385482788
Iteration 33: train_loss 1.0906195640563965
Iteration 34: train_loss 1.0891340970993042
Iteration 35: train_loss 1.0925240516662598
Iteration 36: train_loss 1.0851854085922241
Iteration 37: train_loss 1.1442089080810547
Iteration 38: train_loss 1.2270026206970215
Iteration 39: train_loss 1.1248711347579956
Iteration 40: train_loss 1.215919017791748
Iteration 41: train_loss 1.0505850315093994
Iteration 42: train_loss 1.142897605895996
Iteration 43: train_loss 1.1463919878005981
Iteration 44: train_loss 1.1616584062576294
Iteration 45: train_loss 1.1548398733139038
Iteration 46: train_loss 1.1753735542297363
Iteration 47: train_loss 1.1672285795211792
Iteration 48: train_loss 1.1419808864593506
Iteration 49: train_loss 1.1218430995941162
Iteration 50: train_loss 1.1078397035598755
Iteration 51: train_loss 1.1718496084213257
Iteration 52: train_loss 1.1199414730072021
Iteration 53: train_loss 1.1011074781417847
Iteration 54: train_loss 1.172294020652771
Iteration 55: train_loss 1.11904776096344
Iteration 56: train_loss 1.1265206336975098
Iteration 57: train_loss 1.1881844997406006
Iteration 58: train_loss 1.1326630115509033
Iteration 59: train_loss 1.091872215270996
Iteration 60: train_loss 1.12336003780365
Iteration 61: train_loss 1.111266016960144
Iteration 62: train_loss 1.095934510231018
Iteration 63: train_loss 1.135925531387329
Iteration 64: train_loss 1.1720213890075684
Iteration 65: train_loss 1.1261537075042725
Iteration 66: train_loss 1.137372612953186
Iteration 67: train_loss 1.1372703313827515
Iteration 68: train_loss 1.144274115562439
Iteration 69: train_loss 1.125964641571045
Iteration 70: train_loss 1.0796735286712646
Iteration 71: train_loss 1.122423768043518
Iteration 72: train_loss 1.161302089691162
Iteration 73: train_loss 1.056246042251587
Iteration 74: train_loss 1.1089208126068115
Iteration 75: train_loss 1.1208016872406006
Iteration 76: train_loss 1.1523075103759766
Iteration 77: train_loss 1.1235514879226685
Iteration 78: train_loss 1.1529343128204346
Iteration 79: train_loss 1.1245238780975342
Iteration 80: train_loss 1.1075961589813232
Iteration 81: train_loss 1.1013264656066895
Iteration 82: train_loss 1.0792007446289062
Iteration 83: train_loss 1.0914585590362549
Iteration 84: train_loss 1.1067126989364624
Iteration 85: train_loss 1.1542834043502808
Iteration 86: train_loss 1.1259137392044067
Iteration 87: train_loss 1.147965431213379
Iteration 88: train_loss 1.1853845119476318
Iteration 89: train_loss 1.0948371887207031
Iteration 90: train_loss 1.178353190422058
Iteration 91: train_loss 1.1203755140304565
Iteration 92: train_loss 1.196481466293335
Iteration 93: train_loss 1.1727983951568604
Iteration 94: train_loss 1.140071988105774
Iteration 95: train_loss 1.1301519870758057
Iteration 96: train_loss 1.1259695291519165
Iteration 97: train_loss 1.1512175798416138
Iteration 98: train_loss 1.1622140407562256
Iteration 99: train_loss 1.2012147903442383
Iteration 100: train_loss 1.1582220792770386
Iteration 101: train_loss 1.1519873142242432
Iteration 102: train_loss 1.1369441747665405
Iteration 103: train_loss 1.0990231037139893
Iteration 104: train_loss 1.084744930267334
Iteration 105: train_loss 1.1488949060440063
Iteration 106: train_loss 1.1372108459472656
Iteration 107: train_loss 1.189945101737976
Iteration 108: train_loss 1.1207385063171387
Iteration 109: train_loss 1.0931532382965088
Iteration 110: train_loss 1.1172231435775757
Iteration 111: train_loss 1.1265252828598022
Iteration 112: train_loss 1.1118345260620117
Iteration 113: train_loss 1.2196877002716064
Iteration 114: train_loss 1.1600046157836914
Iteration 115: train_loss 1.1369013786315918
Iteration 116: train_loss 1.189638376235962
Iteration 117: train_loss 1.146537184715271
Iteration 118: train_loss 1.1817742586135864
Iteration 119: train_loss 1.1402970552444458
Iteration 120: train_loss 1.1252001523971558
Iteration 121: train_loss 1.1404318809509277
Iteration 122: train_loss 1.1372047662734985
Iteration 123: train_loss 1.1603131294250488
Iteration 124: train_loss 1.1884289979934692
Iteration 125: train_loss 1.1252515316009521
Iteration 126: train_loss 1.1445375680923462
Iteration 127: train_loss 1.1939771175384521
Iteration 128: train_loss 1.1340525150299072
Iteration 129: train_loss 1.180483102798462
Iteration 130: train_loss 1.1558314561843872
Iteration 131: train_loss 1.0960837602615356
Iteration 132: train_loss 1.0831844806671143
Iteration 133: train_loss 1.1405364274978638
Iteration 134: train_loss 1.1243613958358765
Iteration 135: train_loss 1.1597777605056763
Iteration 136: train_loss 1.1256234645843506
Iteration 137: train_loss 1.1468889713287354
Iteration 138: train_loss 1.12360417842865
Iteration 139: train_loss 1.1692371368408203
Iteration 140: train_loss 1.2091888189315796
Iteration 141: train_loss 1.1445534229278564
Iteration 142: train_loss 1.1265170574188232
Iteration 143: train_loss 1.1531201601028442
Iteration 144: train_loss 1.1339689493179321
Iteration 145: train_loss 1.0628447532653809
Iteration 146: train_loss 1.1322715282440186
Iteration 147: train_loss 1.1228740215301514
Iteration 148: train_loss 1.1682183742523193
Iteration 149: train_loss 1.120639681816101
Iteration 150: train_loss 1.1642240285873413
Iteration 151: train_loss 1.1367127895355225
Iteration 152: train_loss 1.127813458442688
Iteration 153: train_loss 1.0950888395309448
Iteration 154: train_loss 1.1105082035064697
Iteration 155: train_loss 1.1387943029403687
Iteration 156: train_loss 1.1002360582351685
Iteration 157: train_loss 1.1507484912872314
Iteration 158: train_loss 1.1292396783828735
Iteration 159: train_loss 1.1509920358657837
Iteration 160: train_loss 1.1311044692993164
Iteration 161: train_loss 1.1592580080032349
Iteration 162: train_loss 1.1092137098312378
Iteration 163: train_loss 1.1325337886810303
Iteration 164: train_loss 1.1406766176223755
Iteration 165: train_loss 1.1203535795211792
Iteration 166: train_loss 1.1854695081710815
Iteration 167: train_loss 1.1061429977416992
Iteration 168: train_loss 1.1437227725982666
Iteration 169: train_loss 1.157202124595642
Iteration 170: train_loss 1.1651266813278198
Iteration 171: train_loss 1.169808268547058
Iteration 172: train_loss 1.1584011316299438
Iteration 173: train_loss 1.124152660369873
Iteration 174: train_loss 1.2085530757904053
Iteration 175: train_loss 1.1535013914108276
Iteration 176: train_loss 1.175536036491394
Iteration 177: train_loss 1.1301515102386475
Epoch 189: train_avg_loss 1.1334500016465698 eval_avg_acc: 0.3414521230020584 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:55:32] [32mIntermediate result: 0.3414521230020584  (Index 188)[0m
================Epoch: 190================
Iteration 1: train_loss 1.1803826093673706
Iteration 2: train_loss 1.1456199884414673
Iteration 3: train_loss 1.1606700420379639
Iteration 4: train_loss 1.146600365638733
Iteration 5: train_loss 1.148269534111023
Iteration 6: train_loss 1.1191834211349487
Iteration 7: train_loss 1.2013758420944214
Iteration 8: train_loss 1.0993441343307495
Iteration 9: train_loss 1.1485261917114258
Iteration 10: train_loss 1.129359245300293
Iteration 11: train_loss 1.2322105169296265
Iteration 12: train_loss 1.1591174602508545
Iteration 13: train_loss 1.181617021560669
Iteration 14: train_loss 1.1602176427841187
Iteration 15: train_loss 1.1593044996261597
Iteration 16: train_loss 1.156159520149231
Iteration 17: train_loss 1.18572199344635
Iteration 18: train_loss 1.1451761722564697
Iteration 19: train_loss 1.16031813621521
Iteration 20: train_loss 1.230120301246643
Iteration 21: train_loss 1.1878976821899414
Iteration 22: train_loss 1.086246132850647
Iteration 23: train_loss 1.0975395441055298
Iteration 24: train_loss 1.202990174293518
Iteration 25: train_loss 1.144959568977356
Iteration 26: train_loss 1.1082792282104492
Iteration 27: train_loss 1.1559697389602661
Iteration 28: train_loss 1.1480412483215332
Iteration 29: train_loss 1.0778666734695435
Iteration 30: train_loss 1.1022197008132935
Iteration 31: train_loss 1.179947853088379
Iteration 32: train_loss 1.150921106338501
Iteration 33: train_loss 1.1616976261138916
Iteration 34: train_loss 1.0582118034362793
Iteration 35: train_loss 1.0932116508483887
Iteration 36: train_loss 1.1239482164382935
Iteration 37: train_loss 1.1096484661102295
Iteration 38: train_loss 1.1230143308639526
Iteration 39: train_loss 1.1350950002670288
Iteration 40: train_loss 1.1168831586837769
Iteration 41: train_loss 1.1135897636413574
Iteration 42: train_loss 1.1607990264892578
Iteration 43: train_loss 1.1511592864990234
Iteration 44: train_loss 1.2123159170150757
Iteration 45: train_loss 1.1868003606796265
Iteration 46: train_loss 1.115112543106079
Iteration 47: train_loss 1.1387306451797485
Iteration 48: train_loss 1.2030730247497559
Iteration 49: train_loss 1.1386624574661255
Iteration 50: train_loss 1.1413867473602295
Iteration 51: train_loss 1.184478998184204
Iteration 52: train_loss 1.1434049606323242
Iteration 53: train_loss 1.170894742012024
Iteration 54: train_loss 1.1291593313217163
Iteration 55: train_loss 1.1345638036727905
Iteration 56: train_loss 1.1594104766845703
Iteration 57: train_loss 1.1421743631362915
Iteration 58: train_loss 1.1653430461883545
Iteration 59: train_loss 1.1640996932983398
Iteration 60: train_loss 1.1319829225540161
Iteration 61: train_loss 1.1599771976470947
Iteration 62: train_loss 1.1032884120941162
Iteration 63: train_loss 1.1211193799972534
Iteration 64: train_loss 1.1298823356628418
Iteration 65: train_loss 1.1706838607788086
Iteration 66: train_loss 1.1565735340118408
Iteration 67: train_loss 1.1601873636245728
Iteration 68: train_loss 1.1994746923446655
Iteration 69: train_loss 1.1510018110275269
Iteration 70: train_loss 1.1358263492584229
Iteration 71: train_loss 1.1004317998886108
Iteration 72: train_loss 1.151042103767395
Iteration 73: train_loss 1.1672160625457764
Iteration 74: train_loss 1.118076205253601
Iteration 75: train_loss 1.162169098854065
Iteration 76: train_loss 1.1030558347702026
Iteration 77: train_loss 1.1110447645187378
Iteration 78: train_loss 1.1543060541152954
Iteration 79: train_loss 1.1854456663131714
Iteration 80: train_loss 1.104102611541748
Iteration 81: train_loss 1.1710679531097412
Iteration 82: train_loss 1.143988013267517
Iteration 83: train_loss 1.1283867359161377
Iteration 84: train_loss 1.1296619176864624
Iteration 85: train_loss 1.1561713218688965
Iteration 86: train_loss 1.1545031070709229
Iteration 87: train_loss 1.1562870740890503
Iteration 88: train_loss 1.149183988571167
Iteration 89: train_loss 1.1255710124969482
Iteration 90: train_loss 1.1409375667572021
Iteration 91: train_loss 1.1787643432617188
Iteration 92: train_loss 1.1480787992477417
Iteration 93: train_loss 1.163421630859375
Iteration 94: train_loss 1.1674518585205078
Iteration 95: train_loss 1.0635040998458862
Iteration 96: train_loss 1.1653138399124146
Iteration 97: train_loss 1.1374669075012207
Iteration 98: train_loss 1.147863745689392
Iteration 99: train_loss 1.1451653242111206
Iteration 100: train_loss 1.114678144454956
Iteration 101: train_loss 1.1285203695297241
Iteration 102: train_loss 1.1427390575408936
Iteration 103: train_loss 1.1095632314682007
Iteration 104: train_loss 1.1760945320129395
Iteration 105: train_loss 1.1609057188034058
Iteration 106: train_loss 1.1123433113098145
Iteration 107: train_loss 1.1482881307601929
Iteration 108: train_loss 1.1189905405044556
Iteration 109: train_loss 1.238263726234436
Iteration 110: train_loss 1.170087218284607
Iteration 111: train_loss 1.153388500213623
Iteration 112: train_loss 1.115238904953003
Iteration 113: train_loss 1.17406165599823
Iteration 114: train_loss 1.1921368837356567
Iteration 115: train_loss 1.2037516832351685
Iteration 116: train_loss 1.1444311141967773
Iteration 117: train_loss 1.2418863773345947
Iteration 118: train_loss 1.188607096672058
Iteration 119: train_loss 1.173263669013977
Iteration 120: train_loss 1.1421858072280884
Iteration 121: train_loss 1.1467466354370117
Iteration 122: train_loss 1.226090431213379
Iteration 123: train_loss 1.1734737157821655
Iteration 124: train_loss 1.1735153198242188
Iteration 125: train_loss 1.1572012901306152
Iteration 126: train_loss 1.2200369834899902
Iteration 127: train_loss 1.181405782699585
Iteration 128: train_loss 1.2104548215866089
Iteration 129: train_loss 1.168570876121521
Iteration 130: train_loss 1.2030669450759888
Iteration 131: train_loss 1.1426419019699097
Iteration 132: train_loss 1.1302719116210938
Iteration 133: train_loss 1.1412055492401123
Iteration 134: train_loss 1.1657532453536987
Iteration 135: train_loss 1.112671971321106
Iteration 136: train_loss 1.1378132104873657
Iteration 137: train_loss 1.145119309425354
Iteration 138: train_loss 1.1106680631637573
Iteration 139: train_loss 1.14839506149292
Iteration 140: train_loss 1.1136330366134644
Iteration 141: train_loss 1.2301297187805176
Iteration 142: train_loss 1.139013648033142
Iteration 143: train_loss 1.2426130771636963
Iteration 144: train_loss 1.100069284439087
Iteration 145: train_loss 1.122002124786377
Iteration 146: train_loss 1.1292616128921509
Iteration 147: train_loss 1.0995854139328003
Iteration 148: train_loss 1.1299017667770386
Iteration 149: train_loss 1.1283217668533325
Iteration 150: train_loss 1.083545207977295
Iteration 151: train_loss 1.1328625679016113
Iteration 152: train_loss 1.0660556554794312
Iteration 153: train_loss 1.1154171228408813
Iteration 154: train_loss 1.142655849456787
Iteration 155: train_loss 1.1397730112075806
Iteration 156: train_loss 1.2132594585418701
Iteration 157: train_loss 1.0996408462524414
Iteration 158: train_loss 1.1054396629333496
Iteration 159: train_loss 1.1194566488265991
Iteration 160: train_loss 1.1440556049346924
Iteration 161: train_loss 1.1584672927856445
Iteration 162: train_loss 1.1006606817245483
Iteration 163: train_loss 1.1196858882904053
Iteration 164: train_loss 1.2217644453048706
Iteration 165: train_loss 1.1690746545791626
Iteration 166: train_loss 1.113684058189392
Iteration 167: train_loss 1.1525851488113403
Iteration 168: train_loss 1.1164122819900513
Iteration 169: train_loss 1.0871318578720093
Iteration 170: train_loss 1.1780775785446167
Iteration 171: train_loss 1.132277011871338
Iteration 172: train_loss 1.1225563287734985
Iteration 173: train_loss 1.164641261100769
Iteration 174: train_loss 1.1067274808883667
Iteration 175: train_loss 1.159575343132019
Iteration 176: train_loss 1.1058286428451538
Iteration 177: train_loss 1.118910551071167
Epoch 190: train_avg_loss 1.1473898436390073 eval_avg_acc: 0.3426959491342599 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:56:14] [32mIntermediate result: 0.3426959491342599  (Index 189)[0m
================Epoch: 191================
Iteration 1: train_loss 1.1278414726257324
Iteration 2: train_loss 1.1136332750320435
Iteration 3: train_loss 1.1279759407043457
Iteration 4: train_loss 1.1625622510910034
Iteration 5: train_loss 1.0791109800338745
Iteration 6: train_loss 1.1337451934814453
Iteration 7: train_loss 1.0822947025299072
Iteration 8: train_loss 1.1419819593429565
Iteration 9: train_loss 1.1267175674438477
Iteration 10: train_loss 1.1501216888427734
Iteration 11: train_loss 1.1022781133651733
Iteration 12: train_loss 1.1360456943511963
Iteration 13: train_loss 1.1156541109085083
Iteration 14: train_loss 1.1457545757293701
Iteration 15: train_loss 1.103201985359192
Iteration 16: train_loss 1.1675267219543457
Iteration 17: train_loss 1.1337411403656006
Iteration 18: train_loss 1.1101576089859009
Iteration 19: train_loss 1.094326376914978
Iteration 20: train_loss 1.111322045326233
Iteration 21: train_loss 1.151828646659851
Iteration 22: train_loss 1.1539790630340576
Iteration 23: train_loss 1.1247692108154297
Iteration 24: train_loss 1.1068133115768433
Iteration 25: train_loss 1.0986223220825195
Iteration 26: train_loss 1.1108596324920654
Iteration 27: train_loss 1.0523898601531982
Iteration 28: train_loss 1.091719150543213
Iteration 29: train_loss 1.0756809711456299
Iteration 30: train_loss 1.1146031618118286
Iteration 31: train_loss 1.0456924438476562
Iteration 32: train_loss 1.1062967777252197
Iteration 33: train_loss 1.1227511167526245
Iteration 34: train_loss 1.0679265260696411
Iteration 35: train_loss 1.118979811668396
Iteration 36: train_loss 1.1214646100997925
Iteration 37: train_loss 1.1421308517456055
Iteration 38: train_loss 1.1191669702529907
Iteration 39: train_loss 1.1388070583343506
Iteration 40: train_loss 1.124616265296936
Iteration 41: train_loss 1.0683096647262573
Iteration 42: train_loss 1.094692587852478
Iteration 43: train_loss 1.094199776649475
Iteration 44: train_loss 1.091023325920105
Iteration 45: train_loss 1.1113970279693604
Iteration 46: train_loss 1.1358968019485474
Iteration 47: train_loss 1.0607997179031372
Iteration 48: train_loss 1.1370412111282349
Iteration 49: train_loss 1.1282813549041748
Iteration 50: train_loss 1.0885679721832275
Iteration 51: train_loss 1.113349437713623
Iteration 52: train_loss 1.1162633895874023
Iteration 53: train_loss 1.1483664512634277
Iteration 54: train_loss 1.0812212228775024
Iteration 55: train_loss 1.1658257246017456
Iteration 56: train_loss 1.1064245700836182
Iteration 57: train_loss 1.1576707363128662
Iteration 58: train_loss 1.0667228698730469
Iteration 59: train_loss 1.0842255353927612
Iteration 60: train_loss 1.106077790260315
Iteration 61: train_loss 1.095009207725525
Iteration 62: train_loss 1.1440740823745728
Iteration 63: train_loss 1.1777204275131226
Iteration 64: train_loss 1.1014468669891357
Iteration 65: train_loss 1.1314644813537598
Iteration 66: train_loss 1.0908902883529663
Iteration 67: train_loss 1.1691474914550781
Iteration 68: train_loss 1.108357310295105
Iteration 69: train_loss 1.116754174232483
Iteration 70: train_loss 1.1440213918685913
Iteration 71: train_loss 1.10330331325531
Iteration 72: train_loss 1.0717971324920654
Iteration 73: train_loss 1.1272540092468262
Iteration 74: train_loss 1.113381028175354
Iteration 75: train_loss 1.1099481582641602
Iteration 76: train_loss 1.0986696481704712
Iteration 77: train_loss 1.1488343477249146
Iteration 78: train_loss 1.0993090867996216
Iteration 79: train_loss 1.1257826089859009
Iteration 80: train_loss 1.1222001314163208
Iteration 81: train_loss 1.094896912574768
Iteration 82: train_loss 1.1466623544692993
Iteration 83: train_loss 1.1173409223556519
Iteration 84: train_loss 1.1900352239608765
Iteration 85: train_loss 1.1597137451171875
Iteration 86: train_loss 1.175636887550354
Iteration 87: train_loss 1.1473233699798584
Iteration 88: train_loss 1.1329978704452515
Iteration 89: train_loss 1.1216472387313843
Iteration 90: train_loss 1.182408094406128
Iteration 91: train_loss 1.1113942861557007
Iteration 92: train_loss 1.151675820350647
Iteration 93: train_loss 1.095247507095337
Iteration 94: train_loss 1.114282250404358
Iteration 95: train_loss 1.1785765886306763
Iteration 96: train_loss 1.1147637367248535
Iteration 97: train_loss 1.1174721717834473
Iteration 98: train_loss 1.1271172761917114
Iteration 99: train_loss 1.1599814891815186
Iteration 100: train_loss 1.179958462715149
Iteration 101: train_loss 1.1310523748397827
Iteration 102: train_loss 1.1145402193069458
Iteration 103: train_loss 1.1627070903778076
Iteration 104: train_loss 1.1196345090866089
Iteration 105: train_loss 1.1495689153671265
Iteration 106: train_loss 1.1547712087631226
Iteration 107: train_loss 1.2045152187347412
Iteration 108: train_loss 1.1577218770980835
Iteration 109: train_loss 1.1420190334320068
Iteration 110: train_loss 1.1064374446868896
Iteration 111: train_loss 1.107921838760376
Iteration 112: train_loss 1.1349420547485352
Iteration 113: train_loss 1.1012710332870483
Iteration 114: train_loss 1.092231273651123
Iteration 115: train_loss 1.1457997560501099
Iteration 116: train_loss 1.1459782123565674
Iteration 117: train_loss 1.1320956945419312
Iteration 118: train_loss 1.0778800249099731
Iteration 119: train_loss 1.1041210889816284
Iteration 120: train_loss 1.008151650428772
Iteration 121: train_loss 1.096357822418213
Iteration 122: train_loss 1.1730376482009888
Iteration 123: train_loss 1.0488839149475098
Iteration 124: train_loss 1.1898552179336548
Iteration 125: train_loss 1.1486709117889404
Iteration 126: train_loss 1.1071412563323975
Iteration 127: train_loss 1.1121572256088257
Iteration 128: train_loss 1.1477769613265991
Iteration 129: train_loss 1.1426924467086792
Iteration 130: train_loss 1.1346460580825806
Iteration 131: train_loss 1.1578896045684814
Iteration 132: train_loss 1.0883197784423828
Iteration 133: train_loss 1.1257448196411133
Iteration 134: train_loss 1.1780190467834473
Iteration 135: train_loss 1.1118320226669312
Iteration 136: train_loss 1.168773889541626
Iteration 137: train_loss 1.1217213869094849
Iteration 138: train_loss 1.131867527961731
Iteration 139: train_loss 1.115393042564392
Iteration 140: train_loss 1.1293524503707886
Iteration 141: train_loss 1.1992532014846802
Iteration 142: train_loss 1.1560637950897217
Iteration 143: train_loss 1.1129900217056274
Iteration 144: train_loss 1.1339082717895508
Iteration 145: train_loss 1.0890837907791138
Iteration 146: train_loss 1.1036252975463867
Iteration 147: train_loss 1.165649175643921
Iteration 148: train_loss 1.1785070896148682
Iteration 149: train_loss 1.147411823272705
Iteration 150: train_loss 1.1552448272705078
Iteration 151: train_loss 1.1415119171142578
Iteration 152: train_loss 1.1512186527252197
Iteration 153: train_loss 1.1340208053588867
Iteration 154: train_loss 1.158327341079712
Iteration 155: train_loss 1.1568820476531982
Iteration 156: train_loss 1.1799383163452148
Iteration 157: train_loss 1.1781805753707886
Iteration 158: train_loss 1.1088124513626099
Iteration 159: train_loss 1.1938331127166748
Iteration 160: train_loss 1.1381545066833496
Iteration 161: train_loss 1.1213947534561157
Iteration 162: train_loss 1.0808733701705933
Iteration 163: train_loss 1.1559925079345703
Iteration 164: train_loss 1.1150422096252441
Iteration 165: train_loss 1.1500226259231567
Iteration 166: train_loss 1.14276123046875
Iteration 167: train_loss 1.12935209274292
Iteration 168: train_loss 1.1529576778411865
Iteration 169: train_loss 1.0894882678985596
Iteration 170: train_loss 1.1544663906097412
Iteration 171: train_loss 1.1556280851364136
Iteration 172: train_loss 1.1190581321716309
Iteration 173: train_loss 1.1825941801071167
Iteration 174: train_loss 1.1585659980773926
Iteration 175: train_loss 1.1984498500823975
Iteration 176: train_loss 1.1001877784729004
Iteration 177: train_loss 1.1716090440750122
Epoch 191: train_avg_loss 1.1272005677896704 eval_avg_acc: 0.3439428093370886 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:56:55] [32mIntermediate result: 0.3439428093370886  (Index 190)[0m
================Epoch: 192================
Iteration 1: train_loss 1.1327526569366455
Iteration 2: train_loss 1.2262659072875977
Iteration 3: train_loss 1.1429758071899414
Iteration 4: train_loss 1.1413698196411133
Iteration 5: train_loss 1.2256449460983276
Iteration 6: train_loss 1.2228209972381592
Iteration 7: train_loss 1.2294189929962158
Iteration 8: train_loss 1.1753456592559814
Iteration 9: train_loss 1.1799396276474
Iteration 10: train_loss 1.1857478618621826
Iteration 11: train_loss 1.1649880409240723
Iteration 12: train_loss 1.1072685718536377
Iteration 13: train_loss 1.139088749885559
Iteration 14: train_loss 1.1236932277679443
Iteration 15: train_loss 1.1725865602493286
Iteration 16: train_loss 1.1308232545852661
Iteration 17: train_loss 1.0566455125808716
Iteration 18: train_loss 1.131301760673523
Iteration 19: train_loss 1.0957671403884888
Iteration 20: train_loss 1.09047269821167
Iteration 21: train_loss 1.0909721851348877
Iteration 22: train_loss 1.1070506572723389
Iteration 23: train_loss 1.1338406801223755
Iteration 24: train_loss 1.1312627792358398
Iteration 25: train_loss 1.1614034175872803
Iteration 26: train_loss 1.0829596519470215
Iteration 27: train_loss 1.0360468626022339
Iteration 28: train_loss 1.080350399017334
Iteration 29: train_loss 1.0737700462341309
Iteration 30: train_loss 1.1316049098968506
Iteration 31: train_loss 1.1425894498825073
Iteration 32: train_loss 1.0943206548690796
Iteration 33: train_loss 1.0686317682266235
Iteration 34: train_loss 1.1341661214828491
Iteration 35: train_loss 1.1140573024749756
Iteration 36: train_loss 1.0449963808059692
Iteration 37: train_loss 1.1443688869476318
Iteration 38: train_loss 1.0904619693756104
Iteration 39: train_loss 1.1119651794433594
Iteration 40: train_loss 1.1062113046646118
Iteration 41: train_loss 1.1038469076156616
Iteration 42: train_loss 1.14712393283844
Iteration 43: train_loss 1.09019935131073
Iteration 44: train_loss 1.102642297744751
Iteration 45: train_loss 1.1550337076187134
Iteration 46: train_loss 1.0703827142715454
Iteration 47: train_loss 1.136146068572998
Iteration 48: train_loss 1.132144808769226
Iteration 49: train_loss 1.1091450452804565
Iteration 50: train_loss 1.101012110710144
Iteration 51: train_loss 1.1525979042053223
Iteration 52: train_loss 1.0802464485168457
Iteration 53: train_loss 1.1039670705795288
Iteration 54: train_loss 1.1360340118408203
Iteration 55: train_loss 1.1025009155273438
Iteration 56: train_loss 1.0646476745605469
Iteration 57: train_loss 1.1437352895736694
Iteration 58: train_loss 1.139365553855896
Iteration 59: train_loss 1.0889365673065186
Iteration 60: train_loss 1.0965059995651245
Iteration 61: train_loss 1.1093964576721191
Iteration 62: train_loss 1.0890703201293945
Iteration 63: train_loss 1.0744980573654175
Iteration 64: train_loss 1.0936470031738281
Iteration 65: train_loss 1.0783528089523315
Iteration 66: train_loss 1.0453864336013794
Iteration 67: train_loss 1.055182695388794
Iteration 68: train_loss 1.087915301322937
Iteration 69: train_loss 1.1124073266983032
Iteration 70: train_loss 1.1591373682022095
Iteration 71: train_loss 1.1075094938278198
Iteration 72: train_loss 1.0936520099639893
Iteration 73: train_loss 1.0825715065002441
Iteration 74: train_loss 1.0823261737823486
Iteration 75: train_loss 1.0638470649719238
Iteration 76: train_loss 1.115311622619629
Iteration 77: train_loss 1.1309415102005005
Iteration 78: train_loss 1.1175569295883179
Iteration 79: train_loss 1.1517945528030396
Iteration 80: train_loss 1.1183918714523315
Iteration 81: train_loss 1.091639757156372
Iteration 82: train_loss 1.109331727027893
Iteration 83: train_loss 1.0517449378967285
Iteration 84: train_loss 1.135198950767517
Iteration 85: train_loss 1.1260946989059448
Iteration 86: train_loss 1.079703450202942
Iteration 87: train_loss 1.0956649780273438
Iteration 88: train_loss 1.147845983505249
Iteration 89: train_loss 1.0777766704559326
Iteration 90: train_loss 1.1270251274108887
Iteration 91: train_loss 1.1127735376358032
Iteration 92: train_loss 1.0959558486938477
Iteration 93: train_loss 1.0773118734359741
Iteration 94: train_loss 1.0970431566238403
Iteration 95: train_loss 1.1324535608291626
Iteration 96: train_loss 1.1396535634994507
Iteration 97: train_loss 1.120688796043396
Iteration 98: train_loss 1.0850541591644287
Iteration 99: train_loss 1.0927520990371704
Iteration 100: train_loss 1.1077897548675537
Iteration 101: train_loss 1.0971229076385498
Iteration 102: train_loss 1.1238034963607788
Iteration 103: train_loss 1.1228104829788208
Iteration 104: train_loss 1.1413549184799194
Iteration 105: train_loss 1.1593297719955444
Iteration 106: train_loss 1.1228523254394531
Iteration 107: train_loss 1.181420087814331
Iteration 108: train_loss 1.1268243789672852
Iteration 109: train_loss 1.1543983221054077
Iteration 110: train_loss 1.1402546167373657
Iteration 111: train_loss 1.1501314640045166
Iteration 112: train_loss 1.1692835092544556
Iteration 113: train_loss 1.1426746845245361
Iteration 114: train_loss 1.1320905685424805
Iteration 115: train_loss 1.101096272468567
Iteration 116: train_loss 1.182830572128296
Iteration 117: train_loss 1.1396818161010742
Iteration 118: train_loss 1.1178674697875977
Iteration 119: train_loss 1.1575729846954346
Iteration 120: train_loss 1.105188250541687
Iteration 121: train_loss 1.1393511295318604
Iteration 122: train_loss 1.0970721244812012
Iteration 123: train_loss 1.1365933418273926
Iteration 124: train_loss 1.168208360671997
Iteration 125: train_loss 1.097140908241272
Iteration 126: train_loss 1.080723524093628
Iteration 127: train_loss 1.1336641311645508
Iteration 128: train_loss 1.1778035163879395
Iteration 129: train_loss 1.1351535320281982
Iteration 130: train_loss 1.1181409358978271
Iteration 131: train_loss 1.1294082403182983
Iteration 132: train_loss 1.1234090328216553
Iteration 133: train_loss 1.1276921033859253
Iteration 134: train_loss 1.108742356300354
Iteration 135: train_loss 1.0971165895462036
Iteration 136: train_loss 1.1030679941177368
Iteration 137: train_loss 1.121372103691101
Iteration 138: train_loss 1.0919140577316284
Iteration 139: train_loss 1.169748067855835
Iteration 140: train_loss 1.150645136833191
Iteration 141: train_loss 1.151978850364685
Iteration 142: train_loss 1.1432819366455078
Iteration 143: train_loss 1.141865611076355
Iteration 144: train_loss 1.121297001838684
Iteration 145: train_loss 1.1445242166519165
Iteration 146: train_loss 1.1527742147445679
Iteration 147: train_loss 1.10674250125885
Iteration 148: train_loss 1.1671358346939087
Iteration 149: train_loss 1.1300837993621826
Iteration 150: train_loss 1.1733077764511108
Iteration 151: train_loss 1.1579996347427368
Iteration 152: train_loss 1.1606647968292236
Iteration 153: train_loss 1.0986698865890503
Iteration 154: train_loss 1.1547130346298218
Iteration 155: train_loss 1.1812704801559448
Iteration 156: train_loss 1.1972821950912476
Iteration 157: train_loss 1.1229513883590698
Iteration 158: train_loss 1.135532259941101
Iteration 159: train_loss 1.1639610528945923
Iteration 160: train_loss 1.1983880996704102
Iteration 161: train_loss 1.148590087890625
Iteration 162: train_loss 1.1249884366989136
Iteration 163: train_loss 1.1428816318511963
Iteration 164: train_loss 1.1653873920440674
Iteration 165: train_loss 1.1203632354736328
Iteration 166: train_loss 1.143627643585205
Iteration 167: train_loss 1.1396945714950562
Iteration 168: train_loss 1.1484779119491577
Iteration 169: train_loss 1.190723180770874
Iteration 170: train_loss 1.1221110820770264
Iteration 171: train_loss 1.1265324354171753
Iteration 172: train_loss 1.1600008010864258
Iteration 173: train_loss 1.1703108549118042
Iteration 174: train_loss 1.0859384536743164
Iteration 175: train_loss 1.195854663848877
Iteration 176: train_loss 1.1197788715362549
Iteration 177: train_loss 1.1569271087646484
Epoch 192: train_avg_loss 1.1255747510888483 eval_avg_acc: 0.3390085489885135 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:57:36] [32mIntermediate result: 0.3390085489885135  (Index 191)[0m
================Epoch: 193================
Iteration 1: train_loss 1.0674731731414795
Iteration 2: train_loss 1.0858094692230225
Iteration 3: train_loss 1.1283349990844727
Iteration 4: train_loss 1.1616262197494507
Iteration 5: train_loss 1.1126797199249268
Iteration 6: train_loss 1.1575478315353394
Iteration 7: train_loss 1.065832495689392
Iteration 8: train_loss 1.1056324243545532
Iteration 9: train_loss 1.1286946535110474
Iteration 10: train_loss 1.195953369140625
Iteration 11: train_loss 1.0762706995010376
Iteration 12: train_loss 1.079842448234558
Iteration 13: train_loss 1.0815681219100952
Iteration 14: train_loss 1.0946497917175293
Iteration 15: train_loss 1.1251908540725708
Iteration 16: train_loss 1.0991328954696655
Iteration 17: train_loss 1.1327415704727173
Iteration 18: train_loss 1.1116503477096558
Iteration 19: train_loss 1.0773249864578247
Iteration 20: train_loss 1.1638818979263306
Iteration 21: train_loss 1.0994205474853516
Iteration 22: train_loss 1.0646778345108032
Iteration 23: train_loss 1.1197731494903564
Iteration 24: train_loss 1.1058117151260376
Iteration 25: train_loss 1.0901479721069336
Iteration 26: train_loss 1.1009865999221802
Iteration 27: train_loss 1.108163833618164
Iteration 28: train_loss 1.0965720415115356
Iteration 29: train_loss 1.124406099319458
Iteration 30: train_loss 1.0810327529907227
Iteration 31: train_loss 1.1266361474990845
Iteration 32: train_loss 1.0971338748931885
Iteration 33: train_loss 1.1512105464935303
Iteration 34: train_loss 1.095070481300354
Iteration 35: train_loss 1.1687028408050537
Iteration 36: train_loss 1.0993294715881348
Iteration 37: train_loss 1.1645095348358154
Iteration 38: train_loss 1.1740658283233643
Iteration 39: train_loss 1.1114827394485474
Iteration 40: train_loss 1.1288498640060425
Iteration 41: train_loss 1.0980850458145142
Iteration 42: train_loss 1.1298861503601074
Iteration 43: train_loss 1.0885374546051025
Iteration 44: train_loss 1.0690573453903198
Iteration 45: train_loss 1.096859097480774
Iteration 46: train_loss 1.1140302419662476
Iteration 47: train_loss 1.161169171333313
Iteration 48: train_loss 1.1475106477737427
Iteration 49: train_loss 1.1600618362426758
Iteration 50: train_loss 1.1173896789550781
Iteration 51: train_loss 1.1490694284439087
Iteration 52: train_loss 1.171015977859497
Iteration 53: train_loss 1.1031405925750732
Iteration 54: train_loss 1.0695065259933472
Iteration 55: train_loss 1.1311955451965332
Iteration 56: train_loss 1.135376214981079
Iteration 57: train_loss 1.1470770835876465
Iteration 58: train_loss 1.1287988424301147
Iteration 59: train_loss 1.2083756923675537
Iteration 60: train_loss 1.1312777996063232
Iteration 61: train_loss 1.1019092798233032
Iteration 62: train_loss 1.1419907808303833
Iteration 63: train_loss 1.1527340412139893
Iteration 64: train_loss 1.1574629545211792
Iteration 65: train_loss 1.1928266286849976
Iteration 66: train_loss 1.1484293937683105
Iteration 67: train_loss 1.1051418781280518
Iteration 68: train_loss 1.1372610330581665
Iteration 69: train_loss 1.136506199836731
Iteration 70: train_loss 1.1359652280807495
Iteration 71: train_loss 1.0859956741333008
Iteration 72: train_loss 1.1562392711639404
Iteration 73: train_loss 1.1148321628570557
Iteration 74: train_loss 1.0903701782226562
Iteration 75: train_loss 1.1262340545654297
Iteration 76: train_loss 1.13901948928833
Iteration 77: train_loss 1.109811782836914
Iteration 78: train_loss 1.0534169673919678
Iteration 79: train_loss 1.107988953590393
Iteration 80: train_loss 1.1388531923294067
Iteration 81: train_loss 1.0683354139328003
Iteration 82: train_loss 1.1366848945617676
Iteration 83: train_loss 1.0878416299819946
Iteration 84: train_loss 1.1551223993301392
Iteration 85: train_loss 1.0842527151107788
Iteration 86: train_loss 1.073927402496338
Iteration 87: train_loss 1.1217745542526245
Iteration 88: train_loss 1.1203352212905884
Iteration 89: train_loss 1.1385045051574707
Iteration 90: train_loss 1.1420506238937378
Iteration 91: train_loss 1.1161880493164062
Iteration 92: train_loss 1.1655585765838623
Iteration 93: train_loss 1.1291611194610596
Iteration 94: train_loss 1.1165364980697632
Iteration 95: train_loss 1.1550689935684204
Iteration 96: train_loss 1.124048113822937
Iteration 97: train_loss 1.1410729885101318
Iteration 98: train_loss 1.147118330001831
Iteration 99: train_loss 1.1241872310638428
Iteration 100: train_loss 1.058353304862976
Iteration 101: train_loss 1.0910379886627197
Iteration 102: train_loss 1.1358628273010254
Iteration 103: train_loss 1.0974429845809937
Iteration 104: train_loss 1.1159335374832153
Iteration 105: train_loss 1.1050715446472168
Iteration 106: train_loss 1.1826114654541016
Iteration 107: train_loss 1.091962218284607
Iteration 108: train_loss 1.1422234773635864
Iteration 109: train_loss 1.142856478691101
Iteration 110: train_loss 1.1586180925369263
Iteration 111: train_loss 1.1107550859451294
Iteration 112: train_loss 1.1436264514923096
Iteration 113: train_loss 1.1063556671142578
Iteration 114: train_loss 1.0981491804122925
Iteration 115: train_loss 1.1769546270370483
Iteration 116: train_loss 1.2233943939208984
Iteration 117: train_loss 1.157334566116333
Iteration 118: train_loss 1.151324987411499
Iteration 119: train_loss 1.1403368711471558
Iteration 120: train_loss 1.165297269821167
Iteration 121: train_loss 1.1787726879119873
Iteration 122: train_loss 1.1733410358428955
Iteration 123: train_loss 1.1618967056274414
Iteration 124: train_loss 1.1899875402450562
Iteration 125: train_loss 1.1887526512145996
Iteration 126: train_loss 1.2457510232925415
Iteration 127: train_loss 1.1762605905532837
Iteration 128: train_loss 1.1816209554672241
Iteration 129: train_loss 1.1903210878372192
Iteration 130: train_loss 1.1434752941131592
Iteration 131: train_loss 1.1370902061462402
Iteration 132: train_loss 1.0961284637451172
Iteration 133: train_loss 1.1544451713562012
Iteration 134: train_loss 1.1752619743347168
Iteration 135: train_loss 1.1561776399612427
Iteration 136: train_loss 1.0909548997879028
Iteration 137: train_loss 1.1716134548187256
Iteration 138: train_loss 1.1350446939468384
Iteration 139: train_loss 1.1340073347091675
Iteration 140: train_loss 1.1151479482650757
Iteration 141: train_loss 1.1764283180236816
Iteration 142: train_loss 1.1070923805236816
Iteration 143: train_loss 1.141782522201538
Iteration 144: train_loss 1.202488660812378
Iteration 145: train_loss 1.1263805627822876
Iteration 146: train_loss 1.1632434129714966
Iteration 147: train_loss 1.117984652519226
Iteration 148: train_loss 1.1452690362930298
Iteration 149: train_loss 1.141751766204834
Iteration 150: train_loss 1.200336217880249
Iteration 151: train_loss 1.1712288856506348
Iteration 152: train_loss 1.1396996974945068
Iteration 153: train_loss 1.1653603315353394
Iteration 154: train_loss 1.1686996221542358
Iteration 155: train_loss 1.165481686592102
Iteration 156: train_loss 1.197523832321167
Iteration 157: train_loss 1.183937907218933
Iteration 158: train_loss 1.286239743232727
Iteration 159: train_loss 1.2372263669967651
Iteration 160: train_loss 1.1412712335586548
Iteration 161: train_loss 1.1889240741729736
Iteration 162: train_loss 1.166508674621582
Iteration 163: train_loss 1.1731717586517334
Iteration 164: train_loss 1.1964361667633057
Iteration 165: train_loss 1.14988112449646
Iteration 166: train_loss 1.1239210367202759
Iteration 167: train_loss 1.1601327657699585
Iteration 168: train_loss 1.1582096815109253
Iteration 169: train_loss 1.1446033716201782
Iteration 170: train_loss 1.178759217262268
Iteration 171: train_loss 1.183505654335022
Iteration 172: train_loss 1.153852105140686
Iteration 173: train_loss 1.1102702617645264
Iteration 174: train_loss 1.1651943922042847
Iteration 175: train_loss 1.172749400138855
Iteration 176: train_loss 1.1648809909820557
Iteration 177: train_loss 1.193123459815979
Epoch 193: train_avg_loss 1.136458225842923 eval_avg_acc: 0.34411402121726137 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:58:18] [32mIntermediate result: 0.34411402121726137  (Index 192)[0m
================Epoch: 194================
Iteration 1: train_loss 1.0978608131408691
Iteration 2: train_loss 1.078616738319397
Iteration 3: train_loss 1.096514105796814
Iteration 4: train_loss 1.0630624294281006
Iteration 5: train_loss 1.1520473957061768
Iteration 6: train_loss 1.1504312753677368
Iteration 7: train_loss 1.119960904121399
Iteration 8: train_loss 1.099940299987793
Iteration 9: train_loss 1.1154694557189941
Iteration 10: train_loss 1.1422934532165527
Iteration 11: train_loss 1.0845927000045776
Iteration 12: train_loss 1.148040771484375
Iteration 13: train_loss 1.1214805841445923
Iteration 14: train_loss 1.0712764263153076
Iteration 15: train_loss 1.139754056930542
Iteration 16: train_loss 1.1760741472244263
Iteration 17: train_loss 1.1636531352996826
Iteration 18: train_loss 1.1300041675567627
Iteration 19: train_loss 1.0844378471374512
Iteration 20: train_loss 1.1473984718322754
Iteration 21: train_loss 1.135923147201538
Iteration 22: train_loss 1.095259428024292
Iteration 23: train_loss 1.089918613433838
Iteration 24: train_loss 1.0934282541275024
Iteration 25: train_loss 1.1205476522445679
Iteration 26: train_loss 1.194318413734436
Iteration 27: train_loss 1.1300287246704102
Iteration 28: train_loss 1.125441074371338
Iteration 29: train_loss 1.1218425035476685
Iteration 30: train_loss 1.1348248720169067
Iteration 31: train_loss 1.1611469984054565
Iteration 32: train_loss 1.172574758529663
Iteration 33: train_loss 1.2402143478393555
Iteration 34: train_loss 1.099616289138794
Iteration 35: train_loss 1.1274442672729492
Iteration 36: train_loss 1.1456871032714844
Iteration 37: train_loss 1.1374006271362305
Iteration 38: train_loss 1.183730125427246
Iteration 39: train_loss 1.2436344623565674
Iteration 40: train_loss 1.1683025360107422
Iteration 41: train_loss 1.1439491510391235
Iteration 42: train_loss 1.2407172918319702
Iteration 43: train_loss 1.1954575777053833
Iteration 44: train_loss 1.154097318649292
Iteration 45: train_loss 1.1216858625411987
Iteration 46: train_loss 1.185584545135498
Iteration 47: train_loss 1.090666651725769
Iteration 48: train_loss 1.1179580688476562
Iteration 49: train_loss 1.1104555130004883
Iteration 50: train_loss 1.1318703889846802
Iteration 51: train_loss 1.0772650241851807
Iteration 52: train_loss 1.131913661956787
Iteration 53: train_loss 1.1104148626327515
Iteration 54: train_loss 1.084170937538147
Iteration 55: train_loss 1.0940173864364624
Iteration 56: train_loss 1.135100245475769
Iteration 57: train_loss 1.1398972272872925
Iteration 58: train_loss 1.0895612239837646
Iteration 59: train_loss 1.1816216707229614
Iteration 60: train_loss 1.062076210975647
Iteration 61: train_loss 1.100608229637146
Iteration 62: train_loss 1.0913347005844116
Iteration 63: train_loss 1.0540657043457031
Iteration 64: train_loss 1.0475029945373535
Iteration 65: train_loss 1.025770664215088
Iteration 66: train_loss 1.1430739164352417
Iteration 67: train_loss 1.0936676263809204
Iteration 68: train_loss 1.068512201309204
Iteration 69: train_loss 1.0920499563217163
Iteration 70: train_loss 1.1168029308319092
Iteration 71: train_loss 1.089714765548706
Iteration 72: train_loss 1.0996685028076172
Iteration 73: train_loss 1.068985104560852
Iteration 74: train_loss 1.1600991487503052
Iteration 75: train_loss 1.0744659900665283
Iteration 76: train_loss 1.0925716161727905
Iteration 77: train_loss 1.1079118251800537
Iteration 78: train_loss 1.108159065246582
Iteration 79: train_loss 1.0890002250671387
Iteration 80: train_loss 1.152037501335144
Iteration 81: train_loss 1.171130895614624
Iteration 82: train_loss 1.0950031280517578
Iteration 83: train_loss 1.0936486721038818
Iteration 84: train_loss 1.124777913093567
Iteration 85: train_loss 1.0838370323181152
Iteration 86: train_loss 1.112754464149475
Iteration 87: train_loss 1.1520792245864868
Iteration 88: train_loss 1.1288015842437744
Iteration 89: train_loss 1.148752212524414
Iteration 90: train_loss 1.1394503116607666
Iteration 91: train_loss 1.105821967124939
Iteration 92: train_loss 1.1281142234802246
Iteration 93: train_loss 1.111141562461853
Iteration 94: train_loss 1.070764422416687
Iteration 95: train_loss 1.1031073331832886
Iteration 96: train_loss 1.1270841360092163
Iteration 97: train_loss 1.0855672359466553
Iteration 98: train_loss 1.0934302806854248
Iteration 99: train_loss 1.1020127534866333
Iteration 100: train_loss 1.1092883348464966
Iteration 101: train_loss 1.1020289659500122
Iteration 102: train_loss 1.1232644319534302
Iteration 103: train_loss 1.1144670248031616
Iteration 104: train_loss 1.1256687641143799
Iteration 105: train_loss 1.1103718280792236
Iteration 106: train_loss 1.1190307140350342
Iteration 107: train_loss 1.059370756149292
Iteration 108: train_loss 1.1053601503372192
Iteration 109: train_loss 1.107143521308899
Iteration 110: train_loss 1.1288785934448242
Iteration 111: train_loss 1.1585464477539062
Iteration 112: train_loss 1.131077527999878
Iteration 113: train_loss 1.1374496221542358
Iteration 114: train_loss 1.149932861328125
Iteration 115: train_loss 1.1682146787643433
Iteration 116: train_loss 1.0827035903930664
Iteration 117: train_loss 1.1654188632965088
Iteration 118: train_loss 1.1258236169815063
Iteration 119: train_loss 1.1390178203582764
Iteration 120: train_loss 1.1702909469604492
Iteration 121: train_loss 1.1196173429489136
Iteration 122: train_loss 1.180333137512207
Iteration 123: train_loss 1.1258914470672607
Iteration 124: train_loss 1.13140869140625
Iteration 125: train_loss 1.1057301759719849
Iteration 126: train_loss 1.160367727279663
Iteration 127: train_loss 1.1082592010498047
Iteration 128: train_loss 1.11495041847229
Iteration 129: train_loss 1.1693470478057861
Iteration 130: train_loss 1.0951027870178223
Iteration 131: train_loss 1.1325664520263672
Iteration 132: train_loss 1.1510952711105347
Iteration 133: train_loss 1.084896445274353
Iteration 134: train_loss 1.095787763595581
Iteration 135: train_loss 1.1150681972503662
Iteration 136: train_loss 1.1429250240325928
Iteration 137: train_loss 1.097861409187317
Iteration 138: train_loss 1.1265389919281006
Iteration 139: train_loss 1.0876641273498535
Iteration 140: train_loss 1.1171321868896484
Iteration 141: train_loss 1.096838355064392
Iteration 142: train_loss 1.136942982673645
Iteration 143: train_loss 1.1279611587524414
Iteration 144: train_loss 1.1010123491287231
Iteration 145: train_loss 1.0980786085128784
Iteration 146: train_loss 1.1321476697921753
Iteration 147: train_loss 1.1001787185668945
Iteration 148: train_loss 1.1238857507705688
Iteration 149: train_loss 1.105486512184143
Iteration 150: train_loss 1.0916905403137207
Iteration 151: train_loss 1.0577592849731445
Iteration 152: train_loss 1.0753411054611206
Iteration 153: train_loss 1.1340614557266235
Iteration 154: train_loss 1.1444461345672607
Iteration 155: train_loss 1.1503702402114868
Iteration 156: train_loss 1.125516414642334
Iteration 157: train_loss 1.1146342754364014
Iteration 158: train_loss 1.1160506010055542
Iteration 159: train_loss 1.1618521213531494
Iteration 160: train_loss 1.1825213432312012
Iteration 161: train_loss 1.1335200071334839
Iteration 162: train_loss 1.160485029220581
Iteration 163: train_loss 1.1682130098342896
Iteration 164: train_loss 1.116856575012207
Iteration 165: train_loss 1.111611008644104
Iteration 166: train_loss 1.1413832902908325
Iteration 167: train_loss 1.1851856708526611
Iteration 168: train_loss 1.1349059343338013
Iteration 169: train_loss 1.1208661794662476
Iteration 170: train_loss 1.112609624862671
Iteration 171: train_loss 1.1336894035339355
Iteration 172: train_loss 1.1352388858795166
Iteration 173: train_loss 1.1846243143081665
Iteration 174: train_loss 1.1606614589691162
Iteration 175: train_loss 1.1316362619400024
Iteration 176: train_loss 1.193049669265747
Iteration 177: train_loss 1.1497995853424072
Epoch 194: train_avg_loss 1.1237455404410928 eval_avg_acc: 0.3437817184106614 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:58:59] [32mIntermediate result: 0.3437817184106614  (Index 193)[0m
================Epoch: 195================
Iteration 1: train_loss 1.0962860584259033
Iteration 2: train_loss 1.111775279045105
Iteration 3: train_loss 1.096962571144104
Iteration 4: train_loss 1.1345984935760498
Iteration 5: train_loss 1.0813651084899902
Iteration 6: train_loss 1.1807982921600342
Iteration 7: train_loss 1.1546454429626465
Iteration 8: train_loss 1.1207690238952637
Iteration 9: train_loss 1.1552441120147705
Iteration 10: train_loss 1.079744577407837
Iteration 11: train_loss 1.1220101118087769
Iteration 12: train_loss 1.1239138841629028
Iteration 13: train_loss 1.134544849395752
Iteration 14: train_loss 1.1467909812927246
Iteration 15: train_loss 1.0776629447937012
Iteration 16: train_loss 1.1092047691345215
Iteration 17: train_loss 1.0896618366241455
Iteration 18: train_loss 1.1000665426254272
Iteration 19: train_loss 1.0737580060958862
Iteration 20: train_loss 1.0932977199554443
Iteration 21: train_loss 1.1158115863800049
Iteration 22: train_loss 1.0798192024230957
Iteration 23: train_loss 1.072838544845581
Iteration 24: train_loss 1.129501223564148
Iteration 25: train_loss 1.0634015798568726
Iteration 26: train_loss 1.1365448236465454
Iteration 27: train_loss 1.0908218622207642
Iteration 28: train_loss 1.0990757942199707
Iteration 29: train_loss 1.1179001331329346
Iteration 30: train_loss 1.1550439596176147
Iteration 31: train_loss 1.1008249521255493
Iteration 32: train_loss 1.0821409225463867
Iteration 33: train_loss 1.0925836563110352
Iteration 34: train_loss 1.1533221006393433
Iteration 35: train_loss 1.0962620973587036
Iteration 36: train_loss 1.1067628860473633
Iteration 37: train_loss 1.0740381479263306
Iteration 38: train_loss 1.0995253324508667
Iteration 39: train_loss 1.0770119428634644
Iteration 40: train_loss 1.0783826112747192
Iteration 41: train_loss 1.045743703842163
Iteration 42: train_loss 1.1162687540054321
Iteration 43: train_loss 1.056536316871643
Iteration 44: train_loss 1.0473594665527344
Iteration 45: train_loss 1.1531546115875244
Iteration 46: train_loss 1.1135430335998535
Iteration 47: train_loss 1.1440871953964233
Iteration 48: train_loss 1.1726969480514526
Iteration 49: train_loss 1.1347604990005493
Iteration 50: train_loss 1.1002464294433594
Iteration 51: train_loss 1.1110304594039917
Iteration 52: train_loss 1.1638193130493164
Iteration 53: train_loss 1.098272681236267
Iteration 54: train_loss 1.1282957792282104
Iteration 55: train_loss 1.1424474716186523
Iteration 56: train_loss 1.1035914421081543
Iteration 57: train_loss 1.0924266576766968
Iteration 58: train_loss 1.1108652353286743
Iteration 59: train_loss 1.130928635597229
Iteration 60: train_loss 1.1231226921081543
Iteration 61: train_loss 1.1215423345565796
Iteration 62: train_loss 1.1129515171051025
Iteration 63: train_loss 1.125643014907837
Iteration 64: train_loss 1.1374503374099731
Iteration 65: train_loss 1.0938446521759033
Iteration 66: train_loss 1.1378135681152344
Iteration 67: train_loss 1.0860215425491333
Iteration 68: train_loss 1.068522334098816
Iteration 69: train_loss 1.0731756687164307
Iteration 70: train_loss 1.1768431663513184
Iteration 71: train_loss 1.1627638339996338
Iteration 72: train_loss 1.208511233329773
Iteration 73: train_loss 1.1133760213851929
Iteration 74: train_loss 1.1391193866729736
Iteration 75: train_loss 1.1333361864089966
Iteration 76: train_loss 1.171579360961914
Iteration 77: train_loss 1.1356884241104126
Iteration 78: train_loss 1.1005147695541382
Iteration 79: train_loss 1.2016024589538574
Iteration 80: train_loss 1.107612133026123
Iteration 81: train_loss 1.103775978088379
Iteration 82: train_loss 1.087769627571106
Iteration 83: train_loss 1.0863525867462158
Iteration 84: train_loss 1.136752963066101
Iteration 85: train_loss 1.1264678239822388
Iteration 86: train_loss 1.145901083946228
Iteration 87: train_loss 1.1112653017044067
Iteration 88: train_loss 1.1261298656463623
Iteration 89: train_loss 1.1591126918792725
Iteration 90: train_loss 1.1224875450134277
Iteration 91: train_loss 1.1261484622955322
Iteration 92: train_loss 1.1556715965270996
Iteration 93: train_loss 1.0793700218200684
Iteration 94: train_loss 1.1070257425308228
Iteration 95: train_loss 1.170186161994934
Iteration 96: train_loss 1.1058076620101929
Iteration 97: train_loss 1.1311770677566528
Iteration 98: train_loss 1.1302188634872437
Iteration 99: train_loss 1.1504501104354858
Iteration 100: train_loss 1.1654597520828247
Iteration 101: train_loss 1.1590441465377808
Iteration 102: train_loss 1.1228688955307007
Iteration 103: train_loss 1.135718584060669
Iteration 104: train_loss 1.1686135530471802
Iteration 105: train_loss 1.181682825088501
Iteration 106: train_loss 1.1428942680358887
Iteration 107: train_loss 1.1067813634872437
Iteration 108: train_loss 1.1207619905471802
Iteration 109: train_loss 1.1280803680419922
Iteration 110: train_loss 1.1411985158920288
Iteration 111: train_loss 1.130611538887024
Iteration 112: train_loss 1.1210559606552124
Iteration 113: train_loss 1.1580153703689575
Iteration 114: train_loss 1.0957472324371338
Iteration 115: train_loss 1.08480966091156
Iteration 116: train_loss 1.1571033000946045
Iteration 117: train_loss 1.167301058769226
Iteration 118: train_loss 1.161699891090393
Iteration 119: train_loss 1.1465648412704468
Iteration 120: train_loss 1.1257215738296509
Iteration 121: train_loss 1.1261262893676758
Iteration 122: train_loss 1.1145144701004028
Iteration 123: train_loss 1.1600898504257202
Iteration 124: train_loss 1.1307313442230225
Iteration 125: train_loss 1.0763851404190063
Iteration 126: train_loss 1.1329951286315918
Iteration 127: train_loss 1.1977717876434326
Iteration 128: train_loss 1.1226390600204468
Iteration 129: train_loss 1.168099045753479
Iteration 130: train_loss 1.1524903774261475
Iteration 131: train_loss 1.1167073249816895
Iteration 132: train_loss 1.1097277402877808
Iteration 133: train_loss 1.205515742301941
Iteration 134: train_loss 1.1235547065734863
Iteration 135: train_loss 1.1010584831237793
Iteration 136: train_loss 1.1219470500946045
Iteration 137: train_loss 1.0907810926437378
Iteration 138: train_loss 1.138136625289917
Iteration 139: train_loss 1.1202389001846313
Iteration 140: train_loss 1.1355680227279663
Iteration 141: train_loss 1.084668517112732
Iteration 142: train_loss 1.150490403175354
Iteration 143: train_loss 1.1573288440704346
Iteration 144: train_loss 1.145226001739502
Iteration 145: train_loss 1.1792891025543213
Iteration 146: train_loss 1.1637977361679077
Iteration 147: train_loss 1.13973069190979
Iteration 148: train_loss 1.1333318948745728
Iteration 149: train_loss 1.1457245349884033
Iteration 150: train_loss 1.1921547651290894
Iteration 151: train_loss 1.0855958461761475
Iteration 152: train_loss 1.1576786041259766
Iteration 153: train_loss 1.1641687154769897
Iteration 154: train_loss 1.1546350717544556
Iteration 155: train_loss 1.1201554536819458
Iteration 156: train_loss 1.1045960187911987
Iteration 157: train_loss 1.1241105794906616
Iteration 158: train_loss 1.1587401628494263
Iteration 159: train_loss 1.1490118503570557
Iteration 160: train_loss 1.154589295387268
Iteration 161: train_loss 1.0764555931091309
Iteration 162: train_loss 1.131825566291809
Iteration 163: train_loss 1.1885987520217896
Iteration 164: train_loss 1.2260719537734985
Iteration 165: train_loss 1.1114670038223267
Iteration 166: train_loss 1.1464824676513672
Iteration 167: train_loss 1.1029566526412964
Iteration 168: train_loss 1.1482487916946411
Iteration 169: train_loss 1.123515248298645
Iteration 170: train_loss 1.161807894706726
Iteration 171: train_loss 1.1185450553894043
Iteration 172: train_loss 1.1581798791885376
Iteration 173: train_loss 1.124333381652832
Iteration 174: train_loss 1.1199780702590942
Iteration 175: train_loss 1.1164214611053467
Iteration 176: train_loss 1.158742904663086
Iteration 177: train_loss 1.1686142683029175
Epoch 195: train_avg_loss 1.126429244623346 eval_avg_acc: 0.3414802392340169 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 03:59:41] [32mIntermediate result: 0.3414802392340169  (Index 194)[0m
================Epoch: 196================
Iteration 1: train_loss 1.1803979873657227
Iteration 2: train_loss 1.1623350381851196
Iteration 3: train_loss 1.1175634860992432
Iteration 4: train_loss 1.1755698919296265
Iteration 5: train_loss 1.087546467781067
Iteration 6: train_loss 1.1325297355651855
Iteration 7: train_loss 1.1476893424987793
Iteration 8: train_loss 1.1503273248672485
Iteration 9: train_loss 1.1352530717849731
Iteration 10: train_loss 1.180579423904419
Iteration 11: train_loss 1.0453166961669922
Iteration 12: train_loss 1.1265474557876587
Iteration 13: train_loss 1.1483078002929688
Iteration 14: train_loss 1.088483452796936
Iteration 15: train_loss 1.082172155380249
Iteration 16: train_loss 1.1363507509231567
Iteration 17: train_loss 1.1142799854278564
Iteration 18: train_loss 1.1254746913909912
Iteration 19: train_loss 1.0586044788360596
Iteration 20: train_loss 1.128950595855713
Iteration 21: train_loss 1.1427372694015503
Iteration 22: train_loss 1.1385581493377686
Iteration 23: train_loss 1.060240387916565
Iteration 24: train_loss 1.1976579427719116
Iteration 25: train_loss 1.0968116521835327
Iteration 26: train_loss 1.1131659746170044
Iteration 27: train_loss 1.0796176195144653
Iteration 28: train_loss 1.108370304107666
Iteration 29: train_loss 1.0438801050186157
Iteration 30: train_loss 1.1057045459747314
Iteration 31: train_loss 1.1401478052139282
Iteration 32: train_loss 1.0917620658874512
Iteration 33: train_loss 1.105199933052063
Iteration 34: train_loss 1.0768355131149292
Iteration 35: train_loss 1.0969316959381104
Iteration 36: train_loss 1.0754332542419434
Iteration 37: train_loss 1.0805542469024658
Iteration 38: train_loss 1.1020787954330444
Iteration 39: train_loss 1.1588035821914673
Iteration 40: train_loss 1.1200549602508545
Iteration 41: train_loss 1.093199610710144
Iteration 42: train_loss 1.1118500232696533
Iteration 43: train_loss 1.093815565109253
Iteration 44: train_loss 1.1098159551620483
Iteration 45: train_loss 1.0817620754241943
Iteration 46: train_loss 1.1387765407562256
Iteration 47: train_loss 1.116646409034729
Iteration 48: train_loss 1.0897016525268555
Iteration 49: train_loss 1.0890897512435913
Iteration 50: train_loss 1.135410189628601
Iteration 51: train_loss 1.1230863332748413
Iteration 52: train_loss 1.1079226732254028
Iteration 53: train_loss 1.1140576601028442
Iteration 54: train_loss 1.0561153888702393
Iteration 55: train_loss 1.1247186660766602
Iteration 56: train_loss 1.1011039018630981
Iteration 57: train_loss 1.1228952407836914
Iteration 58: train_loss 1.0974122285842896
Iteration 59: train_loss 1.132561445236206
Iteration 60: train_loss 1.0604602098464966
Iteration 61: train_loss 1.0655250549316406
Iteration 62: train_loss 1.141727089881897
Iteration 63: train_loss 1.1051479578018188
Iteration 64: train_loss 1.0986322164535522
Iteration 65: train_loss 1.1405415534973145
Iteration 66: train_loss 1.1303308010101318
Iteration 67: train_loss 1.0771327018737793
Iteration 68: train_loss 1.1678446531295776
Iteration 69: train_loss 1.1268033981323242
Iteration 70: train_loss 1.0576553344726562
Iteration 71: train_loss 1.1101350784301758
Iteration 72: train_loss 1.1049830913543701
Iteration 73: train_loss 1.126688003540039
Iteration 74: train_loss 1.0893886089324951
Iteration 75: train_loss 1.0988270044326782
Iteration 76: train_loss 1.1210744380950928
Iteration 77: train_loss 1.1564579010009766
Iteration 78: train_loss 1.1397753953933716
Iteration 79: train_loss 1.106552243232727
Iteration 80: train_loss 1.0894789695739746
Iteration 81: train_loss 1.0789158344268799
Iteration 82: train_loss 1.1271129846572876
Iteration 83: train_loss 1.1215615272521973
Iteration 84: train_loss 1.093377947807312
Iteration 85: train_loss 1.118471384048462
Iteration 86: train_loss 1.1142088174819946
Iteration 87: train_loss 1.1878576278686523
Iteration 88: train_loss 1.089476227760315
Iteration 89: train_loss 1.0803545713424683
Iteration 90: train_loss 1.094907522201538
Iteration 91: train_loss 1.1031057834625244
Iteration 92: train_loss 1.151473879814148
Iteration 93: train_loss 1.069210410118103
Iteration 94: train_loss 1.0997726917266846
Iteration 95: train_loss 1.110584020614624
Iteration 96: train_loss 1.082247257232666
Iteration 97: train_loss 1.1144909858703613
Iteration 98: train_loss 1.100893259048462
Iteration 99: train_loss 1.0557981729507446
Iteration 100: train_loss 1.079596757888794
Iteration 101: train_loss 1.0494357347488403
Iteration 102: train_loss 1.1520543098449707
Iteration 103: train_loss 1.168203592300415
Iteration 104: train_loss 1.150540828704834
Iteration 105: train_loss 1.0971983671188354
Iteration 106: train_loss 1.1003073453903198
Iteration 107: train_loss 1.0929577350616455
Iteration 108: train_loss 1.1272388696670532
Iteration 109: train_loss 1.1356719732284546
Iteration 110: train_loss 1.0748307704925537
Iteration 111: train_loss 1.0955135822296143
Iteration 112: train_loss 1.0915828943252563
Iteration 113: train_loss 1.094552993774414
Iteration 114: train_loss 1.12081778049469
Iteration 115: train_loss 1.1370245218276978
Iteration 116: train_loss 1.136551856994629
Iteration 117: train_loss 1.0582410097122192
Iteration 118: train_loss 1.094620704650879
Iteration 119: train_loss 1.156948208808899
Iteration 120: train_loss 1.097964882850647
Iteration 121: train_loss 1.1258950233459473
Iteration 122: train_loss 1.0979243516921997
Iteration 123: train_loss 1.1445605754852295
Iteration 124: train_loss 1.0856060981750488
Iteration 125: train_loss 1.1333562135696411
Iteration 126: train_loss 1.110300898551941
Iteration 127: train_loss 1.1149452924728394
Iteration 128: train_loss 1.1017985343933105
Iteration 129: train_loss 1.1147879362106323
Iteration 130: train_loss 1.0736777782440186
Iteration 131: train_loss 1.114784598350525
Iteration 132: train_loss 1.1107293367385864
Iteration 133: train_loss 1.152141809463501
Iteration 134: train_loss 1.064551830291748
Iteration 135: train_loss 1.1350747346878052
Iteration 136: train_loss 1.1040279865264893
Iteration 137: train_loss 1.1313698291778564
Iteration 138: train_loss 1.1635055541992188
Iteration 139: train_loss 1.1015543937683105
Iteration 140: train_loss 1.0967990159988403
Iteration 141: train_loss 1.1620279550552368
Iteration 142: train_loss 1.1237987279891968
Iteration 143: train_loss 1.1318920850753784
Iteration 144: train_loss 1.1334478855133057
Iteration 145: train_loss 1.1521975994110107
Iteration 146: train_loss 1.1330821514129639
Iteration 147: train_loss 1.112391710281372
Iteration 148: train_loss 1.1384474039077759
Iteration 149: train_loss 1.1033538579940796
Iteration 150: train_loss 1.1093753576278687
Iteration 151: train_loss 1.0815824270248413
Iteration 152: train_loss 1.1089699268341064
Iteration 153: train_loss 1.0841634273529053
Iteration 154: train_loss 1.132647156715393
Iteration 155: train_loss 1.1818031072616577
Iteration 156: train_loss 1.1371933221817017
Iteration 157: train_loss 1.1201691627502441
Iteration 158: train_loss 1.1016079187393188
Iteration 159: train_loss 1.1669557094573975
Iteration 160: train_loss 1.152225136756897
Iteration 161: train_loss 1.0836999416351318
Iteration 162: train_loss 1.1545886993408203
Iteration 163: train_loss 1.149694800376892
Iteration 164: train_loss 1.084586262702942
Iteration 165: train_loss 1.167138695716858
Iteration 166: train_loss 1.135787844657898
Iteration 167: train_loss 1.1328195333480835
Iteration 168: train_loss 1.116824984550476
Iteration 169: train_loss 1.1072357892990112
Iteration 170: train_loss 1.1569647789001465
Iteration 171: train_loss 1.1511427164077759
Iteration 172: train_loss 1.1239651441574097
Iteration 173: train_loss 1.1896318197250366
Iteration 174: train_loss 1.1064201593399048
Iteration 175: train_loss 1.1339426040649414
Iteration 176: train_loss 1.0933269262313843
Iteration 177: train_loss 1.0873262882232666
Epoch 196: train_avg_loss 1.1149120061411022 eval_avg_acc: 0.3443422781249418 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 04:00:23] [32mIntermediate result: 0.3443422781249418  (Index 195)[0m
================Epoch: 197================
Iteration 1: train_loss 1.1372665166854858
Iteration 2: train_loss 1.1369990110397339
Iteration 3: train_loss 1.1401481628417969
Iteration 4: train_loss 1.1135560274124146
Iteration 5: train_loss 1.1098793745040894
Iteration 6: train_loss 1.1883025169372559
Iteration 7: train_loss 1.1324634552001953
Iteration 8: train_loss 1.1545501947402954
Iteration 9: train_loss 1.0991789102554321
Iteration 10: train_loss 1.0807982683181763
Iteration 11: train_loss 1.086592674255371
Iteration 12: train_loss 1.1164770126342773
Iteration 13: train_loss 1.1241443157196045
Iteration 14: train_loss 1.1528319120407104
Iteration 15: train_loss 1.1578189134597778
Iteration 16: train_loss 1.111392617225647
Iteration 17: train_loss 1.16110360622406
Iteration 18: train_loss 1.0552667379379272
Iteration 19: train_loss 1.0924382209777832
Iteration 20: train_loss 1.1294660568237305
Iteration 21: train_loss 1.0832115411758423
Iteration 22: train_loss 1.0388602018356323
Iteration 23: train_loss 1.126812219619751
Iteration 24: train_loss 1.0953019857406616
Iteration 25: train_loss 1.150270700454712
Iteration 26: train_loss 1.1323153972625732
Iteration 27: train_loss 1.1523324251174927
Iteration 28: train_loss 1.1321474313735962
Iteration 29: train_loss 1.0975500345230103
Iteration 30: train_loss 1.1822152137756348
Iteration 31: train_loss 1.1375514268875122
Iteration 32: train_loss 1.1408913135528564
Iteration 33: train_loss 1.1621408462524414
Iteration 34: train_loss 1.1444041728973389
Iteration 35: train_loss 1.1340528726577759
Iteration 36: train_loss 1.1450451612472534
Iteration 37: train_loss 1.1635499000549316
Iteration 38: train_loss 1.117309808731079
Iteration 39: train_loss 1.1011853218078613
Iteration 40: train_loss 1.190941333770752
Iteration 41: train_loss 1.0981084108352661
Iteration 42: train_loss 1.0860532522201538
Iteration 43: train_loss 1.06234872341156
Iteration 44: train_loss 1.0414197444915771
Iteration 45: train_loss 1.114251732826233
Iteration 46: train_loss 1.127860426902771
Iteration 47: train_loss 1.1514960527420044
Iteration 48: train_loss 1.10390305519104
Iteration 49: train_loss 1.1024092435836792
Iteration 50: train_loss 1.167541265487671
Iteration 51: train_loss 1.137479543685913
Iteration 52: train_loss 1.1792118549346924
Iteration 53: train_loss 1.1866282224655151
Iteration 54: train_loss 1.1413252353668213
Iteration 55: train_loss 1.0785492658615112
Iteration 56: train_loss 1.1737232208251953
Iteration 57: train_loss 1.118330478668213
Iteration 58: train_loss 1.129410982131958
Iteration 59: train_loss 1.117419958114624
Iteration 60: train_loss 1.1545637845993042
Iteration 61: train_loss 1.17863130569458
Iteration 62: train_loss 1.13010573387146
Iteration 63: train_loss 1.0306698083877563
Iteration 64: train_loss 1.1645504236221313
Iteration 65: train_loss 1.0508228540420532
Iteration 66: train_loss 1.0707684755325317
Iteration 67: train_loss 1.0815006494522095
Iteration 68: train_loss 1.0958677530288696
Iteration 69: train_loss 1.0854036808013916
Iteration 70: train_loss 1.1054741144180298
Iteration 71: train_loss 1.0998425483703613
Iteration 72: train_loss 1.0819307565689087
Iteration 73: train_loss 1.0748149156570435
Iteration 74: train_loss 1.1309595108032227
Iteration 75: train_loss 1.1243692636489868
Iteration 76: train_loss 1.1345112323760986
Iteration 77: train_loss 1.0476043224334717
Iteration 78: train_loss 1.135990858078003
Iteration 79: train_loss 1.125077247619629
Iteration 80: train_loss 1.0762308835983276
Iteration 81: train_loss 1.1259422302246094
Iteration 82: train_loss 1.1127103567123413
Iteration 83: train_loss 1.1415835618972778
Iteration 84: train_loss 1.0811420679092407
Iteration 85: train_loss 1.126601219177246
Iteration 86: train_loss 1.1302638053894043
Iteration 87: train_loss 1.1516813039779663
Iteration 88: train_loss 1.1343226432800293
Iteration 89: train_loss 1.1554063558578491
Iteration 90: train_loss 1.1214706897735596
Iteration 91: train_loss 1.1734130382537842
Iteration 92: train_loss 1.1550967693328857
Iteration 93: train_loss 1.1383516788482666
Iteration 94: train_loss 1.1669714450836182
Iteration 95: train_loss 1.1216378211975098
Iteration 96: train_loss 1.0846545696258545
Iteration 97: train_loss 1.1204524040222168
Iteration 98: train_loss 1.1558195352554321
Iteration 99: train_loss 1.1117702722549438
Iteration 100: train_loss 1.1101393699645996
Iteration 101: train_loss 1.0849004983901978
Iteration 102: train_loss 1.185028314590454
Iteration 103: train_loss 1.1520262956619263
Iteration 104: train_loss 1.1060154438018799
Iteration 105: train_loss 1.09556245803833
Iteration 106: train_loss 1.1642812490463257
Iteration 107: train_loss 1.1051312685012817
Iteration 108: train_loss 1.1025704145431519
Iteration 109: train_loss 1.1599068641662598
Iteration 110: train_loss 1.0701297521591187
Iteration 111: train_loss 1.159860610961914
Iteration 112: train_loss 1.096990704536438
Iteration 113: train_loss 1.1108683347702026
Iteration 114: train_loss 1.078709363937378
Iteration 115: train_loss 1.1063969135284424
Iteration 116: train_loss 1.0643060207366943
Iteration 117: train_loss 1.0752564668655396
Iteration 118: train_loss 1.1389367580413818
Iteration 119: train_loss 1.0460846424102783
Iteration 120: train_loss 1.0678808689117432
Iteration 121: train_loss 1.1052733659744263
Iteration 122: train_loss 1.0961275100708008
Iteration 123: train_loss 1.1709489822387695
Iteration 124: train_loss 1.161118745803833
Iteration 125: train_loss 1.1612393856048584
Iteration 126: train_loss 1.0355383157730103
Iteration 127: train_loss 1.1555660963058472
Iteration 128: train_loss 1.1160943508148193
Iteration 129: train_loss 1.2042698860168457
Iteration 130: train_loss 1.1412476301193237
Iteration 131: train_loss 1.1244349479675293
Iteration 132: train_loss 1.1152498722076416
Iteration 133: train_loss 1.1537137031555176
Iteration 134: train_loss 1.1154773235321045
Iteration 135: train_loss 1.1238701343536377
Iteration 136: train_loss 1.1471105813980103
Iteration 137: train_loss 1.1401798725128174
Iteration 138: train_loss 1.1103323698043823
Iteration 139: train_loss 1.1610081195831299
Iteration 140: train_loss 1.1467978954315186
Iteration 141: train_loss 1.0843771696090698
Iteration 142: train_loss 1.1432942152023315
Iteration 143: train_loss 1.1039807796478271
Iteration 144: train_loss 1.0879932641983032
Iteration 145: train_loss 1.1656798124313354
Iteration 146: train_loss 1.1355324983596802
Iteration 147: train_loss 1.1494207382202148
Iteration 148: train_loss 1.126186728477478
Iteration 149: train_loss 1.1411983966827393
Iteration 150: train_loss 1.1090917587280273
Iteration 151: train_loss 1.1579612493515015
Iteration 152: train_loss 1.1469483375549316
Iteration 153: train_loss 1.1786397695541382
Iteration 154: train_loss 1.0804904699325562
Iteration 155: train_loss 1.1289461851119995
Iteration 156: train_loss 1.127053141593933
Iteration 157: train_loss 1.1586401462554932
Iteration 158: train_loss 1.136454701423645
Iteration 159: train_loss 1.1234599351882935
Iteration 160: train_loss 1.119826316833496
Iteration 161: train_loss 1.1073633432388306
Iteration 162: train_loss 1.1303973197937012
Iteration 163: train_loss 1.1025830507278442
Iteration 164: train_loss 1.1127440929412842
Iteration 165: train_loss 1.124730110168457
Iteration 166: train_loss 1.1277285814285278
Iteration 167: train_loss 1.1524587869644165
Iteration 168: train_loss 1.1010229587554932
Iteration 169: train_loss 1.163489818572998
Iteration 170: train_loss 1.090578317642212
Iteration 171: train_loss 1.1405930519104004
Iteration 172: train_loss 1.1125363111495972
Iteration 173: train_loss 1.1798022985458374
Iteration 174: train_loss 1.1416983604431152
Iteration 175: train_loss 1.198896050453186
Iteration 176: train_loss 1.0922130346298218
Iteration 177: train_loss 1.0671013593673706
Epoch 197: train_avg_loss 1.123349777049264 eval_avg_acc: 0.3433676671028084 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 04:01:04] [32mIntermediate result: 0.3433676671028084  (Index 196)[0m
================Epoch: 198================
Iteration 1: train_loss 1.2056344747543335
Iteration 2: train_loss 1.1497395038604736
Iteration 3: train_loss 1.121282696723938
Iteration 4: train_loss 1.162205457687378
Iteration 5: train_loss 1.1392966508865356
Iteration 6: train_loss 1.1548597812652588
Iteration 7: train_loss 1.1501985788345337
Iteration 8: train_loss 1.1317147016525269
Iteration 9: train_loss 1.1363506317138672
Iteration 10: train_loss 1.1642932891845703
Iteration 11: train_loss 1.0954227447509766
Iteration 12: train_loss 1.0907329320907593
Iteration 13: train_loss 1.0941916704177856
Iteration 14: train_loss 1.0626368522644043
Iteration 15: train_loss 1.0604445934295654
Iteration 16: train_loss 1.1063947677612305
Iteration 17: train_loss 1.0634000301361084
Iteration 18: train_loss 1.0701944828033447
Iteration 19: train_loss 1.1326271295547485
Iteration 20: train_loss 1.0901507139205933
Iteration 21: train_loss 1.0964995622634888
Iteration 22: train_loss 1.123871922492981
Iteration 23: train_loss 1.1308722496032715
Iteration 24: train_loss 1.0715899467468262
Iteration 25: train_loss 1.128584384918213
Iteration 26: train_loss 1.0576062202453613
Iteration 27: train_loss 1.1010370254516602
Iteration 28: train_loss 1.1251529455184937
Iteration 29: train_loss 1.1016260385513306
Iteration 30: train_loss 1.1129258871078491
Iteration 31: train_loss 1.1032721996307373
Iteration 32: train_loss 1.1483542919158936
Iteration 33: train_loss 1.1814454793930054
Iteration 34: train_loss 1.135901927947998
Iteration 35: train_loss 1.1008700132369995
Iteration 36: train_loss 1.1085636615753174
Iteration 37: train_loss 1.1294132471084595
Iteration 38: train_loss 1.1110942363739014
Iteration 39: train_loss 1.139133095741272
Iteration 40: train_loss 1.0836944580078125
Iteration 41: train_loss 1.0697658061981201
Iteration 42: train_loss 1.1215957403182983
Iteration 43: train_loss 1.0848454236984253
Iteration 44: train_loss 1.114956021308899
Iteration 45: train_loss 1.0978463888168335
Iteration 46: train_loss 1.0702052116394043
Iteration 47: train_loss 1.127264142036438
Iteration 48: train_loss 1.0944409370422363
Iteration 49: train_loss 1.0832698345184326
Iteration 50: train_loss 1.118492603302002
Iteration 51: train_loss 1.1063839197158813
Iteration 52: train_loss 1.1285194158554077
Iteration 53: train_loss 1.0928339958190918
Iteration 54: train_loss 1.1183645725250244
Iteration 55: train_loss 1.0932891368865967
Iteration 56: train_loss 1.0836937427520752
Iteration 57: train_loss 1.1440454721450806
Iteration 58: train_loss 1.1057251691818237
Iteration 59: train_loss 1.0807756185531616
Iteration 60: train_loss 1.0951659679412842
Iteration 61: train_loss 1.1148406267166138
Iteration 62: train_loss 1.1232620477676392
Iteration 63: train_loss 1.1328620910644531
Iteration 64: train_loss 1.05869460105896
Iteration 65: train_loss 1.1165446043014526
Iteration 66: train_loss 1.1093767881393433
Iteration 67: train_loss 1.1077148914337158
Iteration 68: train_loss 1.0773805379867554
Iteration 69: train_loss 1.13582444190979
Iteration 70: train_loss 1.1394004821777344
Iteration 71: train_loss 1.1253944635391235
Iteration 72: train_loss 1.1489338874816895
Iteration 73: train_loss 1.129949688911438
Iteration 74: train_loss 1.0917869806289673
Iteration 75: train_loss 1.121206521987915
Iteration 76: train_loss 1.092220664024353
Iteration 77: train_loss 1.098660945892334
Iteration 78: train_loss 1.0823581218719482
Iteration 79: train_loss 1.07514488697052
Iteration 80: train_loss 1.1232868432998657
Iteration 81: train_loss 1.0877046585083008
Iteration 82: train_loss 1.1632628440856934
Iteration 83: train_loss 1.1658544540405273
Iteration 84: train_loss 1.0419925451278687
Iteration 85: train_loss 1.1234686374664307
Iteration 86: train_loss 1.1455870866775513
Iteration 87: train_loss 1.0981053113937378
Iteration 88: train_loss 1.1108016967773438
Iteration 89: train_loss 1.1239681243896484
Iteration 90: train_loss 1.121936559677124
Iteration 91: train_loss 1.0801239013671875
Iteration 92: train_loss 1.0810645818710327
Iteration 93: train_loss 1.0930124521255493
Iteration 94: train_loss 1.0922194719314575
Iteration 95: train_loss 1.1038504838943481
Iteration 96: train_loss 1.1271318197250366
Iteration 97: train_loss 1.1306244134902954
Iteration 98: train_loss 1.1713354587554932
Iteration 99: train_loss 1.1128954887390137
Iteration 100: train_loss 1.0587247610092163
Iteration 101: train_loss 1.0625191926956177
Iteration 102: train_loss 1.1272395849227905
Iteration 103: train_loss 1.123458981513977
Iteration 104: train_loss 1.14191472530365
Iteration 105: train_loss 1.1118276119232178
Iteration 106: train_loss 1.1305781602859497
Iteration 107: train_loss 1.0896986722946167
Iteration 108: train_loss 1.121835470199585
Iteration 109: train_loss 1.0958198308944702
Iteration 110: train_loss 1.0860251188278198
Iteration 111: train_loss 1.0911362171173096
Iteration 112: train_loss 1.1230334043502808
Iteration 113: train_loss 1.1099326610565186
Iteration 114: train_loss 1.0913997888565063
Iteration 115: train_loss 1.15837562084198
Iteration 116: train_loss 1.093532919883728
Iteration 117: train_loss 1.070711374282837
Iteration 118: train_loss 1.095513939857483
Iteration 119: train_loss 1.109351634979248
Iteration 120: train_loss 1.098795771598816
Iteration 121: train_loss 1.094425082206726
Iteration 122: train_loss 1.0747133493423462
Iteration 123: train_loss 1.0758339166641235
Iteration 124: train_loss 1.1185989379882812
Iteration 125: train_loss 1.1520864963531494
Iteration 126: train_loss 1.0524135828018188
Iteration 127: train_loss 1.0953766107559204
Iteration 128: train_loss 1.1710835695266724
Iteration 129: train_loss 1.069325566291809
Iteration 130: train_loss 1.0607022047042847
Iteration 131: train_loss 1.1417152881622314
Iteration 132: train_loss 1.1743249893188477
Iteration 133: train_loss 1.1825047731399536
Iteration 134: train_loss 1.1216977834701538
Iteration 135: train_loss 1.1093039512634277
Iteration 136: train_loss 1.1186054944992065
Iteration 137: train_loss 1.1601216793060303
Iteration 138: train_loss 1.1340229511260986
Iteration 139: train_loss 1.0965111255645752
Iteration 140: train_loss 1.0843634605407715
Iteration 141: train_loss 1.1190844774246216
Iteration 142: train_loss 1.0727211236953735
Iteration 143: train_loss 1.1465543508529663
Iteration 144: train_loss 1.108673334121704
Iteration 145: train_loss 1.0755504369735718
Iteration 146: train_loss 1.1038440465927124
Iteration 147: train_loss 1.102512001991272
Iteration 148: train_loss 1.1480281352996826
Iteration 149: train_loss 1.1339075565338135
Iteration 150: train_loss 1.1113266944885254
Iteration 151: train_loss 1.107242226600647
Iteration 152: train_loss 1.1436970233917236
Iteration 153: train_loss 1.1008260250091553
Iteration 154: train_loss 1.0753668546676636
Iteration 155: train_loss 1.045914649963379
Iteration 156: train_loss 1.100079894065857
Iteration 157: train_loss 1.1086256504058838
Iteration 158: train_loss 1.0912294387817383
Iteration 159: train_loss 1.1000415086746216
Iteration 160: train_loss 1.1047067642211914
Iteration 161: train_loss 1.1331818103790283
Iteration 162: train_loss 1.123100996017456
Iteration 163: train_loss 1.1277947425842285
Iteration 164: train_loss 1.1376473903656006
Iteration 165: train_loss 1.0965816974639893
Iteration 166: train_loss 1.1027190685272217
Iteration 167: train_loss 1.1430332660675049
Iteration 168: train_loss 1.166490077972412
Iteration 169: train_loss 1.1121927499771118
Iteration 170: train_loss 1.1359285116195679
Iteration 171: train_loss 1.1505342721939087
Iteration 172: train_loss 1.124610424041748
Iteration 173: train_loss 1.1212748289108276
Iteration 174: train_loss 1.1166414022445679
Iteration 175: train_loss 1.131793737411499
Iteration 176: train_loss 1.1290711164474487
Iteration 177: train_loss 1.1463255882263184
Epoch 198: train_avg_loss 1.112217818276357 eval_avg_acc: 0.34430689078553145 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 04:01:45] [32mIntermediate result: 0.34430689078553145  (Index 197)[0m
================Epoch: 199================
Iteration 1: train_loss 1.143804907798767
Iteration 2: train_loss 1.1588256359100342
Iteration 3: train_loss 1.1125965118408203
Iteration 4: train_loss 1.1194511651992798
Iteration 5: train_loss 1.1257697343826294
Iteration 6: train_loss 1.0663565397262573
Iteration 7: train_loss 1.1149383783340454
Iteration 8: train_loss 1.0559855699539185
Iteration 9: train_loss 1.1309027671813965
Iteration 10: train_loss 1.0756292343139648
Iteration 11: train_loss 1.0812137126922607
Iteration 12: train_loss 1.1110382080078125
Iteration 13: train_loss 1.1383229494094849
Iteration 14: train_loss 1.1305745840072632
Iteration 15: train_loss 1.075031042098999
Iteration 16: train_loss 1.0780739784240723
Iteration 17: train_loss 1.0801284313201904
Iteration 18: train_loss 1.1068592071533203
Iteration 19: train_loss 1.1271417140960693
Iteration 20: train_loss 1.0923471450805664
Iteration 21: train_loss 1.1015526056289673
Iteration 22: train_loss 1.0987662076950073
Iteration 23: train_loss 1.0926357507705688
Iteration 24: train_loss 1.066088318824768
Iteration 25: train_loss 1.1453322172164917
Iteration 26: train_loss 1.1229053735733032
Iteration 27: train_loss 1.113553762435913
Iteration 28: train_loss 1.1298699378967285
Iteration 29: train_loss 1.1235936880111694
Iteration 30: train_loss 1.1481448411941528
Iteration 31: train_loss 1.117493987083435
Iteration 32: train_loss 1.0618647336959839
Iteration 33: train_loss 1.0900897979736328
Iteration 34: train_loss 1.0980041027069092
Iteration 35: train_loss 1.0634956359863281
Iteration 36: train_loss 1.0902279615402222
Iteration 37: train_loss 1.1099107265472412
Iteration 38: train_loss 1.1139843463897705
Iteration 39: train_loss 1.1165863275527954
Iteration 40: train_loss 1.0659083127975464
Iteration 41: train_loss 1.1151702404022217
Iteration 42: train_loss 1.0466663837432861
Iteration 43: train_loss 1.1026703119277954
Iteration 44: train_loss 1.1265132427215576
Iteration 45: train_loss 1.1172153949737549
Iteration 46: train_loss 1.0844635963439941
Iteration 47: train_loss 1.0802147388458252
Iteration 48: train_loss 1.0556389093399048
Iteration 49: train_loss 1.1072181463241577
Iteration 50: train_loss 1.0621304512023926
Iteration 51: train_loss 1.0789750814437866
Iteration 52: train_loss 1.0960559844970703
Iteration 53: train_loss 1.1397435665130615
Iteration 54: train_loss 1.1373300552368164
Iteration 55: train_loss 1.0770833492279053
Iteration 56: train_loss 1.0943902730941772
Iteration 57: train_loss 1.1598106622695923
Iteration 58: train_loss 1.115148663520813
Iteration 59: train_loss 1.1227242946624756
Iteration 60: train_loss 1.089066743850708
Iteration 61: train_loss 1.0930103063583374
Iteration 62: train_loss 1.102412223815918
Iteration 63: train_loss 1.054646372795105
Iteration 64: train_loss 1.059843897819519
Iteration 65: train_loss 1.1297990083694458
Iteration 66: train_loss 1.1236522197723389
Iteration 67: train_loss 1.0706099271774292
Iteration 68: train_loss 1.09673011302948
Iteration 69: train_loss 1.0695351362228394
Iteration 70: train_loss 1.0902444124221802
Iteration 71: train_loss 1.0799022912979126
Iteration 72: train_loss 1.062321662902832
Iteration 73: train_loss 1.1209689378738403
Iteration 74: train_loss 1.073894739151001
Iteration 75: train_loss 1.1071314811706543
Iteration 76: train_loss 1.0769846439361572
Iteration 77: train_loss 1.1152398586273193
Iteration 78: train_loss 1.0688042640686035
Iteration 79: train_loss 1.1130824089050293
Iteration 80: train_loss 1.0420410633087158
Iteration 81: train_loss 1.085197925567627
Iteration 82: train_loss 1.106646180152893
Iteration 83: train_loss 1.110931396484375
Iteration 84: train_loss 1.0799009799957275
Iteration 85: train_loss 1.0961753129959106
Iteration 86: train_loss 1.072847843170166
Iteration 87: train_loss 1.102630615234375
Iteration 88: train_loss 1.0955647230148315
Iteration 89: train_loss 1.0444793701171875
Iteration 90: train_loss 1.0926274061203003
Iteration 91: train_loss 1.1252285242080688
Iteration 92: train_loss 1.1310222148895264
Iteration 93: train_loss 1.134376049041748
Iteration 94: train_loss 1.107217788696289
Iteration 95: train_loss 1.1093686819076538
Iteration 96: train_loss 1.1128885746002197
Iteration 97: train_loss 1.1210083961486816
Iteration 98: train_loss 1.123871088027954
Iteration 99: train_loss 1.138638973236084
Iteration 100: train_loss 1.0444015264511108
Iteration 101: train_loss 1.0798001289367676
Iteration 102: train_loss 1.0967316627502441
Iteration 103: train_loss 1.0961939096450806
Iteration 104: train_loss 1.0899819135665894
Iteration 105: train_loss 1.1123384237289429
Iteration 106: train_loss 1.1089942455291748
Iteration 107: train_loss 1.0374361276626587
Iteration 108: train_loss 1.0964183807373047
Iteration 109: train_loss 1.0769819021224976
Iteration 110: train_loss 1.075059175491333
Iteration 111: train_loss 1.1224490404129028
Iteration 112: train_loss 1.0661091804504395
Iteration 113: train_loss 1.1099988222122192
Iteration 114: train_loss 1.1341487169265747
Iteration 115: train_loss 1.083640217781067
Iteration 116: train_loss 1.090010643005371
Iteration 117: train_loss 1.047214388847351
Iteration 118: train_loss 1.0936380624771118
Iteration 119: train_loss 1.1307227611541748
Iteration 120: train_loss 1.1063673496246338
Iteration 121: train_loss 1.127079963684082
Iteration 122: train_loss 1.04962158203125
Iteration 123: train_loss 1.0998094081878662
Iteration 124: train_loss 1.0786471366882324
Iteration 125: train_loss 1.1142901182174683
Iteration 126: train_loss 1.1165608167648315
Iteration 127: train_loss 1.1176936626434326
Iteration 128: train_loss 1.1498960256576538
Iteration 129: train_loss 1.0669960975646973
Iteration 130: train_loss 1.0331014394760132
Iteration 131: train_loss 1.128221035003662
Iteration 132: train_loss 1.1301366090774536
Iteration 133: train_loss 1.2028001546859741
Iteration 134: train_loss 1.1184501647949219
Iteration 135: train_loss 1.1623544692993164
Iteration 136: train_loss 1.1284475326538086
Iteration 137: train_loss 1.138893485069275
Iteration 138: train_loss 1.1473348140716553
Iteration 139: train_loss 1.1436963081359863
Iteration 140: train_loss 1.1241203546524048
Iteration 141: train_loss 1.0873405933380127
Iteration 142: train_loss 1.1804938316345215
Iteration 143: train_loss 1.1738063097000122
Iteration 144: train_loss 1.1841404438018799
Iteration 145: train_loss 1.1058813333511353
Iteration 146: train_loss 1.1530429124832153
Iteration 147: train_loss 1.1549890041351318
Iteration 148: train_loss 1.187151312828064
Iteration 149: train_loss 1.1302719116210938
Iteration 150: train_loss 1.1767452955245972
Iteration 151: train_loss 1.1205207109451294
Iteration 152: train_loss 1.1250159740447998
Iteration 153: train_loss 1.1927111148834229
Iteration 154: train_loss 1.116220235824585
Iteration 155: train_loss 1.067623496055603
Iteration 156: train_loss 1.1420271396636963
Iteration 157: train_loss 1.1292660236358643
Iteration 158: train_loss 1.164415955543518
Iteration 159: train_loss 1.1130828857421875
Iteration 160: train_loss 1.1259478330612183
Iteration 161: train_loss 1.1082903146743774
Iteration 162: train_loss 1.119997501373291
Iteration 163: train_loss 1.1019725799560547
Iteration 164: train_loss 1.084768295288086
Iteration 165: train_loss 1.1124475002288818
Iteration 166: train_loss 1.1332786083221436
Iteration 167: train_loss 1.1555259227752686
Iteration 168: train_loss 1.1054774522781372
Iteration 169: train_loss 1.1246925592422485
Iteration 170: train_loss 1.1251788139343262
Iteration 171: train_loss 1.1443485021591187
Iteration 172: train_loss 1.0810006856918335
Iteration 173: train_loss 1.173386573791504
Iteration 174: train_loss 1.1463323831558228
Iteration 175: train_loss 1.1130489110946655
Iteration 176: train_loss 1.0996586084365845
Iteration 177: train_loss 1.1419305801391602
Epoch 199: train_avg_loss 1.1080425142568384 eval_avg_acc: 0.33258236648137274 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 04:02:26] [32mIntermediate result: 0.33258236648137274  (Index 198)[0m
================Epoch: 200================
Iteration 1: train_loss 1.1444650888442993
Iteration 2: train_loss 1.0897314548492432
Iteration 3: train_loss 1.1143550872802734
Iteration 4: train_loss 1.1334121227264404
Iteration 5: train_loss 1.1655011177062988
Iteration 6: train_loss 1.0914762020111084
Iteration 7: train_loss 1.0889148712158203
Iteration 8: train_loss 1.0853867530822754
Iteration 9: train_loss 1.1386868953704834
Iteration 10: train_loss 1.0951435565948486
Iteration 11: train_loss 1.0955281257629395
Iteration 12: train_loss 1.1359336376190186
Iteration 13: train_loss 1.102088451385498
Iteration 14: train_loss 1.1226840019226074
Iteration 15: train_loss 1.0957307815551758
Iteration 16: train_loss 1.0812931060791016
Iteration 17: train_loss 1.0786093473434448
Iteration 18: train_loss 1.1717605590820312
Iteration 19: train_loss 1.1142945289611816
Iteration 20: train_loss 1.1961443424224854
Iteration 21: train_loss 1.0931458473205566
Iteration 22: train_loss 1.1707091331481934
Iteration 23: train_loss 1.1863213777542114
Iteration 24: train_loss 1.0919488668441772
Iteration 25: train_loss 1.106855869293213
Iteration 26: train_loss 1.129144310951233
Iteration 27: train_loss 1.1448661088943481
Iteration 28: train_loss 1.1436326503753662
Iteration 29: train_loss 1.0900986194610596
Iteration 30: train_loss 1.2021174430847168
Iteration 31: train_loss 1.1313796043395996
Iteration 32: train_loss 1.1740851402282715
Iteration 33: train_loss 1.1711201667785645
Iteration 34: train_loss 1.066651463508606
Iteration 35: train_loss 1.1408461332321167
Iteration 36: train_loss 1.0899535417556763
Iteration 37: train_loss 1.1708518266677856
Iteration 38: train_loss 1.084341287612915
Iteration 39: train_loss 1.1987169981002808
Iteration 40: train_loss 1.1258792877197266
Iteration 41: train_loss 1.1150864362716675
Iteration 42: train_loss 1.1215468645095825
Iteration 43: train_loss 1.073540210723877
Iteration 44: train_loss 1.1013895273208618
Iteration 45: train_loss 1.0867983102798462
Iteration 46: train_loss 1.1542123556137085
Iteration 47: train_loss 1.1183207035064697
Iteration 48: train_loss 1.140480399131775
Iteration 49: train_loss 1.114060878753662
Iteration 50: train_loss 1.1413366794586182
Iteration 51: train_loss 1.081170916557312
Iteration 52: train_loss 1.1185044050216675
Iteration 53: train_loss 1.0567383766174316
Iteration 54: train_loss 1.1402227878570557
Iteration 55: train_loss 1.0699183940887451
Iteration 56: train_loss 1.0691673755645752
Iteration 57: train_loss 1.0570968389511108
Iteration 58: train_loss 1.0882600545883179
Iteration 59: train_loss 1.132006049156189
Iteration 60: train_loss 1.0807851552963257
Iteration 61: train_loss 1.1156485080718994
Iteration 62: train_loss 1.0748538970947266
Iteration 63: train_loss 1.0686146020889282
Iteration 64: train_loss 1.142565131187439
Iteration 65: train_loss 1.1311215162277222
Iteration 66: train_loss 1.0985227823257446
Iteration 67: train_loss 1.0910563468933105
Iteration 68: train_loss 1.0801124572753906
Iteration 69: train_loss 1.1713271141052246
Iteration 70: train_loss 1.1152938604354858
Iteration 71: train_loss 1.1407904624938965
Iteration 72: train_loss 1.167144775390625
Iteration 73: train_loss 1.148939609527588
Iteration 74: train_loss 1.1143959760665894
Iteration 75: train_loss 1.1467301845550537
Iteration 76: train_loss 1.0856741666793823
Iteration 77: train_loss 1.0892152786254883
Iteration 78: train_loss 1.133660912513733
Iteration 79: train_loss 1.1066581010818481
Iteration 80: train_loss 1.124674916267395
Iteration 81: train_loss 1.1119972467422485
Iteration 82: train_loss 1.1184707880020142
Iteration 83: train_loss 1.139225959777832
Iteration 84: train_loss 1.1272201538085938
Iteration 85: train_loss 1.1335498094558716
Iteration 86: train_loss 1.1118220090866089
Iteration 87: train_loss 1.086442232131958
Iteration 88: train_loss 1.1125677824020386
Iteration 89: train_loss 1.0999176502227783
Iteration 90: train_loss 1.0846548080444336
Iteration 91: train_loss 1.0792288780212402
Iteration 92: train_loss 1.0972272157669067
Iteration 93: train_loss 1.091639518737793
Iteration 94: train_loss 1.0474292039871216
Iteration 95: train_loss 1.0427284240722656
Iteration 96: train_loss 1.0513482093811035
Iteration 97: train_loss 1.062476634979248
Iteration 98: train_loss 1.0952943563461304
Iteration 99: train_loss 1.0143669843673706
Iteration 100: train_loss 1.1201257705688477
Iteration 101: train_loss 1.0893442630767822
Iteration 102: train_loss 1.0551484823226929
Iteration 103: train_loss 1.0904593467712402
Iteration 104: train_loss 1.075508713722229
Iteration 105: train_loss 1.1193093061447144
Iteration 106: train_loss 1.098998785018921
Iteration 107: train_loss 1.1252213716506958
Iteration 108: train_loss 1.1461151838302612
Iteration 109: train_loss 1.12290358543396
Iteration 110: train_loss 1.1323926448822021
Iteration 111: train_loss 1.0927865505218506
Iteration 112: train_loss 1.1156396865844727
Iteration 113: train_loss 1.1407684087753296
Iteration 114: train_loss 1.1093858480453491
Iteration 115: train_loss 1.14481782913208
Iteration 116: train_loss 1.113422155380249
Iteration 117: train_loss 1.0980318784713745
Iteration 118: train_loss 1.1237958669662476
Iteration 119: train_loss 1.0610581636428833
Iteration 120: train_loss 1.1046035289764404
Iteration 121: train_loss 1.1232178211212158
Iteration 122: train_loss 1.109401822090149
Iteration 123: train_loss 1.1477690935134888
Iteration 124: train_loss 1.1607531309127808
Iteration 125: train_loss 1.147854208946228
Iteration 126: train_loss 1.191206693649292
Iteration 127: train_loss 1.168441891670227
Iteration 128: train_loss 1.125586986541748
Iteration 129: train_loss 1.1439164876937866
Iteration 130: train_loss 1.0993833541870117
Iteration 131: train_loss 1.1380757093429565
Iteration 132: train_loss 1.1857945919036865
Iteration 133: train_loss 1.1232891082763672
Iteration 134: train_loss 1.1574689149856567
Iteration 135: train_loss 1.112500786781311
Iteration 136: train_loss 1.0727338790893555
Iteration 137: train_loss 1.135308027267456
Iteration 138: train_loss 1.123822808265686
Iteration 139: train_loss 1.069049596786499
Iteration 140: train_loss 1.0572428703308105
Iteration 141: train_loss 1.1066030263900757
Iteration 142: train_loss 1.1084798574447632
Iteration 143: train_loss 1.0992642641067505
Iteration 144: train_loss 1.086562991142273
Iteration 145: train_loss 1.073832631111145
Iteration 146: train_loss 1.1153367757797241
Iteration 147: train_loss 1.0933804512023926
Iteration 148: train_loss 1.1282224655151367
Iteration 149: train_loss 1.1358251571655273
Iteration 150: train_loss 1.0741798877716064
Iteration 151: train_loss 1.1019322872161865
Iteration 152: train_loss 1.1590349674224854
Iteration 153: train_loss 1.075255274772644
Iteration 154: train_loss 1.1429725885391235
Iteration 155: train_loss 1.1596657037734985
Iteration 156: train_loss 1.116453766822815
Iteration 157: train_loss 1.1500258445739746
Iteration 158: train_loss 1.097462773323059
Iteration 159: train_loss 1.1071202754974365
Iteration 160: train_loss 1.0951470136642456
Iteration 161: train_loss 1.1478573083877563
Iteration 162: train_loss 1.136269450187683
Iteration 163: train_loss 1.1755151748657227
Iteration 164: train_loss 1.1456230878829956
Iteration 165: train_loss 1.171995997428894
Iteration 166: train_loss 1.1373358964920044
Iteration 167: train_loss 1.1387406587600708
Iteration 168: train_loss 1.1706329584121704
Iteration 169: train_loss 1.2204514741897583
Iteration 170: train_loss 1.159813404083252
Iteration 171: train_loss 1.1305216550827026
Iteration 172: train_loss 1.161810278892517
Iteration 173: train_loss 1.1422736644744873
Iteration 174: train_loss 1.147062063217163
Iteration 175: train_loss 1.167793869972229
Iteration 176: train_loss 1.156348466873169
Iteration 177: train_loss 1.1987226009368896
Epoch 200: train_avg_loss 1.118515469260135 eval_avg_acc: 0.34014657214857236 eval_avg_r 0.0 eval_avg_p 0.0
[2022-10-12 04:03:07] [32mIntermediate result: 0.34014657214857236  (Index 199)[0m
trainset: acc(0.5600598937692247)
[2022-10-12 04:03:27] [32mFinal result: 0.35257037222037996[0m
testset: acc(0.35257037222037996) recall(0.0) precision(0.0)
